{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92349e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# print(torch.cuda.is_available())\n",
    "# print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c026e5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "Training with ent_coef=0.0\n",
      "Using cuda device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.3e+03   |\n",
      "|    ep_rew_mean     | -3.13e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 657       |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 3         |\n",
      "|    total_timesteps | 2304      |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.3e+03      |\n",
      "|    ep_rew_mean          | -2.06e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 658          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 6            |\n",
      "|    total_timesteps      | 4608         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075111436 |\n",
      "|    clip_fraction        | 0.118        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.772       |\n",
      "|    explained_variance   | 0.000462     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.66e+03     |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0168      |\n",
      "|    value_loss           | 3.27e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.3e+03     |\n",
      "|    ep_rew_mean          | -630        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 668         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 6912        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009472138 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.755      |\n",
      "|    explained_variance   | 0.00573     |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.36e+03    |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    value_loss           | 2.45e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.3e+03     |\n",
      "|    ep_rew_mean          | 416         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 676         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 9216        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013196224 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.745      |\n",
      "|    explained_variance   | 0.0104      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 550         |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    value_loss           | 1.24e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.3e+03    |\n",
      "|    ep_rew_mean          | 1.45e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 676        |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 11520      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01072788 |\n",
      "|    clip_fraction        | 0.12       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.716     |\n",
      "|    explained_variance   | 0.0281     |\n",
      "|    learning_rate        | 0.003      |\n",
      "|    loss                 | 525        |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.0107    |\n",
      "|    value_loss           | 1.43e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.26e+03    |\n",
      "|    ep_rew_mean          | 2.03e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 680         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 13824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011963474 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.678      |\n",
      "|    explained_variance   | 0.0696      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 275         |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    value_loss           | 1.13e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.12e+03    |\n",
      "|    ep_rew_mean          | 2.32e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 683         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 23          |\n",
      "|    total_timesteps      | 16128       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012395945 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.637      |\n",
      "|    explained_variance   | 0.0108      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 292         |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    value_loss           | 1.09e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.97e+03    |\n",
      "|    ep_rew_mean          | 2.9e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 687         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010960695 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.588      |\n",
      "|    explained_variance   | 0.00982     |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 507         |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00885    |\n",
      "|    value_loss           | 1.54e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.81e+03    |\n",
      "|    ep_rew_mean          | 3.18e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 689         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 20736       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011906524 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.554      |\n",
      "|    explained_variance   | 0.00207     |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 407         |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00972    |\n",
      "|    value_loss           | 1.52e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.6e+03     |\n",
      "|    ep_rew_mean          | 3.31e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 691         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 33          |\n",
      "|    total_timesteps      | 23040       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020401139 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.465      |\n",
      "|    explained_variance   | 0.000779    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 467         |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    value_loss           | 1.58e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.47e+03    |\n",
      "|    ep_rew_mean          | 3.45e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 693         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 25344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019991428 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.407      |\n",
      "|    explained_variance   | 5.8e-05     |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 582         |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00488    |\n",
      "|    value_loss           | 1.84e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.36e+03    |\n",
      "|    ep_rew_mean          | 3.47e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 694         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 27648       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021807354 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.348      |\n",
      "|    explained_variance   | 5.92e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 624         |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00762    |\n",
      "|    value_loss           | 2.01e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.25e+03   |\n",
      "|    ep_rew_mean          | 3.49e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 696        |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 43         |\n",
      "|    total_timesteps      | 29952      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01297833 |\n",
      "|    clip_fraction        | 0.085      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.29      |\n",
      "|    explained_variance   | 4.4e-05    |\n",
      "|    learning_rate        | 0.003      |\n",
      "|    loss                 | 625        |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.00369   |\n",
      "|    value_loss           | 1.99e+03   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.18e+03     |\n",
      "|    ep_rew_mean          | 3.48e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 695          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 46           |\n",
      "|    total_timesteps      | 32256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064957105 |\n",
      "|    clip_fraction        | 0.0716       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.27        |\n",
      "|    explained_variance   | 2.56e-05     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 549          |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.000702    |\n",
      "|    value_loss           | 1.74e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.13e+03    |\n",
      "|    ep_rew_mean          | 3.45e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 696         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 49          |\n",
      "|    total_timesteps      | 34560       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018043661 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.241      |\n",
      "|    explained_variance   | 3.12e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 497         |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | 0.00824     |\n",
      "|    value_loss           | 1.57e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.08e+03    |\n",
      "|    ep_rew_mean          | 3.42e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 698         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008649301 |\n",
      "|    clip_fraction        | 0.0514      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.206      |\n",
      "|    explained_variance   | 3.17e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 223         |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | 0.000875    |\n",
      "|    value_loss           | 938         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.05e+03    |\n",
      "|    ep_rew_mean          | 3.46e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 699         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 55          |\n",
      "|    total_timesteps      | 39168       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015304345 |\n",
      "|    clip_fraction        | 0.0664      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.167      |\n",
      "|    explained_variance   | 2.13e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 369         |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | 0.0023      |\n",
      "|    value_loss           | 1.22e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.02e+03    |\n",
      "|    ep_rew_mean          | 3.49e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 700         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 59          |\n",
      "|    total_timesteps      | 41472       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004869917 |\n",
      "|    clip_fraction        | 0.0469      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.151      |\n",
      "|    explained_variance   | 2.21e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 523         |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.00194    |\n",
      "|    value_loss           | 1.26e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 973         |\n",
      "|    ep_rew_mean          | 3.42e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 701         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 62          |\n",
      "|    total_timesteps      | 43776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028500045 |\n",
      "|    clip_fraction        | 0.0592      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.154      |\n",
      "|    explained_variance   | 1.91e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 289         |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00127    |\n",
      "|    value_loss           | 1.06e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 990        |\n",
      "|    ep_rew_mean          | 3.49e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 701        |\n",
      "|    iterations           | 20         |\n",
      "|    time_elapsed         | 65         |\n",
      "|    total_timesteps      | 46080      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.47137326 |\n",
      "|    clip_fraction        | 0.115      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0933    |\n",
      "|    explained_variance   | 1.51e-05   |\n",
      "|    learning_rate        | 0.003      |\n",
      "|    loss                 | 591        |\n",
      "|    n_updates            | 190        |\n",
      "|    policy_gradient_loss | 0.0273     |\n",
      "|    value_loss           | 1.41e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 3.55e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 701         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 68          |\n",
      "|    total_timesteps      | 48384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005999147 |\n",
      "|    clip_fraction        | 0.07        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.11       |\n",
      "|    explained_variance   | 0.0628      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 240         |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00514    |\n",
      "|    value_loss           | 450         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 3.58e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 702        |\n",
      "|    iterations           | 22         |\n",
      "|    time_elapsed         | 72         |\n",
      "|    total_timesteps      | 50688      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01059939 |\n",
      "|    clip_fraction        | 0.0697     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.127     |\n",
      "|    explained_variance   | 0.0826     |\n",
      "|    learning_rate        | 0.003      |\n",
      "|    loss                 | 252        |\n",
      "|    n_updates            | 210        |\n",
      "|    policy_gradient_loss | -0.00277   |\n",
      "|    value_loss           | 590        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 988        |\n",
      "|    ep_rew_mean          | 3.58e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 702        |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 75         |\n",
      "|    total_timesteps      | 52992      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02350305 |\n",
      "|    clip_fraction        | 0.128      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.164     |\n",
      "|    explained_variance   | 0.109      |\n",
      "|    learning_rate        | 0.003      |\n",
      "|    loss                 | 366        |\n",
      "|    n_updates            | 220        |\n",
      "|    policy_gradient_loss | -0.00112   |\n",
      "|    value_loss           | 614        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 963          |\n",
      "|    ep_rew_mean          | 3.54e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 702          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 78           |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025241382 |\n",
      "|    clip_fraction        | 0.0476       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.17        |\n",
      "|    explained_variance   | 0.0643       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 548          |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.00217     |\n",
      "|    value_loss           | 956          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 929          |\n",
      "|    ep_rew_mean          | 3.48e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 703          |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 81           |\n",
      "|    total_timesteps      | 57600        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038216398 |\n",
      "|    clip_fraction        | 0.0508       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.167       |\n",
      "|    explained_variance   | 0.0605       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 748          |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | 0.000501     |\n",
      "|    value_loss           | 1.34e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 929        |\n",
      "|    ep_rew_mean          | 3.5e+03    |\n",
      "| time/                   |            |\n",
      "|    fps                  | 703        |\n",
      "|    iterations           | 26         |\n",
      "|    time_elapsed         | 85         |\n",
      "|    total_timesteps      | 59904      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07723229 |\n",
      "|    clip_fraction        | 0.0712     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.15      |\n",
      "|    explained_variance   | 0.052      |\n",
      "|    learning_rate        | 0.003      |\n",
      "|    loss                 | 764        |\n",
      "|    n_updates            | 250        |\n",
      "|    policy_gradient_loss | 0.00277    |\n",
      "|    value_loss           | 1.64e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 923         |\n",
      "|    ep_rew_mean          | 3.51e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 704         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 88          |\n",
      "|    total_timesteps      | 62208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009771629 |\n",
      "|    clip_fraction        | 0.0935      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.139      |\n",
      "|    explained_variance   | 0.081       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 276         |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.00185    |\n",
      "|    value_loss           | 826         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 916           |\n",
      "|    ep_rew_mean          | 3.52e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 704           |\n",
      "|    iterations           | 28            |\n",
      "|    time_elapsed         | 91            |\n",
      "|    total_timesteps      | 64512         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00033291982 |\n",
      "|    clip_fraction        | 0.113         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.159        |\n",
      "|    explained_variance   | 0.0632        |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 361           |\n",
      "|    n_updates            | 270           |\n",
      "|    policy_gradient_loss | 0.000782      |\n",
      "|    value_loss           | 1.08e+03      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 908         |\n",
      "|    ep_rew_mean          | 3.52e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 704         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 94          |\n",
      "|    total_timesteps      | 66816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007930592 |\n",
      "|    clip_fraction        | 0.054       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.13       |\n",
      "|    explained_variance   | 0.0498      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 361         |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.00117    |\n",
      "|    value_loss           | 1.11e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 894          |\n",
      "|    ep_rew_mean          | 3.51e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 705          |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 97           |\n",
      "|    total_timesteps      | 69120        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077707693 |\n",
      "|    clip_fraction        | 0.0505       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.124       |\n",
      "|    explained_variance   | 0.0623       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 504          |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | 0.00491      |\n",
      "|    value_loss           | 1.14e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 891         |\n",
      "|    ep_rew_mean          | 3.53e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 705         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 101         |\n",
      "|    total_timesteps      | 71424       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018698465 |\n",
      "|    clip_fraction        | 0.0308      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.107      |\n",
      "|    explained_variance   | 0.059       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 558         |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | 0.000405    |\n",
      "|    value_loss           | 1.43e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 891          |\n",
      "|    ep_rew_mean          | 3.56e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 705          |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 104          |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017242677 |\n",
      "|    clip_fraction        | 0.00629      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0921      |\n",
      "|    explained_variance   | 0.0784       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 465          |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.00078     |\n",
      "|    value_loss           | 1.11e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 873        |\n",
      "|    ep_rew_mean          | 3.52e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 705        |\n",
      "|    iterations           | 33         |\n",
      "|    time_elapsed         | 107        |\n",
      "|    total_timesteps      | 76032      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02076381 |\n",
      "|    clip_fraction        | 0.0219     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0831    |\n",
      "|    explained_variance   | 0.0786     |\n",
      "|    learning_rate        | 0.003      |\n",
      "|    loss                 | 338        |\n",
      "|    n_updates            | 320        |\n",
      "|    policy_gradient_loss | 0.000503   |\n",
      "|    value_loss           | 897        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 860         |\n",
      "|    ep_rew_mean          | 3.49e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 706         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 110         |\n",
      "|    total_timesteps      | 78336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004342678 |\n",
      "|    clip_fraction        | 0.0456      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.122      |\n",
      "|    explained_variance   | 0.0541      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.3e+03     |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.00207    |\n",
      "|    value_loss           | 2.49e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 853          |\n",
      "|    ep_rew_mean          | 3.49e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 706          |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 114          |\n",
      "|    total_timesteps      | 80640        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018394534 |\n",
      "|    clip_fraction        | 0.0164       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.123       |\n",
      "|    explained_variance   | 0.0709       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 834          |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.00197     |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 848         |\n",
      "|    ep_rew_mean          | 3.49e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 706         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 117         |\n",
      "|    total_timesteps      | 82944       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031623594 |\n",
      "|    clip_fraction        | 0.0626      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0826     |\n",
      "|    explained_variance   | 0.0961      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 589         |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | 0.00827     |\n",
      "|    value_loss           | 1.29e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 849          |\n",
      "|    ep_rew_mean          | 3.52e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 706          |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 120          |\n",
      "|    total_timesteps      | 85248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007812392 |\n",
      "|    clip_fraction        | 0.0131       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0613      |\n",
      "|    explained_variance   | 0.0732       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 564          |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.000355    |\n",
      "|    value_loss           | 1.31e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 802         |\n",
      "|    ep_rew_mean          | 3.66e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 707         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 123         |\n",
      "|    total_timesteps      | 87552       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010005524 |\n",
      "|    clip_fraction        | 0.0149      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0644     |\n",
      "|    explained_variance   | 0.0714      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 697         |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | 0.00133     |\n",
      "|    value_loss           | 1.3e+03     |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 757           |\n",
      "|    ep_rew_mean          | 3.63e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 707           |\n",
      "|    iterations           | 39            |\n",
      "|    time_elapsed         | 126           |\n",
      "|    total_timesteps      | 89856         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00028536352 |\n",
      "|    clip_fraction        | 0.0197        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0621       |\n",
      "|    explained_variance   | 0.0612        |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 455           |\n",
      "|    n_updates            | 380           |\n",
      "|    policy_gradient_loss | 0.00114       |\n",
      "|    value_loss           | 1.45e+03      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 742         |\n",
      "|    ep_rew_mean          | 3.62e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 707         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 130         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009698534 |\n",
      "|    clip_fraction        | 0.0156      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0681     |\n",
      "|    explained_variance   | 0.0471      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 653         |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | 0.000411    |\n",
      "|    value_loss           | 1.38e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 728         |\n",
      "|    ep_rew_mean          | 3.6e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 708         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 133         |\n",
      "|    total_timesteps      | 94464       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010479401 |\n",
      "|    clip_fraction        | 0.047       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.108      |\n",
      "|    explained_variance   | 0.0653      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 870         |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.00478    |\n",
      "|    value_loss           | 1.35e+03    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 723           |\n",
      "|    ep_rew_mean          | 3.59e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 709           |\n",
      "|    iterations           | 42            |\n",
      "|    time_elapsed         | 136           |\n",
      "|    total_timesteps      | 96768         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00042501354 |\n",
      "|    clip_fraction        | 0.0129        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.107        |\n",
      "|    explained_variance   | 0.0793        |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 386           |\n",
      "|    n_updates            | 410           |\n",
      "|    policy_gradient_loss | 0.000618      |\n",
      "|    value_loss           | 1.64e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 719           |\n",
      "|    ep_rew_mean          | 3.58e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 710           |\n",
      "|    iterations           | 43            |\n",
      "|    time_elapsed         | 139           |\n",
      "|    total_timesteps      | 99072         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00028961766 |\n",
      "|    clip_fraction        | 0.00926       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0929       |\n",
      "|    explained_variance   | 0.0909        |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 541           |\n",
      "|    n_updates            | 420           |\n",
      "|    policy_gradient_loss | -0.000474     |\n",
      "|    value_loss           | 1.4e+03       |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 720         |\n",
      "|    ep_rew_mean          | 3.58e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 709         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 142         |\n",
      "|    total_timesteps      | 101376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004304258 |\n",
      "|    clip_fraction        | 0.0103      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.085      |\n",
      "|    explained_variance   | 0.0809      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 492         |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | 0.000379    |\n",
      "|    value_loss           | 1.65e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 717         |\n",
      "|    ep_rew_mean          | 3.57e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 708         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 146         |\n",
      "|    total_timesteps      | 103680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020749032 |\n",
      "|    clip_fraction        | 0.0419      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.103      |\n",
      "|    explained_variance   | 0.0966      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 699         |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00241    |\n",
      "|    value_loss           | 1.37e+03    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 714           |\n",
      "|    ep_rew_mean          | 3.56e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 707           |\n",
      "|    iterations           | 46            |\n",
      "|    time_elapsed         | 149           |\n",
      "|    total_timesteps      | 105984        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00088889303 |\n",
      "|    clip_fraction        | 0.0118        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.101        |\n",
      "|    explained_variance   | 0.104         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.1e+03       |\n",
      "|    n_updates            | 450           |\n",
      "|    policy_gradient_loss | -0.000844     |\n",
      "|    value_loss           | 1.81e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 714          |\n",
      "|    ep_rew_mean          | 3.57e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 707          |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 153          |\n",
      "|    total_timesteps      | 108288       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009962491 |\n",
      "|    clip_fraction        | 0.02         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0956      |\n",
      "|    explained_variance   | 0.12         |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 865          |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.00152     |\n",
      "|    value_loss           | 2.29e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 713           |\n",
      "|    ep_rew_mean          | 3.57e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 707           |\n",
      "|    iterations           | 48            |\n",
      "|    time_elapsed         | 156           |\n",
      "|    total_timesteps      | 110592        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00079436006 |\n",
      "|    clip_fraction        | 0.00383       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0955       |\n",
      "|    explained_variance   | 0.143         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 736           |\n",
      "|    n_updates            | 470           |\n",
      "|    policy_gradient_loss | -0.000752     |\n",
      "|    value_loss           | 1.34e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 712           |\n",
      "|    ep_rew_mean          | 3.57e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 708           |\n",
      "|    iterations           | 49            |\n",
      "|    time_elapsed         | 159           |\n",
      "|    total_timesteps      | 112896        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00040942253 |\n",
      "|    clip_fraction        | 0.00496       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0842       |\n",
      "|    explained_variance   | 0.136         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 665           |\n",
      "|    n_updates            | 480           |\n",
      "|    policy_gradient_loss | -0.000964     |\n",
      "|    value_loss           | 1.31e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 716          |\n",
      "|    ep_rew_mean          | 3.59e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 708          |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 162          |\n",
      "|    total_timesteps      | 115200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005561807 |\n",
      "|    clip_fraction        | 0.00316      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0803      |\n",
      "|    explained_variance   | 0.127        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 419          |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.000955    |\n",
      "|    value_loss           | 1.59e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 702          |\n",
      "|    ep_rew_mean          | 3.57e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 708          |\n",
      "|    iterations           | 51           |\n",
      "|    time_elapsed         | 165          |\n",
      "|    total_timesteps      | 117504       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063139973 |\n",
      "|    clip_fraction        | 0.0252       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.102       |\n",
      "|    explained_variance   | 0.156        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 750          |\n",
      "|    n_updates            | 500          |\n",
      "|    policy_gradient_loss | -0.00279     |\n",
      "|    value_loss           | 1.04e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 685         |\n",
      "|    ep_rew_mean          | 3.52e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 708         |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 169         |\n",
      "|    total_timesteps      | 119808      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000786266 |\n",
      "|    clip_fraction        | 0.0146      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.111      |\n",
      "|    explained_variance   | 0.107       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.42e+03    |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | 0.000249    |\n",
      "|    value_loss           | 1.98e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 682          |\n",
      "|    ep_rew_mean          | 3.51e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 708          |\n",
      "|    iterations           | 53           |\n",
      "|    time_elapsed         | 172          |\n",
      "|    total_timesteps      | 122112       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008120071 |\n",
      "|    clip_fraction        | 0.0185       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.104       |\n",
      "|    explained_variance   | 0.11         |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.15e+03     |\n",
      "|    n_updates            | 520          |\n",
      "|    policy_gradient_loss | 0.000153     |\n",
      "|    value_loss           | 1.9e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 685          |\n",
      "|    ep_rew_mean          | 3.54e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 708          |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 175          |\n",
      "|    total_timesteps      | 124416       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012982923 |\n",
      "|    clip_fraction        | 0.0198       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0855      |\n",
      "|    explained_variance   | 0.101        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 810          |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | -0.00206     |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 692           |\n",
      "|    ep_rew_mean          | 3.59e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 708           |\n",
      "|    iterations           | 55            |\n",
      "|    time_elapsed         | 178           |\n",
      "|    total_timesteps      | 126720        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00052587705 |\n",
      "|    clip_fraction        | 0.00797       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0836       |\n",
      "|    explained_variance   | 0.146         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 588           |\n",
      "|    n_updates            | 540           |\n",
      "|    policy_gradient_loss | -0.00032      |\n",
      "|    value_loss           | 1.31e+03      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 680         |\n",
      "|    ep_rew_mean          | 3.53e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 709         |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 181         |\n",
      "|    total_timesteps      | 129024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012011315 |\n",
      "|    clip_fraction        | 0.0677      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.118      |\n",
      "|    explained_variance   | 0.144       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 705         |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.00406    |\n",
      "|    value_loss           | 1.4e+03     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 670          |\n",
      "|    ep_rew_mean          | 3.49e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 709          |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 185          |\n",
      "|    total_timesteps      | 131328       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010679013 |\n",
      "|    clip_fraction        | 0.0238       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.109       |\n",
      "|    explained_variance   | 0.121        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.38e+03     |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.00332     |\n",
      "|    value_loss           | 3.13e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 667         |\n",
      "|    ep_rew_mean          | 3.49e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 709         |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 188         |\n",
      "|    total_timesteps      | 133632      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001192482 |\n",
      "|    clip_fraction        | 0.0211      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.104      |\n",
      "|    explained_variance   | 0.134       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.09e+03    |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.00135    |\n",
      "|    value_loss           | 1.98e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 668          |\n",
      "|    ep_rew_mean          | 3.5e+03      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 709          |\n",
      "|    iterations           | 59           |\n",
      "|    time_elapsed         | 191          |\n",
      "|    total_timesteps      | 135936       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.556732e-05 |\n",
      "|    clip_fraction        | 0.00117      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.104       |\n",
      "|    explained_variance   | 0.161        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 554          |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | -0.000274    |\n",
      "|    value_loss           | 1.4e+03      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 659           |\n",
      "|    ep_rew_mean          | 3.45e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 709           |\n",
      "|    iterations           | 60            |\n",
      "|    time_elapsed         | 194           |\n",
      "|    total_timesteps      | 138240        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00086200156 |\n",
      "|    clip_fraction        | 0.00742       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0966       |\n",
      "|    explained_variance   | 0.14          |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.06e+03      |\n",
      "|    n_updates            | 590           |\n",
      "|    policy_gradient_loss | -0.000999     |\n",
      "|    value_loss           | 1.72e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 657          |\n",
      "|    ep_rew_mean          | 3.45e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 709          |\n",
      "|    iterations           | 61           |\n",
      "|    time_elapsed         | 198          |\n",
      "|    total_timesteps      | 140544       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006421893 |\n",
      "|    clip_fraction        | 0.00816      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0921      |\n",
      "|    explained_variance   | 0.16         |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 697          |\n",
      "|    n_updates            | 600          |\n",
      "|    policy_gradient_loss | -0.000667    |\n",
      "|    value_loss           | 1.83e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 661           |\n",
      "|    ep_rew_mean          | 3.48e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 709           |\n",
      "|    iterations           | 62            |\n",
      "|    time_elapsed         | 201           |\n",
      "|    total_timesteps      | 142848        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00021349182 |\n",
      "|    clip_fraction        | 0.0048        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0864       |\n",
      "|    explained_variance   | 0.159         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 519           |\n",
      "|    n_updates            | 610           |\n",
      "|    policy_gradient_loss | -3.34e-05     |\n",
      "|    value_loss           | 1.36e+03      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 661         |\n",
      "|    ep_rew_mean          | 3.48e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 709         |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 204         |\n",
      "|    total_timesteps      | 145152      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 7.56938e-05 |\n",
      "|    clip_fraction        | 0.000273    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.1        |\n",
      "|    explained_variance   | 0.169       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 622         |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | 4.91e-05    |\n",
      "|    value_loss           | 1.69e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 662         |\n",
      "|    ep_rew_mean          | 3.49e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 709         |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 207         |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005852595 |\n",
      "|    clip_fraction        | 0.0182      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0872     |\n",
      "|    explained_variance   | 0.189       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 807         |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | -0.000206   |\n",
      "|    value_loss           | 1.85e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 658          |\n",
      "|    ep_rew_mean          | 3.48e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 709          |\n",
      "|    iterations           | 65           |\n",
      "|    time_elapsed         | 211          |\n",
      "|    total_timesteps      | 149760       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002293691 |\n",
      "|    clip_fraction        | 0.0146       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0897      |\n",
      "|    explained_variance   | 0.205        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 783          |\n",
      "|    n_updates            | 640          |\n",
      "|    policy_gradient_loss | 0.000859     |\n",
      "|    value_loss           | 1.33e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 649          |\n",
      "|    ep_rew_mean          | 3.43e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 709          |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 214          |\n",
      "|    total_timesteps      | 152064       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058224685 |\n",
      "|    clip_fraction        | 0.0156       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0926      |\n",
      "|    explained_variance   | 0.187        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 534          |\n",
      "|    n_updates            | 650          |\n",
      "|    policy_gradient_loss | -0.0015      |\n",
      "|    value_loss           | 1.66e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 649         |\n",
      "|    ep_rew_mean          | 3.43e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 710         |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 217         |\n",
      "|    total_timesteps      | 154368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017204124 |\n",
      "|    clip_fraction        | 0.0568      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0762     |\n",
      "|    explained_variance   | 0.179       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 885         |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | 0.00291     |\n",
      "|    value_loss           | 2.26e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 648          |\n",
      "|    ep_rew_mean          | 3.43e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 710          |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 220          |\n",
      "|    total_timesteps      | 156672       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013011748 |\n",
      "|    clip_fraction        | 0.0103       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0705      |\n",
      "|    explained_variance   | 0.227        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 631          |\n",
      "|    n_updates            | 670          |\n",
      "|    policy_gradient_loss | 0.00075      |\n",
      "|    value_loss           | 1.31e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 651         |\n",
      "|    ep_rew_mean          | 3.44e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 710         |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 223         |\n",
      "|    total_timesteps      | 158976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 7.76835e-05 |\n",
      "|    clip_fraction        | 0.00555     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0625     |\n",
      "|    explained_variance   | 0.257       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 749         |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | 0.000273    |\n",
      "|    value_loss           | 1.22e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 655          |\n",
      "|    ep_rew_mean          | 3.46e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 710          |\n",
      "|    iterations           | 70           |\n",
      "|    time_elapsed         | 227          |\n",
      "|    total_timesteps      | 161280       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013950178 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.074       |\n",
      "|    explained_variance   | 0.191        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 654          |\n",
      "|    n_updates            | 690          |\n",
      "|    policy_gradient_loss | 0.000584     |\n",
      "|    value_loss           | 992          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 657          |\n",
      "|    ep_rew_mean          | 3.47e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 710          |\n",
      "|    iterations           | 71           |\n",
      "|    time_elapsed         | 230          |\n",
      "|    total_timesteps      | 163584       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001626964 |\n",
      "|    clip_fraction        | 0.00215      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0686      |\n",
      "|    explained_variance   | 0.114        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 574          |\n",
      "|    n_updates            | 700          |\n",
      "|    policy_gradient_loss | 0.000167     |\n",
      "|    value_loss           | 1.63e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 659          |\n",
      "|    ep_rew_mean          | 3.48e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 710          |\n",
      "|    iterations           | 72           |\n",
      "|    time_elapsed         | 233          |\n",
      "|    total_timesteps      | 165888       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010677509 |\n",
      "|    clip_fraction        | 0.00574      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0758      |\n",
      "|    explained_variance   | 0.254        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 437          |\n",
      "|    n_updates            | 710          |\n",
      "|    policy_gradient_loss | -0.000252    |\n",
      "|    value_loss           | 958          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 659          |\n",
      "|    ep_rew_mean          | 3.49e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 711          |\n",
      "|    iterations           | 73           |\n",
      "|    time_elapsed         | 236          |\n",
      "|    total_timesteps      | 168192       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006338286 |\n",
      "|    clip_fraction        | 0.00344      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0772      |\n",
      "|    explained_variance   | 0.189        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 737          |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | -0.000491    |\n",
      "|    value_loss           | 1.59e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 665          |\n",
      "|    ep_rew_mean          | 3.52e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 711          |\n",
      "|    iterations           | 74           |\n",
      "|    time_elapsed         | 239          |\n",
      "|    total_timesteps      | 170496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002610613 |\n",
      "|    clip_fraction        | 0.00145      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0722      |\n",
      "|    explained_variance   | 0.261        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 329          |\n",
      "|    n_updates            | 730          |\n",
      "|    policy_gradient_loss | -0.000266    |\n",
      "|    value_loss           | 1.34e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 669           |\n",
      "|    ep_rew_mean          | 3.54e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 711           |\n",
      "|    iterations           | 75            |\n",
      "|    time_elapsed         | 242           |\n",
      "|    total_timesteps      | 172800        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00041178678 |\n",
      "|    clip_fraction        | 0.00926       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0846       |\n",
      "|    explained_variance   | 0.247         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 556           |\n",
      "|    n_updates            | 740           |\n",
      "|    policy_gradient_loss | -3.99e-05     |\n",
      "|    value_loss           | 1.34e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 671          |\n",
      "|    ep_rew_mean          | 3.56e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 711          |\n",
      "|    iterations           | 76           |\n",
      "|    time_elapsed         | 245          |\n",
      "|    total_timesteps      | 175104       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008671377 |\n",
      "|    clip_fraction        | 0.0134       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0677      |\n",
      "|    explained_variance   | 0.248        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 483          |\n",
      "|    n_updates            | 750          |\n",
      "|    policy_gradient_loss | 0.00186      |\n",
      "|    value_loss           | 1.31e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 669           |\n",
      "|    ep_rew_mean          | 3.55e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 712           |\n",
      "|    iterations           | 77            |\n",
      "|    time_elapsed         | 249           |\n",
      "|    total_timesteps      | 177408        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00029663456 |\n",
      "|    clip_fraction        | 0.0122        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0966       |\n",
      "|    explained_variance   | 0.268         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 489           |\n",
      "|    n_updates            | 760           |\n",
      "|    policy_gradient_loss | -0.000208     |\n",
      "|    value_loss           | 1.28e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 670          |\n",
      "|    ep_rew_mean          | 3.55e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 712          |\n",
      "|    iterations           | 78           |\n",
      "|    time_elapsed         | 252          |\n",
      "|    total_timesteps      | 179712       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006895751 |\n",
      "|    clip_fraction        | 0.0134       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0819      |\n",
      "|    explained_variance   | 0.2          |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 776          |\n",
      "|    n_updates            | 770          |\n",
      "|    policy_gradient_loss | -0.000983    |\n",
      "|    value_loss           | 1.63e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 671           |\n",
      "|    ep_rew_mean          | 3.55e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 712           |\n",
      "|    iterations           | 79            |\n",
      "|    time_elapsed         | 255           |\n",
      "|    total_timesteps      | 182016        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.0100207e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0767       |\n",
      "|    explained_variance   | 0.279         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 618           |\n",
      "|    n_updates            | 780           |\n",
      "|    policy_gradient_loss | -0.000487     |\n",
      "|    value_loss           | 1.27e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 673           |\n",
      "|    ep_rew_mean          | 3.56e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 712           |\n",
      "|    iterations           | 80            |\n",
      "|    time_elapsed         | 258           |\n",
      "|    total_timesteps      | 184320        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00043945332 |\n",
      "|    clip_fraction        | 0.00734       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0728       |\n",
      "|    explained_variance   | 0.264         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 781           |\n",
      "|    n_updates            | 790           |\n",
      "|    policy_gradient_loss | -0.00109      |\n",
      "|    value_loss           | 1.37e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 678           |\n",
      "|    ep_rew_mean          | 3.59e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 713           |\n",
      "|    iterations           | 81            |\n",
      "|    time_elapsed         | 261           |\n",
      "|    total_timesteps      | 186624        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017016122 |\n",
      "|    clip_fraction        | 0.000391      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0756       |\n",
      "|    explained_variance   | 0.285         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 796           |\n",
      "|    n_updates            | 800           |\n",
      "|    policy_gradient_loss | -0.00019      |\n",
      "|    value_loss           | 1.28e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 682           |\n",
      "|    ep_rew_mean          | 3.62e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 713           |\n",
      "|    iterations           | 82            |\n",
      "|    time_elapsed         | 264           |\n",
      "|    total_timesteps      | 188928        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7573964e-05 |\n",
      "|    clip_fraction        | 0.00176       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0787       |\n",
      "|    explained_variance   | 0.245         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.19e+03      |\n",
      "|    n_updates            | 810           |\n",
      "|    policy_gradient_loss | -0.000176     |\n",
      "|    value_loss           | 1.68e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 682          |\n",
      "|    ep_rew_mean          | 3.62e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 713          |\n",
      "|    iterations           | 83           |\n",
      "|    time_elapsed         | 268          |\n",
      "|    total_timesteps      | 191232       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018201877 |\n",
      "|    clip_fraction        | 0.0107       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0826      |\n",
      "|    explained_variance   | 0.289        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 814          |\n",
      "|    n_updates            | 820          |\n",
      "|    policy_gradient_loss | -0.00054     |\n",
      "|    value_loss           | 1.31e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 680           |\n",
      "|    ep_rew_mean          | 3.61e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 713           |\n",
      "|    iterations           | 84            |\n",
      "|    time_elapsed         | 271           |\n",
      "|    total_timesteps      | 193536        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00031368592 |\n",
      "|    clip_fraction        | 0.00594       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0894       |\n",
      "|    explained_variance   | 0.283         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 745           |\n",
      "|    n_updates            | 830           |\n",
      "|    policy_gradient_loss | 0.000239      |\n",
      "|    value_loss           | 1.26e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 681           |\n",
      "|    ep_rew_mean          | 3.62e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 713           |\n",
      "|    iterations           | 85            |\n",
      "|    time_elapsed         | 274           |\n",
      "|    total_timesteps      | 195840        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014714245 |\n",
      "|    clip_fraction        | 0.0111        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0769       |\n",
      "|    explained_variance   | 0.3           |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 965           |\n",
      "|    n_updates            | 840           |\n",
      "|    policy_gradient_loss | -0.000365     |\n",
      "|    value_loss           | 1.61e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 688           |\n",
      "|    ep_rew_mean          | 3.66e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 713           |\n",
      "|    iterations           | 86            |\n",
      "|    time_elapsed         | 277           |\n",
      "|    total_timesteps      | 198144        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 9.6723714e-05 |\n",
      "|    clip_fraction        | 0.00547       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0743       |\n",
      "|    explained_variance   | 0.327         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 511           |\n",
      "|    n_updates            | 850           |\n",
      "|    policy_gradient_loss | -0.000617     |\n",
      "|    value_loss           | 1.23e+03      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 688         |\n",
      "|    ep_rew_mean          | 3.66e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 713         |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 280         |\n",
      "|    total_timesteps      | 200448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020463498 |\n",
      "|    clip_fraction        | 0.0401      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.103      |\n",
      "|    explained_variance   | 0.344       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 418         |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.00504    |\n",
      "|    value_loss           | 1.28e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 684          |\n",
      "|    ep_rew_mean          | 3.64e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 714          |\n",
      "|    iterations           | 88           |\n",
      "|    time_elapsed         | 283          |\n",
      "|    total_timesteps      | 202752       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013018658 |\n",
      "|    clip_fraction        | 0.00793      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.116       |\n",
      "|    explained_variance   | 0.285        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 829          |\n",
      "|    n_updates            | 870          |\n",
      "|    policy_gradient_loss | -0.00163     |\n",
      "|    value_loss           | 2.01e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 681           |\n",
      "|    ep_rew_mean          | 3.63e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 714           |\n",
      "|    iterations           | 89            |\n",
      "|    time_elapsed         | 287           |\n",
      "|    total_timesteps      | 205056        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.3788128e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.114        |\n",
      "|    explained_variance   | 0.271         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 696           |\n",
      "|    n_updates            | 880           |\n",
      "|    policy_gradient_loss | -2.33e-05     |\n",
      "|    value_loss           | 1.93e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 676          |\n",
      "|    ep_rew_mean          | 3.59e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 714          |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 290          |\n",
      "|    total_timesteps      | 207360       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019883518 |\n",
      "|    clip_fraction        | 0.0205       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.113       |\n",
      "|    explained_variance   | 0.303        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 978          |\n",
      "|    n_updates            | 890          |\n",
      "|    policy_gradient_loss | 0.000468     |\n",
      "|    value_loss           | 1.64e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 669          |\n",
      "|    ep_rew_mean          | 3.54e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 714          |\n",
      "|    iterations           | 91           |\n",
      "|    time_elapsed         | 293          |\n",
      "|    total_timesteps      | 209664       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026030228 |\n",
      "|    clip_fraction        | 0.0347       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.111       |\n",
      "|    explained_variance   | 0.357        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.32e+03     |\n",
      "|    n_updates            | 900          |\n",
      "|    policy_gradient_loss | -0.00365     |\n",
      "|    value_loss           | 2.68e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 669        |\n",
      "|    ep_rew_mean          | 3.55e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 714        |\n",
      "|    iterations           | 92         |\n",
      "|    time_elapsed         | 296        |\n",
      "|    total_timesteps      | 211968     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00161698 |\n",
      "|    clip_fraction        | 0.0141     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.104     |\n",
      "|    explained_variance   | 0.373      |\n",
      "|    learning_rate        | 0.003      |\n",
      "|    loss                 | 1.05e+03   |\n",
      "|    n_updates            | 910        |\n",
      "|    policy_gradient_loss | -0.00192   |\n",
      "|    value_loss           | 2.72e+03   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 666          |\n",
      "|    ep_rew_mean          | 3.53e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 714          |\n",
      "|    iterations           | 93           |\n",
      "|    time_elapsed         | 299          |\n",
      "|    total_timesteps      | 214272       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015198862 |\n",
      "|    clip_fraction        | 0.0145       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.094       |\n",
      "|    explained_variance   | 0.411        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 566          |\n",
      "|    n_updates            | 920          |\n",
      "|    policy_gradient_loss | -8.79e-05    |\n",
      "|    value_loss           | 1.48e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 664          |\n",
      "|    ep_rew_mean          | 3.52e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 714          |\n",
      "|    iterations           | 94           |\n",
      "|    time_elapsed         | 302          |\n",
      "|    total_timesteps      | 216576       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006252572 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0867      |\n",
      "|    explained_variance   | 0.367        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 753          |\n",
      "|    n_updates            | 930          |\n",
      "|    policy_gradient_loss | -0.00123     |\n",
      "|    value_loss           | 1.4e+03      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 667           |\n",
      "|    ep_rew_mean          | 3.54e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 715           |\n",
      "|    iterations           | 95            |\n",
      "|    time_elapsed         | 306           |\n",
      "|    total_timesteps      | 218880        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.2411353e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0847       |\n",
      "|    explained_variance   | 0.429         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 439           |\n",
      "|    n_updates            | 940           |\n",
      "|    policy_gradient_loss | -0.000185     |\n",
      "|    value_loss           | 1.22e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 664          |\n",
      "|    ep_rew_mean          | 3.53e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 715          |\n",
      "|    iterations           | 96           |\n",
      "|    time_elapsed         | 309          |\n",
      "|    total_timesteps      | 221184       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005150767 |\n",
      "|    clip_fraction        | 0.00453      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0899      |\n",
      "|    explained_variance   | 0.454        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 822          |\n",
      "|    n_updates            | 950          |\n",
      "|    policy_gradient_loss | -0.000468    |\n",
      "|    value_loss           | 1.49e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 659         |\n",
      "|    ep_rew_mean          | 3.51e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 715         |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 312         |\n",
      "|    total_timesteps      | 223488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002331211 |\n",
      "|    clip_fraction        | 0.0282      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0739     |\n",
      "|    explained_variance   | 0.324       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 704         |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | 0.00175     |\n",
      "|    value_loss           | 1.24e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 656          |\n",
      "|    ep_rew_mean          | 3.49e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 715          |\n",
      "|    iterations           | 98           |\n",
      "|    time_elapsed         | 315          |\n",
      "|    total_timesteps      | 225792       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008322617 |\n",
      "|    clip_fraction        | 0.0103       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0895      |\n",
      "|    explained_variance   | 0.472        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 925          |\n",
      "|    n_updates            | 970          |\n",
      "|    policy_gradient_loss | -0.000563    |\n",
      "|    value_loss           | 1.45e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 651          |\n",
      "|    ep_rew_mean          | 3.46e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 715          |\n",
      "|    iterations           | 99           |\n",
      "|    time_elapsed         | 318          |\n",
      "|    total_timesteps      | 228096       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013961397 |\n",
      "|    clip_fraction        | 0.0105       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0974      |\n",
      "|    explained_variance   | 0.45         |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 508          |\n",
      "|    n_updates            | 980          |\n",
      "|    policy_gradient_loss | -0.00143     |\n",
      "|    value_loss           | 1.27e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 644           |\n",
      "|    ep_rew_mean          | 3.43e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 715           |\n",
      "|    iterations           | 100           |\n",
      "|    time_elapsed         | 321           |\n",
      "|    total_timesteps      | 230400        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00058104674 |\n",
      "|    clip_fraction        | 0.00383       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.105        |\n",
      "|    explained_variance   | 0.432         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 817           |\n",
      "|    n_updates            | 990           |\n",
      "|    policy_gradient_loss | -0.000279     |\n",
      "|    value_loss           | 1.63e+03      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 638         |\n",
      "|    ep_rew_mean          | 3.4e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 715         |\n",
      "|    iterations           | 101         |\n",
      "|    time_elapsed         | 325         |\n",
      "|    total_timesteps      | 232704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001175286 |\n",
      "|    clip_fraction        | 0.00637     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0987     |\n",
      "|    explained_variance   | 0.173       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 620         |\n",
      "|    n_updates            | 1000        |\n",
      "|    policy_gradient_loss | -0.000612   |\n",
      "|    value_loss           | 1.51e+03    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 632           |\n",
      "|    ep_rew_mean          | 3.37e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 715           |\n",
      "|    iterations           | 102           |\n",
      "|    time_elapsed         | 328           |\n",
      "|    total_timesteps      | 235008        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.6710408e-05 |\n",
      "|    clip_fraction        | 0.00406       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.104        |\n",
      "|    explained_variance   | 0.462         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 818           |\n",
      "|    n_updates            | 1010          |\n",
      "|    policy_gradient_loss | -0.000279     |\n",
      "|    value_loss           | 1.51e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 629          |\n",
      "|    ep_rew_mean          | 3.35e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 715          |\n",
      "|    iterations           | 103          |\n",
      "|    time_elapsed         | 331          |\n",
      "|    total_timesteps      | 237312       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.961992e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0936      |\n",
      "|    explained_variance   | 0.491        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 854          |\n",
      "|    n_updates            | 1020         |\n",
      "|    policy_gradient_loss | 3.19e-05     |\n",
      "|    value_loss           | 1.52e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 626          |\n",
      "|    ep_rew_mean          | 3.33e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 716          |\n",
      "|    iterations           | 104          |\n",
      "|    time_elapsed         | 334          |\n",
      "|    total_timesteps      | 239616       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006627003 |\n",
      "|    clip_fraction        | 0.00258      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.101       |\n",
      "|    explained_variance   | 0.478        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 562          |\n",
      "|    n_updates            | 1030         |\n",
      "|    policy_gradient_loss | -0.000319    |\n",
      "|    value_loss           | 1.45e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 622          |\n",
      "|    ep_rew_mean          | 3.31e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 716          |\n",
      "|    iterations           | 105          |\n",
      "|    time_elapsed         | 337          |\n",
      "|    total_timesteps      | 241920       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006012331 |\n",
      "|    clip_fraction        | 0.015        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0945      |\n",
      "|    explained_variance   | 0.405        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 774          |\n",
      "|    n_updates            | 1040         |\n",
      "|    policy_gradient_loss | -0.00211     |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 616          |\n",
      "|    ep_rew_mean          | 3.29e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 716          |\n",
      "|    iterations           | 106          |\n",
      "|    time_elapsed         | 340          |\n",
      "|    total_timesteps      | 244224       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006631335 |\n",
      "|    clip_fraction        | 0.00594      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.106       |\n",
      "|    explained_variance   | 0.525        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 707          |\n",
      "|    n_updates            | 1050         |\n",
      "|    policy_gradient_loss | -0.000528    |\n",
      "|    value_loss           | 1.2e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 606          |\n",
      "|    ep_rew_mean          | 3.23e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 716          |\n",
      "|    iterations           | 107          |\n",
      "|    time_elapsed         | 344          |\n",
      "|    total_timesteps      | 246528       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018245764 |\n",
      "|    clip_fraction        | 0.019        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.115       |\n",
      "|    explained_variance   | 0.494        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 716          |\n",
      "|    n_updates            | 1060         |\n",
      "|    policy_gradient_loss | -0.00119     |\n",
      "|    value_loss           | 1.5e+03      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 599         |\n",
      "|    ep_rew_mean          | 3.2e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 716         |\n",
      "|    iterations           | 108         |\n",
      "|    time_elapsed         | 347         |\n",
      "|    total_timesteps      | 248832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000849285 |\n",
      "|    clip_fraction        | 0.000703    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.11       |\n",
      "|    explained_variance   | 0.344       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 879         |\n",
      "|    n_updates            | 1070        |\n",
      "|    policy_gradient_loss | -0.000308   |\n",
      "|    value_loss           | 1.96e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 597          |\n",
      "|    ep_rew_mean          | 3.18e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 716          |\n",
      "|    iterations           | 109          |\n",
      "|    time_elapsed         | 350          |\n",
      "|    total_timesteps      | 251136       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010470619 |\n",
      "|    clip_fraction        | 0.0158       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0953      |\n",
      "|    explained_variance   | 0.496        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 480          |\n",
      "|    n_updates            | 1080         |\n",
      "|    policy_gradient_loss | -0.000582    |\n",
      "|    value_loss           | 1.49e+03     |\n",
      "------------------------------------------\n",
      "\n",
      "Training with ent_coef=0.001\n",
      "Using cuda device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.3e+03   |\n",
      "|    ep_rew_mean     | -6.41e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 745       |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 3         |\n",
      "|    total_timesteps | 2304      |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.3e+03     |\n",
      "|    ep_rew_mean          | -3.39e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 732         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 4608        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007823422 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.772      |\n",
      "|    explained_variance   | -0.000558   |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 2.35e+03    |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0199     |\n",
      "|    value_loss           | 5.61e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.3e+03    |\n",
      "|    ep_rew_mean          | -1.38e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 726        |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 9          |\n",
      "|    total_timesteps      | 6912       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06376918 |\n",
      "|    clip_fraction        | 0.245      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.718     |\n",
      "|    explained_variance   | -4.89e-06  |\n",
      "|    learning_rate        | 0.003      |\n",
      "|    loss                 | 545        |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | 0.00347    |\n",
      "|    value_loss           | 1.22e+03   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.29e+03     |\n",
      "|    ep_rew_mean          | 86.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 722          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 9216         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064540775 |\n",
      "|    clip_fraction        | 0.0761       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.7         |\n",
      "|    explained_variance   | 0.0137       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 402          |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.0103      |\n",
      "|    value_loss           | 1.1e+03      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.25e+03    |\n",
      "|    ep_rew_mean          | 744         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 719         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 11520       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007637462 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.669      |\n",
      "|    explained_variance   | 0.00203     |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 327         |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00846    |\n",
      "|    value_loss           | 1.19e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.2e+03     |\n",
      "|    ep_rew_mean          | 1.39e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 717         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 13824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008154808 |\n",
      "|    clip_fraction        | 0.0998      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.633      |\n",
      "|    explained_variance   | 7.63e-06    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 881         |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    value_loss           | 2.35e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.21e+03     |\n",
      "|    ep_rew_mean          | 2.09e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 715          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 22           |\n",
      "|    total_timesteps      | 16128        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067905514 |\n",
      "|    clip_fraction        | 0.0902       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.614       |\n",
      "|    explained_variance   | 5.3e-05      |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 264          |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.0103      |\n",
      "|    value_loss           | 971          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.03e+03   |\n",
      "|    ep_rew_mean          | 2.68e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 715        |\n",
      "|    iterations           | 8          |\n",
      "|    time_elapsed         | 25         |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00846919 |\n",
      "|    clip_fraction        | 0.101      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.584     |\n",
      "|    explained_variance   | 4.73e-05   |\n",
      "|    learning_rate        | 0.003      |\n",
      "|    loss                 | 317        |\n",
      "|    n_updates            | 70         |\n",
      "|    policy_gradient_loss | -0.0117    |\n",
      "|    value_loss           | 1.13e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.97e+03    |\n",
      "|    ep_rew_mean          | 2.92e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 712         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 20736       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006355693 |\n",
      "|    clip_fraction        | 0.0893      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.539      |\n",
      "|    explained_variance   | 3.68e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 431         |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    value_loss           | 1.46e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.75e+03    |\n",
      "|    ep_rew_mean          | 3.2e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 715         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 23040       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012836687 |\n",
      "|    clip_fraction        | 0.0875      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.487      |\n",
      "|    explained_variance   | 4e-05       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 503         |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00962    |\n",
      "|    value_loss           | 1.71e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.57e+03    |\n",
      "|    ep_rew_mean          | 3.25e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 717         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 35          |\n",
      "|    total_timesteps      | 25344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011710749 |\n",
      "|    clip_fraction        | 0.0859      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.457      |\n",
      "|    explained_variance   | 3.55e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 485         |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00865    |\n",
      "|    value_loss           | 1.61e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.43e+03    |\n",
      "|    ep_rew_mean          | 3.18e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 718         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 27648       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007817281 |\n",
      "|    clip_fraction        | 0.0642      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.424      |\n",
      "|    explained_variance   | 3.02e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 444         |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00363    |\n",
      "|    value_loss           | 1.62e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.3e+03     |\n",
      "|    ep_rew_mean          | 3.2e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 718         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 29952       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005721945 |\n",
      "|    clip_fraction        | 0.0617      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.387      |\n",
      "|    explained_variance   | 1.56e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 541         |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00158    |\n",
      "|    value_loss           | 1.61e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.22e+03    |\n",
      "|    ep_rew_mean          | 3.13e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 718         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 44          |\n",
      "|    total_timesteps      | 32256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005475774 |\n",
      "|    clip_fraction        | 0.0611      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.368      |\n",
      "|    explained_variance   | 2.06e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 558         |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | 0.00168     |\n",
      "|    value_loss           | 1.86e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.14e+03     |\n",
      "|    ep_rew_mean          | 3.09e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 716          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 48           |\n",
      "|    total_timesteps      | 34560        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077655027 |\n",
      "|    clip_fraction        | 0.0887       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.316       |\n",
      "|    explained_variance   | 1.29e-05     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 497          |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00305     |\n",
      "|    value_loss           | 1.4e+03      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.11e+03    |\n",
      "|    ep_rew_mean          | 3.1e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 714         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013694523 |\n",
      "|    clip_fraction        | 0.0724      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.31       |\n",
      "|    explained_variance   | 1.62e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 382         |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | 0.000743    |\n",
      "|    value_loss           | 1.19e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.08e+03    |\n",
      "|    ep_rew_mean          | 3.14e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 714         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 54          |\n",
      "|    total_timesteps      | 39168       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007881242 |\n",
      "|    clip_fraction        | 0.0354      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.282      |\n",
      "|    explained_variance   | 1.76e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 252         |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | 0.00173     |\n",
      "|    value_loss           | 738         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.07e+03    |\n",
      "|    ep_rew_mean          | 3.16e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 714         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 58          |\n",
      "|    total_timesteps      | 41472       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019775208 |\n",
      "|    clip_fraction        | 0.0396      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.236      |\n",
      "|    explained_variance   | 1.56e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 176         |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | 0.00194     |\n",
      "|    value_loss           | 682         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 3.15e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 715         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 61          |\n",
      "|    total_timesteps      | 43776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009722513 |\n",
      "|    clip_fraction        | 0.0946      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.253      |\n",
      "|    explained_variance   | 1.71e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 229         |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | 0.00724     |\n",
      "|    value_loss           | 618         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.05e+03    |\n",
      "|    ep_rew_mean          | 3.23e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 715         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 64          |\n",
      "|    total_timesteps      | 46080       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.052577328 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.277      |\n",
      "|    explained_variance   | 1.31e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 399         |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | 0.0253      |\n",
      "|    value_loss           | 1.04e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.06e+03    |\n",
      "|    ep_rew_mean          | 3.33e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 714         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 67          |\n",
      "|    total_timesteps      | 48384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019059684 |\n",
      "|    clip_fraction        | 0.05        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.18       |\n",
      "|    explained_variance   | 0.0533      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 105         |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00461    |\n",
      "|    value_loss           | 353         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.08e+03     |\n",
      "|    ep_rew_mean          | 3.46e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 713          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 70           |\n",
      "|    total_timesteps      | 50688        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023728001 |\n",
      "|    clip_fraction        | 0.0216       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.186       |\n",
      "|    explained_variance   | 0.0589       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 226          |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.00191     |\n",
      "|    value_loss           | 738          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.08e+03    |\n",
      "|    ep_rew_mean          | 3.51e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 714         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 74          |\n",
      "|    total_timesteps      | 52992       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009054805 |\n",
      "|    clip_fraction        | 0.0131      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.184      |\n",
      "|    explained_variance   | 8.82e-06    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 221         |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.000297   |\n",
      "|    value_loss           | 685         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.08e+03     |\n",
      "|    ep_rew_mean          | 3.57e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 713          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 77           |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063121645 |\n",
      "|    clip_fraction        | 0.0469       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.224       |\n",
      "|    explained_variance   | 0.0367       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 274          |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.00161     |\n",
      "|    value_loss           | 578          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.07e+03    |\n",
      "|    ep_rew_mean          | 3.62e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 713         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 80          |\n",
      "|    total_timesteps      | 57600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008793435 |\n",
      "|    clip_fraction        | 0.0488      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.177      |\n",
      "|    explained_variance   | 0.0367      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 218         |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00122    |\n",
      "|    value_loss           | 612         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.06e+03     |\n",
      "|    ep_rew_mean          | 3.61e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 714          |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 83           |\n",
      "|    total_timesteps      | 59904        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022365067 |\n",
      "|    clip_fraction        | 0.0304       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.22        |\n",
      "|    explained_variance   | 0.0445       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 489          |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.00153     |\n",
      "|    value_loss           | 936          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 3.62e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 714          |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 87           |\n",
      "|    total_timesteps      | 62208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023746258 |\n",
      "|    clip_fraction        | 0.0355       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.214       |\n",
      "|    explained_variance   | 0.0287       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.07e+03     |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.00222     |\n",
      "|    value_loss           | 1.41e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | 3.64e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 714          |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 90           |\n",
      "|    total_timesteps      | 64512        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024568844 |\n",
      "|    clip_fraction        | 0.0206       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.243       |\n",
      "|    explained_variance   | 0.0366       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 612          |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.000362    |\n",
      "|    value_loss           | 1.2e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.02e+03     |\n",
      "|    ep_rew_mean          | 3.65e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 713          |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 93           |\n",
      "|    total_timesteps      | 66816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011901454 |\n",
      "|    clip_fraction        | 0.0587       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.224       |\n",
      "|    explained_variance   | 0.0419       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 576          |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | 0.00165      |\n",
      "|    value_loss           | 1.15e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.02e+03    |\n",
      "|    ep_rew_mean          | 3.68e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 713         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 96          |\n",
      "|    total_timesteps      | 69120       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008808623 |\n",
      "|    clip_fraction        | 0.0259      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.208      |\n",
      "|    explained_variance   | 0.0424      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 742         |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.000784   |\n",
      "|    value_loss           | 1.19e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.02e+03    |\n",
      "|    ep_rew_mean          | 3.72e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 713         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 100         |\n",
      "|    total_timesteps      | 71424       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004383918 |\n",
      "|    clip_fraction        | 0.0461      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.163      |\n",
      "|    explained_variance   | 0.046       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 698         |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | 0.00163     |\n",
      "|    value_loss           | 965         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.02e+03    |\n",
      "|    ep_rew_mean          | 3.75e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 712         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 103         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002513413 |\n",
      "|    clip_fraction        | 0.0291      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.206      |\n",
      "|    explained_variance   | 0.0593      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 606         |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.000863   |\n",
      "|    value_loss           | 723         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.01e+03     |\n",
      "|    ep_rew_mean          | 3.75e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 713          |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 106          |\n",
      "|    total_timesteps      | 76032        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038383864 |\n",
      "|    clip_fraction        | 0.021        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.203       |\n",
      "|    explained_variance   | 0.0468       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 418          |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.000989    |\n",
      "|    value_loss           | 997          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 998          |\n",
      "|    ep_rew_mean          | 3.74e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 712          |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 109          |\n",
      "|    total_timesteps      | 78336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035098693 |\n",
      "|    clip_fraction        | 0.04         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.205       |\n",
      "|    explained_variance   | 0.0349       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 527          |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | 0.00161      |\n",
      "|    value_loss           | 1.24e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 991          |\n",
      "|    ep_rew_mean          | 3.75e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 712          |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 113          |\n",
      "|    total_timesteps      | 80640        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034707834 |\n",
      "|    clip_fraction        | 0.0436       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.214       |\n",
      "|    explained_variance   | 0.0591       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 372          |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.000501    |\n",
      "|    value_loss           | 1.2e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 991          |\n",
      "|    ep_rew_mean          | 3.77e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 712          |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 116          |\n",
      "|    total_timesteps      | 82944        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023958501 |\n",
      "|    clip_fraction        | 0.0228       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.22        |\n",
      "|    explained_variance   | 0.0361       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 471          |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.00193     |\n",
      "|    value_loss           | 1.12e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 978         |\n",
      "|    ep_rew_mean          | 3.76e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 712         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 119         |\n",
      "|    total_timesteps      | 85248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017782036 |\n",
      "|    clip_fraction        | 0.0788      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.218      |\n",
      "|    explained_variance   | 0.0425      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 382         |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.00608    |\n",
      "|    value_loss           | 810         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 967          |\n",
      "|    ep_rew_mean          | 3.73e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 712          |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 122          |\n",
      "|    total_timesteps      | 87552        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018071346 |\n",
      "|    clip_fraction        | 0.0539       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.207       |\n",
      "|    explained_variance   | 0.0364       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 574          |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.00381     |\n",
      "|    value_loss           | 1.57e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 959          |\n",
      "|    ep_rew_mean          | 3.72e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 711          |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 126          |\n",
      "|    total_timesteps      | 89856        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025380768 |\n",
      "|    clip_fraction        | 0.0348       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.208       |\n",
      "|    explained_variance   | 0.0522       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.13e+03     |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.00305     |\n",
      "|    value_loss           | 1.9e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 955          |\n",
      "|    ep_rew_mean          | 3.73e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 710          |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 129          |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018039132 |\n",
      "|    clip_fraction        | 0.0254       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.201       |\n",
      "|    explained_variance   | 0.04         |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 613          |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | 0.000528     |\n",
      "|    value_loss           | 1.33e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 944          |\n",
      "|    ep_rew_mean          | 3.71e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 711          |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 132          |\n",
      "|    total_timesteps      | 94464        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026251937 |\n",
      "|    clip_fraction        | 0.0505       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.226       |\n",
      "|    explained_variance   | 0.0494       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 431          |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | 2.99e-05     |\n",
      "|    value_loss           | 1.18e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 915          |\n",
      "|    ep_rew_mean          | 3.86e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 711          |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 136          |\n",
      "|    total_timesteps      | 96768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009443555 |\n",
      "|    clip_fraction        | 0.0639       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.203       |\n",
      "|    explained_variance   | 0.0345       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 527          |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.000949    |\n",
      "|    value_loss           | 1.59e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 876         |\n",
      "|    ep_rew_mean          | 3.87e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 711         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 139         |\n",
      "|    total_timesteps      | 99072       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011470454 |\n",
      "|    clip_fraction        | 0.094       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.17       |\n",
      "|    explained_variance   | 0.0657      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 353         |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | 0.00118     |\n",
      "|    value_loss           | 872         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 841          |\n",
      "|    ep_rew_mean          | 3.82e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 711          |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 142          |\n",
      "|    total_timesteps      | 101376       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010116979 |\n",
      "|    clip_fraction        | 0.0173       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.175       |\n",
      "|    explained_variance   | 0.046        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 832          |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.000401    |\n",
      "|    value_loss           | 1.21e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 832           |\n",
      "|    ep_rew_mean          | 3.8e+03       |\n",
      "| time/                   |               |\n",
      "|    fps                  | 711           |\n",
      "|    iterations           | 45            |\n",
      "|    time_elapsed         | 145           |\n",
      "|    total_timesteps      | 103680        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00067975296 |\n",
      "|    clip_fraction        | 0.0155        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.187        |\n",
      "|    explained_variance   | 0.072         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 452           |\n",
      "|    n_updates            | 440           |\n",
      "|    policy_gradient_loss | -0.00062      |\n",
      "|    value_loss           | 1.13e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 827          |\n",
      "|    ep_rew_mean          | 3.78e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 711          |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 148          |\n",
      "|    total_timesteps      | 105984       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018435121 |\n",
      "|    clip_fraction        | 0.0118       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.185       |\n",
      "|    explained_variance   | 0.0883       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 399          |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.00115     |\n",
      "|    value_loss           | 710          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 829           |\n",
      "|    ep_rew_mean          | 3.81e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 711           |\n",
      "|    iterations           | 47            |\n",
      "|    time_elapsed         | 152           |\n",
      "|    total_timesteps      | 108288        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00087822636 |\n",
      "|    clip_fraction        | 0.0231        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.164        |\n",
      "|    explained_variance   | 0.0641        |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 900           |\n",
      "|    n_updates            | 460           |\n",
      "|    policy_gradient_loss | -0.00224      |\n",
      "|    value_loss           | 1.1e+03       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 833          |\n",
      "|    ep_rew_mean          | 3.83e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 711          |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 155          |\n",
      "|    total_timesteps      | 110592       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005449053 |\n",
      "|    clip_fraction        | 0.0112       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.189       |\n",
      "|    explained_variance   | 0.069        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 428          |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.000436    |\n",
      "|    value_loss           | 1.05e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 840          |\n",
      "|    ep_rew_mean          | 3.87e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 711          |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 158          |\n",
      "|    total_timesteps      | 112896       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013172366 |\n",
      "|    clip_fraction        | 0.0215       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.197       |\n",
      "|    explained_variance   | 0.108        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 701          |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.000861    |\n",
      "|    value_loss           | 801          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 844          |\n",
      "|    ep_rew_mean          | 3.89e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 711          |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 161          |\n",
      "|    total_timesteps      | 115200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014347859 |\n",
      "|    clip_fraction        | 0.0105       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.209       |\n",
      "|    explained_variance   | 0.0561       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 564          |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.000902    |\n",
      "|    value_loss           | 1.05e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 851          |\n",
      "|    ep_rew_mean          | 3.93e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 712          |\n",
      "|    iterations           | 51           |\n",
      "|    time_elapsed         | 164          |\n",
      "|    total_timesteps      | 117504       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009930184 |\n",
      "|    clip_fraction        | 0.0032       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.211       |\n",
      "|    explained_variance   | 0.0517       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 328          |\n",
      "|    n_updates            | 500          |\n",
      "|    policy_gradient_loss | -0.000748    |\n",
      "|    value_loss           | 1.11e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 855          |\n",
      "|    ep_rew_mean          | 3.96e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 712          |\n",
      "|    iterations           | 52           |\n",
      "|    time_elapsed         | 168          |\n",
      "|    total_timesteps      | 119808       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037702892 |\n",
      "|    clip_fraction        | 0.0189       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.208       |\n",
      "|    explained_variance   | 0.0822       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 280          |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | -0.00135     |\n",
      "|    value_loss           | 828          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 855          |\n",
      "|    ep_rew_mean          | 3.98e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 711          |\n",
      "|    iterations           | 53           |\n",
      "|    time_elapsed         | 171          |\n",
      "|    total_timesteps      | 122112       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026556891 |\n",
      "|    clip_fraction        | 0.0282       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.204       |\n",
      "|    explained_variance   | 0.0417       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.17e+03     |\n",
      "|    n_updates            | 520          |\n",
      "|    policy_gradient_loss | -0.0016      |\n",
      "|    value_loss           | 1.68e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 861          |\n",
      "|    ep_rew_mean          | 4.02e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 710          |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 175          |\n",
      "|    total_timesteps      | 124416       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052609774 |\n",
      "|    clip_fraction        | 0.012        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.199       |\n",
      "|    explained_variance   | 0.0505       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 431          |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | 0.000361     |\n",
      "|    value_loss           | 1.22e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 868         |\n",
      "|    ep_rew_mean          | 4.06e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 711         |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 178         |\n",
      "|    total_timesteps      | 126720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004882986 |\n",
      "|    clip_fraction        | 0.0296      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.157      |\n",
      "|    explained_variance   | 0.0736      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 243         |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | 0.0039      |\n",
      "|    value_loss           | 771         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 864        |\n",
      "|    ep_rew_mean          | 4.06e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 711        |\n",
      "|    iterations           | 56         |\n",
      "|    time_elapsed         | 181        |\n",
      "|    total_timesteps      | 129024     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01841912 |\n",
      "|    clip_fraction        | 0.0901     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.224     |\n",
      "|    explained_variance   | 0.0537     |\n",
      "|    learning_rate        | 0.003      |\n",
      "|    loss                 | 487        |\n",
      "|    n_updates            | 550        |\n",
      "|    policy_gradient_loss | -0.008     |\n",
      "|    value_loss           | 853        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 873         |\n",
      "|    ep_rew_mean          | 4.11e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 711         |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 184         |\n",
      "|    total_timesteps      | 131328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032039218 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.258      |\n",
      "|    explained_variance   | 0.0434      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 408         |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | 0.0198      |\n",
      "|    value_loss           | 1.34e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 845        |\n",
      "|    ep_rew_mean          | 3.99e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 712        |\n",
      "|    iterations           | 58         |\n",
      "|    time_elapsed         | 187        |\n",
      "|    total_timesteps      | 133632     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05306641 |\n",
      "|    clip_fraction        | 0.0768     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.201     |\n",
      "|    explained_variance   | -0.0115    |\n",
      "|    learning_rate        | 0.003      |\n",
      "|    loss                 | 414        |\n",
      "|    n_updates            | 570        |\n",
      "|    policy_gradient_loss | -0.00384   |\n",
      "|    value_loss           | 873        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 827          |\n",
      "|    ep_rew_mean          | 3.91e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 712          |\n",
      "|    iterations           | 59           |\n",
      "|    time_elapsed         | 190          |\n",
      "|    total_timesteps      | 135936       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030590533 |\n",
      "|    clip_fraction        | 0.057        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.197       |\n",
      "|    explained_variance   | 0.0319       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 698          |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | -0.00176     |\n",
      "|    value_loss           | 2.03e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 821          |\n",
      "|    ep_rew_mean          | 3.88e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 713          |\n",
      "|    iterations           | 60           |\n",
      "|    time_elapsed         | 193          |\n",
      "|    total_timesteps      | 138240       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066125467 |\n",
      "|    clip_fraction        | 0.105        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.155       |\n",
      "|    explained_variance   | 0.0463       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 326          |\n",
      "|    n_updates            | 590          |\n",
      "|    policy_gradient_loss | 0.000407     |\n",
      "|    value_loss           | 1.31e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 828          |\n",
      "|    ep_rew_mean          | 3.91e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 713          |\n",
      "|    iterations           | 61           |\n",
      "|    time_elapsed         | 197          |\n",
      "|    total_timesteps      | 140544       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014175675 |\n",
      "|    clip_fraction        | 0.0082       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.155       |\n",
      "|    explained_variance   | 0.0873       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 780          |\n",
      "|    n_updates            | 600          |\n",
      "|    policy_gradient_loss | -9.81e-05    |\n",
      "|    value_loss           | 1.22e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 833         |\n",
      "|    ep_rew_mean          | 3.93e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 712         |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 200         |\n",
      "|    total_timesteps      | 142848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001460012 |\n",
      "|    clip_fraction        | 0.0147      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.155      |\n",
      "|    explained_variance   | 0.221       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 489         |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.000328   |\n",
      "|    value_loss           | 919         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 831         |\n",
      "|    ep_rew_mean          | 3.91e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 711         |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 203         |\n",
      "|    total_timesteps      | 145152      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007924005 |\n",
      "|    clip_fraction        | 0.02        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.173      |\n",
      "|    explained_variance   | 0.274       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 455         |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.000115   |\n",
      "|    value_loss           | 885         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 834          |\n",
      "|    ep_rew_mean          | 3.91e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 711          |\n",
      "|    iterations           | 64           |\n",
      "|    time_elapsed         | 207          |\n",
      "|    total_timesteps      | 147456       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077184304 |\n",
      "|    clip_fraction        | 0.088        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.175       |\n",
      "|    explained_variance   | 0.097        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 772          |\n",
      "|    n_updates            | 630          |\n",
      "|    policy_gradient_loss | -0.0041      |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 834          |\n",
      "|    ep_rew_mean          | 3.9e+03      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 711          |\n",
      "|    iterations           | 65           |\n",
      "|    time_elapsed         | 210          |\n",
      "|    total_timesteps      | 149760       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014916433 |\n",
      "|    clip_fraction        | 0.0248       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.194       |\n",
      "|    explained_variance   | 0.0846       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 575          |\n",
      "|    n_updates            | 640          |\n",
      "|    policy_gradient_loss | 0.001        |\n",
      "|    value_loss           | 1.05e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 835          |\n",
      "|    ep_rew_mean          | 3.9e+03      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 710          |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 213          |\n",
      "|    total_timesteps      | 152064       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021712533 |\n",
      "|    clip_fraction        | 0.0333       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.176       |\n",
      "|    explained_variance   | 0.135        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 673          |\n",
      "|    n_updates            | 650          |\n",
      "|    policy_gradient_loss | -0.00218     |\n",
      "|    value_loss           | 1.17e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 831           |\n",
      "|    ep_rew_mean          | 3.88e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 710           |\n",
      "|    iterations           | 67            |\n",
      "|    time_elapsed         | 217           |\n",
      "|    total_timesteps      | 154368        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00070047786 |\n",
      "|    clip_fraction        | 0.0141        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.179        |\n",
      "|    explained_variance   | 0.122         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 273           |\n",
      "|    n_updates            | 660           |\n",
      "|    policy_gradient_loss | -0.00101      |\n",
      "|    value_loss           | 699           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 830         |\n",
      "|    ep_rew_mean          | 3.87e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 710         |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 220         |\n",
      "|    total_timesteps      | 156672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004943853 |\n",
      "|    clip_fraction        | 0.0103      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.168      |\n",
      "|    explained_variance   | 0.0997      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 833         |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | 0.000226    |\n",
      "|    value_loss           | 1.11e+03    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 830           |\n",
      "|    ep_rew_mean          | 3.86e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 710           |\n",
      "|    iterations           | 69            |\n",
      "|    time_elapsed         | 223           |\n",
      "|    total_timesteps      | 158976        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016960237 |\n",
      "|    clip_fraction        | 0.000508      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.144        |\n",
      "|    explained_variance   | 0.191         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 251           |\n",
      "|    n_updates            | 680           |\n",
      "|    policy_gradient_loss | -0.00123      |\n",
      "|    value_loss           | 832           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 832           |\n",
      "|    ep_rew_mean          | 3.86e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 709           |\n",
      "|    iterations           | 70            |\n",
      "|    time_elapsed         | 227           |\n",
      "|    total_timesteps      | 161280        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00019119494 |\n",
      "|    clip_fraction        | 3.91e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.152        |\n",
      "|    explained_variance   | 0.25          |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 396           |\n",
      "|    n_updates            | 690           |\n",
      "|    policy_gradient_loss | 0.00014       |\n",
      "|    value_loss           | 1.07e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 831           |\n",
      "|    ep_rew_mean          | 3.84e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 709           |\n",
      "|    iterations           | 71            |\n",
      "|    time_elapsed         | 230           |\n",
      "|    total_timesteps      | 163584        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00097268017 |\n",
      "|    clip_fraction        | 0.00898       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.161        |\n",
      "|    explained_variance   | 0.335         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 458           |\n",
      "|    n_updates            | 700           |\n",
      "|    policy_gradient_loss | -0.00142      |\n",
      "|    value_loss           | 872           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 823          |\n",
      "|    ep_rew_mean          | 3.79e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 708          |\n",
      "|    iterations           | 72           |\n",
      "|    time_elapsed         | 234          |\n",
      "|    total_timesteps      | 165888       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018081426 |\n",
      "|    clip_fraction        | 0.0345       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.178       |\n",
      "|    explained_variance   | 0.323        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 559          |\n",
      "|    n_updates            | 710          |\n",
      "|    policy_gradient_loss | -0.00177     |\n",
      "|    value_loss           | 873          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 824          |\n",
      "|    ep_rew_mean          | 3.78e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 708          |\n",
      "|    iterations           | 73           |\n",
      "|    time_elapsed         | 237          |\n",
      "|    total_timesteps      | 168192       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023042706 |\n",
      "|    clip_fraction        | 0.0302       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.166       |\n",
      "|    explained_variance   | 0.222        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 629          |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | -0.00345     |\n",
      "|    value_loss           | 1.53e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 826          |\n",
      "|    ep_rew_mean          | 3.79e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 708          |\n",
      "|    iterations           | 74           |\n",
      "|    time_elapsed         | 240          |\n",
      "|    total_timesteps      | 170496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004443017 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.17        |\n",
      "|    explained_variance   | 0.295        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 478          |\n",
      "|    n_updates            | 730          |\n",
      "|    policy_gradient_loss | -0.000301    |\n",
      "|    value_loss           | 911          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 828          |\n",
      "|    ep_rew_mean          | 3.79e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 709          |\n",
      "|    iterations           | 75           |\n",
      "|    time_elapsed         | 243          |\n",
      "|    total_timesteps      | 172800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017708227 |\n",
      "|    clip_fraction        | 0.0209       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.173       |\n",
      "|    explained_variance   | 0.281        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 321          |\n",
      "|    n_updates            | 740          |\n",
      "|    policy_gradient_loss | -0.00184     |\n",
      "|    value_loss           | 1.31e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 825         |\n",
      "|    ep_rew_mean          | 3.78e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 709         |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 246         |\n",
      "|    total_timesteps      | 175104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000872075 |\n",
      "|    clip_fraction        | 0.00277     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.18       |\n",
      "|    explained_variance   | 0.325       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 607         |\n",
      "|    n_updates            | 750         |\n",
      "|    policy_gradient_loss | -0.000879   |\n",
      "|    value_loss           | 919         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 830          |\n",
      "|    ep_rew_mean          | 3.79e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 709          |\n",
      "|    iterations           | 77           |\n",
      "|    time_elapsed         | 250          |\n",
      "|    total_timesteps      | 177408       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007301723 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.173       |\n",
      "|    explained_variance   | 0.168        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 422          |\n",
      "|    n_updates            | 760          |\n",
      "|    policy_gradient_loss | -0.000311    |\n",
      "|    value_loss           | 909          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 825          |\n",
      "|    ep_rew_mean          | 3.76e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 709          |\n",
      "|    iterations           | 78           |\n",
      "|    time_elapsed         | 253          |\n",
      "|    total_timesteps      | 179712       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012217211 |\n",
      "|    clip_fraction        | 0.00172      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.174       |\n",
      "|    explained_variance   | 0.347        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 674          |\n",
      "|    n_updates            | 770          |\n",
      "|    policy_gradient_loss | -0.0001      |\n",
      "|    value_loss           | 874          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 822           |\n",
      "|    ep_rew_mean          | 3.76e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 709           |\n",
      "|    iterations           | 79            |\n",
      "|    time_elapsed         | 256           |\n",
      "|    total_timesteps      | 182016        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00089395774 |\n",
      "|    clip_fraction        | 0.000781      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.179        |\n",
      "|    explained_variance   | 0.218         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 437           |\n",
      "|    n_updates            | 780           |\n",
      "|    policy_gradient_loss | -0.000177     |\n",
      "|    value_loss           | 1.14e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 821           |\n",
      "|    ep_rew_mean          | 3.75e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 709           |\n",
      "|    iterations           | 80            |\n",
      "|    time_elapsed         | 259           |\n",
      "|    total_timesteps      | 184320        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00042804424 |\n",
      "|    clip_fraction        | 0.00391       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.172        |\n",
      "|    explained_variance   | 0.342         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 410           |\n",
      "|    n_updates            | 790           |\n",
      "|    policy_gradient_loss | -0.00129      |\n",
      "|    value_loss           | 857           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 822          |\n",
      "|    ep_rew_mean          | 3.77e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 709          |\n",
      "|    iterations           | 81           |\n",
      "|    time_elapsed         | 263          |\n",
      "|    total_timesteps      | 186624       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016386996 |\n",
      "|    clip_fraction        | 0.00762      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.165       |\n",
      "|    explained_variance   | 0.377        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 869          |\n",
      "|    n_updates            | 800          |\n",
      "|    policy_gradient_loss | -0.00165     |\n",
      "|    value_loss           | 1.05e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 822          |\n",
      "|    ep_rew_mean          | 3.76e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 709          |\n",
      "|    iterations           | 82           |\n",
      "|    time_elapsed         | 266          |\n",
      "|    total_timesteps      | 188928       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021295073 |\n",
      "|    clip_fraction        | 0.0103       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.169       |\n",
      "|    explained_variance   | 0.265        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 449          |\n",
      "|    n_updates            | 810          |\n",
      "|    policy_gradient_loss | -0.00153     |\n",
      "|    value_loss           | 663          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 823         |\n",
      "|    ep_rew_mean          | 3.76e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 709         |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 269         |\n",
      "|    total_timesteps      | 191232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002507345 |\n",
      "|    clip_fraction        | 0.0098      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.177      |\n",
      "|    explained_variance   | 0.296       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 377         |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | 0.000173    |\n",
      "|    value_loss           | 932         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 827          |\n",
      "|    ep_rew_mean          | 3.78e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 708          |\n",
      "|    iterations           | 84           |\n",
      "|    time_elapsed         | 273          |\n",
      "|    total_timesteps      | 193536       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010902109 |\n",
      "|    clip_fraction        | 0.00492      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.177       |\n",
      "|    explained_variance   | 0.345        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 264          |\n",
      "|    n_updates            | 830          |\n",
      "|    policy_gradient_loss | -7.78e-05    |\n",
      "|    value_loss           | 954          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 832           |\n",
      "|    ep_rew_mean          | 3.79e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 708           |\n",
      "|    iterations           | 85            |\n",
      "|    time_elapsed         | 276           |\n",
      "|    total_timesteps      | 195840        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00022548805 |\n",
      "|    clip_fraction        | 0.0134        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.173        |\n",
      "|    explained_variance   | 0.245         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 403           |\n",
      "|    n_updates            | 840           |\n",
      "|    policy_gradient_loss | 0.000149      |\n",
      "|    value_loss           | 642           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 834          |\n",
      "|    ep_rew_mean          | 3.8e+03      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 709          |\n",
      "|    iterations           | 86           |\n",
      "|    time_elapsed         | 279          |\n",
      "|    total_timesteps      | 198144       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009008739 |\n",
      "|    clip_fraction        | 0.0161       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.172       |\n",
      "|    explained_variance   | 0.342        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 256          |\n",
      "|    n_updates            | 850          |\n",
      "|    policy_gradient_loss | -0.00139     |\n",
      "|    value_loss           | 604          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 831          |\n",
      "|    ep_rew_mean          | 3.77e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 709          |\n",
      "|    iterations           | 87           |\n",
      "|    time_elapsed         | 282          |\n",
      "|    total_timesteps      | 200448       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053950856 |\n",
      "|    clip_fraction        | 0.0791       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.211       |\n",
      "|    explained_variance   | 0.292        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 242          |\n",
      "|    n_updates            | 860          |\n",
      "|    policy_gradient_loss | -0.00179     |\n",
      "|    value_loss           | 742          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 823         |\n",
      "|    ep_rew_mean          | 3.71e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 709         |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 285         |\n",
      "|    total_timesteps      | 202752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003935889 |\n",
      "|    clip_fraction        | 0.0669      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.19       |\n",
      "|    explained_variance   | 0.0541      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.1e+03     |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | 0.00368     |\n",
      "|    value_loss           | 1.87e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 816          |\n",
      "|    ep_rew_mean          | 3.67e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 709          |\n",
      "|    iterations           | 89           |\n",
      "|    time_elapsed         | 289          |\n",
      "|    total_timesteps      | 205056       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038655892 |\n",
      "|    clip_fraction        | 0.0345       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.211       |\n",
      "|    explained_variance   | 0.133        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.27e+03     |\n",
      "|    n_updates            | 880          |\n",
      "|    policy_gradient_loss | -0.00652     |\n",
      "|    value_loss           | 2.41e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 805          |\n",
      "|    ep_rew_mean          | 3.62e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 709          |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 292          |\n",
      "|    total_timesteps      | 207360       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035791746 |\n",
      "|    clip_fraction        | 0.0331       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.194       |\n",
      "|    explained_variance   | 0.209        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.01e+03     |\n",
      "|    n_updates            | 890          |\n",
      "|    policy_gradient_loss | -0.00486     |\n",
      "|    value_loss           | 1.76e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 809          |\n",
      "|    ep_rew_mean          | 3.64e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 708          |\n",
      "|    iterations           | 91           |\n",
      "|    time_elapsed         | 295          |\n",
      "|    total_timesteps      | 209664       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004889257 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.19        |\n",
      "|    explained_variance   | 0.342        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 667          |\n",
      "|    n_updates            | 900          |\n",
      "|    policy_gradient_loss | -0.000407    |\n",
      "|    value_loss           | 869          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 797          |\n",
      "|    ep_rew_mean          | 3.58e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 708          |\n",
      "|    iterations           | 92           |\n",
      "|    time_elapsed         | 299          |\n",
      "|    total_timesteps      | 211968       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032854266 |\n",
      "|    clip_fraction        | 0.00887      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.198       |\n",
      "|    explained_variance   | 0.306        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 986          |\n",
      "|    n_updates            | 910          |\n",
      "|    policy_gradient_loss | 2.69e-05     |\n",
      "|    value_loss           | 1.01e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 800         |\n",
      "|    ep_rew_mean          | 3.6e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 708         |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 302         |\n",
      "|    total_timesteps      | 214272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002801152 |\n",
      "|    clip_fraction        | 0.00633     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.192      |\n",
      "|    explained_variance   | 0.149       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 651         |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.00175    |\n",
      "|    value_loss           | 1.13e+03    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 803           |\n",
      "|    ep_rew_mean          | 3.62e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 709           |\n",
      "|    iterations           | 94            |\n",
      "|    time_elapsed         | 305           |\n",
      "|    total_timesteps      | 216576        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00037002104 |\n",
      "|    clip_fraction        | 0.000898      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.186        |\n",
      "|    explained_variance   | 0.268         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 680           |\n",
      "|    n_updates            | 930           |\n",
      "|    policy_gradient_loss | -0.000411     |\n",
      "|    value_loss           | 1.13e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 801          |\n",
      "|    ep_rew_mean          | 3.62e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 709          |\n",
      "|    iterations           | 95           |\n",
      "|    time_elapsed         | 308          |\n",
      "|    total_timesteps      | 218880       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014990501 |\n",
      "|    clip_fraction        | 0.00996      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.181       |\n",
      "|    explained_variance   | 0.307        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 491          |\n",
      "|    n_updates            | 940          |\n",
      "|    policy_gradient_loss | -0.00142     |\n",
      "|    value_loss           | 1.18e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 800           |\n",
      "|    ep_rew_mean          | 3.62e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 709           |\n",
      "|    iterations           | 96            |\n",
      "|    time_elapsed         | 311           |\n",
      "|    total_timesteps      | 221184        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00058665004 |\n",
      "|    clip_fraction        | 0.000898      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.175        |\n",
      "|    explained_variance   | 0.421         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 370           |\n",
      "|    n_updates            | 950           |\n",
      "|    policy_gradient_loss | -0.000547     |\n",
      "|    value_loss           | 859           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 799          |\n",
      "|    ep_rew_mean          | 3.63e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 708          |\n",
      "|    iterations           | 97           |\n",
      "|    time_elapsed         | 315          |\n",
      "|    total_timesteps      | 223488       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011331331 |\n",
      "|    clip_fraction        | 0.00711      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.191       |\n",
      "|    explained_variance   | 0.332        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 624          |\n",
      "|    n_updates            | 960          |\n",
      "|    policy_gradient_loss | -0.000846    |\n",
      "|    value_loss           | 708          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 805           |\n",
      "|    ep_rew_mean          | 3.67e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 708           |\n",
      "|    iterations           | 98            |\n",
      "|    time_elapsed         | 318           |\n",
      "|    total_timesteps      | 225792        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00066915003 |\n",
      "|    clip_fraction        | 0.000664      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.192        |\n",
      "|    explained_variance   | 0.313         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 383           |\n",
      "|    n_updates            | 970           |\n",
      "|    policy_gradient_loss | -0.000678     |\n",
      "|    value_loss           | 948           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 805          |\n",
      "|    ep_rew_mean          | 3.68e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 708          |\n",
      "|    iterations           | 99           |\n",
      "|    time_elapsed         | 321          |\n",
      "|    total_timesteps      | 228096       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005427048 |\n",
      "|    clip_fraction        | 0.0243       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.199       |\n",
      "|    explained_variance   | 0.248        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 240          |\n",
      "|    n_updates            | 980          |\n",
      "|    policy_gradient_loss | 0.000774     |\n",
      "|    value_loss           | 705          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 814         |\n",
      "|    ep_rew_mean          | 3.73e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 708         |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 325         |\n",
      "|    total_timesteps      | 230400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018817842 |\n",
      "|    clip_fraction        | 0.0753      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.207      |\n",
      "|    explained_variance   | 0.0724      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 524         |\n",
      "|    n_updates            | 990         |\n",
      "|    policy_gradient_loss | 0.000881    |\n",
      "|    value_loss           | 1.16e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 820         |\n",
      "|    ep_rew_mean          | 3.75e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 707         |\n",
      "|    iterations           | 101         |\n",
      "|    time_elapsed         | 328         |\n",
      "|    total_timesteps      | 232704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006736605 |\n",
      "|    clip_fraction        | 0.0349      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0885     |\n",
      "|    explained_variance   | 0.0406      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 686         |\n",
      "|    n_updates            | 1000        |\n",
      "|    policy_gradient_loss | 0.0121      |\n",
      "|    value_loss           | 760         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 826         |\n",
      "|    ep_rew_mean          | 3.78e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 707         |\n",
      "|    iterations           | 102         |\n",
      "|    time_elapsed         | 331         |\n",
      "|    total_timesteps      | 235008      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008531412 |\n",
      "|    clip_fraction        | 0.0522      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.173      |\n",
      "|    explained_variance   | 0.13        |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 333         |\n",
      "|    n_updates            | 1010        |\n",
      "|    policy_gradient_loss | -0.00063    |\n",
      "|    value_loss           | 426         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 839         |\n",
      "|    ep_rew_mean          | 3.85e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 707         |\n",
      "|    iterations           | 103         |\n",
      "|    time_elapsed         | 335         |\n",
      "|    total_timesteps      | 237312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012477202 |\n",
      "|    clip_fraction        | 0.0344      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.166      |\n",
      "|    explained_variance   | 0.0688      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 785         |\n",
      "|    n_updates            | 1020        |\n",
      "|    policy_gradient_loss | 0.000835    |\n",
      "|    value_loss           | 698         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 843         |\n",
      "|    ep_rew_mean          | 3.86e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 707         |\n",
      "|    iterations           | 104         |\n",
      "|    time_elapsed         | 338         |\n",
      "|    total_timesteps      | 239616      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019294847 |\n",
      "|    clip_fraction        | 0.0698      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.138      |\n",
      "|    explained_variance   | 0.0478      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 316         |\n",
      "|    n_updates            | 1030        |\n",
      "|    policy_gradient_loss | 0.00543     |\n",
      "|    value_loss           | 814         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 853        |\n",
      "|    ep_rew_mean          | 3.9e+03    |\n",
      "| time/                   |            |\n",
      "|    fps                  | 707        |\n",
      "|    iterations           | 105        |\n",
      "|    time_elapsed         | 341        |\n",
      "|    total_timesteps      | 241920     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33568197 |\n",
      "|    clip_fraction        | 0.129      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.102     |\n",
      "|    explained_variance   | 0.0821     |\n",
      "|    learning_rate        | 0.003      |\n",
      "|    loss                 | 239        |\n",
      "|    n_updates            | 1040       |\n",
      "|    policy_gradient_loss | 0.0185     |\n",
      "|    value_loss           | 460        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 872         |\n",
      "|    ep_rew_mean          | 3.96e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 707         |\n",
      "|    iterations           | 106         |\n",
      "|    time_elapsed         | 345         |\n",
      "|    total_timesteps      | 244224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022188794 |\n",
      "|    clip_fraction        | 0.0317      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0673     |\n",
      "|    explained_variance   | -0.0148     |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 108         |\n",
      "|    n_updates            | 1050        |\n",
      "|    policy_gradient_loss | 0.000427    |\n",
      "|    value_loss           | 510         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 886         |\n",
      "|    ep_rew_mean          | 3.99e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 707         |\n",
      "|    iterations           | 107         |\n",
      "|    time_elapsed         | 348         |\n",
      "|    total_timesteps      | 246528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026961273 |\n",
      "|    clip_fraction        | 0.0357      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0575     |\n",
      "|    explained_variance   | 0.0929      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 246         |\n",
      "|    n_updates            | 1060        |\n",
      "|    policy_gradient_loss | 0.00817     |\n",
      "|    value_loss           | 425         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 902         |\n",
      "|    ep_rew_mean          | 4.04e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 706         |\n",
      "|    iterations           | 108         |\n",
      "|    time_elapsed         | 352         |\n",
      "|    total_timesteps      | 248832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044595324 |\n",
      "|    clip_fraction        | 0.0198      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0399     |\n",
      "|    explained_variance   | 0.342       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 32.3        |\n",
      "|    n_updates            | 1070        |\n",
      "|    policy_gradient_loss | 0.00591     |\n",
      "|    value_loss           | 96.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 917          |\n",
      "|    ep_rew_mean          | 4.08e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 706          |\n",
      "|    iterations           | 109          |\n",
      "|    time_elapsed         | 355          |\n",
      "|    total_timesteps      | 251136       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.906363e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.00235     |\n",
      "|    explained_variance   | 0.439        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 21.7         |\n",
      "|    n_updates            | 1080         |\n",
      "|    policy_gradient_loss | 2.76e-05     |\n",
      "|    value_loss           | 58.7         |\n",
      "------------------------------------------\n",
      "\n",
      "Training with ent_coef=0.01\n",
      "Using cuda device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.3e+03   |\n",
      "|    ep_rew_mean     | -3.66e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 746       |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 3         |\n",
      "|    total_timesteps | 2304      |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.3e+03     |\n",
      "|    ep_rew_mean          | -2.24e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 728         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 4608        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011249681 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.771      |\n",
      "|    explained_variance   | 0.000185    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 2.12e+03    |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    value_loss           | 4.03e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.3e+03      |\n",
      "|    ep_rew_mean          | -1.1e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 723          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 6912         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075602354 |\n",
      "|    clip_fraction        | 0.137        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.757       |\n",
      "|    explained_variance   | -0.00128     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 722          |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0146      |\n",
      "|    value_loss           | 1.4e+03      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.3e+03     |\n",
      "|    ep_rew_mean          | -13.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 718         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 9216        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009077262 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.738      |\n",
      "|    explained_variance   | 0.0212      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 534         |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    value_loss           | 1.27e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 2.3e+03   |\n",
      "|    ep_rew_mean          | 693       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 718       |\n",
      "|    iterations           | 5         |\n",
      "|    time_elapsed         | 16        |\n",
      "|    total_timesteps      | 11520     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0195653 |\n",
      "|    clip_fraction        | 0.147     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.721    |\n",
      "|    explained_variance   | 0.0731    |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 179       |\n",
      "|    n_updates            | 40        |\n",
      "|    policy_gradient_loss | -0.0154   |\n",
      "|    value_loss           | 560       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 2.3e+03   |\n",
      "|    ep_rew_mean          | 1.54e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 717       |\n",
      "|    iterations           | 6         |\n",
      "|    time_elapsed         | 19        |\n",
      "|    total_timesteps      | 13824     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0118186 |\n",
      "|    clip_fraction        | 0.211     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.674    |\n",
      "|    explained_variance   | 0.00319   |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 381       |\n",
      "|    n_updates            | 50        |\n",
      "|    policy_gradient_loss | -0.00357  |\n",
      "|    value_loss           | 1.03e+03  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.2e+03    |\n",
      "|    ep_rew_mean          | 2e+03      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 715        |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 22         |\n",
      "|    total_timesteps      | 16128      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07754375 |\n",
      "|    clip_fraction        | 0.265      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.584     |\n",
      "|    explained_variance   | 0.00772    |\n",
      "|    learning_rate        | 0.003      |\n",
      "|    loss                 | 186        |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | 0.0201     |\n",
      "|    value_loss           | 912        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.99e+03   |\n",
      "|    ep_rew_mean          | 2.47e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 715        |\n",
      "|    iterations           | 8          |\n",
      "|    time_elapsed         | 25         |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00789613 |\n",
      "|    clip_fraction        | 0.111      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.557     |\n",
      "|    explained_variance   | 0.00167    |\n",
      "|    learning_rate        | 0.003      |\n",
      "|    loss                 | 347        |\n",
      "|    n_updates            | 70         |\n",
      "|    policy_gradient_loss | -0.0103    |\n",
      "|    value_loss           | 1.3e+03    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.83e+03    |\n",
      "|    ep_rew_mean          | 2.77e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 715         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 20736       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011365103 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.5        |\n",
      "|    explained_variance   | 1.84e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 328         |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    value_loss           | 1.15e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.63e+03    |\n",
      "|    ep_rew_mean          | 2.97e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 718         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 23040       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009185325 |\n",
      "|    clip_fraction        | 0.0933      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.453      |\n",
      "|    explained_variance   | 1.6e-05     |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 419         |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00674    |\n",
      "|    value_loss           | 1.42e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.49e+03    |\n",
      "|    ep_rew_mean          | 3.08e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 713         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 35          |\n",
      "|    total_timesteps      | 25344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009526234 |\n",
      "|    clip_fraction        | 0.0688      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.398      |\n",
      "|    explained_variance   | 3.05e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 429         |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00786    |\n",
      "|    value_loss           | 1.5e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.37e+03    |\n",
      "|    ep_rew_mean          | 3.1e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 714         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 27648       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008776028 |\n",
      "|    clip_fraction        | 0.0805      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.369      |\n",
      "|    explained_variance   | 2.95e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 444         |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.000924   |\n",
      "|    value_loss           | 1.49e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.24e+03     |\n",
      "|    ep_rew_mean          | 3.06e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 715          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 41           |\n",
      "|    total_timesteps      | 29952        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072226436 |\n",
      "|    clip_fraction        | 0.0835       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.341       |\n",
      "|    explained_variance   | 2.59e-05     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 438          |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00665     |\n",
      "|    value_loss           | 1.49e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | 3.05e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 716         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 45          |\n",
      "|    total_timesteps      | 32256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007859038 |\n",
      "|    clip_fraction        | 0.0537      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.31       |\n",
      "|    explained_variance   | 1.84e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 401         |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.00259    |\n",
      "|    value_loss           | 1.31e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 3.03e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 717         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 48          |\n",
      "|    total_timesteps      | 34560       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013794114 |\n",
      "|    clip_fraction        | 0.0764      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.295      |\n",
      "|    explained_variance   | 2.04e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 428         |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00235    |\n",
      "|    value_loss           | 1.33e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.02e+03    |\n",
      "|    ep_rew_mean          | 2.87e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 718         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011846055 |\n",
      "|    clip_fraction        | 0.0832      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.262      |\n",
      "|    explained_variance   | 1.64e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 306         |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | 0.000271    |\n",
      "|    value_loss           | 1.13e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 953         |\n",
      "|    ep_rew_mean          | 2.74e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 719         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 54          |\n",
      "|    total_timesteps      | 39168       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.066085175 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.235      |\n",
      "|    explained_variance   | 5.78e-06    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1e+03       |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | 0.0107      |\n",
      "|    value_loss           | 1.63e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 922         |\n",
      "|    ep_rew_mean          | 2.75e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 720         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 57          |\n",
      "|    total_timesteps      | 41472       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014434537 |\n",
      "|    clip_fraction        | 0.0905      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.225      |\n",
      "|    explained_variance   | 0.0369      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 689         |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.000452   |\n",
      "|    value_loss           | 1.39e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 902         |\n",
      "|    ep_rew_mean          | 2.78e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 720         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 60          |\n",
      "|    total_timesteps      | 43776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019674113 |\n",
      "|    clip_fraction        | 0.0631      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.231      |\n",
      "|    explained_variance   | 0.08        |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 364         |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | 0.001       |\n",
      "|    value_loss           | 988         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 879         |\n",
      "|    ep_rew_mean          | 2.8e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 720         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 63          |\n",
      "|    total_timesteps      | 46080       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005271479 |\n",
      "|    clip_fraction        | 0.0305      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.234      |\n",
      "|    explained_variance   | 5.88e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 495         |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.00247    |\n",
      "|    value_loss           | 1.07e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 858          |\n",
      "|    ep_rew_mean          | 2.8e+03      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 721          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 67           |\n",
      "|    total_timesteps      | 48384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073747514 |\n",
      "|    clip_fraction        | 0.0441       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.224       |\n",
      "|    explained_variance   | 3.17e-05     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 391          |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00342     |\n",
      "|    value_loss           | 1.06e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 831       |\n",
      "|    ep_rew_mean          | 2.71e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 721       |\n",
      "|    iterations           | 22        |\n",
      "|    time_elapsed         | 70        |\n",
      "|    total_timesteps      | 50688     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3124934 |\n",
      "|    clip_fraction        | 0.108     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.227    |\n",
      "|    explained_variance   | 2.61e-05  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 622       |\n",
      "|    n_updates            | 210       |\n",
      "|    policy_gradient_loss | 0.0133    |\n",
      "|    value_loss           | 1.13e+03  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 819        |\n",
      "|    ep_rew_mean          | 2.71e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 722        |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 73         |\n",
      "|    total_timesteps      | 52992      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08381208 |\n",
      "|    clip_fraction        | 0.211      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.274     |\n",
      "|    explained_variance   | 0.00199    |\n",
      "|    learning_rate        | 0.003      |\n",
      "|    loss                 | 1.29e+03   |\n",
      "|    n_updates            | 220        |\n",
      "|    policy_gradient_loss | 0.0251     |\n",
      "|    value_loss           | 2.45e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 816         |\n",
      "|    ep_rew_mean          | 2.77e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 722         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 76          |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030898187 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.269      |\n",
      "|    explained_variance   | 0.076       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 829         |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | 0.00988     |\n",
      "|    value_loss           | 1.39e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 814         |\n",
      "|    ep_rew_mean          | 2.84e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 722         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 79          |\n",
      "|    total_timesteps      | 57600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005097941 |\n",
      "|    clip_fraction        | 0.0752      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.259      |\n",
      "|    explained_variance   | 0.054       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 684         |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | 0.00152     |\n",
      "|    value_loss           | 1.31e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 809         |\n",
      "|    ep_rew_mean          | 2.89e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 722         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 82          |\n",
      "|    total_timesteps      | 59904       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033819128 |\n",
      "|    clip_fraction        | 0.0582      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.277      |\n",
      "|    explained_variance   | 0.0524      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 348         |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0033     |\n",
      "|    value_loss           | 1.26e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 809         |\n",
      "|    ep_rew_mean          | 2.91e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 722         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 86          |\n",
      "|    total_timesteps      | 62208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.106407546 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.164      |\n",
      "|    explained_variance   | 0.0223      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 950         |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | 0.0065      |\n",
      "|    value_loss           | 1.46e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 796         |\n",
      "|    ep_rew_mean          | 2.89e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 722         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 89          |\n",
      "|    total_timesteps      | 64512       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046893395 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.178      |\n",
      "|    explained_variance   | 0.0517      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 367         |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | 0.00312     |\n",
      "|    value_loss           | 788         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 792         |\n",
      "|    ep_rew_mean          | 2.89e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 723         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 92          |\n",
      "|    total_timesteps      | 66816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021337248 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.2        |\n",
      "|    explained_variance   | 0.0161      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 896         |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | 0.0111      |\n",
      "|    value_loss           | 2.13e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 810       |\n",
      "|    ep_rew_mean          | 2.93e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 722       |\n",
      "|    iterations           | 30        |\n",
      "|    time_elapsed         | 95        |\n",
      "|    total_timesteps      | 69120     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7792135 |\n",
      "|    clip_fraction        | 0.21      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.0957   |\n",
      "|    explained_variance   | 0.031     |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 531       |\n",
      "|    n_updates            | 290       |\n",
      "|    policy_gradient_loss | 0.0357    |\n",
      "|    value_loss           | 1.06e+03  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 827         |\n",
      "|    ep_rew_mean          | 2.97e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 722         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 98          |\n",
      "|    total_timesteps      | 71424       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047790293 |\n",
      "|    clip_fraction        | 0.0729      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0905     |\n",
      "|    explained_variance   | 0.152       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 85.5        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.00774    |\n",
      "|    value_loss           | 332         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 835         |\n",
      "|    ep_rew_mean          | 3e+03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 721         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 102         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018542746 |\n",
      "|    clip_fraction        | 0.0829      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.125      |\n",
      "|    explained_variance   | 0.347       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 31.3        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0098     |\n",
      "|    value_loss           | 81          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 844         |\n",
      "|    ep_rew_mean          | 3.06e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 721         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 105         |\n",
      "|    total_timesteps      | 76032       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001261248 |\n",
      "|    clip_fraction        | 0.0411      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.172      |\n",
      "|    explained_variance   | 0.155       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 223         |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.001      |\n",
      "|    value_loss           | 310         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 847         |\n",
      "|    ep_rew_mean          | 3.09e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 721         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 108         |\n",
      "|    total_timesteps      | 78336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019890849 |\n",
      "|    clip_fraction        | 0.0454      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.193      |\n",
      "|    explained_variance   | 0.115       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 139         |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.00189    |\n",
      "|    value_loss           | 527         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 847         |\n",
      "|    ep_rew_mean          | 3.12e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 720         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 111         |\n",
      "|    total_timesteps      | 80640       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006796853 |\n",
      "|    clip_fraction        | 0.0543      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.215      |\n",
      "|    explained_variance   | 0.0748      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 586         |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | 0.00232     |\n",
      "|    value_loss           | 854         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 848         |\n",
      "|    ep_rew_mean          | 3.14e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 719         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 115         |\n",
      "|    total_timesteps      | 82944       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012632923 |\n",
      "|    clip_fraction        | 0.0661      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.246      |\n",
      "|    explained_variance   | 0.065       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 388         |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.000899   |\n",
      "|    value_loss           | 853         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 846         |\n",
      "|    ep_rew_mean          | 3.16e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 719         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 118         |\n",
      "|    total_timesteps      | 85248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039881755 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.305      |\n",
      "|    explained_variance   | 0.0739      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 117         |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | 0.00367     |\n",
      "|    value_loss           | 650         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 804        |\n",
      "|    ep_rew_mean          | 3.27e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 719        |\n",
      "|    iterations           | 38         |\n",
      "|    time_elapsed         | 121        |\n",
      "|    total_timesteps      | 87552      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.25536373 |\n",
      "|    clip_fraction        | 0.187      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.229     |\n",
      "|    explained_variance   | 0.0425     |\n",
      "|    learning_rate        | 0.003      |\n",
      "|    loss                 | 625        |\n",
      "|    n_updates            | 370        |\n",
      "|    policy_gradient_loss | 0.0257     |\n",
      "|    value_loss           | 998        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 778         |\n",
      "|    ep_rew_mean          | 3.27e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 718         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 124         |\n",
      "|    total_timesteps      | 89856       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021726597 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.257      |\n",
      "|    explained_variance   | 0.0273      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 799         |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.00179    |\n",
      "|    value_loss           | 1.58e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 764         |\n",
      "|    ep_rew_mean          | 3.23e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 719         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 128         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.065794766 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.211      |\n",
      "|    explained_variance   | 0.0439      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 554         |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | 0.0131      |\n",
      "|    value_loss           | 835         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 753         |\n",
      "|    ep_rew_mean          | 3.17e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 719         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 131         |\n",
      "|    total_timesteps      | 94464       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.053949498 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.202      |\n",
      "|    explained_variance   | 0.0585      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 156         |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | 0.0108      |\n",
      "|    value_loss           | 571         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 746         |\n",
      "|    ep_rew_mean          | 3.1e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 719         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 134         |\n",
      "|    total_timesteps      | 96768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018894177 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.245      |\n",
      "|    explained_variance   | 0.0391      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 594         |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | 0.00349     |\n",
      "|    value_loss           | 1.39e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 750         |\n",
      "|    ep_rew_mean          | 3.09e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 719         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 137         |\n",
      "|    total_timesteps      | 99072       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017787823 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.241      |\n",
      "|    explained_variance   | 0.0314      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 708         |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | 0.0189      |\n",
      "|    value_loss           | 1.32e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 744        |\n",
      "|    ep_rew_mean          | 2.83e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 719        |\n",
      "|    iterations           | 44         |\n",
      "|    time_elapsed         | 140        |\n",
      "|    total_timesteps      | 101376     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07419835 |\n",
      "|    clip_fraction        | 0.157      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.241     |\n",
      "|    explained_variance   | 0.0758     |\n",
      "|    learning_rate        | 0.003      |\n",
      "|    loss                 | 215        |\n",
      "|    n_updates            | 430        |\n",
      "|    policy_gradient_loss | 0.0111     |\n",
      "|    value_loss           | 592        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 741        |\n",
      "|    ep_rew_mean          | 2.53e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 719        |\n",
      "|    iterations           | 45         |\n",
      "|    time_elapsed         | 144        |\n",
      "|    total_timesteps      | 103680     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16994475 |\n",
      "|    clip_fraction        | 0.0779     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.104     |\n",
      "|    explained_variance   | 0.00548    |\n",
      "|    learning_rate        | 0.003      |\n",
      "|    loss                 | 8.3e+03    |\n",
      "|    n_updates            | 440        |\n",
      "|    policy_gradient_loss | 0.0534     |\n",
      "|    value_loss           | 2.4e+04    |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 739          |\n",
      "|    ep_rew_mean          | 2.22e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 718          |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 147          |\n",
      "|    total_timesteps      | 105984       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027046346 |\n",
      "|    clip_fraction        | 0.0104       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.132       |\n",
      "|    explained_variance   | 0.0231       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 6.95e+03     |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.000223    |\n",
      "|    value_loss           | 2.39e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 738          |\n",
      "|    ep_rew_mean          | 1.92e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 718          |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 150          |\n",
      "|    total_timesteps      | 108288       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024147336 |\n",
      "|    clip_fraction        | 0.0147       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.131       |\n",
      "|    explained_variance   | 0.0185       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 7.17e+03     |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.00285     |\n",
      "|    value_loss           | 2.11e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 740          |\n",
      "|    ep_rew_mean          | 1.67e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 718          |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 153          |\n",
      "|    total_timesteps      | 110592       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018163379 |\n",
      "|    clip_fraction        | 0.00918      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.121       |\n",
      "|    explained_variance   | 0.0116       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 5.19e+03     |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.00158     |\n",
      "|    value_loss           | 1.71e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 743          |\n",
      "|    ep_rew_mean          | 1.35e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 717          |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 157          |\n",
      "|    total_timesteps      | 112896       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016028464 |\n",
      "|    clip_fraction        | 0.013        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.124       |\n",
      "|    explained_variance   | -1.61e-05    |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 4.9e+03      |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.00198     |\n",
      "|    value_loss           | 1.4e+04      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 741          |\n",
      "|    ep_rew_mean          | 1.08e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 717          |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 160          |\n",
      "|    total_timesteps      | 115200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014150399 |\n",
      "|    clip_fraction        | 0.0174       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.126       |\n",
      "|    explained_variance   | -4.65e-06    |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 5.21e+03     |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.00183     |\n",
      "|    value_loss           | 1.58e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 738         |\n",
      "|    ep_rew_mean          | 790         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 717         |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 163         |\n",
      "|    total_timesteps      | 117504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001263777 |\n",
      "|    clip_fraction        | 0.0151      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.127      |\n",
      "|    explained_variance   | -0.00292    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 4.13e+03    |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.00137    |\n",
      "|    value_loss           | 1.21e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 734          |\n",
      "|    ep_rew_mean          | 439          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 718          |\n",
      "|    iterations           | 52           |\n",
      "|    time_elapsed         | 166          |\n",
      "|    total_timesteps      | 119808       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007629087 |\n",
      "|    clip_fraction        | 0.00434      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.125       |\n",
      "|    explained_variance   | -0.00306     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 3.43e+03     |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | -0.000483    |\n",
      "|    value_loss           | 1.08e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 732          |\n",
      "|    ep_rew_mean          | 170          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 718          |\n",
      "|    iterations           | 53           |\n",
      "|    time_elapsed         | 169          |\n",
      "|    total_timesteps      | 122112       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015489463 |\n",
      "|    clip_fraction        | 0.00895      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.137       |\n",
      "|    explained_variance   | 2.98e-07     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 4.55e+03     |\n",
      "|    n_updates            | 520          |\n",
      "|    policy_gradient_loss | -0.00118     |\n",
      "|    value_loss           | 1.07e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 731          |\n",
      "|    ep_rew_mean          | -104         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 719          |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 172          |\n",
      "|    total_timesteps      | 124416       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017175395 |\n",
      "|    clip_fraction        | 0.0152       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.14        |\n",
      "|    explained_variance   | 2.98e-07     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 3.74e+03     |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | -0.00146     |\n",
      "|    value_loss           | 9.31e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 726          |\n",
      "|    ep_rew_mean          | -374         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 720          |\n",
      "|    iterations           | 55           |\n",
      "|    time_elapsed         | 175          |\n",
      "|    total_timesteps      | 126720       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024525814 |\n",
      "|    clip_fraction        | 0.0227       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.144       |\n",
      "|    explained_variance   | 8.34e-07     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 3.25e+03     |\n",
      "|    n_updates            | 540          |\n",
      "|    policy_gradient_loss | -0.002       |\n",
      "|    value_loss           | 8.66e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 711          |\n",
      "|    ep_rew_mean          | -756         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 720          |\n",
      "|    iterations           | 56           |\n",
      "|    time_elapsed         | 179          |\n",
      "|    total_timesteps      | 129024       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019540547 |\n",
      "|    clip_fraction        | 0.0315       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.155       |\n",
      "|    explained_variance   | -0.000131    |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.89e+03     |\n",
      "|    n_updates            | 550          |\n",
      "|    policy_gradient_loss | -0.00196     |\n",
      "|    value_loss           | 7.05e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 698          |\n",
      "|    ep_rew_mean          | -1.1e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 720          |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 182          |\n",
      "|    total_timesteps      | 131328       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023099587 |\n",
      "|    clip_fraction        | 0.0345       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.169       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.28e+03     |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.00315     |\n",
      "|    value_loss           | 6.94e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 694         |\n",
      "|    ep_rew_mean          | -1.31e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 720         |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 185         |\n",
      "|    total_timesteps      | 133632      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002287867 |\n",
      "|    clip_fraction        | 0.0399      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.182      |\n",
      "|    explained_variance   | 1.79e-07    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 3.5e+03     |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.00308    |\n",
      "|    value_loss           | 6.34e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 670         |\n",
      "|    ep_rew_mean          | -1.59e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 720         |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 188         |\n",
      "|    total_timesteps      | 135936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027025318 |\n",
      "|    clip_fraction        | 0.082       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.205      |\n",
      "|    explained_variance   | 1.79e-07    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 3.99e+03    |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | -0.00372    |\n",
      "|    value_loss           | 5.77e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 664       |\n",
      "|    ep_rew_mean          | -1.62e+03 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 720       |\n",
      "|    iterations           | 60        |\n",
      "|    time_elapsed         | 191       |\n",
      "|    total_timesteps      | 138240    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.8253046 |\n",
      "|    clip_fraction        | 0.246     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.172    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.19e+03  |\n",
      "|    n_updates            | 590       |\n",
      "|    policy_gradient_loss | 0.0683    |\n",
      "|    value_loss           | 7.49e+03  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 647        |\n",
      "|    ep_rew_mean          | -1.69e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 719        |\n",
      "|    iterations           | 61         |\n",
      "|    time_elapsed         | 195        |\n",
      "|    total_timesteps      | 140544     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02235667 |\n",
      "|    clip_fraction        | 0.253      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.175     |\n",
      "|    explained_variance   | 4.17e-07   |\n",
      "|    learning_rate        | 0.003      |\n",
      "|    loss                 | 4.29e+03   |\n",
      "|    n_updates            | 600        |\n",
      "|    policy_gradient_loss | 0.022      |\n",
      "|    value_loss           | 1.13e+04   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 639          |\n",
      "|    ep_rew_mean          | -1.73e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 719          |\n",
      "|    iterations           | 62           |\n",
      "|    time_elapsed         | 198          |\n",
      "|    total_timesteps      | 142848       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014539186 |\n",
      "|    clip_fraction        | 0.0312       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.167       |\n",
      "|    explained_variance   | 5.96e-07     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 5.93e+03     |\n",
      "|    n_updates            | 610          |\n",
      "|    policy_gradient_loss | -0.00151     |\n",
      "|    value_loss           | 1.52e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 633          |\n",
      "|    ep_rew_mean          | -1.78e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 719          |\n",
      "|    iterations           | 63           |\n",
      "|    time_elapsed         | 201          |\n",
      "|    total_timesteps      | 145152       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025135607 |\n",
      "|    clip_fraction        | 0.0517       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.174       |\n",
      "|    explained_variance   | 5.96e-07     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 5.8e+03      |\n",
      "|    n_updates            | 620          |\n",
      "|    policy_gradient_loss | -0.00426     |\n",
      "|    value_loss           | 1.49e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 627          |\n",
      "|    ep_rew_mean          | -1.81e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 718          |\n",
      "|    iterations           | 64           |\n",
      "|    time_elapsed         | 205          |\n",
      "|    total_timesteps      | 147456       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017566069 |\n",
      "|    clip_fraction        | 0.00809      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.16        |\n",
      "|    explained_variance   | 3.58e-07     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 4.75e+03     |\n",
      "|    n_updates            | 630          |\n",
      "|    policy_gradient_loss | -0.0013      |\n",
      "|    value_loss           | 1.22e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 612          |\n",
      "|    ep_rew_mean          | -1.84e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 718          |\n",
      "|    iterations           | 65           |\n",
      "|    time_elapsed         | 208          |\n",
      "|    total_timesteps      | 149760       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019824947 |\n",
      "|    clip_fraction        | 0.0175       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.161       |\n",
      "|    explained_variance   | 8.34e-07     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 5.23e+03     |\n",
      "|    n_updates            | 640          |\n",
      "|    policy_gradient_loss | -0.00182     |\n",
      "|    value_loss           | 1.31e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 598          |\n",
      "|    ep_rew_mean          | -1.85e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 718          |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 211          |\n",
      "|    total_timesteps      | 152064       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017385101 |\n",
      "|    clip_fraction        | 0.0226       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.152       |\n",
      "|    explained_variance   | 5.96e-07     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 5.01e+03     |\n",
      "|    n_updates            | 650          |\n",
      "|    policy_gradient_loss | -0.00209     |\n",
      "|    value_loss           | 1.13e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 589          |\n",
      "|    ep_rew_mean          | -1.81e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 718          |\n",
      "|    iterations           | 67           |\n",
      "|    time_elapsed         | 214          |\n",
      "|    total_timesteps      | 154368       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016957826 |\n",
      "|    clip_fraction        | 0.0361       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.158       |\n",
      "|    explained_variance   | 1.43e-06     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 4.54e+03     |\n",
      "|    n_updates            | 660          |\n",
      "|    policy_gradient_loss | -0.00251     |\n",
      "|    value_loss           | 1.15e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 577          |\n",
      "|    ep_rew_mean          | -1.81e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 718          |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 218          |\n",
      "|    total_timesteps      | 156672       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016092615 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.157       |\n",
      "|    explained_variance   | 1.19e-06     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 4.69e+03     |\n",
      "|    n_updates            | 670          |\n",
      "|    policy_gradient_loss | -0.00105     |\n",
      "|    value_loss           | 1.14e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 578         |\n",
      "|    ep_rew_mean          | -1.57e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 718         |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 221         |\n",
      "|    total_timesteps      | 158976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002255462 |\n",
      "|    clip_fraction        | 0.0286      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.146      |\n",
      "|    explained_variance   | 9.54e-07    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 3.74e+03    |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.00243    |\n",
      "|    value_loss           | 8.81e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 579          |\n",
      "|    ep_rew_mean          | -1.28e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 718          |\n",
      "|    iterations           | 70           |\n",
      "|    time_elapsed         | 224          |\n",
      "|    total_timesteps      | 161280       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017205558 |\n",
      "|    clip_fraction        | 0.0285       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.154       |\n",
      "|    explained_variance   | 2.09e-06     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 3.76e+03     |\n",
      "|    n_updates            | 690          |\n",
      "|    policy_gradient_loss | -0.00206     |\n",
      "|    value_loss           | 9.61e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 576          |\n",
      "|    ep_rew_mean          | -1e+03       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 717          |\n",
      "|    iterations           | 71           |\n",
      "|    time_elapsed         | 227          |\n",
      "|    total_timesteps      | 163584       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017376055 |\n",
      "|    clip_fraction        | 0.0173       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.154       |\n",
      "|    explained_variance   | 1.43e-06     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 3.45e+03     |\n",
      "|    n_updates            | 700          |\n",
      "|    policy_gradient_loss | -0.00182     |\n",
      "|    value_loss           | 8.41e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 577         |\n",
      "|    ep_rew_mean          | -713        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 717         |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 231         |\n",
      "|    total_timesteps      | 165888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002617083 |\n",
      "|    clip_fraction        | 0.0452      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.14       |\n",
      "|    explained_variance   | 1.07e-06    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 2.8e+03     |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.0036     |\n",
      "|    value_loss           | 7.25e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 582          |\n",
      "|    ep_rew_mean          | -477         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 717          |\n",
      "|    iterations           | 73           |\n",
      "|    time_elapsed         | 234          |\n",
      "|    total_timesteps      | 168192       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013830665 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.137       |\n",
      "|    explained_variance   | 2.09e-06     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.89e+03     |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | -0.00123     |\n",
      "|    value_loss           | 7.08e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 582          |\n",
      "|    ep_rew_mean          | -209         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 717          |\n",
      "|    iterations           | 74           |\n",
      "|    time_elapsed         | 237          |\n",
      "|    total_timesteps      | 170496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017328418 |\n",
      "|    clip_fraction        | 0.0228       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.143       |\n",
      "|    explained_variance   | 4.23e-06     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.54e+03     |\n",
      "|    n_updates            | 730          |\n",
      "|    policy_gradient_loss | -0.00188     |\n",
      "|    value_loss           | 6.29e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 587          |\n",
      "|    ep_rew_mean          | 89.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 717          |\n",
      "|    iterations           | 75           |\n",
      "|    time_elapsed         | 240          |\n",
      "|    total_timesteps      | 172800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017182033 |\n",
      "|    clip_fraction        | 0.0331       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.127       |\n",
      "|    explained_variance   | 2.68e-06     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.9e+03      |\n",
      "|    n_updates            | 740          |\n",
      "|    policy_gradient_loss | -0.00378     |\n",
      "|    value_loss           | 5.44e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 591          |\n",
      "|    ep_rew_mean          | 316          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 717          |\n",
      "|    iterations           | 76           |\n",
      "|    time_elapsed         | 244          |\n",
      "|    total_timesteps      | 175104       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015793659 |\n",
      "|    clip_fraction        | 0.0203       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.122       |\n",
      "|    explained_variance   | 5.13e-06     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.04e+03     |\n",
      "|    n_updates            | 750          |\n",
      "|    policy_gradient_loss | -0.00197     |\n",
      "|    value_loss           | 5.38e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 593         |\n",
      "|    ep_rew_mean          | 575         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 717         |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 247         |\n",
      "|    total_timesteps      | 177408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008360412 |\n",
      "|    clip_fraction        | 0.0415      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.138      |\n",
      "|    explained_variance   | 4.4e-05     |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.67e+03    |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.00399    |\n",
      "|    value_loss           | 4.93e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 597          |\n",
      "|    ep_rew_mean          | 854          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 717          |\n",
      "|    iterations           | 78           |\n",
      "|    time_elapsed         | 250          |\n",
      "|    total_timesteps      | 179712       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017576372 |\n",
      "|    clip_fraction        | 0.043        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.118       |\n",
      "|    explained_variance   | 8.34e-07     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.47e+03     |\n",
      "|    n_updates            | 770          |\n",
      "|    policy_gradient_loss | -0.00478     |\n",
      "|    value_loss           | 3.84e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 601          |\n",
      "|    ep_rew_mean          | 1.13e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 717          |\n",
      "|    iterations           | 79           |\n",
      "|    time_elapsed         | 253          |\n",
      "|    total_timesteps      | 182016       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009853275 |\n",
      "|    clip_fraction        | 0.0155       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.113       |\n",
      "|    explained_variance   | 1.19e-06     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.48e+03     |\n",
      "|    n_updates            | 780          |\n",
      "|    policy_gradient_loss | -0.00165     |\n",
      "|    value_loss           | 3.8e+03      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 608           |\n",
      "|    ep_rew_mean          | 1.35e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 717           |\n",
      "|    iterations           | 80            |\n",
      "|    time_elapsed         | 257           |\n",
      "|    total_timesteps      | 184320        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00021475789 |\n",
      "|    clip_fraction        | 0.00168       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.108        |\n",
      "|    explained_variance   | 2.09e-06      |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.18e+03      |\n",
      "|    n_updates            | 790           |\n",
      "|    policy_gradient_loss | -0.00101      |\n",
      "|    value_loss           | 3.52e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 612           |\n",
      "|    ep_rew_mean          | 1.56e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 717           |\n",
      "|    iterations           | 81            |\n",
      "|    time_elapsed         | 260           |\n",
      "|    total_timesteps      | 186624        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00033727998 |\n",
      "|    clip_fraction        | 0.00402       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.105        |\n",
      "|    explained_variance   | 1.97e-06      |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.08e+03      |\n",
      "|    n_updates            | 800           |\n",
      "|    policy_gradient_loss | -0.00115      |\n",
      "|    value_loss           | 3.34e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 619           |\n",
      "|    ep_rew_mean          | 1.83e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 717           |\n",
      "|    iterations           | 82            |\n",
      "|    time_elapsed         | 263           |\n",
      "|    total_timesteps      | 188928        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00095871475 |\n",
      "|    clip_fraction        | 0.00781       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.105        |\n",
      "|    explained_variance   | 2.26e-06      |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 945           |\n",
      "|    n_updates            | 810           |\n",
      "|    policy_gradient_loss | -0.000852     |\n",
      "|    value_loss           | 2.8e+03       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 624          |\n",
      "|    ep_rew_mean          | 2.08e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 717          |\n",
      "|    iterations           | 83           |\n",
      "|    time_elapsed         | 266          |\n",
      "|    total_timesteps      | 191232       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009166499 |\n",
      "|    clip_fraction        | 0.0193       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.109       |\n",
      "|    explained_variance   | 2.03e-06     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 816          |\n",
      "|    n_updates            | 820          |\n",
      "|    policy_gradient_loss | -0.00157     |\n",
      "|    value_loss           | 2.51e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 630          |\n",
      "|    ep_rew_mean          | 2.28e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 717          |\n",
      "|    iterations           | 84           |\n",
      "|    time_elapsed         | 269          |\n",
      "|    total_timesteps      | 193536       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008099227 |\n",
      "|    clip_fraction        | 0.0129       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.102       |\n",
      "|    explained_variance   | 1.25e-06     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 779          |\n",
      "|    n_updates            | 830          |\n",
      "|    policy_gradient_loss | -0.00156     |\n",
      "|    value_loss           | 2.38e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 636           |\n",
      "|    ep_rew_mean          | 2.48e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 717           |\n",
      "|    iterations           | 85            |\n",
      "|    time_elapsed         | 273           |\n",
      "|    total_timesteps      | 195840        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00061232044 |\n",
      "|    clip_fraction        | 0.0148        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0884       |\n",
      "|    explained_variance   | 1.73e-06      |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 751           |\n",
      "|    n_updates            | 840           |\n",
      "|    policy_gradient_loss | -0.000513     |\n",
      "|    value_loss           | 2.26e+03      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 639         |\n",
      "|    ep_rew_mean          | 2.7e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 717         |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 276         |\n",
      "|    total_timesteps      | 198144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011282651 |\n",
      "|    clip_fraction        | 0.021       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.103      |\n",
      "|    explained_variance   | 1.25e-06    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 591         |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | -0.00167    |\n",
      "|    value_loss           | 1.83e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 642         |\n",
      "|    ep_rew_mean          | 2.9e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 717         |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 279         |\n",
      "|    total_timesteps      | 200448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001504455 |\n",
      "|    clip_fraction        | 0.0307      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0995     |\n",
      "|    explained_variance   | 5.96e-07    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 612         |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.00186    |\n",
      "|    value_loss           | 1.73e+03    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 630           |\n",
      "|    ep_rew_mean          | 2.89e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 717           |\n",
      "|    iterations           | 88            |\n",
      "|    time_elapsed         | 282           |\n",
      "|    total_timesteps      | 202752        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00052881177 |\n",
      "|    clip_fraction        | 0.014         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0875       |\n",
      "|    explained_variance   | 8.94e-07      |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 555           |\n",
      "|    n_updates            | 870           |\n",
      "|    policy_gradient_loss | 0.000246      |\n",
      "|    value_loss           | 1.58e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 630           |\n",
      "|    ep_rew_mean          | 2.92e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 717           |\n",
      "|    iterations           | 89            |\n",
      "|    time_elapsed         | 285           |\n",
      "|    total_timesteps      | 205056        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00053017744 |\n",
      "|    clip_fraction        | 0.00988       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0911       |\n",
      "|    explained_variance   | 1.01e-06      |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 530           |\n",
      "|    n_updates            | 880           |\n",
      "|    policy_gradient_loss | 6.4e-05       |\n",
      "|    value_loss           | 1.32e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 630          |\n",
      "|    ep_rew_mean          | 2.94e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 717          |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 289          |\n",
      "|    total_timesteps      | 207360       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012597605 |\n",
      "|    clip_fraction        | 0.00809      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.078       |\n",
      "|    explained_variance   | 6.56e-07     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 569          |\n",
      "|    n_updates            | 890          |\n",
      "|    policy_gradient_loss | -0.000363    |\n",
      "|    value_loss           | 1.3e+03      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 633         |\n",
      "|    ep_rew_mean          | 2.98e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 717         |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 292         |\n",
      "|    total_timesteps      | 209664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007767751 |\n",
      "|    clip_fraction        | 0.0151      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0648     |\n",
      "|    explained_variance   | 7.75e-07    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 335         |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | 0.000174    |\n",
      "|    value_loss           | 1.08e+03    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 638           |\n",
      "|    ep_rew_mean          | 3.01e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 717           |\n",
      "|    iterations           | 92            |\n",
      "|    time_elapsed         | 295           |\n",
      "|    total_timesteps      | 211968        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00097277237 |\n",
      "|    clip_fraction        | 0.00844       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0572       |\n",
      "|    explained_variance   | 5.36e-07      |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 434           |\n",
      "|    n_updates            | 910           |\n",
      "|    policy_gradient_loss | 0.000307      |\n",
      "|    value_loss           | 1.08e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 650          |\n",
      "|    ep_rew_mean          | 3.09e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 717          |\n",
      "|    iterations           | 93           |\n",
      "|    time_elapsed         | 298          |\n",
      "|    total_timesteps      | 214272       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062351143 |\n",
      "|    clip_fraction        | 0.0232       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0362      |\n",
      "|    explained_variance   | 1.13e-06     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 209          |\n",
      "|    n_updates            | 920          |\n",
      "|    policy_gradient_loss | 0.0107       |\n",
      "|    value_loss           | 760          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 653          |\n",
      "|    ep_rew_mean          | 3.12e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 717          |\n",
      "|    iterations           | 94           |\n",
      "|    time_elapsed         | 301          |\n",
      "|    total_timesteps      | 216576       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011127873 |\n",
      "|    clip_fraction        | 0.0802       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0368      |\n",
      "|    explained_variance   | 5.36e-07     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 412          |\n",
      "|    n_updates            | 930          |\n",
      "|    policy_gradient_loss | 0.0434       |\n",
      "|    value_loss           | 987          |\n",
      "------------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 639      |\n",
      "|    ep_rew_mean          | 2.93e+03 |\n",
      "| time/                   |          |\n",
      "|    fps                  | 717      |\n",
      "|    iterations           | 95       |\n",
      "|    time_elapsed         | 305      |\n",
      "|    total_timesteps      | 218880   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.032892 |\n",
      "|    clip_fraction        | 0.0362   |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -0.0448  |\n",
      "|    explained_variance   | 6.56e-07 |\n",
      "|    learning_rate        | 0.003    |\n",
      "|    loss                 | 567      |\n",
      "|    n_updates            | 940      |\n",
      "|    policy_gradient_loss | 0.0105   |\n",
      "|    value_loss           | 1.11e+03 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 610      |\n",
      "|    ep_rew_mean          | 2.24e+03 |\n",
      "| time/                   |          |\n",
      "|    fps                  | 717      |\n",
      "|    iterations           | 96       |\n",
      "|    time_elapsed         | 308      |\n",
      "|    total_timesteps      | 221184   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 2.415153 |\n",
      "|    clip_fraction        | 0.167    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -0.0532  |\n",
      "|    explained_variance   | 5.96e-07 |\n",
      "|    learning_rate        | 0.003    |\n",
      "|    loss                 | 5.38e+03 |\n",
      "|    n_updates            | 950      |\n",
      "|    policy_gradient_loss | 0.115    |\n",
      "|    value_loss           | 1.27e+04 |\n",
      "--------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 584           |\n",
      "|    ep_rew_mean          | 1.53e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 717           |\n",
      "|    iterations           | 97            |\n",
      "|    time_elapsed         | 311           |\n",
      "|    total_timesteps      | 223488        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00061170425 |\n",
      "|    clip_fraction        | 0.00125       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0908       |\n",
      "|    explained_variance   | -3.46e-06     |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 2.4e+04       |\n",
      "|    n_updates            | 960           |\n",
      "|    policy_gradient_loss | -0.000614     |\n",
      "|    value_loss           | 1.1e+05       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 552          |\n",
      "|    ep_rew_mean          | 782          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 717          |\n",
      "|    iterations           | 98           |\n",
      "|    time_elapsed         | 314          |\n",
      "|    total_timesteps      | 225792       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009933809 |\n",
      "|    clip_fraction        | 0.00719      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.079       |\n",
      "|    explained_variance   | -8.85e-05    |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 3.6e+04      |\n",
      "|    n_updates            | 970          |\n",
      "|    policy_gradient_loss | -0.000754    |\n",
      "|    value_loss           | 1e+05        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 520          |\n",
      "|    ep_rew_mean          | 95.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 717          |\n",
      "|    iterations           | 99           |\n",
      "|    time_elapsed         | 318          |\n",
      "|    total_timesteps      | 228096       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.663264e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0746      |\n",
      "|    explained_variance   | 9.45e-05     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 4.87e+04     |\n",
      "|    n_updates            | 980          |\n",
      "|    policy_gradient_loss | 4.95e-06     |\n",
      "|    value_loss           | 1.08e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 491           |\n",
      "|    ep_rew_mean          | -639          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 717           |\n",
      "|    iterations           | 100           |\n",
      "|    time_elapsed         | 321           |\n",
      "|    total_timesteps      | 230400        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016677422 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0753       |\n",
      "|    explained_variance   | -0.000386     |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 4.63e+04      |\n",
      "|    n_updates            | 990           |\n",
      "|    policy_gradient_loss | -1.3e-07      |\n",
      "|    value_loss           | 1.04e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 453           |\n",
      "|    ep_rew_mean          | -1.44e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 717           |\n",
      "|    iterations           | 101           |\n",
      "|    time_elapsed         | 324           |\n",
      "|    total_timesteps      | 232704        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00039805975 |\n",
      "|    clip_fraction        | 0.00207       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0842       |\n",
      "|    explained_variance   | -4.77e-07     |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 4.16e+04      |\n",
      "|    n_updates            | 1000          |\n",
      "|    policy_gradient_loss | -0.000153     |\n",
      "|    value_loss           | 9.99e+04      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 417          |\n",
      "|    ep_rew_mean          | -2.23e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 717          |\n",
      "|    iterations           | 102          |\n",
      "|    time_elapsed         | 327          |\n",
      "|    total_timesteps      | 235008       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009830504 |\n",
      "|    clip_fraction        | 0.00723      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0802      |\n",
      "|    explained_variance   | -3.34e-06    |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 4.51e+04     |\n",
      "|    n_updates            | 1010         |\n",
      "|    policy_gradient_loss | -0.000424    |\n",
      "|    value_loss           | 1.02e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 389           |\n",
      "|    ep_rew_mean          | -2.91e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 717           |\n",
      "|    iterations           | 103           |\n",
      "|    time_elapsed         | 330           |\n",
      "|    total_timesteps      | 237312        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5566544e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0759       |\n",
      "|    explained_variance   | 0.000436      |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 4.18e+04      |\n",
      "|    n_updates            | 1020          |\n",
      "|    policy_gradient_loss | 3.56e-05      |\n",
      "|    value_loss           | 9.18e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 353           |\n",
      "|    ep_rew_mean          | -3.71e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 717           |\n",
      "|    iterations           | 104           |\n",
      "|    time_elapsed         | 334           |\n",
      "|    total_timesteps      | 239616        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00036236335 |\n",
      "|    clip_fraction        | 0.00863       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0818       |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 4.61e+04      |\n",
      "|    n_updates            | 1030          |\n",
      "|    policy_gradient_loss | -0.000735     |\n",
      "|    value_loss           | 9.49e+04      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 308         |\n",
      "|    ep_rew_mean          | -4.55e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 717         |\n",
      "|    iterations           | 105         |\n",
      "|    time_elapsed         | 337         |\n",
      "|    total_timesteps      | 241920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000745932 |\n",
      "|    clip_fraction        | 0.00793     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0753     |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 4.38e+04    |\n",
      "|    n_updates            | 1040        |\n",
      "|    policy_gradient_loss | -0.000674   |\n",
      "|    value_loss           | 9.25e+04    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 269           |\n",
      "|    ep_rew_mean          | -5.26e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 717           |\n",
      "|    iterations           | 106           |\n",
      "|    time_elapsed         | 340           |\n",
      "|    total_timesteps      | 244224        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00061171746 |\n",
      "|    clip_fraction        | 0.00551       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0664       |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 4.31e+04      |\n",
      "|    n_updates            | 1050          |\n",
      "|    policy_gradient_loss | -0.000292     |\n",
      "|    value_loss           | 9.11e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 264           |\n",
      "|    ep_rew_mean          | -5.5e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 717           |\n",
      "|    iterations           | 107           |\n",
      "|    time_elapsed         | 343           |\n",
      "|    total_timesteps      | 246528        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00029630933 |\n",
      "|    clip_fraction        | 0.00516       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0692       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 4.12e+04      |\n",
      "|    n_updates            | 1060          |\n",
      "|    policy_gradient_loss | -0.000672     |\n",
      "|    value_loss           | 8.98e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 264           |\n",
      "|    ep_rew_mean          | -5.49e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 717           |\n",
      "|    iterations           | 108           |\n",
      "|    time_elapsed         | 346           |\n",
      "|    total_timesteps      | 248832        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00049192604 |\n",
      "|    clip_fraction        | 0.00695       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0781       |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 4.14e+04      |\n",
      "|    n_updates            | 1070          |\n",
      "|    policy_gradient_loss | -0.000587     |\n",
      "|    value_loss           | 8.8e+04       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 264          |\n",
      "|    ep_rew_mean          | -5.49e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 717          |\n",
      "|    iterations           | 109          |\n",
      "|    time_elapsed         | 350          |\n",
      "|    total_timesteps      | 251136       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007244969 |\n",
      "|    clip_fraction        | 0.000859     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0739      |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 3.93e+04     |\n",
      "|    n_updates            | 1080         |\n",
      "|    policy_gradient_loss | -0.00024     |\n",
      "|    value_loss           | 8.57e+04     |\n",
      "------------------------------------------\n",
      "\n",
      "=== Final Results ===\n",
      "Entropy: 0.0 | Mean reward: 4969.57 ± 0.04\n",
      "Entropy: 0.001 | Mean reward: 7565.57 ± 0.01\n",
      "Entropy: 0.01 | Mean reward: -5438.40 ± 0.00\n",
      "The best entropy coefficient: 0.001\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from sb3_contrib import MaskablePPO\n",
    "from sb3_contrib.common.maskable.evaluation import evaluate_policy\n",
    "import torch\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from environment3 import LifeStyleEnv\n",
    "from sb3_contrib.common.wrappers import ActionMasker\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "def mask_fn(env: gym.Env) -> np.ndarray:\n",
    "    unwrapped_env = env\n",
    "    while hasattr(unwrapped_env, \"env\"):\n",
    "        unwrapped_env = unwrapped_env.env\n",
    "    return unwrapped_env.action_masks()\n",
    "\n",
    "def make_env():\n",
    "    env = LifeStyleEnv()\n",
    "    env = Monitor(env)\n",
    "    check_env(env, warn=True) \n",
    "    return env \n",
    "\n",
    "lr = 0.003\n",
    "ent_coefs = [0.0, 0.001, 0.01]\n",
    "results = []\n",
    "\n",
    "env = make_env()\n",
    "env = ActionMasker(env, mask_fn)\n",
    "\n",
    "eval_env = make_env()\n",
    "eval_env = ActionMasker(eval_env, mask_fn)\n",
    "\n",
    "for ent_coef in ent_coefs:\n",
    "    print(f\"\\nTraining with ent_coef={ent_coef}\")\n",
    "\n",
    "    model = MaskablePPO(\n",
    "        \"MultiInputPolicy\",\n",
    "        env,\n",
    "        learning_rate=lr,\n",
    "        n_steps=2304,\n",
    "        batch_size=512,\n",
    "        n_epochs=10,\n",
    "        gamma=0.99,\n",
    "        gae_lambda=0.95,\n",
    "        clip_range=0.2,\n",
    "        ent_coef=ent_coef,\n",
    "        vf_coef=0.5,\n",
    "        max_grad_norm=0.5,\n",
    "        verbose=1,\n",
    "        device=device,\n",
    "        policy_kwargs=dict(net_arch=[128, 128])\n",
    "    )\n",
    "\n",
    "    model.learn(total_timesteps=250000)\n",
    "\n",
    "    mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=20)\n",
    "    results.append((ent_coef, mean_reward, std_reward))\n",
    "\n",
    "highest = 0\n",
    "best_entropy_coef = 0.01\n",
    "\n",
    "print(\"\\n=== Final Results ===\")\n",
    "for ent_coef, mean_reward, std_reward in results:\n",
    "    print(f\"Entropy: {ent_coef} | Mean reward: {mean_reward:.2f} ± {std_reward:.2f}\")\n",
    "\n",
    "    if mean_reward > highest:\n",
    "        highest = mean_reward\n",
    "        best_entropy_coef = ent_coef\n",
    "\n",
    "print(f\"The best entropy coefficient: {best_entropy_coef}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e50688e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Using cuda device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.3e+03   |\n",
      "|    ep_rew_mean     | -4.27e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 682       |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 3         |\n",
      "|    total_timesteps | 2304      |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.3e+03     |\n",
      "|    ep_rew_mean          | -1.89e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 682         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 4608        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009501146 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.772      |\n",
      "|    explained_variance   | -0.000495   |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.67e+03    |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0199     |\n",
      "|    value_loss           | 3.76e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5000, episode_reward=5378.82 +/- 0.12\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.3e+03      |\n",
      "|    mean_reward          | 5.38e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 5000         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0107665155 |\n",
      "|    clip_fraction        | 0.143        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.749       |\n",
      "|    explained_variance   | 6.2e-06      |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.05e+03     |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0154      |\n",
      "|    value_loss           | 2.42e+03     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.16e+03 |\n",
      "|    ep_rew_mean     | -220     |\n",
      "| time/              |          |\n",
      "|    fps             | 190      |\n",
      "|    iterations      | 3        |\n",
      "|    time_elapsed    | 36       |\n",
      "|    total_timesteps | 6912     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.2e+03     |\n",
      "|    ep_rew_mean          | 1.12e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 9216        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009506884 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.741      |\n",
      "|    explained_variance   | 0.00847     |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 671         |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    value_loss           | 1.99e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=9551.68 +/- 0.01\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.3e+03     |\n",
      "|    mean_reward          | 9.55e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 10000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009756736 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.718      |\n",
      "|    explained_variance   | 0.000873    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 563         |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    value_loss           | 1.83e+03    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.1e+03  |\n",
      "|    ep_rew_mean     | 1.97e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 166      |\n",
      "|    iterations      | 5        |\n",
      "|    time_elapsed    | 69       |\n",
      "|    total_timesteps | 11520    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.89e+03   |\n",
      "|    ep_rew_mean          | 2.78e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 191        |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 72         |\n",
      "|    total_timesteps      | 13824      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01206303 |\n",
      "|    clip_fraction        | 0.153      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.688     |\n",
      "|    explained_variance   | 0.000122   |\n",
      "|    learning_rate        | 0.003      |\n",
      "|    loss                 | 627        |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | -0.0158    |\n",
      "|    value_loss           | 2e+03      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=15000, episode_reward=10475.30 +/- 0.01\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.3e+03     |\n",
      "|    mean_reward          | 1.05e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 15000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008261872 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.653      |\n",
      "|    explained_variance   | 0.000104    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.02e+03    |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    value_loss           | 2.84e+03    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.7e+03  |\n",
      "|    ep_rew_mean     | 3.02e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 158      |\n",
      "|    iterations      | 7        |\n",
      "|    time_elapsed    | 101      |\n",
      "|    total_timesteps | 16128    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.52e+03    |\n",
      "|    ep_rew_mean          | 3.42e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 176         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 104         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011412831 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.6        |\n",
      "|    explained_variance   | 0.000228    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 966         |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    value_loss           | 2.81e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=4581.58 +/- 0.01\n",
      "Episode length: 960.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 960         |\n",
      "|    mean_reward          | 4.58e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 20000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008565808 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.556      |\n",
      "|    explained_variance   | 0.000156    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.32e+03    |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    value_loss           | 3.74e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 3.66e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 174      |\n",
      "|    iterations      | 9        |\n",
      "|    time_elapsed    | 118      |\n",
      "|    total_timesteps | 20736    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.35e+03    |\n",
      "|    ep_rew_mean          | 3.95e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 189         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 121         |\n",
      "|    total_timesteps      | 23040       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009269834 |\n",
      "|    clip_fraction        | 0.0908      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.512      |\n",
      "|    explained_variance   | 0.000268    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.47e+03    |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00975    |\n",
      "|    value_loss           | 3.95e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=25000, episode_reward=5254.47 +/- 0.00\n",
      "Episode length: 960.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 960         |\n",
      "|    mean_reward          | 5.25e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 25000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017172378 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.475      |\n",
      "|    explained_variance   | 7.66e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.54e+03    |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00772    |\n",
      "|    value_loss           | 4.29e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.26e+03 |\n",
      "|    ep_rew_mean     | 4.07e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 187      |\n",
      "|    iterations      | 11       |\n",
      "|    time_elapsed    | 135      |\n",
      "|    total_timesteps | 25344    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.19e+03    |\n",
      "|    ep_rew_mean          | 4.15e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 199         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 138         |\n",
      "|    total_timesteps      | 27648       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011642848 |\n",
      "|    clip_fraction        | 0.0877      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.419      |\n",
      "|    explained_variance   | 4.62e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.74e+03    |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00659    |\n",
      "|    value_loss           | 4.93e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.14e+03    |\n",
      "|    ep_rew_mean          | 4.22e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 211         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 141         |\n",
      "|    total_timesteps      | 29952       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016023722 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.384      |\n",
      "|    explained_variance   | 3.87e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.93e+03    |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00501    |\n",
      "|    value_loss           | 4.95e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=3421.56 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 552         |\n",
      "|    mean_reward          | 3.42e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 30000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006709603 |\n",
      "|    clip_fraction        | 0.079       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.351      |\n",
      "|    explained_variance   | 2.86e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 2.15e+03    |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0014     |\n",
      "|    value_loss           | 5.49e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.07e+03 |\n",
      "|    ep_rew_mean     | 4.27e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 213      |\n",
      "|    iterations      | 14       |\n",
      "|    time_elapsed    | 150      |\n",
      "|    total_timesteps | 32256    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.02e+03    |\n",
      "|    ep_rew_mean          | 4.25e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 224         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 154         |\n",
      "|    total_timesteps      | 34560       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009467018 |\n",
      "|    clip_fraction        | 0.0811      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.337      |\n",
      "|    explained_variance   | 2.07e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.62e+03    |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | 0.00297     |\n",
      "|    value_loss           | 4.87e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=35000, episode_reward=5092.78 +/- 0.00\n",
      "Episode length: 960.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 960         |\n",
      "|    mean_reward          | 5.09e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 35000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008920923 |\n",
      "|    clip_fraction        | 0.0768      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.337      |\n",
      "|    explained_variance   | 2.13e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.75e+03    |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | 0.0052      |\n",
      "|    value_loss           | 4.48e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 984      |\n",
      "|    ep_rew_mean     | 4.26e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 219      |\n",
      "|    iterations      | 16       |\n",
      "|    time_elapsed    | 167      |\n",
      "|    total_timesteps | 36864    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 964          |\n",
      "|    ep_rew_mean          | 4.29e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 228          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 171          |\n",
      "|    total_timesteps      | 39168        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075491085 |\n",
      "|    clip_fraction        | 0.0719       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.308       |\n",
      "|    explained_variance   | 1.81e-05     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.61e+03     |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00123     |\n",
      "|    value_loss           | 4.13e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=3228.27 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 552         |\n",
      "|    mean_reward          | 3.23e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 40000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005946988 |\n",
      "|    clip_fraction        | 0.0632      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.302      |\n",
      "|    explained_variance   | 1.73e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.25e+03    |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.00106    |\n",
      "|    value_loss           | 3.33e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 935      |\n",
      "|    ep_rew_mean     | 4.3e+03  |\n",
      "| time/              |          |\n",
      "|    fps             | 229      |\n",
      "|    iterations      | 18       |\n",
      "|    time_elapsed    | 180      |\n",
      "|    total_timesteps | 41472    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 908         |\n",
      "|    ep_rew_mean          | 4.27e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 183         |\n",
      "|    total_timesteps      | 43776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009380875 |\n",
      "|    clip_fraction        | 0.0538      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.295      |\n",
      "|    explained_variance   | 1.13e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.3e+03     |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | 0.00195     |\n",
      "|    value_loss           | 3.52e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=45000, episode_reward=4576.79 +/- 0.00\n",
      "Episode length: 960.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 960          |\n",
      "|    mean_reward          | 4.58e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 45000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071582473 |\n",
      "|    clip_fraction        | 0.0755       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.267       |\n",
      "|    explained_variance   | 1.84e-05     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.18e+03     |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | 0.00104      |\n",
      "|    value_loss           | 2.67e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 883      |\n",
      "|    ep_rew_mean     | 4.25e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 233      |\n",
      "|    iterations      | 20       |\n",
      "|    time_elapsed    | 197      |\n",
      "|    total_timesteps | 46080    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 858         |\n",
      "|    ep_rew_mean          | 4.17e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 200         |\n",
      "|    total_timesteps      | 48384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011952983 |\n",
      "|    clip_fraction        | 0.0741      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.267      |\n",
      "|    explained_variance   | 8.77e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.07e+03    |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00156    |\n",
      "|    value_loss           | 3.02e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=5803.94 +/- 0.00\n",
      "Episode length: 960.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 960          |\n",
      "|    mean_reward          | 5.8e+03      |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 50000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043503665 |\n",
      "|    clip_fraction        | 0.0737       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.3         |\n",
      "|    explained_variance   | 0.00826      |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.35e+03     |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.00286     |\n",
      "|    value_loss           | 3.11e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 840      |\n",
      "|    ep_rew_mean     | 4.15e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 236      |\n",
      "|    iterations      | 22       |\n",
      "|    time_elapsed    | 214      |\n",
      "|    total_timesteps | 50688    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 825         |\n",
      "|    ep_rew_mean          | 4.15e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 243         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 217         |\n",
      "|    total_timesteps      | 52992       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004675894 |\n",
      "|    clip_fraction        | 0.0583      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.282      |\n",
      "|    explained_variance   | 0.02        |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.11e+03    |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00461    |\n",
      "|    value_loss           | 3.08e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=55000, episode_reward=4914.01 +/- 0.00\n",
      "Episode length: 960.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 960          |\n",
      "|    mean_reward          | 4.91e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 55000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027573812 |\n",
      "|    clip_fraction        | 0.0449       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.286       |\n",
      "|    explained_variance   | 0.00676      |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.26e+03     |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.00129     |\n",
      "|    value_loss           | 2.89e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 811      |\n",
      "|    ep_rew_mean     | 4.15e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 239      |\n",
      "|    iterations      | 24       |\n",
      "|    time_elapsed    | 231      |\n",
      "|    total_timesteps | 55296    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 811        |\n",
      "|    ep_rew_mean          | 4.21e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 245        |\n",
      "|    iterations           | 25         |\n",
      "|    time_elapsed         | 234        |\n",
      "|    total_timesteps      | 57600      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03241722 |\n",
      "|    clip_fraction        | 0.0539     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.258     |\n",
      "|    explained_variance   | 0.00854    |\n",
      "|    learning_rate        | 0.003      |\n",
      "|    loss                 | 955        |\n",
      "|    n_updates            | 240        |\n",
      "|    policy_gradient_loss | -0.000267  |\n",
      "|    value_loss           | 2.79e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 798         |\n",
      "|    ep_rew_mean          | 4.19e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 237         |\n",
      "|    total_timesteps      | 59904       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032417115 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.257      |\n",
      "|    explained_variance   | 0.000864    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 878         |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | 0.00456     |\n",
      "|    value_loss           | 2.49e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=4576.79 +/- 0.00\n",
      "Episode length: 960.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 960          |\n",
      "|    mean_reward          | 4.58e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 60000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068960353 |\n",
      "|    clip_fraction        | 0.0625       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.232       |\n",
      "|    explained_variance   | 0.00758      |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 967          |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.000353    |\n",
      "|    value_loss           | 2.52e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 794      |\n",
      "|    ep_rew_mean     | 4.2e+03  |\n",
      "| time/              |          |\n",
      "|    fps             | 247      |\n",
      "|    iterations      | 27       |\n",
      "|    time_elapsed    | 251      |\n",
      "|    total_timesteps | 62208    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 791         |\n",
      "|    ep_rew_mean          | 4.22e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 253         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 254         |\n",
      "|    total_timesteps      | 64512       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010205049 |\n",
      "|    clip_fraction        | 0.0602      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.224      |\n",
      "|    explained_variance   | 0.00884     |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 726         |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -3.72e-05   |\n",
      "|    value_loss           | 1.8e+03     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=65000, episode_reward=3302.35 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 3.3e+03      |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 65000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067750597 |\n",
      "|    clip_fraction        | 0.0781       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.222       |\n",
      "|    explained_variance   | 0.0233       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.1e+03      |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.00085     |\n",
      "|    value_loss           | 2.09e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 780      |\n",
      "|    ep_rew_mean     | 4.2e+03  |\n",
      "| time/              |          |\n",
      "|    fps             | 253      |\n",
      "|    iterations      | 29       |\n",
      "|    time_elapsed    | 263      |\n",
      "|    total_timesteps | 66816    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 782         |\n",
      "|    ep_rew_mean          | 4.24e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 259         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 266         |\n",
      "|    total_timesteps      | 69120       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012182542 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.199      |\n",
      "|    explained_variance   | 7.74e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.05e+03    |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | 0.00328     |\n",
      "|    value_loss           | 2.63e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=10123.59 +/- 0.01\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.3e+03     |\n",
      "|    mean_reward          | 1.01e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 70000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.057594728 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.224      |\n",
      "|    explained_variance   | 0.0194      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.14e+03    |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | 0.00545     |\n",
      "|    value_loss           | 2.07e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 793      |\n",
      "|    ep_rew_mean     | 4.3e+03  |\n",
      "| time/              |          |\n",
      "|    fps             | 241      |\n",
      "|    iterations      | 31       |\n",
      "|    time_elapsed    | 295      |\n",
      "|    total_timesteps | 71424    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 804        |\n",
      "|    ep_rew_mean          | 4.36e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 246        |\n",
      "|    iterations           | 32         |\n",
      "|    time_elapsed         | 299        |\n",
      "|    total_timesteps      | 73728      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06377581 |\n",
      "|    clip_fraction        | 0.0749     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0989    |\n",
      "|    explained_variance   | 0.025      |\n",
      "|    learning_rate        | 0.003      |\n",
      "|    loss                 | 123        |\n",
      "|    n_updates            | 310        |\n",
      "|    policy_gradient_loss | 0.0162     |\n",
      "|    value_loss           | 754        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=75000, episode_reward=10123.59 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.3e+03      |\n",
      "|    mean_reward          | 1.01e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 75000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065816357 |\n",
      "|    clip_fraction        | 0.0229       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.105       |\n",
      "|    explained_variance   | 0.0613       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 176          |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.0017      |\n",
      "|    value_loss           | 686          |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 816      |\n",
      "|    ep_rew_mean     | 4.41e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 231      |\n",
      "|    iterations      | 33       |\n",
      "|    time_elapsed    | 328      |\n",
      "|    total_timesteps | 76032    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 824         |\n",
      "|    ep_rew_mean          | 4.45e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 331         |\n",
      "|    total_timesteps      | 78336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008436515 |\n",
      "|    clip_fraction        | 0.0621      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.129      |\n",
      "|    explained_variance   | 0.0511      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 544         |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | 0.0039      |\n",
      "|    value_loss           | 1.3e+03     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=3606.12 +/- 0.08\n",
      "Episode length: 552.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 552       |\n",
      "|    mean_reward          | 3.61e+03  |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 80000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0629777 |\n",
      "|    clip_fraction        | 0.0548    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.128    |\n",
      "|    explained_variance   | 0.0494    |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 1.03e+03  |\n",
      "|    n_updates            | 340       |\n",
      "|    policy_gradient_loss | 0.00206   |\n",
      "|    value_loss           | 1.92e+03  |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 806      |\n",
      "|    ep_rew_mean     | 4.33e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 236      |\n",
      "|    iterations      | 35       |\n",
      "|    time_elapsed    | 340      |\n",
      "|    total_timesteps | 80640    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 723          |\n",
      "|    ep_rew_mean          | 4.34e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 343          |\n",
      "|    total_timesteps      | 82944        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017376099 |\n",
      "|    clip_fraction        | 0.0813       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.154       |\n",
      "|    explained_variance   | -0.00641     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.94e+03     |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.00578     |\n",
      "|    value_loss           | 3.98e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=85000, episode_reward=10123.59 +/- 0.01\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.3e+03      |\n",
      "|    mean_reward          | 1.01e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 85000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028174266 |\n",
      "|    clip_fraction        | 0.037        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.151       |\n",
      "|    explained_variance   | 0.0176       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.91e+03     |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.00396     |\n",
      "|    value_loss           | 3.84e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 688      |\n",
      "|    ep_rew_mean     | 4.24e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 228      |\n",
      "|    iterations      | 37       |\n",
      "|    time_elapsed    | 372      |\n",
      "|    total_timesteps | 85248    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 673          |\n",
      "|    ep_rew_mean          | 4.19e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 232          |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 375          |\n",
      "|    total_timesteps      | 87552        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034170114 |\n",
      "|    clip_fraction        | 0.0721       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.147       |\n",
      "|    explained_variance   | 0.0322       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.81e+03     |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.0053      |\n",
      "|    value_loss           | 3.51e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 660          |\n",
      "|    ep_rew_mean          | 4.12e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 237          |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 379          |\n",
      "|    total_timesteps      | 89856        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069698244 |\n",
      "|    clip_fraction        | 0.0327       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.157       |\n",
      "|    explained_variance   | 0.0472       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.01e+03     |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | 0.000737     |\n",
      "|    value_loss           | 2.17e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=10123.59 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.3e+03      |\n",
      "|    mean_reward          | 1.01e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 90000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065458594 |\n",
      "|    clip_fraction        | 0.129        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.13        |\n",
      "|    explained_variance   | 0.0431       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.97e+03     |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | 0.00903      |\n",
      "|    value_loss           | 2.44e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 656      |\n",
      "|    ep_rew_mean     | 4.1e+03  |\n",
      "| time/              |          |\n",
      "|    fps             | 225      |\n",
      "|    iterations      | 40       |\n",
      "|    time_elapsed    | 408      |\n",
      "|    total_timesteps | 92160    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 649          |\n",
      "|    ep_rew_mean          | 4.03e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 229          |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 411          |\n",
      "|    total_timesteps      | 94464        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019104462 |\n",
      "|    clip_fraction        | 0.112        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.135       |\n",
      "|    explained_variance   | 0.0681       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 707          |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | 0.00665      |\n",
      "|    value_loss           | 1.87e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=95000, episode_reward=10123.59 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.3e+03     |\n",
      "|    mean_reward          | 1.01e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 95000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020276006 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.126      |\n",
      "|    explained_variance   | 0.0357      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.7e+03     |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | 0.00919     |\n",
      "|    value_loss           | 2.88e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 658      |\n",
      "|    ep_rew_mean     | 4.06e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 219      |\n",
      "|    iterations      | 42       |\n",
      "|    time_elapsed    | 440      |\n",
      "|    total_timesteps | 96768    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 660          |\n",
      "|    ep_rew_mean          | 4.06e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 223          |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 444          |\n",
      "|    total_timesteps      | 99072        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060854075 |\n",
      "|    clip_fraction        | 0.0619       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.142       |\n",
      "|    explained_variance   | 0.0594       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 752          |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.00269     |\n",
      "|    value_loss           | 1.37e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=10123.59 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.3e+03      |\n",
      "|    mean_reward          | 1.01e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 100000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010684334 |\n",
      "|    clip_fraction        | 0.0552       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.137       |\n",
      "|    explained_variance   | 0.0457       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 563          |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | 0.00162      |\n",
      "|    value_loss           | 1.9e+03      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 663      |\n",
      "|    ep_rew_mean     | 4.06e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 214      |\n",
      "|    iterations      | 44       |\n",
      "|    time_elapsed    | 473      |\n",
      "|    total_timesteps | 101376   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 658         |\n",
      "|    ep_rew_mean          | 4.01e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 217         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 476         |\n",
      "|    total_timesteps      | 103680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011423231 |\n",
      "|    clip_fraction        | 0.0482      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.152      |\n",
      "|    explained_variance   | 0.0639      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.12e+03    |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00158    |\n",
      "|    value_loss           | 1.96e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=105000, episode_reward=3606.12 +/- 0.08\n",
      "Episode length: 552.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 552         |\n",
      "|    mean_reward          | 3.61e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 105000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004262341 |\n",
      "|    clip_fraction        | 0.0389      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.156      |\n",
      "|    explained_variance   | 0.0362      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.77e+03    |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | 0.000509    |\n",
      "|    value_loss           | 3.2e+03     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 652      |\n",
      "|    ep_rew_mean     | 3.96e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 218      |\n",
      "|    iterations      | 46       |\n",
      "|    time_elapsed    | 485      |\n",
      "|    total_timesteps | 105984   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 647          |\n",
      "|    ep_rew_mean          | 3.91e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 221          |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 488          |\n",
      "|    total_timesteps      | 108288       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023339528 |\n",
      "|    clip_fraction        | 0.0762       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.139       |\n",
      "|    explained_variance   | 0.0509       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.14e+03     |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | 0.0061       |\n",
      "|    value_loss           | 2.9e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=110000, episode_reward=3606.15 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 552         |\n",
      "|    mean_reward          | 3.61e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 110000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002441787 |\n",
      "|    clip_fraction        | 0.00414     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.152      |\n",
      "|    explained_variance   | 0.0441      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.52e+03    |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.000517   |\n",
      "|    value_loss           | 3.01e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 644      |\n",
      "|    ep_rew_mean     | 3.88e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 222      |\n",
      "|    iterations      | 48       |\n",
      "|    time_elapsed    | 497      |\n",
      "|    total_timesteps | 110592   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 645          |\n",
      "|    ep_rew_mean          | 3.88e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 225          |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 500          |\n",
      "|    total_timesteps      | 112896       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029635667 |\n",
      "|    clip_fraction        | 0.066        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.146       |\n",
      "|    explained_variance   | 0.102        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.25e+03     |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.00309     |\n",
      "|    value_loss           | 2.57e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=115000, episode_reward=10123.59 +/- 0.01\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.3e+03      |\n",
      "|    mean_reward          | 1.01e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 115000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001466845 |\n",
      "|    clip_fraction        | 0.0117       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.148       |\n",
      "|    explained_variance   | 0.147        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.08e+03     |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.000295    |\n",
      "|    value_loss           | 2.75e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 643      |\n",
      "|    ep_rew_mean     | 3.87e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 217      |\n",
      "|    iterations      | 50       |\n",
      "|    time_elapsed    | 530      |\n",
      "|    total_timesteps | 115200   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 638          |\n",
      "|    ep_rew_mean          | 3.81e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 220          |\n",
      "|    iterations           | 51           |\n",
      "|    time_elapsed         | 533          |\n",
      "|    total_timesteps      | 117504       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.778513e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.153       |\n",
      "|    explained_variance   | 0.137        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.14e+03     |\n",
      "|    n_updates            | 500          |\n",
      "|    policy_gradient_loss | -3.57e-05    |\n",
      "|    value_loss           | 2.73e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 637          |\n",
      "|    ep_rew_mean          | 3.79e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 223          |\n",
      "|    iterations           | 52           |\n",
      "|    time_elapsed         | 536          |\n",
      "|    total_timesteps      | 119808       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031548783 |\n",
      "|    clip_fraction        | 0.00836      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.145       |\n",
      "|    explained_variance   | 0.138        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.09e+03     |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | -0.00143     |\n",
      "|    value_loss           | 3.15e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=120000, episode_reward=10123.59 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.3e+03      |\n",
      "|    mean_reward          | 1.01e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 120000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003203791 |\n",
      "|    clip_fraction        | 0.000469     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.154       |\n",
      "|    explained_variance   | 0.156        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 965          |\n",
      "|    n_updates            | 520          |\n",
      "|    policy_gradient_loss | -0.000207    |\n",
      "|    value_loss           | 2.45e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 633      |\n",
      "|    ep_rew_mean     | 3.75e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 215      |\n",
      "|    iterations      | 53       |\n",
      "|    time_elapsed    | 565      |\n",
      "|    total_timesteps | 122112   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 630          |\n",
      "|    ep_rew_mean          | 3.73e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 218          |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 568          |\n",
      "|    total_timesteps      | 124416       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.924212e-05 |\n",
      "|    clip_fraction        | 0.00043      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.149       |\n",
      "|    explained_variance   | 0.134        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.11e+03     |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | -0.000345    |\n",
      "|    value_loss           | 2.53e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=125000, episode_reward=10123.59 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.3e+03      |\n",
      "|    mean_reward          | 1.01e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 125000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023259413 |\n",
      "|    clip_fraction        | 0.00574      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.137       |\n",
      "|    explained_variance   | 0.135        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.31e+03     |\n",
      "|    n_updates            | 540          |\n",
      "|    policy_gradient_loss | -0.00065     |\n",
      "|    value_loss           | 2.48e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 630      |\n",
      "|    ep_rew_mean     | 3.72e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 212      |\n",
      "|    iterations      | 55       |\n",
      "|    time_elapsed    | 597      |\n",
      "|    total_timesteps | 126720   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 629          |\n",
      "|    ep_rew_mean          | 3.71e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 214          |\n",
      "|    iterations           | 56           |\n",
      "|    time_elapsed         | 600          |\n",
      "|    total_timesteps      | 129024       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049135587 |\n",
      "|    clip_fraction        | 0.0453       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.152       |\n",
      "|    explained_variance   | 0.17         |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.7e+03      |\n",
      "|    n_updates            | 550          |\n",
      "|    policy_gradient_loss | -0.00412     |\n",
      "|    value_loss           | 2.11e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=130000, episode_reward=10123.59 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.3e+03      |\n",
      "|    mean_reward          | 1.01e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 130000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013572725 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.144       |\n",
      "|    explained_variance   | 0.106        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.42e+03     |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.000562    |\n",
      "|    value_loss           | 2.52e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 625      |\n",
      "|    ep_rew_mean     | 3.67e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 208      |\n",
      "|    iterations      | 57       |\n",
      "|    time_elapsed    | 629      |\n",
      "|    total_timesteps | 131328   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 592           |\n",
      "|    ep_rew_mean          | 3.53e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 211           |\n",
      "|    iterations           | 58            |\n",
      "|    time_elapsed         | 632           |\n",
      "|    total_timesteps      | 133632        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.7353406e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.144        |\n",
      "|    explained_variance   | 0.153         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 611           |\n",
      "|    n_updates            | 570           |\n",
      "|    policy_gradient_loss | -0.000103     |\n",
      "|    value_loss           | 2.31e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=135000, episode_reward=10123.59 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 2.3e+03       |\n",
      "|    mean_reward          | 1.01e+04      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 135000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00061210647 |\n",
      "|    clip_fraction        | 0.000859      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.134        |\n",
      "|    explained_variance   | 0.166         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 860           |\n",
      "|    n_updates            | 580           |\n",
      "|    policy_gradient_loss | 0.000288      |\n",
      "|    value_loss           | 1.96e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 576      |\n",
      "|    ep_rew_mean     | 3.47e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 205      |\n",
      "|    iterations      | 59       |\n",
      "|    time_elapsed    | 662      |\n",
      "|    total_timesteps | 135936   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 581          |\n",
      "|    ep_rew_mean          | 3.52e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 207          |\n",
      "|    iterations           | 60           |\n",
      "|    time_elapsed         | 665          |\n",
      "|    total_timesteps      | 138240       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030647304 |\n",
      "|    clip_fraction        | 0.0276       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.144       |\n",
      "|    explained_variance   | 0.159        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.33e+03     |\n",
      "|    n_updates            | 590          |\n",
      "|    policy_gradient_loss | -0.00183     |\n",
      "|    value_loss           | 2.57e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=140000, episode_reward=6687.82 +/- 0.02\n",
      "Episode length: 960.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 960          |\n",
      "|    mean_reward          | 6.69e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 140000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035776116 |\n",
      "|    clip_fraction        | 0.0186       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.145       |\n",
      "|    explained_variance   | 0.162        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.03e+03     |\n",
      "|    n_updates            | 600          |\n",
      "|    policy_gradient_loss | -0.00092     |\n",
      "|    value_loss           | 2.26e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 584      |\n",
      "|    ep_rew_mean     | 3.59e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 206      |\n",
      "|    iterations      | 61       |\n",
      "|    time_elapsed    | 679      |\n",
      "|    total_timesteps | 140544   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 588         |\n",
      "|    ep_rew_mean          | 3.64e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 209         |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 682         |\n",
      "|    total_timesteps      | 142848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002295864 |\n",
      "|    clip_fraction        | 0.0206      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.141      |\n",
      "|    explained_variance   | 0.157       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.78e+03    |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.0017     |\n",
      "|    value_loss           | 3.23e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=145000, episode_reward=10123.59 +/- 0.01\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.3e+03      |\n",
      "|    mean_reward          | 1.01e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 145000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030723927 |\n",
      "|    clip_fraction        | 0.00691      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.138       |\n",
      "|    explained_variance   | 0.187        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.06e+03     |\n",
      "|    n_updates            | 620          |\n",
      "|    policy_gradient_loss | -0.00111     |\n",
      "|    value_loss           | 2.41e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 597      |\n",
      "|    ep_rew_mean     | 3.7e+03  |\n",
      "| time/              |          |\n",
      "|    fps             | 204      |\n",
      "|    iterations      | 63       |\n",
      "|    time_elapsed    | 711      |\n",
      "|    total_timesteps | 145152   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 598          |\n",
      "|    ep_rew_mean          | 3.72e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 206          |\n",
      "|    iterations           | 64           |\n",
      "|    time_elapsed         | 714          |\n",
      "|    total_timesteps      | 147456       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014216828 |\n",
      "|    clip_fraction        | 0.0109       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.142       |\n",
      "|    explained_variance   | 0.217        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 723          |\n",
      "|    n_updates            | 630          |\n",
      "|    policy_gradient_loss | -0.000637    |\n",
      "|    value_loss           | 1.87e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 597          |\n",
      "|    ep_rew_mean          | 3.73e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 208          |\n",
      "|    iterations           | 65           |\n",
      "|    time_elapsed         | 717          |\n",
      "|    total_timesteps      | 149760       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016967828 |\n",
      "|    clip_fraction        | 0.00125      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.138       |\n",
      "|    explained_variance   | 0.17         |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.21e+03     |\n",
      "|    n_updates            | 640          |\n",
      "|    policy_gradient_loss | -0.000738    |\n",
      "|    value_loss           | 2.66e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=150000, episode_reward=4447.08 +/- 0.07\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 150000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014855627 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.144       |\n",
      "|    explained_variance   | 0.169        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.1e+03      |\n",
      "|    n_updates            | 650          |\n",
      "|    policy_gradient_loss | -0.000151    |\n",
      "|    value_loss           | 2.76e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 593      |\n",
      "|    ep_rew_mean     | 3.7e+03  |\n",
      "| time/              |          |\n",
      "|    fps             | 209      |\n",
      "|    iterations      | 66       |\n",
      "|    time_elapsed    | 727      |\n",
      "|    total_timesteps | 152064   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 588          |\n",
      "|    ep_rew_mean          | 3.68e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 211          |\n",
      "|    iterations           | 67           |\n",
      "|    time_elapsed         | 730          |\n",
      "|    total_timesteps      | 154368       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008030863 |\n",
      "|    clip_fraction        | 0.0428       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.137       |\n",
      "|    explained_variance   | 0.19         |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 982          |\n",
      "|    n_updates            | 660          |\n",
      "|    policy_gradient_loss | -0.000834    |\n",
      "|    value_loss           | 3.22e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=155000, episode_reward=6687.82 +/- 0.00\n",
      "Episode length: 960.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 960           |\n",
      "|    mean_reward          | 6.69e+03      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 155000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020033443 |\n",
      "|    clip_fraction        | 0.000391      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.137        |\n",
      "|    explained_variance   | 0.213         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.45e+03      |\n",
      "|    n_updates            | 670           |\n",
      "|    policy_gradient_loss | -0.000657     |\n",
      "|    value_loss           | 2.72e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 577      |\n",
      "|    ep_rew_mean     | 3.64e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 210      |\n",
      "|    iterations      | 68       |\n",
      "|    time_elapsed    | 744      |\n",
      "|    total_timesteps | 156672   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 576          |\n",
      "|    ep_rew_mean          | 3.64e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 212          |\n",
      "|    iterations           | 69           |\n",
      "|    time_elapsed         | 747          |\n",
      "|    total_timesteps      | 158976       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033459128 |\n",
      "|    clip_fraction        | 0.0109       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.136       |\n",
      "|    explained_variance   | 0.163        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.16e+03     |\n",
      "|    n_updates            | 680          |\n",
      "|    policy_gradient_loss | -0.000932    |\n",
      "|    value_loss           | 2.75e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=6687.82 +/- 0.00\n",
      "Episode length: 960.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 960          |\n",
      "|    mean_reward          | 6.69e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 160000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017853689 |\n",
      "|    clip_fraction        | 0.00547      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.139       |\n",
      "|    explained_variance   | 0.223        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 754          |\n",
      "|    n_updates            | 690          |\n",
      "|    policy_gradient_loss | -0.000694    |\n",
      "|    value_loss           | 2.21e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 576      |\n",
      "|    ep_rew_mean     | 3.66e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 211      |\n",
      "|    iterations      | 70       |\n",
      "|    time_elapsed    | 761      |\n",
      "|    total_timesteps | 161280   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 577          |\n",
      "|    ep_rew_mean          | 3.67e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 213          |\n",
      "|    iterations           | 71           |\n",
      "|    time_elapsed         | 764          |\n",
      "|    total_timesteps      | 163584       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045306426 |\n",
      "|    clip_fraction        | 0.0471       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.143       |\n",
      "|    explained_variance   | 0.162        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.77e+03     |\n",
      "|    n_updates            | 700          |\n",
      "|    policy_gradient_loss | -0.00111     |\n",
      "|    value_loss           | 2.93e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=165000, episode_reward=6687.82 +/- 0.00\n",
      "Episode length: 960.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 960          |\n",
      "|    mean_reward          | 6.69e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 165000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013747832 |\n",
      "|    clip_fraction        | 0.00238      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.135       |\n",
      "|    explained_variance   | 0.21         |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.07e+03     |\n",
      "|    n_updates            | 710          |\n",
      "|    policy_gradient_loss | -0.000371    |\n",
      "|    value_loss           | 2.61e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 579      |\n",
      "|    ep_rew_mean     | 3.7e+03  |\n",
      "| time/              |          |\n",
      "|    fps             | 213      |\n",
      "|    iterations      | 72       |\n",
      "|    time_elapsed    | 778      |\n",
      "|    total_timesteps | 165888   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 578          |\n",
      "|    ep_rew_mean          | 3.7e+03      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 215          |\n",
      "|    iterations           | 73           |\n",
      "|    time_elapsed         | 781          |\n",
      "|    total_timesteps      | 168192       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042699506 |\n",
      "|    clip_fraction        | 0.0314       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.142       |\n",
      "|    explained_variance   | 0.189        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 973          |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | -0.000702    |\n",
      "|    value_loss           | 2.42e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=170000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 170000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017794861 |\n",
      "|    clip_fraction        | 0.0164       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.132       |\n",
      "|    explained_variance   | 0.127        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.28e+03     |\n",
      "|    n_updates            | 730          |\n",
      "|    policy_gradient_loss | -0.00138     |\n",
      "|    value_loss           | 3.37e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 578      |\n",
      "|    ep_rew_mean     | 3.7e+03  |\n",
      "| time/              |          |\n",
      "|    fps             | 215      |\n",
      "|    iterations      | 74       |\n",
      "|    time_elapsed    | 791      |\n",
      "|    total_timesteps | 170496   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 579           |\n",
      "|    ep_rew_mean          | 3.71e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 217           |\n",
      "|    iterations           | 75            |\n",
      "|    time_elapsed         | 794           |\n",
      "|    total_timesteps      | 172800        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00048161455 |\n",
      "|    clip_fraction        | 0.00109       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.133        |\n",
      "|    explained_variance   | 0.2           |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.64e+03      |\n",
      "|    n_updates            | 740           |\n",
      "|    policy_gradient_loss | -0.000136     |\n",
      "|    value_loss           | 2.47e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=175000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 175000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009776641 |\n",
      "|    clip_fraction        | 0.00602      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.137       |\n",
      "|    explained_variance   | 0.222        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.53e+03     |\n",
      "|    n_updates            | 750          |\n",
      "|    policy_gradient_loss | -0.00034     |\n",
      "|    value_loss           | 2.66e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 579      |\n",
      "|    ep_rew_mean     | 3.72e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 217      |\n",
      "|    iterations      | 76       |\n",
      "|    time_elapsed    | 803      |\n",
      "|    total_timesteps | 175104   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 575          |\n",
      "|    ep_rew_mean          | 3.71e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 219          |\n",
      "|    iterations           | 77           |\n",
      "|    time_elapsed         | 806          |\n",
      "|    total_timesteps      | 177408       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.950461e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.135       |\n",
      "|    explained_variance   | 0.206        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.52e+03     |\n",
      "|    n_updates            | 760          |\n",
      "|    policy_gradient_loss | 1.41e-05     |\n",
      "|    value_loss           | 2.5e+03      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 574           |\n",
      "|    ep_rew_mean          | 3.7e+03       |\n",
      "| time/                   |               |\n",
      "|    fps                  | 221           |\n",
      "|    iterations           | 78            |\n",
      "|    time_elapsed         | 809           |\n",
      "|    total_timesteps      | 179712        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00018519419 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.141        |\n",
      "|    explained_variance   | 0.218         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.03e+03      |\n",
      "|    n_updates            | 770           |\n",
      "|    policy_gradient_loss | -3.11e-05     |\n",
      "|    value_loss           | 3.45e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=180000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 552           |\n",
      "|    mean_reward          | 4.45e+03      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 180000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00039292444 |\n",
      "|    clip_fraction        | 0.0581        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.129        |\n",
      "|    explained_variance   | 0.217         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 818           |\n",
      "|    n_updates            | 780           |\n",
      "|    policy_gradient_loss | 0.000558      |\n",
      "|    value_loss           | 2.79e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 572      |\n",
      "|    ep_rew_mean     | 3.7e+03  |\n",
      "| time/              |          |\n",
      "|    fps             | 222      |\n",
      "|    iterations      | 79       |\n",
      "|    time_elapsed    | 819      |\n",
      "|    total_timesteps | 182016   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 564          |\n",
      "|    ep_rew_mean          | 3.64e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 224          |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 822          |\n",
      "|    total_timesteps      | 184320       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014948323 |\n",
      "|    clip_fraction        | 0.0052       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.14        |\n",
      "|    explained_variance   | 0.259        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.38e+03     |\n",
      "|    n_updates            | 790          |\n",
      "|    policy_gradient_loss | -0.00106     |\n",
      "|    value_loss           | 2.62e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=185000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 185000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013632344 |\n",
      "|    clip_fraction        | 0.0421       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.128       |\n",
      "|    explained_variance   | 0.193        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.81e+03     |\n",
      "|    n_updates            | 800          |\n",
      "|    policy_gradient_loss | -0.00194     |\n",
      "|    value_loss           | 3.7e+03      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 559      |\n",
      "|    ep_rew_mean     | 3.63e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 224      |\n",
      "|    iterations      | 81       |\n",
      "|    time_elapsed    | 831      |\n",
      "|    total_timesteps | 186624   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 553          |\n",
      "|    ep_rew_mean          | 3.59e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 226          |\n",
      "|    iterations           | 82           |\n",
      "|    time_elapsed         | 834          |\n",
      "|    total_timesteps      | 188928       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003780514 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.137       |\n",
      "|    explained_variance   | 0.248        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.58e+03     |\n",
      "|    n_updates            | 810          |\n",
      "|    policy_gradient_loss | -0.000454    |\n",
      "|    value_loss           | 3.1e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=190000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 190000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.065971e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.135       |\n",
      "|    explained_variance   | 0.19         |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.39e+03     |\n",
      "|    n_updates            | 820          |\n",
      "|    policy_gradient_loss | -1.88e-05    |\n",
      "|    value_loss           | 2.83e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 546      |\n",
      "|    ep_rew_mean     | 3.55e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 226      |\n",
      "|    iterations      | 83       |\n",
      "|    time_elapsed    | 844      |\n",
      "|    total_timesteps | 191232   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 544          |\n",
      "|    ep_rew_mean          | 3.54e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 228          |\n",
      "|    iterations           | 84           |\n",
      "|    time_elapsed         | 847          |\n",
      "|    total_timesteps      | 193536       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019591388 |\n",
      "|    clip_fraction        | 0.0279       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.132       |\n",
      "|    explained_variance   | 0.232        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.02e+03     |\n",
      "|    n_updates            | 830          |\n",
      "|    policy_gradient_loss | -0.0026      |\n",
      "|    value_loss           | 3.27e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=195000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 552           |\n",
      "|    mean_reward          | 4.45e+03      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 195000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00041849888 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.139        |\n",
      "|    explained_variance   | 0.267         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.56e+03      |\n",
      "|    n_updates            | 840           |\n",
      "|    policy_gradient_loss | -0.000166     |\n",
      "|    value_loss           | 2.66e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 545      |\n",
      "|    ep_rew_mean     | 3.56e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 228      |\n",
      "|    iterations      | 85       |\n",
      "|    time_elapsed    | 856      |\n",
      "|    total_timesteps | 195840   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 537           |\n",
      "|    ep_rew_mean          | 3.52e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 230           |\n",
      "|    iterations           | 86            |\n",
      "|    time_elapsed         | 859           |\n",
      "|    total_timesteps      | 198144        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00038116606 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.138        |\n",
      "|    explained_variance   | 0.242         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.05e+03      |\n",
      "|    n_updates            | 850           |\n",
      "|    policy_gradient_loss | -0.000404     |\n",
      "|    value_loss           | 3.06e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=200000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 552           |\n",
      "|    mean_reward          | 4.45e+03      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 200000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00067426666 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.134        |\n",
      "|    explained_variance   | 0.193         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.09e+03      |\n",
      "|    n_updates            | 860           |\n",
      "|    policy_gradient_loss | -0.000278     |\n",
      "|    value_loss           | 3.42e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 534      |\n",
      "|    ep_rew_mean     | 3.51e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 230      |\n",
      "|    iterations      | 87       |\n",
      "|    time_elapsed    | 869      |\n",
      "|    total_timesteps | 200448   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 530           |\n",
      "|    ep_rew_mean          | 3.47e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 232           |\n",
      "|    iterations           | 88            |\n",
      "|    time_elapsed         | 872           |\n",
      "|    total_timesteps      | 202752        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00082643173 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.137        |\n",
      "|    explained_variance   | 0.243         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 881           |\n",
      "|    n_updates            | 870           |\n",
      "|    policy_gradient_loss | -0.000227     |\n",
      "|    value_loss           | 2.57e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=205000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 205000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014721825 |\n",
      "|    clip_fraction        | 0.0134       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.131       |\n",
      "|    explained_variance   | 0.248        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.06e+03     |\n",
      "|    n_updates            | 880          |\n",
      "|    policy_gradient_loss | -0.000618    |\n",
      "|    value_loss           | 3.62e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 530      |\n",
      "|    ep_rew_mean     | 3.49e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 232      |\n",
      "|    iterations      | 89       |\n",
      "|    time_elapsed    | 881      |\n",
      "|    total_timesteps | 205056   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 530          |\n",
      "|    ep_rew_mean          | 3.5e+03      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 234          |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 884          |\n",
      "|    total_timesteps      | 207360       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024306655 |\n",
      "|    clip_fraction        | 0.014        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.132       |\n",
      "|    explained_variance   | 0.26         |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.07e+03     |\n",
      "|    n_updates            | 890          |\n",
      "|    policy_gradient_loss | -0.00202     |\n",
      "|    value_loss           | 3.41e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 530           |\n",
      "|    ep_rew_mean          | 3.5e+03       |\n",
      "| time/                   |               |\n",
      "|    fps                  | 236           |\n",
      "|    iterations           | 91            |\n",
      "|    time_elapsed         | 887           |\n",
      "|    total_timesteps      | 209664        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00046805284 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.134        |\n",
      "|    explained_variance   | 0.27          |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.03e+03      |\n",
      "|    n_updates            | 900           |\n",
      "|    policy_gradient_loss | -0.000131     |\n",
      "|    value_loss           | 2.59e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=210000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 552           |\n",
      "|    mean_reward          | 4.45e+03      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 210000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00025848724 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.136        |\n",
      "|    explained_variance   | 0.14          |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.57e+03      |\n",
      "|    n_updates            | 910           |\n",
      "|    policy_gradient_loss | -0.000167     |\n",
      "|    value_loss           | 3.04e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 526      |\n",
      "|    ep_rew_mean     | 3.48e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 236      |\n",
      "|    iterations      | 92       |\n",
      "|    time_elapsed    | 897      |\n",
      "|    total_timesteps | 211968   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 527          |\n",
      "|    ep_rew_mean          | 3.49e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 238          |\n",
      "|    iterations           | 93           |\n",
      "|    time_elapsed         | 900          |\n",
      "|    total_timesteps      | 214272       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026270398 |\n",
      "|    clip_fraction        | 0.018        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.13        |\n",
      "|    explained_variance   | 0.243        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 680          |\n",
      "|    n_updates            | 920          |\n",
      "|    policy_gradient_loss | -0.00251     |\n",
      "|    value_loss           | 2.69e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=215000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 215000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027023084 |\n",
      "|    clip_fraction        | 0.0201       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.136       |\n",
      "|    explained_variance   | 0.237        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.25e+03     |\n",
      "|    n_updates            | 930          |\n",
      "|    policy_gradient_loss | -0.00102     |\n",
      "|    value_loss           | 2.74e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 529      |\n",
      "|    ep_rew_mean     | 3.51e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 238      |\n",
      "|    iterations      | 94       |\n",
      "|    time_elapsed    | 909      |\n",
      "|    total_timesteps | 216576   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 528           |\n",
      "|    ep_rew_mean          | 3.5e+03       |\n",
      "| time/                   |               |\n",
      "|    fps                  | 239           |\n",
      "|    iterations           | 95            |\n",
      "|    time_elapsed         | 912           |\n",
      "|    total_timesteps      | 218880        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012164016 |\n",
      "|    clip_fraction        | 0.0173        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.137        |\n",
      "|    explained_variance   | 0.258         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.19e+03      |\n",
      "|    n_updates            | 940           |\n",
      "|    policy_gradient_loss | -0.000221     |\n",
      "|    value_loss           | 2.96e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=220000, episode_reward=6687.82 +/- 0.00\n",
      "Episode length: 960.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 960         |\n",
      "|    mean_reward          | 6.69e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 220000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000708094 |\n",
      "|    clip_fraction        | 0.0111      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.128      |\n",
      "|    explained_variance   | 0.275       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.61e+03    |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | -0.000454   |\n",
      "|    value_loss           | 2.64e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 530      |\n",
      "|    ep_rew_mean     | 3.52e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 238      |\n",
      "|    iterations      | 96       |\n",
      "|    time_elapsed    | 926      |\n",
      "|    total_timesteps | 221184   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 532          |\n",
      "|    ep_rew_mean          | 3.55e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 240          |\n",
      "|    iterations           | 97           |\n",
      "|    time_elapsed         | 929          |\n",
      "|    total_timesteps      | 223488       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023723259 |\n",
      "|    clip_fraction        | 0.00875      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.133       |\n",
      "|    explained_variance   | 0.271        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.85e+03     |\n",
      "|    n_updates            | 960          |\n",
      "|    policy_gradient_loss | -0.000302    |\n",
      "|    value_loss           | 3.05e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=225000, episode_reward=10123.59 +/- 0.01\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.3e+03      |\n",
      "|    mean_reward          | 1.01e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 225000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032161586 |\n",
      "|    clip_fraction        | 0.0153       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.122       |\n",
      "|    explained_variance   | 0.298        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 875          |\n",
      "|    n_updates            | 970          |\n",
      "|    policy_gradient_loss | -0.000748    |\n",
      "|    value_loss           | 2.05e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 536      |\n",
      "|    ep_rew_mean     | 3.57e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 235      |\n",
      "|    iterations      | 98       |\n",
      "|    time_elapsed    | 959      |\n",
      "|    total_timesteps | 225792   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 541          |\n",
      "|    ep_rew_mean          | 3.6e+03      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 237          |\n",
      "|    iterations           | 99           |\n",
      "|    time_elapsed         | 962          |\n",
      "|    total_timesteps      | 228096       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018603548 |\n",
      "|    clip_fraction        | 0.0266       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.129       |\n",
      "|    explained_variance   | 0.304        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.03e+03     |\n",
      "|    n_updates            | 980          |\n",
      "|    policy_gradient_loss | -0.00168     |\n",
      "|    value_loss           | 2.06e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=230000, episode_reward=6687.82 +/- 0.02\n",
      "Episode length: 960.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 960         |\n",
      "|    mean_reward          | 6.69e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 230000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000781375 |\n",
      "|    clip_fraction        | 0.00043     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.135      |\n",
      "|    explained_variance   | 0.272       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.32e+03    |\n",
      "|    n_updates            | 990         |\n",
      "|    policy_gradient_loss | -0.000282   |\n",
      "|    value_loss           | 2.55e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 543      |\n",
      "|    ep_rew_mean     | 3.62e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 236      |\n",
      "|    iterations      | 100      |\n",
      "|    time_elapsed    | 976      |\n",
      "|    total_timesteps | 230400   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 546          |\n",
      "|    ep_rew_mean          | 3.64e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 237          |\n",
      "|    iterations           | 101          |\n",
      "|    time_elapsed         | 979          |\n",
      "|    total_timesteps      | 232704       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017301288 |\n",
      "|    clip_fraction        | 0.00215      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.125       |\n",
      "|    explained_variance   | 0.272        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.05e+03     |\n",
      "|    n_updates            | 1000         |\n",
      "|    policy_gradient_loss | -0.000265    |\n",
      "|    value_loss           | 2.74e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=235000, episode_reward=6687.82 +/- 0.00\n",
      "Episode length: 960.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 960          |\n",
      "|    mean_reward          | 6.69e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 235000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005852474 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.121       |\n",
      "|    explained_variance   | 0.286        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.05e+03     |\n",
      "|    n_updates            | 1010         |\n",
      "|    policy_gradient_loss | -6.6e-05     |\n",
      "|    value_loss           | 2.64e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 550      |\n",
      "|    ep_rew_mean     | 3.67e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 236      |\n",
      "|    iterations      | 102      |\n",
      "|    time_elapsed    | 993      |\n",
      "|    total_timesteps | 235008   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 553         |\n",
      "|    ep_rew_mean          | 3.69e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 103         |\n",
      "|    time_elapsed         | 996         |\n",
      "|    total_timesteps      | 237312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002183235 |\n",
      "|    clip_fraction        | 0.0355      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.129      |\n",
      "|    explained_variance   | 0.291       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.43e+03    |\n",
      "|    n_updates            | 1020        |\n",
      "|    policy_gradient_loss | -0.00133    |\n",
      "|    value_loss           | 2.19e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 560          |\n",
      "|    ep_rew_mean          | 3.74e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 239          |\n",
      "|    iterations           | 104          |\n",
      "|    time_elapsed         | 999          |\n",
      "|    total_timesteps      | 239616       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.932134e-05 |\n",
      "|    clip_fraction        | 0.00313      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.122       |\n",
      "|    explained_variance   | 0.269        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 975          |\n",
      "|    n_updates            | 1030         |\n",
      "|    policy_gradient_loss | 0.000105     |\n",
      "|    value_loss           | 2.7e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=240000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 240000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058471556 |\n",
      "|    clip_fraction        | 0.0534       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.132       |\n",
      "|    explained_variance   | 0.291        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.24e+03     |\n",
      "|    n_updates            | 1040         |\n",
      "|    policy_gradient_loss | -0.00202     |\n",
      "|    value_loss           | 2.65e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 560      |\n",
      "|    ep_rew_mean     | 3.75e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 239      |\n",
      "|    iterations      | 105      |\n",
      "|    time_elapsed    | 1008     |\n",
      "|    total_timesteps | 241920   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 562           |\n",
      "|    ep_rew_mean          | 3.77e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 241           |\n",
      "|    iterations           | 106           |\n",
      "|    time_elapsed         | 1012          |\n",
      "|    total_timesteps      | 244224        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.3374028e-05 |\n",
      "|    clip_fraction        | 0.0179        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.127        |\n",
      "|    explained_variance   | 0.186         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.52e+03      |\n",
      "|    n_updates            | 1050          |\n",
      "|    policy_gradient_loss | 5.41e-05      |\n",
      "|    value_loss           | 3.24e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=245000, episode_reward=6687.82 +/- 0.00\n",
      "Episode length: 960.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 960          |\n",
      "|    mean_reward          | 6.69e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 245000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008274894 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.121       |\n",
      "|    explained_variance   | 0.175        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.59e+03     |\n",
      "|    n_updates            | 1060         |\n",
      "|    policy_gradient_loss | -6.78e-05    |\n",
      "|    value_loss           | 2.67e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 566      |\n",
      "|    ep_rew_mean     | 3.79e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 240      |\n",
      "|    iterations      | 107      |\n",
      "|    time_elapsed    | 1026     |\n",
      "|    total_timesteps | 246528   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 567         |\n",
      "|    ep_rew_mean          | 3.81e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 108         |\n",
      "|    time_elapsed         | 1029        |\n",
      "|    total_timesteps      | 248832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005550883 |\n",
      "|    clip_fraction        | 0.049       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.13       |\n",
      "|    explained_variance   | 0.296       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.41e+03    |\n",
      "|    n_updates            | 1070        |\n",
      "|    policy_gradient_loss | -0.00255    |\n",
      "|    value_loss           | 2.78e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=250000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 552           |\n",
      "|    mean_reward          | 4.45e+03      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 250000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00036881896 |\n",
      "|    clip_fraction        | 0.00398       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.122        |\n",
      "|    explained_variance   | 0.277         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1e+03         |\n",
      "|    n_updates            | 1080          |\n",
      "|    policy_gradient_loss | -0.000554     |\n",
      "|    value_loss           | 2.84e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 568      |\n",
      "|    ep_rew_mean     | 3.82e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 241      |\n",
      "|    iterations      | 109      |\n",
      "|    time_elapsed    | 1038     |\n",
      "|    total_timesteps | 251136   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 567           |\n",
      "|    ep_rew_mean          | 3.81e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 243           |\n",
      "|    iterations           | 110           |\n",
      "|    time_elapsed         | 1041          |\n",
      "|    total_timesteps      | 253440        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00026979292 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.124        |\n",
      "|    explained_variance   | 0.278         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 2.02e+03      |\n",
      "|    n_updates            | 1090          |\n",
      "|    policy_gradient_loss | 8.58e-05      |\n",
      "|    value_loss           | 3.31e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=255000, episode_reward=10123.59 +/- 0.01\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.3e+03     |\n",
      "|    mean_reward          | 1.01e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 255000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021272123 |\n",
      "|    clip_fraction        | 0.0186      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.118      |\n",
      "|    explained_variance   | 0.277       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.82e+03    |\n",
      "|    n_updates            | 1100        |\n",
      "|    policy_gradient_loss | 0.00141     |\n",
      "|    value_loss           | 3.07e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 572      |\n",
      "|    ep_rew_mean     | 3.85e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 238      |\n",
      "|    iterations      | 111      |\n",
      "|    time_elapsed    | 1070     |\n",
      "|    total_timesteps | 255744   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 578          |\n",
      "|    ep_rew_mean          | 3.89e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 240          |\n",
      "|    iterations           | 112          |\n",
      "|    time_elapsed         | 1074         |\n",
      "|    total_timesteps      | 258048       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018349893 |\n",
      "|    clip_fraction        | 0.0248       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.117       |\n",
      "|    explained_variance   | 0.317        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.32e+03     |\n",
      "|    n_updates            | 1110         |\n",
      "|    policy_gradient_loss | -0.0015      |\n",
      "|    value_loss           | 2.21e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=260000, episode_reward=4447.08 +/- 0.07\n",
      "Episode length: 552.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 552         |\n",
      "|    mean_reward          | 4.45e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 260000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016396876 |\n",
      "|    clip_fraction        | 0.0266      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.126      |\n",
      "|    explained_variance   | 0.307       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 754         |\n",
      "|    n_updates            | 1120        |\n",
      "|    policy_gradient_loss | 0.00103     |\n",
      "|    value_loss           | 2.56e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 580      |\n",
      "|    ep_rew_mean     | 3.91e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 240      |\n",
      "|    iterations      | 113      |\n",
      "|    time_elapsed    | 1083     |\n",
      "|    total_timesteps | 260352   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 581          |\n",
      "|    ep_rew_mean          | 3.91e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 114          |\n",
      "|    time_elapsed         | 1086         |\n",
      "|    total_timesteps      | 262656       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012463352 |\n",
      "|    clip_fraction        | 0.0146       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.121       |\n",
      "|    explained_variance   | 0.15         |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.04e+03     |\n",
      "|    n_updates            | 1130         |\n",
      "|    policy_gradient_loss | -0.000644    |\n",
      "|    value_loss           | 2.91e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 584          |\n",
      "|    ep_rew_mean          | 3.94e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 243          |\n",
      "|    iterations           | 115          |\n",
      "|    time_elapsed         | 1089         |\n",
      "|    total_timesteps      | 264960       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010177533 |\n",
      "|    clip_fraction        | 0.011        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.116       |\n",
      "|    explained_variance   | 0.292        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.11e+03     |\n",
      "|    n_updates            | 1140         |\n",
      "|    policy_gradient_loss | -0.000991    |\n",
      "|    value_loss           | 2.83e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=265000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 265000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012439784 |\n",
      "|    clip_fraction        | 0.0263       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.12        |\n",
      "|    explained_variance   | 0.34         |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.3e+03      |\n",
      "|    n_updates            | 1150         |\n",
      "|    policy_gradient_loss | -0.00195     |\n",
      "|    value_loss           | 2.81e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 585      |\n",
      "|    ep_rew_mean     | 3.94e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 243      |\n",
      "|    iterations      | 116      |\n",
      "|    time_elapsed    | 1099     |\n",
      "|    total_timesteps | 267264   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 585           |\n",
      "|    ep_rew_mean          | 3.94e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 244           |\n",
      "|    iterations           | 117           |\n",
      "|    time_elapsed         | 1102          |\n",
      "|    total_timesteps      | 269568        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.2597389e-05 |\n",
      "|    clip_fraction        | 0.0139        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.121        |\n",
      "|    explained_variance   | 0.337         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.63e+03      |\n",
      "|    n_updates            | 1160          |\n",
      "|    policy_gradient_loss | 0.000123      |\n",
      "|    value_loss           | 2.94e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=270000, episode_reward=6687.82 +/- 0.00\n",
      "Episode length: 960.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 960          |\n",
      "|    mean_reward          | 6.69e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 270000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013131312 |\n",
      "|    clip_fraction        | 0.0164       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.118       |\n",
      "|    explained_variance   | 0.331        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.36e+03     |\n",
      "|    n_updates            | 1170         |\n",
      "|    policy_gradient_loss | -0.000967    |\n",
      "|    value_loss           | 2.84e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 586      |\n",
      "|    ep_rew_mean     | 3.96e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 243      |\n",
      "|    iterations      | 118      |\n",
      "|    time_elapsed    | 1116     |\n",
      "|    total_timesteps | 271872   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 585          |\n",
      "|    ep_rew_mean          | 3.96e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 244          |\n",
      "|    iterations           | 119          |\n",
      "|    time_elapsed         | 1119         |\n",
      "|    total_timesteps      | 274176       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004700881 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.118       |\n",
      "|    explained_variance   | 0.333        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.51e+03     |\n",
      "|    n_updates            | 1180         |\n",
      "|    policy_gradient_loss | -0.000201    |\n",
      "|    value_loss           | 2.76e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=275000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 275000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007959055 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.12        |\n",
      "|    explained_variance   | 0.353        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.47e+03     |\n",
      "|    n_updates            | 1190         |\n",
      "|    policy_gradient_loss | -0.000127    |\n",
      "|    value_loss           | 3.37e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 584      |\n",
      "|    ep_rew_mean     | 3.96e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 244      |\n",
      "|    iterations      | 120      |\n",
      "|    time_elapsed    | 1128     |\n",
      "|    total_timesteps | 276480   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 583           |\n",
      "|    ep_rew_mean          | 3.96e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 121           |\n",
      "|    time_elapsed         | 1131          |\n",
      "|    total_timesteps      | 278784        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 8.9137684e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.12         |\n",
      "|    explained_variance   | 0.371         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.83e+03      |\n",
      "|    n_updates            | 1200          |\n",
      "|    policy_gradient_loss | -2.34e-05     |\n",
      "|    value_loss           | 2.8e+03       |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=280000, episode_reward=6687.82 +/- 0.00\n",
      "Episode length: 960.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 960          |\n",
      "|    mean_reward          | 6.69e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 280000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022006822 |\n",
      "|    clip_fraction        | 0.0418       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.111       |\n",
      "|    explained_variance   | 0.372        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.17e+03     |\n",
      "|    n_updates            | 1210         |\n",
      "|    policy_gradient_loss | -0.000118    |\n",
      "|    value_loss           | 3.05e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 585      |\n",
      "|    ep_rew_mean     | 3.98e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 245      |\n",
      "|    iterations      | 122      |\n",
      "|    time_elapsed    | 1145     |\n",
      "|    total_timesteps | 281088   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 582           |\n",
      "|    ep_rew_mean          | 3.97e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 246           |\n",
      "|    iterations           | 123           |\n",
      "|    time_elapsed         | 1148          |\n",
      "|    total_timesteps      | 283392        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00042526974 |\n",
      "|    clip_fraction        | 0.00793       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.112        |\n",
      "|    explained_variance   | 0.384         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.29e+03      |\n",
      "|    n_updates            | 1220          |\n",
      "|    policy_gradient_loss | 2.25e-05      |\n",
      "|    value_loss           | 2.65e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=285000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 285000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009216303 |\n",
      "|    clip_fraction        | 0.00828      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.119       |\n",
      "|    explained_variance   | 0.382        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.34e+03     |\n",
      "|    n_updates            | 1230         |\n",
      "|    policy_gradient_loss | -0.000854    |\n",
      "|    value_loss           | 2.66e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 579      |\n",
      "|    ep_rew_mean     | 3.96e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 246      |\n",
      "|    iterations      | 124      |\n",
      "|    time_elapsed    | 1158     |\n",
      "|    total_timesteps | 285696   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 580          |\n",
      "|    ep_rew_mean          | 3.97e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 125          |\n",
      "|    time_elapsed         | 1161         |\n",
      "|    total_timesteps      | 288000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010767401 |\n",
      "|    clip_fraction        | 0.0297       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.112       |\n",
      "|    explained_variance   | 0.414        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.87e+03     |\n",
      "|    n_updates            | 1240         |\n",
      "|    policy_gradient_loss | -0.00115     |\n",
      "|    value_loss           | 2.93e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=290000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 290000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013614718 |\n",
      "|    clip_fraction        | 0.0351       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.118       |\n",
      "|    explained_variance   | 0.395        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.43e+03     |\n",
      "|    n_updates            | 1250         |\n",
      "|    policy_gradient_loss | -0.00117     |\n",
      "|    value_loss           | 2.39e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 581      |\n",
      "|    ep_rew_mean     | 3.98e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 247      |\n",
      "|    iterations      | 126      |\n",
      "|    time_elapsed    | 1170     |\n",
      "|    total_timesteps | 290304   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 574         |\n",
      "|    ep_rew_mean          | 3.93e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 127         |\n",
      "|    time_elapsed         | 1173        |\n",
      "|    total_timesteps      | 292608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001111356 |\n",
      "|    clip_fraction        | 0.0142      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.12       |\n",
      "|    explained_variance   | 0.395       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.53e+03    |\n",
      "|    n_updates            | 1260        |\n",
      "|    policy_gradient_loss | -0.00137    |\n",
      "|    value_loss           | 2.73e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 571          |\n",
      "|    ep_rew_mean          | 3.92e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 250          |\n",
      "|    iterations           | 128          |\n",
      "|    time_elapsed         | 1176         |\n",
      "|    total_timesteps      | 294912       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008559326 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.11        |\n",
      "|    explained_variance   | 0.351        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.77e+03     |\n",
      "|    n_updates            | 1270         |\n",
      "|    policy_gradient_loss | -0.000548    |\n",
      "|    value_loss           | 3.65e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=295000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 552           |\n",
      "|    mean_reward          | 4.45e+03      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 295000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00090416864 |\n",
      "|    clip_fraction        | 0.00102       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.114        |\n",
      "|    explained_variance   | 0.409         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.73e+03      |\n",
      "|    n_updates            | 1280          |\n",
      "|    policy_gradient_loss | -0.000565     |\n",
      "|    value_loss           | 2.76e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 570      |\n",
      "|    ep_rew_mean     | 3.92e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 250      |\n",
      "|    iterations      | 129      |\n",
      "|    time_elapsed    | 1186     |\n",
      "|    total_timesteps | 297216   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 574           |\n",
      "|    ep_rew_mean          | 3.94e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 251           |\n",
      "|    iterations           | 130           |\n",
      "|    time_elapsed         | 1189          |\n",
      "|    total_timesteps      | 299520        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00028462734 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.112        |\n",
      "|    explained_variance   | 0.416         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.42e+03      |\n",
      "|    n_updates            | 1290          |\n",
      "|    policy_gradient_loss | -0.000195     |\n",
      "|    value_loss           | 2.92e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=300000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 300000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030499871 |\n",
      "|    clip_fraction        | 0.0191       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.117       |\n",
      "|    explained_variance   | 0.395        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 905          |\n",
      "|    n_updates            | 1300         |\n",
      "|    policy_gradient_loss | -0.000327    |\n",
      "|    value_loss           | 2.11e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 575      |\n",
      "|    ep_rew_mean     | 3.95e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 251      |\n",
      "|    iterations      | 131      |\n",
      "|    time_elapsed    | 1198     |\n",
      "|    total_timesteps | 301824   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 574           |\n",
      "|    ep_rew_mean          | 3.95e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 253           |\n",
      "|    iterations           | 132           |\n",
      "|    time_elapsed         | 1201          |\n",
      "|    total_timesteps      | 304128        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00027388122 |\n",
      "|    clip_fraction        | 0.0131        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.109        |\n",
      "|    explained_variance   | 0.366         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.19e+03      |\n",
      "|    n_updates            | 1310          |\n",
      "|    policy_gradient_loss | -0.000633     |\n",
      "|    value_loss           | 2.55e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=305000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 305000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048812767 |\n",
      "|    clip_fraction        | 0.0323       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.114       |\n",
      "|    explained_variance   | 0.368        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.44e+03     |\n",
      "|    n_updates            | 1320         |\n",
      "|    policy_gradient_loss | -0.000921    |\n",
      "|    value_loss           | 3.35e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 574      |\n",
      "|    ep_rew_mean     | 3.95e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 252      |\n",
      "|    iterations      | 133      |\n",
      "|    time_elapsed    | 1211     |\n",
      "|    total_timesteps | 306432   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 575           |\n",
      "|    ep_rew_mean          | 3.96e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 254           |\n",
      "|    iterations           | 134           |\n",
      "|    time_elapsed         | 1214          |\n",
      "|    total_timesteps      | 308736        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00040170504 |\n",
      "|    clip_fraction        | 0.0032        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.113        |\n",
      "|    explained_variance   | 0.398         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.51e+03      |\n",
      "|    n_updates            | 1330          |\n",
      "|    policy_gradient_loss | -0.000248     |\n",
      "|    value_loss           | 3.07e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=310000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 552           |\n",
      "|    mean_reward          | 4.45e+03      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 310000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00032536365 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.114        |\n",
      "|    explained_variance   | 0.391         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.45e+03      |\n",
      "|    n_updates            | 1340          |\n",
      "|    policy_gradient_loss | -0.00022      |\n",
      "|    value_loss           | 3.16e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 576      |\n",
      "|    ep_rew_mean     | 3.98e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 254      |\n",
      "|    iterations      | 135      |\n",
      "|    time_elapsed    | 1223     |\n",
      "|    total_timesteps | 311040   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 572           |\n",
      "|    ep_rew_mean          | 3.95e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 255           |\n",
      "|    iterations           | 136           |\n",
      "|    time_elapsed         | 1226          |\n",
      "|    total_timesteps      | 313344        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 9.2043956e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.113        |\n",
      "|    explained_variance   | 0.385         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.17e+03      |\n",
      "|    n_updates            | 1350          |\n",
      "|    policy_gradient_loss | 4.6e-06       |\n",
      "|    value_loss           | 2.87e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=315000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 552         |\n",
      "|    mean_reward          | 4.45e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 315000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 6.24781e-05 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.11       |\n",
      "|    explained_variance   | 0.408       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.44e+03    |\n",
      "|    n_updates            | 1360        |\n",
      "|    policy_gradient_loss | -0.000204   |\n",
      "|    value_loss           | 3.1e+03     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 567      |\n",
      "|    ep_rew_mean     | 3.93e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 255      |\n",
      "|    iterations      | 137      |\n",
      "|    time_elapsed    | 1236     |\n",
      "|    total_timesteps | 315648   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 569           |\n",
      "|    ep_rew_mean          | 3.95e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 256           |\n",
      "|    iterations           | 138           |\n",
      "|    time_elapsed         | 1239          |\n",
      "|    total_timesteps      | 317952        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020448281 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.11         |\n",
      "|    explained_variance   | 0.389         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.4e+03       |\n",
      "|    n_updates            | 1370          |\n",
      "|    policy_gradient_loss | -7.62e-05     |\n",
      "|    value_loss           | 2.82e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=320000, episode_reward=6687.82 +/- 0.00\n",
      "Episode length: 960.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 960          |\n",
      "|    mean_reward          | 6.69e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 320000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004602599 |\n",
      "|    clip_fraction        | 0.0111       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.106       |\n",
      "|    explained_variance   | 0.423        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.44e+03     |\n",
      "|    n_updates            | 1380         |\n",
      "|    policy_gradient_loss | -0.000229    |\n",
      "|    value_loss           | 2.88e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 570      |\n",
      "|    ep_rew_mean     | 3.96e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 255      |\n",
      "|    iterations      | 139      |\n",
      "|    time_elapsed    | 1253     |\n",
      "|    total_timesteps | 320256   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 570          |\n",
      "|    ep_rew_mean          | 3.96e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 256          |\n",
      "|    iterations           | 140          |\n",
      "|    time_elapsed         | 1256         |\n",
      "|    total_timesteps      | 322560       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019196991 |\n",
      "|    clip_fraction        | 0.0052       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.113       |\n",
      "|    explained_variance   | 0.399        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.91e+03     |\n",
      "|    n_updates            | 1390         |\n",
      "|    policy_gradient_loss | -0.000668    |\n",
      "|    value_loss           | 2.94e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 570           |\n",
      "|    ep_rew_mean          | 3.97e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 257           |\n",
      "|    iterations           | 141           |\n",
      "|    time_elapsed         | 1259          |\n",
      "|    total_timesteps      | 324864        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 8.9834844e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.111        |\n",
      "|    explained_variance   | 0.408         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.11e+03      |\n",
      "|    n_updates            | 1400          |\n",
      "|    policy_gradient_loss | -0.000116     |\n",
      "|    value_loss           | 2.79e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=325000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 552           |\n",
      "|    mean_reward          | 4.45e+03      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 325000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00021504879 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.113        |\n",
      "|    explained_variance   | 0.388         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 2.04e+03      |\n",
      "|    n_updates            | 1410          |\n",
      "|    policy_gradient_loss | -5.93e-05     |\n",
      "|    value_loss           | 3.32e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 568      |\n",
      "|    ep_rew_mean     | 3.96e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 257      |\n",
      "|    iterations      | 142      |\n",
      "|    time_elapsed    | 1268     |\n",
      "|    total_timesteps | 327168   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 567         |\n",
      "|    ep_rew_mean          | 3.96e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 259         |\n",
      "|    iterations           | 143         |\n",
      "|    time_elapsed         | 1271        |\n",
      "|    total_timesteps      | 329472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002163805 |\n",
      "|    clip_fraction        | 0.0235      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.108      |\n",
      "|    explained_variance   | 0.35        |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.82e+03    |\n",
      "|    n_updates            | 1420        |\n",
      "|    policy_gradient_loss | -0.00149    |\n",
      "|    value_loss           | 2.83e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=330000, episode_reward=6687.82 +/- 0.00\n",
      "Episode length: 960.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 960           |\n",
      "|    mean_reward          | 6.69e+03      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 330000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00058553915 |\n",
      "|    clip_fraction        | 0.00129       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.112        |\n",
      "|    explained_variance   | 0.425         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.3e+03       |\n",
      "|    n_updates            | 1430          |\n",
      "|    policy_gradient_loss | -3.93e-05     |\n",
      "|    value_loss           | 2.89e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 570      |\n",
      "|    ep_rew_mean     | 3.98e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 258      |\n",
      "|    iterations      | 144      |\n",
      "|    time_elapsed    | 1285     |\n",
      "|    total_timesteps | 331776   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 573           |\n",
      "|    ep_rew_mean          | 4e+03         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 259           |\n",
      "|    iterations           | 145           |\n",
      "|    time_elapsed         | 1288          |\n",
      "|    total_timesteps      | 334080        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00066165405 |\n",
      "|    clip_fraction        | 0.0126        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.107        |\n",
      "|    explained_variance   | 0.441         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 985           |\n",
      "|    n_updates            | 1440          |\n",
      "|    policy_gradient_loss | 0.000134      |\n",
      "|    value_loss           | 2.68e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=335000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 552           |\n",
      "|    mean_reward          | 4.45e+03      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 335000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017358559 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.103        |\n",
      "|    explained_variance   | 0.44          |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.31e+03      |\n",
      "|    n_updates            | 1450          |\n",
      "|    policy_gradient_loss | 0.00012       |\n",
      "|    value_loss           | 2.8e+03       |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 574      |\n",
      "|    ep_rew_mean     | 4.02e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 259      |\n",
      "|    iterations      | 146      |\n",
      "|    time_elapsed    | 1298     |\n",
      "|    total_timesteps | 336384   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 574          |\n",
      "|    ep_rew_mean          | 4.02e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 260          |\n",
      "|    iterations           | 147          |\n",
      "|    time_elapsed         | 1301         |\n",
      "|    total_timesteps      | 338688       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.892084e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.107       |\n",
      "|    explained_variance   | 0.443        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.05e+03     |\n",
      "|    n_updates            | 1460         |\n",
      "|    policy_gradient_loss | 0.000658     |\n",
      "|    value_loss           | 2.81e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=340000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 552           |\n",
      "|    mean_reward          | 4.45e+03      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 340000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00040398067 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.107        |\n",
      "|    explained_variance   | 0.447         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.35e+03      |\n",
      "|    n_updates            | 1470          |\n",
      "|    policy_gradient_loss | -9.05e-05     |\n",
      "|    value_loss           | 2.56e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 573      |\n",
      "|    ep_rew_mean     | 4.02e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 260      |\n",
      "|    iterations      | 148      |\n",
      "|    time_elapsed    | 1310     |\n",
      "|    total_timesteps | 340992   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 572          |\n",
      "|    ep_rew_mean          | 4.02e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 261          |\n",
      "|    iterations           | 149          |\n",
      "|    time_elapsed         | 1313         |\n",
      "|    total_timesteps      | 343296       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011333944 |\n",
      "|    clip_fraction        | 0.0305       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.1         |\n",
      "|    explained_variance   | 0.433        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.28e+03     |\n",
      "|    n_updates            | 1480         |\n",
      "|    policy_gradient_loss | 0.000656     |\n",
      "|    value_loss           | 2.88e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=345000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 345000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008706201 |\n",
      "|    clip_fraction        | 0.0231       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.108       |\n",
      "|    explained_variance   | 0.457        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.29e+03     |\n",
      "|    n_updates            | 1490         |\n",
      "|    policy_gradient_loss | -0.000464    |\n",
      "|    value_loss           | 2.81e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 571      |\n",
      "|    ep_rew_mean     | 4.03e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 261      |\n",
      "|    iterations      | 150      |\n",
      "|    time_elapsed    | 1323     |\n",
      "|    total_timesteps | 345600   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 572           |\n",
      "|    ep_rew_mean          | 4.04e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 262           |\n",
      "|    iterations           | 151           |\n",
      "|    time_elapsed         | 1326          |\n",
      "|    total_timesteps      | 347904        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00093281316 |\n",
      "|    clip_fraction        | 0.0179        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.104        |\n",
      "|    explained_variance   | 0.452         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.76e+03      |\n",
      "|    n_updates            | 1500          |\n",
      "|    policy_gradient_loss | 0.000108      |\n",
      "|    value_loss           | 2.92e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=350000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 350000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004109876 |\n",
      "|    clip_fraction        | 0.00652      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.102       |\n",
      "|    explained_variance   | 0.456        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 780          |\n",
      "|    n_updates            | 1510         |\n",
      "|    policy_gradient_loss | -0.000565    |\n",
      "|    value_loss           | 2.87e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 575      |\n",
      "|    ep_rew_mean     | 4.07e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 262      |\n",
      "|    iterations      | 152      |\n",
      "|    time_elapsed    | 1335     |\n",
      "|    total_timesteps | 350208   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 576          |\n",
      "|    ep_rew_mean          | 4.07e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 263          |\n",
      "|    iterations           | 153          |\n",
      "|    time_elapsed         | 1338         |\n",
      "|    total_timesteps      | 352512       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003556066 |\n",
      "|    clip_fraction        | 0.00109      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.107       |\n",
      "|    explained_variance   | 0.446        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.2e+03      |\n",
      "|    n_updates            | 1520         |\n",
      "|    policy_gradient_loss | -7.32e-05    |\n",
      "|    value_loss           | 2.86e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 576          |\n",
      "|    ep_rew_mean          | 4.08e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 264          |\n",
      "|    iterations           | 154          |\n",
      "|    time_elapsed         | 1341         |\n",
      "|    total_timesteps      | 354816       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003329091 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.103       |\n",
      "|    explained_variance   | 0.443        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.57e+03     |\n",
      "|    n_updates            | 1530         |\n",
      "|    policy_gradient_loss | -8.17e-06    |\n",
      "|    value_loss           | 3.32e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=355000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 355000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018935127 |\n",
      "|    clip_fraction        | 0.00352      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.105       |\n",
      "|    explained_variance   | 0.424        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.59e+03     |\n",
      "|    n_updates            | 1540         |\n",
      "|    policy_gradient_loss | -0.000147    |\n",
      "|    value_loss           | 2.88e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 572      |\n",
      "|    ep_rew_mean     | 4.05e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 264      |\n",
      "|    iterations      | 155      |\n",
      "|    time_elapsed    | 1351     |\n",
      "|    total_timesteps | 357120   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 572          |\n",
      "|    ep_rew_mean          | 4.06e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 265          |\n",
      "|    iterations           | 156          |\n",
      "|    time_elapsed         | 1354         |\n",
      "|    total_timesteps      | 359424       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004738741 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.102       |\n",
      "|    explained_variance   | 0.225        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.55e+03     |\n",
      "|    n_updates            | 1550         |\n",
      "|    policy_gradient_loss | -9.9e-06     |\n",
      "|    value_loss           | 3.48e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=360000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 552           |\n",
      "|    mean_reward          | 4.45e+03      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 360000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.0579623e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.1          |\n",
      "|    explained_variance   | 0.392         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.26e+03      |\n",
      "|    n_updates            | 1560          |\n",
      "|    policy_gradient_loss | -0.000218     |\n",
      "|    value_loss           | 3.1e+03       |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 573      |\n",
      "|    ep_rew_mean     | 4.08e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 265      |\n",
      "|    iterations      | 157      |\n",
      "|    time_elapsed    | 1363     |\n",
      "|    total_timesteps | 361728   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 574           |\n",
      "|    ep_rew_mean          | 4.09e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 266           |\n",
      "|    iterations           | 158           |\n",
      "|    time_elapsed         | 1366          |\n",
      "|    total_timesteps      | 364032        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.3002866e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.103        |\n",
      "|    explained_variance   | 0.419         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.01e+03      |\n",
      "|    n_updates            | 1570          |\n",
      "|    policy_gradient_loss | -1.7e-05      |\n",
      "|    value_loss           | 2.95e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=365000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 365000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006074736 |\n",
      "|    clip_fraction        | 0.0126       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0972      |\n",
      "|    explained_variance   | 0.432        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 879          |\n",
      "|    n_updates            | 1580         |\n",
      "|    policy_gradient_loss | -0.000787    |\n",
      "|    value_loss           | 3.23e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 576      |\n",
      "|    ep_rew_mean     | 4.1e+03  |\n",
      "| time/              |          |\n",
      "|    fps             | 266      |\n",
      "|    iterations      | 159      |\n",
      "|    time_elapsed    | 1376     |\n",
      "|    total_timesteps | 366336   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 579          |\n",
      "|    ep_rew_mean          | 4.12e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 267          |\n",
      "|    iterations           | 160          |\n",
      "|    time_elapsed         | 1379         |\n",
      "|    total_timesteps      | 368640       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009217599 |\n",
      "|    clip_fraction        | 0.00043      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.102       |\n",
      "|    explained_variance   | 0.463        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 862          |\n",
      "|    n_updates            | 1590         |\n",
      "|    policy_gradient_loss | -0.000175    |\n",
      "|    value_loss           | 2.97e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=370000, episode_reward=6687.82 +/- 0.00\n",
      "Episode length: 960.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 960          |\n",
      "|    mean_reward          | 6.69e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 370000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001721178 |\n",
      "|    clip_fraction        | 0.00336      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0997      |\n",
      "|    explained_variance   | 0.493        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 868          |\n",
      "|    n_updates            | 1600         |\n",
      "|    policy_gradient_loss | 6.69e-06     |\n",
      "|    value_loss           | 2.3e+03      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 585      |\n",
      "|    ep_rew_mean     | 4.16e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 266      |\n",
      "|    iterations      | 161      |\n",
      "|    time_elapsed    | 1393     |\n",
      "|    total_timesteps | 370944   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 586           |\n",
      "|    ep_rew_mean          | 4.17e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 267           |\n",
      "|    iterations           | 162           |\n",
      "|    time_elapsed         | 1396          |\n",
      "|    total_timesteps      | 373248        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00082747405 |\n",
      "|    clip_fraction        | 0.00348       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.102        |\n",
      "|    explained_variance   | 0.478         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.56e+03      |\n",
      "|    n_updates            | 1610          |\n",
      "|    policy_gradient_loss | -0.000256     |\n",
      "|    value_loss           | 2.91e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=375000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 375000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014919665 |\n",
      "|    clip_fraction        | 0.00797      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.1         |\n",
      "|    explained_variance   | 0.491        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.07e+03     |\n",
      "|    n_updates            | 1620         |\n",
      "|    policy_gradient_loss | -0.000227    |\n",
      "|    value_loss           | 2.34e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 589      |\n",
      "|    ep_rew_mean     | 4.2e+03  |\n",
      "| time/              |          |\n",
      "|    fps             | 267      |\n",
      "|    iterations      | 163      |\n",
      "|    time_elapsed    | 1405     |\n",
      "|    total_timesteps | 375552   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 589          |\n",
      "|    ep_rew_mean          | 4.2e+03      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 268          |\n",
      "|    iterations           | 164          |\n",
      "|    time_elapsed         | 1408         |\n",
      "|    total_timesteps      | 377856       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018132854 |\n",
      "|    clip_fraction        | 0.00383      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0999      |\n",
      "|    explained_variance   | 0.461        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.48e+03     |\n",
      "|    n_updates            | 1630         |\n",
      "|    policy_gradient_loss | -0.000189    |\n",
      "|    value_loss           | 3.02e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=380000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 380000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035373613 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0995      |\n",
      "|    explained_variance   | 0.353        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.41e+03     |\n",
      "|    n_updates            | 1640         |\n",
      "|    policy_gradient_loss | -0.00114     |\n",
      "|    value_loss           | 2.81e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 587      |\n",
      "|    ep_rew_mean     | 4.18e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 268      |\n",
      "|    iterations      | 165      |\n",
      "|    time_elapsed    | 1418     |\n",
      "|    total_timesteps | 380160   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 591          |\n",
      "|    ep_rew_mean          | 4.21e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 269          |\n",
      "|    iterations           | 166          |\n",
      "|    time_elapsed         | 1421         |\n",
      "|    total_timesteps      | 382464       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015387485 |\n",
      "|    clip_fraction        | 0.0101       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0921      |\n",
      "|    explained_variance   | 0.46         |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.3e+03      |\n",
      "|    n_updates            | 1650         |\n",
      "|    policy_gradient_loss | -0.00154     |\n",
      "|    value_loss           | 3.16e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 591         |\n",
      "|    ep_rew_mean          | 4.21e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 167         |\n",
      "|    time_elapsed         | 1424        |\n",
      "|    total_timesteps      | 384768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008527415 |\n",
      "|    clip_fraction        | 0.024       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0999     |\n",
      "|    explained_variance   | 0.537       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.02e+03    |\n",
      "|    n_updates            | 1660        |\n",
      "|    policy_gradient_loss | -0.000893   |\n",
      "|    value_loss           | 2.82e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=385000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 385000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023766593 |\n",
      "|    clip_fraction        | 0.00539      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0981      |\n",
      "|    explained_variance   | 0.355        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.48e+03     |\n",
      "|    n_updates            | 1670         |\n",
      "|    policy_gradient_loss | -0.000149    |\n",
      "|    value_loss           | 3.2e+03      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 592      |\n",
      "|    ep_rew_mean     | 4.21e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 269      |\n",
      "|    iterations      | 168      |\n",
      "|    time_elapsed    | 1433     |\n",
      "|    total_timesteps | 387072   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 593           |\n",
      "|    ep_rew_mean          | 4.22e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 270           |\n",
      "|    iterations           | 169           |\n",
      "|    time_elapsed         | 1436          |\n",
      "|    total_timesteps      | 389376        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00074528373 |\n",
      "|    clip_fraction        | 0.00883       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0986       |\n",
      "|    explained_variance   | 0.525         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.88e+03      |\n",
      "|    n_updates            | 1680          |\n",
      "|    policy_gradient_loss | -0.000606     |\n",
      "|    value_loss           | 2.8e+03       |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=390000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 390000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013464399 |\n",
      "|    clip_fraction        | 0.0131       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.102       |\n",
      "|    explained_variance   | 0.533        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.53e+03     |\n",
      "|    n_updates            | 1690         |\n",
      "|    policy_gradient_loss | -0.000129    |\n",
      "|    value_loss           | 2.76e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 594      |\n",
      "|    ep_rew_mean     | 4.23e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 270      |\n",
      "|    iterations      | 170      |\n",
      "|    time_elapsed    | 1446     |\n",
      "|    total_timesteps | 391680   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 594          |\n",
      "|    ep_rew_mean          | 4.23e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 271          |\n",
      "|    iterations           | 171          |\n",
      "|    time_elapsed         | 1449         |\n",
      "|    total_timesteps      | 393984       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.083466e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.101       |\n",
      "|    explained_variance   | 0.511        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.61e+03     |\n",
      "|    n_updates            | 1700         |\n",
      "|    policy_gradient_loss | -0.00012     |\n",
      "|    value_loss           | 2.99e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=395000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 552           |\n",
      "|    mean_reward          | 4.45e+03      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 395000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00084733794 |\n",
      "|    clip_fraction        | 0.000742      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0999       |\n",
      "|    explained_variance   | 0.529         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.25e+03      |\n",
      "|    n_updates            | 1710          |\n",
      "|    policy_gradient_loss | -0.000113     |\n",
      "|    value_loss           | 2.94e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 594      |\n",
      "|    ep_rew_mean     | 4.24e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 271      |\n",
      "|    iterations      | 172      |\n",
      "|    time_elapsed    | 1458     |\n",
      "|    total_timesteps | 396288   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 596           |\n",
      "|    ep_rew_mean          | 4.24e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 272           |\n",
      "|    iterations           | 173           |\n",
      "|    time_elapsed         | 1461          |\n",
      "|    total_timesteps      | 398592        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00084303506 |\n",
      "|    clip_fraction        | 0.00102       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0957       |\n",
      "|    explained_variance   | 0.576         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.1e+03       |\n",
      "|    n_updates            | 1720          |\n",
      "|    policy_gradient_loss | -0.000133     |\n",
      "|    value_loss           | 2.38e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=400000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 400000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010543795 |\n",
      "|    clip_fraction        | 0.00875      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.103       |\n",
      "|    explained_variance   | 0.523        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 833          |\n",
      "|    n_updates            | 1730         |\n",
      "|    policy_gradient_loss | -0.00124     |\n",
      "|    value_loss           | 3.08e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 597      |\n",
      "|    ep_rew_mean     | 4.26e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 272      |\n",
      "|    iterations      | 174      |\n",
      "|    time_elapsed    | 1471     |\n",
      "|    total_timesteps | 400896   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 595         |\n",
      "|    ep_rew_mean          | 4.25e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 273         |\n",
      "|    iterations           | 175         |\n",
      "|    time_elapsed         | 1474        |\n",
      "|    total_timesteps      | 403200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002518662 |\n",
      "|    clip_fraction        | 0.0309      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.104      |\n",
      "|    explained_variance   | 0.539       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 638         |\n",
      "|    n_updates            | 1740        |\n",
      "|    policy_gradient_loss | -0.00132    |\n",
      "|    value_loss           | 3.07e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=405000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 552           |\n",
      "|    mean_reward          | 4.45e+03      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 405000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00093077886 |\n",
      "|    clip_fraction        | 0.00246       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.101        |\n",
      "|    explained_variance   | 0.52          |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.07e+03      |\n",
      "|    n_updates            | 1750          |\n",
      "|    policy_gradient_loss | -0.000333     |\n",
      "|    value_loss           | 3.18e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 594      |\n",
      "|    ep_rew_mean     | 4.24e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 273      |\n",
      "|    iterations      | 176      |\n",
      "|    time_elapsed    | 1483     |\n",
      "|    total_timesteps | 405504   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 591           |\n",
      "|    ep_rew_mean          | 4.23e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 274           |\n",
      "|    iterations           | 177           |\n",
      "|    time_elapsed         | 1486          |\n",
      "|    total_timesteps      | 407808        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00088181737 |\n",
      "|    clip_fraction        | 0.00156       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0987       |\n",
      "|    explained_variance   | 0.525         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.31e+03      |\n",
      "|    n_updates            | 1760          |\n",
      "|    policy_gradient_loss | -0.000344     |\n",
      "|    value_loss           | 3.16e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=410000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 552           |\n",
      "|    mean_reward          | 4.45e+03      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 410000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00061959616 |\n",
      "|    clip_fraction        | 0.0168        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0946       |\n",
      "|    explained_variance   | 0.48          |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.55e+03      |\n",
      "|    n_updates            | 1770          |\n",
      "|    policy_gradient_loss | -0.00158      |\n",
      "|    value_loss           | 3.2e+03       |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 591      |\n",
      "|    ep_rew_mean     | 4.23e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 274      |\n",
      "|    iterations      | 178      |\n",
      "|    time_elapsed    | 1496     |\n",
      "|    total_timesteps | 410112   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 589          |\n",
      "|    ep_rew_mean          | 4.22e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 275          |\n",
      "|    iterations           | 179          |\n",
      "|    time_elapsed         | 1499         |\n",
      "|    total_timesteps      | 412416       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006333788 |\n",
      "|    clip_fraction        | 0.000156     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0986      |\n",
      "|    explained_variance   | 0.498        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.37e+03     |\n",
      "|    n_updates            | 1780         |\n",
      "|    policy_gradient_loss | -5.97e-05    |\n",
      "|    value_loss           | 3.29e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 587          |\n",
      "|    ep_rew_mean          | 4.21e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 276          |\n",
      "|    iterations           | 180          |\n",
      "|    time_elapsed         | 1502         |\n",
      "|    total_timesteps      | 414720       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008685171 |\n",
      "|    clip_fraction        | 0.00227      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0994      |\n",
      "|    explained_variance   | 0.501        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.07e+03     |\n",
      "|    n_updates            | 1790         |\n",
      "|    policy_gradient_loss | -5.83e-05    |\n",
      "|    value_loss           | 3.69e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=415000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 415000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009731292 |\n",
      "|    clip_fraction        | 0.00902      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.093       |\n",
      "|    explained_variance   | 0.507        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.81e+03     |\n",
      "|    n_updates            | 1800         |\n",
      "|    policy_gradient_loss | -0.0015      |\n",
      "|    value_loss           | 3.1e+03      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 588      |\n",
      "|    ep_rew_mean     | 4.21e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 275      |\n",
      "|    iterations      | 181      |\n",
      "|    time_elapsed    | 1511     |\n",
      "|    total_timesteps | 417024   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 589           |\n",
      "|    ep_rew_mean          | 4.22e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 276           |\n",
      "|    iterations           | 182           |\n",
      "|    time_elapsed         | 1514          |\n",
      "|    total_timesteps      | 419328        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00046822027 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0965       |\n",
      "|    explained_variance   | 0.519         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.11e+03      |\n",
      "|    n_updates            | 1810          |\n",
      "|    policy_gradient_loss | -0.000146     |\n",
      "|    value_loss           | 3.13e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=420000, episode_reward=6687.82 +/- 0.00\n",
      "Episode length: 960.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 960          |\n",
      "|    mean_reward          | 6.69e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 420000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021609631 |\n",
      "|    clip_fraction        | 0.0138       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0977      |\n",
      "|    explained_variance   | 0.52         |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.45e+03     |\n",
      "|    n_updates            | 1820         |\n",
      "|    policy_gradient_loss | 0.000398     |\n",
      "|    value_loss           | 3.44e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 590      |\n",
      "|    ep_rew_mean     | 4.22e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 275      |\n",
      "|    iterations      | 183      |\n",
      "|    time_elapsed    | 1528     |\n",
      "|    total_timesteps | 421632   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 589         |\n",
      "|    ep_rew_mean          | 4.23e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 276         |\n",
      "|    iterations           | 184         |\n",
      "|    time_elapsed         | 1531        |\n",
      "|    total_timesteps      | 423936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002285046 |\n",
      "|    clip_fraction        | 0.0155      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0982     |\n",
      "|    explained_variance   | 0.512       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 590         |\n",
      "|    n_updates            | 1830        |\n",
      "|    policy_gradient_loss | -0.000875   |\n",
      "|    value_loss           | 2.59e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=425000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 552           |\n",
      "|    mean_reward          | 4.45e+03      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 425000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00069162453 |\n",
      "|    clip_fraction        | 0.00883       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0959       |\n",
      "|    explained_variance   | 0.507         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 2.05e+03      |\n",
      "|    n_updates            | 1840          |\n",
      "|    policy_gradient_loss | -0.000347     |\n",
      "|    value_loss           | 3.98e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 586      |\n",
      "|    ep_rew_mean     | 4.21e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 276      |\n",
      "|    iterations      | 185      |\n",
      "|    time_elapsed    | 1541     |\n",
      "|    total_timesteps | 426240   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 580          |\n",
      "|    ep_rew_mean          | 4.18e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 277          |\n",
      "|    iterations           | 186          |\n",
      "|    time_elapsed         | 1544         |\n",
      "|    total_timesteps      | 428544       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001384664 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0964      |\n",
      "|    explained_variance   | 0.501        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.68e+03     |\n",
      "|    n_updates            | 1850         |\n",
      "|    policy_gradient_loss | -4.52e-07    |\n",
      "|    value_loss           | 3.52e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=430000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 430000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009139345 |\n",
      "|    clip_fraction        | 0.0135       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0939      |\n",
      "|    explained_variance   | 0.483        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.46e+03     |\n",
      "|    n_updates            | 1860         |\n",
      "|    policy_gradient_loss | -0.000641    |\n",
      "|    value_loss           | 3.08e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 575      |\n",
      "|    ep_rew_mean     | 4.14e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 277      |\n",
      "|    iterations      | 187      |\n",
      "|    time_elapsed    | 1553     |\n",
      "|    total_timesteps | 430848   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 574           |\n",
      "|    ep_rew_mean          | 4.14e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 278           |\n",
      "|    iterations           | 188           |\n",
      "|    time_elapsed         | 1556          |\n",
      "|    total_timesteps      | 433152        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00073988887 |\n",
      "|    clip_fraction        | 0.00395       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0894       |\n",
      "|    explained_variance   | 0.489         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 2.11e+03      |\n",
      "|    n_updates            | 1870          |\n",
      "|    policy_gradient_loss | -0.000795     |\n",
      "|    value_loss           | 3.93e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=435000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 552           |\n",
      "|    mean_reward          | 4.45e+03      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 435000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00021676719 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0968       |\n",
      "|    explained_variance   | 0.561         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.29e+03      |\n",
      "|    n_updates            | 1880          |\n",
      "|    policy_gradient_loss | -0.00015      |\n",
      "|    value_loss           | 2.48e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 576      |\n",
      "|    ep_rew_mean     | 4.15e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 278      |\n",
      "|    iterations      | 189      |\n",
      "|    time_elapsed    | 1566     |\n",
      "|    total_timesteps | 435456   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 578           |\n",
      "|    ep_rew_mean          | 4.17e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 278           |\n",
      "|    iterations           | 190           |\n",
      "|    time_elapsed         | 1569          |\n",
      "|    total_timesteps      | 437760        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00024621212 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0975       |\n",
      "|    explained_variance   | 0.501         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.12e+03      |\n",
      "|    n_updates            | 1890          |\n",
      "|    policy_gradient_loss | 8.58e-05      |\n",
      "|    value_loss           | 3e+03         |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=440000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 552         |\n",
      "|    mean_reward          | 4.45e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 440000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003791514 |\n",
      "|    clip_fraction        | 0.0306      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0998     |\n",
      "|    explained_variance   | 0.563       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.31e+03    |\n",
      "|    n_updates            | 1900        |\n",
      "|    policy_gradient_loss | -0.000308   |\n",
      "|    value_loss           | 3.13e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 572      |\n",
      "|    ep_rew_mean     | 4.13e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 278      |\n",
      "|    iterations      | 191      |\n",
      "|    time_elapsed    | 1578     |\n",
      "|    total_timesteps | 440064   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 574        |\n",
      "|    ep_rew_mean          | 4.14e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 279        |\n",
      "|    iterations           | 192        |\n",
      "|    time_elapsed         | 1581       |\n",
      "|    total_timesteps      | 442368     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00231885 |\n",
      "|    clip_fraction        | 0.0309     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.09      |\n",
      "|    explained_variance   | 0.502      |\n",
      "|    learning_rate        | 0.003      |\n",
      "|    loss                 | 1.89e+03   |\n",
      "|    n_updates            | 1910       |\n",
      "|    policy_gradient_loss | -0.0017    |\n",
      "|    value_loss           | 3.66e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 571         |\n",
      "|    ep_rew_mean          | 4.12e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 280         |\n",
      "|    iterations           | 193         |\n",
      "|    time_elapsed         | 1584        |\n",
      "|    total_timesteps      | 444672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004467204 |\n",
      "|    clip_fraction        | 0.0338      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0972     |\n",
      "|    explained_variance   | 0.578       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 778         |\n",
      "|    n_updates            | 1920        |\n",
      "|    policy_gradient_loss | -0.00104    |\n",
      "|    value_loss           | 2.39e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=445000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 445000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010862764 |\n",
      "|    clip_fraction        | 0.0235       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0924      |\n",
      "|    explained_variance   | 0.472        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.59e+03     |\n",
      "|    n_updates            | 1930         |\n",
      "|    policy_gradient_loss | -0.00213     |\n",
      "|    value_loss           | 3.59e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 568      |\n",
      "|    ep_rew_mean     | 4.1e+03  |\n",
      "| time/              |          |\n",
      "|    fps             | 280      |\n",
      "|    iterations      | 194      |\n",
      "|    time_elapsed    | 1594     |\n",
      "|    total_timesteps | 446976   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 567          |\n",
      "|    ep_rew_mean          | 4.09e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 281          |\n",
      "|    iterations           | 195          |\n",
      "|    time_elapsed         | 1597         |\n",
      "|    total_timesteps      | 449280       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016417895 |\n",
      "|    clip_fraction        | 0.00258      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0937      |\n",
      "|    explained_variance   | 0.522        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.14e+03     |\n",
      "|    n_updates            | 1940         |\n",
      "|    policy_gradient_loss | 0.000193     |\n",
      "|    value_loss           | 2.99e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=450000, episode_reward=6687.82 +/- 0.00\n",
      "Episode length: 960.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 960          |\n",
      "|    mean_reward          | 6.69e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 450000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063374816 |\n",
      "|    clip_fraction        | 0.0226       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0893      |\n",
      "|    explained_variance   | 0.543        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.29e+03     |\n",
      "|    n_updates            | 1950         |\n",
      "|    policy_gradient_loss | 5.31e-05     |\n",
      "|    value_loss           | 3.03e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 570      |\n",
      "|    ep_rew_mean     | 4.11e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 280      |\n",
      "|    iterations      | 196      |\n",
      "|    time_elapsed    | 1611     |\n",
      "|    total_timesteps | 451584   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 570          |\n",
      "|    ep_rew_mean          | 4.11e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 281          |\n",
      "|    iterations           | 197          |\n",
      "|    time_elapsed         | 1614         |\n",
      "|    total_timesteps      | 453888       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035132945 |\n",
      "|    clip_fraction        | 0.0351       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0937      |\n",
      "|    explained_variance   | 0.571        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.17e+03     |\n",
      "|    n_updates            | 1960         |\n",
      "|    policy_gradient_loss | -0.00132     |\n",
      "|    value_loss           | 3e+03        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=455000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 455000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.247675e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0913      |\n",
      "|    explained_variance   | 0.536        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.65e+03     |\n",
      "|    n_updates            | 1970         |\n",
      "|    policy_gradient_loss | 7.02e-06     |\n",
      "|    value_loss           | 2.33e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 569      |\n",
      "|    ep_rew_mean     | 4.1e+03  |\n",
      "| time/              |          |\n",
      "|    fps             | 280      |\n",
      "|    iterations      | 198      |\n",
      "|    time_elapsed    | 1623     |\n",
      "|    total_timesteps | 456192   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 569          |\n",
      "|    ep_rew_mean          | 4.1e+03      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 281          |\n",
      "|    iterations           | 199          |\n",
      "|    time_elapsed         | 1626         |\n",
      "|    total_timesteps      | 458496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.139904e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0939      |\n",
      "|    explained_variance   | 0.595        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.3e+03      |\n",
      "|    n_updates            | 1980         |\n",
      "|    policy_gradient_loss | -1.97e-05    |\n",
      "|    value_loss           | 2.67e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=460000, episode_reward=6687.82 +/- 0.00\n",
      "Episode length: 960.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 960          |\n",
      "|    mean_reward          | 6.69e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 460000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011886948 |\n",
      "|    clip_fraction        | 0.00387      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.092       |\n",
      "|    explained_variance   | 0.566        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.21e+03     |\n",
      "|    n_updates            | 1990         |\n",
      "|    policy_gradient_loss | -0.000429    |\n",
      "|    value_loss           | 3.17e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 571      |\n",
      "|    ep_rew_mean     | 4.12e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 280      |\n",
      "|    iterations      | 200      |\n",
      "|    time_elapsed    | 1640     |\n",
      "|    total_timesteps | 460800   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 575          |\n",
      "|    ep_rew_mean          | 4.14e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 281          |\n",
      "|    iterations           | 201          |\n",
      "|    time_elapsed         | 1644         |\n",
      "|    total_timesteps      | 463104       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012190363 |\n",
      "|    clip_fraction        | 0.00258      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0928      |\n",
      "|    explained_variance   | 0.601        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 942          |\n",
      "|    n_updates            | 2000         |\n",
      "|    policy_gradient_loss | 2.76e-05     |\n",
      "|    value_loss           | 2.27e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=465000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 465000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016099603 |\n",
      "|    clip_fraction        | 0.0195       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0933      |\n",
      "|    explained_variance   | 0.567        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.18e+03     |\n",
      "|    n_updates            | 2010         |\n",
      "|    policy_gradient_loss | 0.00102      |\n",
      "|    value_loss           | 2.86e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 576      |\n",
      "|    ep_rew_mean     | 4.14e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 281      |\n",
      "|    iterations      | 202      |\n",
      "|    time_elapsed    | 1653     |\n",
      "|    total_timesteps | 465408   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 578          |\n",
      "|    ep_rew_mean          | 4.15e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 282          |\n",
      "|    iterations           | 203          |\n",
      "|    time_elapsed         | 1656         |\n",
      "|    total_timesteps      | 467712       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006029005 |\n",
      "|    clip_fraction        | 0.00344      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0891      |\n",
      "|    explained_variance   | 0.58         |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 661          |\n",
      "|    n_updates            | 2020         |\n",
      "|    policy_gradient_loss | -0.000822    |\n",
      "|    value_loss           | 3.02e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=470000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 470000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006131907 |\n",
      "|    clip_fraction        | 0.0032       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0894      |\n",
      "|    explained_variance   | 0.58         |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 702          |\n",
      "|    n_updates            | 2030         |\n",
      "|    policy_gradient_loss | 1.43e-05     |\n",
      "|    value_loss           | 2.92e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 580      |\n",
      "|    ep_rew_mean     | 4.17e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 282      |\n",
      "|    iterations      | 204      |\n",
      "|    time_elapsed    | 1665     |\n",
      "|    total_timesteps | 470016   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 582          |\n",
      "|    ep_rew_mean          | 4.19e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 283          |\n",
      "|    iterations           | 205          |\n",
      "|    time_elapsed         | 1668         |\n",
      "|    total_timesteps      | 472320       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016822803 |\n",
      "|    clip_fraction        | 0.00867      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0925      |\n",
      "|    explained_variance   | 0.596        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.01e+03     |\n",
      "|    n_updates            | 2040         |\n",
      "|    policy_gradient_loss | -0.000581    |\n",
      "|    value_loss           | 2.85e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 582          |\n",
      "|    ep_rew_mean          | 4.2e+03      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 283          |\n",
      "|    iterations           | 206          |\n",
      "|    time_elapsed         | 1672         |\n",
      "|    total_timesteps      | 474624       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017110407 |\n",
      "|    clip_fraction        | 0.021        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0919      |\n",
      "|    explained_variance   | 0.598        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.62e+03     |\n",
      "|    n_updates            | 2050         |\n",
      "|    policy_gradient_loss | -0.000841    |\n",
      "|    value_loss           | 3.03e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=475000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 475000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010534578 |\n",
      "|    clip_fraction        | 0.0127       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0882      |\n",
      "|    explained_variance   | 0.567        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.75e+03     |\n",
      "|    n_updates            | 2060         |\n",
      "|    policy_gradient_loss | -0.000393    |\n",
      "|    value_loss           | 3.07e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 578      |\n",
      "|    ep_rew_mean     | 4.17e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 283      |\n",
      "|    iterations      | 207      |\n",
      "|    time_elapsed    | 1681     |\n",
      "|    total_timesteps | 476928   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 577         |\n",
      "|    ep_rew_mean          | 4.17e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 208         |\n",
      "|    time_elapsed         | 1684        |\n",
      "|    total_timesteps      | 479232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001311022 |\n",
      "|    clip_fraction        | 0.00902     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0862     |\n",
      "|    explained_variance   | 0.565       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.79e+03    |\n",
      "|    n_updates            | 2070        |\n",
      "|    policy_gradient_loss | -0.00111    |\n",
      "|    value_loss           | 3.51e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=480000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 552           |\n",
      "|    mean_reward          | 4.45e+03      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 480000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.0449926e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0905       |\n",
      "|    explained_variance   | 0.626         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.27e+03      |\n",
      "|    n_updates            | 2080          |\n",
      "|    policy_gradient_loss | 3.64e-05      |\n",
      "|    value_loss           | 2.31e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 578      |\n",
      "|    ep_rew_mean     | 4.18e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 284      |\n",
      "|    iterations      | 209      |\n",
      "|    time_elapsed    | 1693     |\n",
      "|    total_timesteps | 481536   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 583         |\n",
      "|    ep_rew_mean          | 4.21e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 210         |\n",
      "|    time_elapsed         | 1697        |\n",
      "|    total_timesteps      | 483840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008031084 |\n",
      "|    clip_fraction        | 0.0261      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.088      |\n",
      "|    explained_variance   | 0.608       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 933         |\n",
      "|    n_updates            | 2090        |\n",
      "|    policy_gradient_loss | 0.00151     |\n",
      "|    value_loss           | 2.91e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=485000, episode_reward=6687.82 +/- 0.00\n",
      "Episode length: 960.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 960          |\n",
      "|    mean_reward          | 6.69e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 485000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013251838 |\n",
      "|    clip_fraction        | 0.0184       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0898      |\n",
      "|    explained_variance   | 0.57         |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 950          |\n",
      "|    n_updates            | 2100         |\n",
      "|    policy_gradient_loss | -0.000979    |\n",
      "|    value_loss           | 2.5e+03      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 589      |\n",
      "|    ep_rew_mean     | 4.25e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 284      |\n",
      "|    iterations      | 211      |\n",
      "|    time_elapsed    | 1711     |\n",
      "|    total_timesteps | 486144   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 591          |\n",
      "|    ep_rew_mean          | 4.26e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 284          |\n",
      "|    iterations           | 212          |\n",
      "|    time_elapsed         | 1714         |\n",
      "|    total_timesteps      | 488448       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024354388 |\n",
      "|    clip_fraction        | 0.0361       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0915      |\n",
      "|    explained_variance   | 0.593        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.27e+03     |\n",
      "|    n_updates            | 2110         |\n",
      "|    policy_gradient_loss | -0.00217     |\n",
      "|    value_loss           | 2.97e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=490000, episode_reward=6687.82 +/- 0.00\n",
      "Episode length: 960.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 960          |\n",
      "|    mean_reward          | 6.69e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 490000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027011228 |\n",
      "|    clip_fraction        | 0.0157       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0854      |\n",
      "|    explained_variance   | 0.609        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.2e+03      |\n",
      "|    n_updates            | 2120         |\n",
      "|    policy_gradient_loss | -0.000622    |\n",
      "|    value_loss           | 2.74e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 594      |\n",
      "|    ep_rew_mean     | 4.29e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 283      |\n",
      "|    iterations      | 213      |\n",
      "|    time_elapsed    | 1728     |\n",
      "|    total_timesteps | 490752   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 596          |\n",
      "|    ep_rew_mean          | 4.3e+03      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 284          |\n",
      "|    iterations           | 214          |\n",
      "|    time_elapsed         | 1731         |\n",
      "|    total_timesteps      | 493056       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019503596 |\n",
      "|    clip_fraction        | 0.0151       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0886      |\n",
      "|    explained_variance   | 0.611        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.18e+03     |\n",
      "|    n_updates            | 2130         |\n",
      "|    policy_gradient_loss | -0.00117     |\n",
      "|    value_loss           | 2.42e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=495000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 552         |\n",
      "|    mean_reward          | 4.45e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 495000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002857493 |\n",
      "|    clip_fraction        | 0.0144      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0914     |\n",
      "|    explained_variance   | 0.591       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.19e+03    |\n",
      "|    n_updates            | 2140        |\n",
      "|    policy_gradient_loss | -0.000427   |\n",
      "|    value_loss           | 3.01e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 594      |\n",
      "|    ep_rew_mean     | 4.29e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 284      |\n",
      "|    iterations      | 215      |\n",
      "|    time_elapsed    | 1740     |\n",
      "|    total_timesteps | 495360   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 594          |\n",
      "|    ep_rew_mean          | 4.3e+03      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 285          |\n",
      "|    iterations           | 216          |\n",
      "|    time_elapsed         | 1743         |\n",
      "|    total_timesteps      | 497664       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012422837 |\n",
      "|    clip_fraction        | 0.0208       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0862      |\n",
      "|    explained_variance   | 0.543        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.06e+03     |\n",
      "|    n_updates            | 2150         |\n",
      "|    policy_gradient_loss | -0.00203     |\n",
      "|    value_loss           | 2.94e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 598         |\n",
      "|    ep_rew_mean          | 4.33e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 217         |\n",
      "|    time_elapsed         | 1746        |\n",
      "|    total_timesteps      | 499968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004501844 |\n",
      "|    clip_fraction        | 0.0401      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0828     |\n",
      "|    explained_variance   | 0.592       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.8e+03     |\n",
      "|    n_updates            | 2160        |\n",
      "|    policy_gradient_loss | 0.00333     |\n",
      "|    value_loss           | 2.87e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=500000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 500000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002592224 |\n",
      "|    clip_fraction        | 0.00148      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0841      |\n",
      "|    explained_variance   | 0.577        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 964          |\n",
      "|    n_updates            | 2170         |\n",
      "|    policy_gradient_loss | -0.000204    |\n",
      "|    value_loss           | 3e+03        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 600      |\n",
      "|    ep_rew_mean     | 4.34e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 286      |\n",
      "|    iterations      | 218      |\n",
      "|    time_elapsed    | 1756     |\n",
      "|    total_timesteps | 502272   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 601          |\n",
      "|    ep_rew_mean          | 4.36e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 286          |\n",
      "|    iterations           | 219          |\n",
      "|    time_elapsed         | 1759         |\n",
      "|    total_timesteps      | 504576       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0140278265 |\n",
      "|    clip_fraction        | 0.0186       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0867      |\n",
      "|    explained_variance   | 0.603        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.87e+03     |\n",
      "|    n_updates            | 2180         |\n",
      "|    policy_gradient_loss | 0.0029       |\n",
      "|    value_loss           | 2.25e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=505000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 505000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005688133 |\n",
      "|    clip_fraction        | 0.0144       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0851      |\n",
      "|    explained_variance   | 0.57         |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.33e+03     |\n",
      "|    n_updates            | 2190         |\n",
      "|    policy_gradient_loss | -5.03e-05    |\n",
      "|    value_loss           | 3.75e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 600      |\n",
      "|    ep_rew_mean     | 4.36e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 286      |\n",
      "|    iterations      | 220      |\n",
      "|    time_elapsed    | 1768     |\n",
      "|    total_timesteps | 506880   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 603         |\n",
      "|    ep_rew_mean          | 4.38e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 221         |\n",
      "|    time_elapsed         | 1771        |\n",
      "|    total_timesteps      | 509184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003845226 |\n",
      "|    clip_fraction        | 0.0435      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0897     |\n",
      "|    explained_variance   | 0.556       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.7e+03     |\n",
      "|    n_updates            | 2200        |\n",
      "|    policy_gradient_loss | 0.0118      |\n",
      "|    value_loss           | 2.94e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=510000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 552           |\n",
      "|    mean_reward          | 4.45e+03      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 510000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012478945 |\n",
      "|    clip_fraction        | 0.000742      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0842       |\n",
      "|    explained_variance   | 0.642         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.36e+03      |\n",
      "|    n_updates            | 2210          |\n",
      "|    policy_gradient_loss | -0.000516     |\n",
      "|    value_loss           | 2.23e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 603      |\n",
      "|    ep_rew_mean     | 4.38e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 287      |\n",
      "|    iterations      | 222      |\n",
      "|    time_elapsed    | 1781     |\n",
      "|    total_timesteps | 511488   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 605           |\n",
      "|    ep_rew_mean          | 4.39e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 287           |\n",
      "|    iterations           | 223           |\n",
      "|    time_elapsed         | 1784          |\n",
      "|    total_timesteps      | 513792        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013627413 |\n",
      "|    clip_fraction        | 3.91e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0869       |\n",
      "|    explained_variance   | 0.602         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 939           |\n",
      "|    n_updates            | 2220          |\n",
      "|    policy_gradient_loss | -1.66e-05     |\n",
      "|    value_loss           | 2.87e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=515000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 552         |\n",
      "|    mean_reward          | 4.45e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 515000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002364868 |\n",
      "|    clip_fraction        | 0.0181      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.083      |\n",
      "|    explained_variance   | 0.633       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 694         |\n",
      "|    n_updates            | 2230        |\n",
      "|    policy_gradient_loss | -0.00151    |\n",
      "|    value_loss           | 2.36e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 605      |\n",
      "|    ep_rew_mean     | 4.39e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 287      |\n",
      "|    iterations      | 224      |\n",
      "|    time_elapsed    | 1793     |\n",
      "|    total_timesteps | 516096   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 606          |\n",
      "|    ep_rew_mean          | 4.41e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 288          |\n",
      "|    iterations           | 225          |\n",
      "|    time_elapsed         | 1796         |\n",
      "|    total_timesteps      | 518400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045924243 |\n",
      "|    clip_fraction        | 0.0176       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0835      |\n",
      "|    explained_variance   | 0.647        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 743          |\n",
      "|    n_updates            | 2240         |\n",
      "|    policy_gradient_loss | -0.000185    |\n",
      "|    value_loss           | 2.78e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=520000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 552         |\n",
      "|    mean_reward          | 4.45e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 520000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003999508 |\n",
      "|    clip_fraction        | 0.0248      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0848     |\n",
      "|    explained_variance   | 0.582       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.34e+03    |\n",
      "|    n_updates            | 2250        |\n",
      "|    policy_gradient_loss | -0.00183    |\n",
      "|    value_loss           | 3.07e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 607      |\n",
      "|    ep_rew_mean     | 4.42e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 288      |\n",
      "|    iterations      | 226      |\n",
      "|    time_elapsed    | 1806     |\n",
      "|    total_timesteps | 520704   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 606          |\n",
      "|    ep_rew_mean          | 4.42e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 289          |\n",
      "|    iterations           | 227          |\n",
      "|    time_elapsed         | 1809         |\n",
      "|    total_timesteps      | 523008       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009860116 |\n",
      "|    clip_fraction        | 0.00582      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0834      |\n",
      "|    explained_variance   | 0.62         |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.66e+03     |\n",
      "|    n_updates            | 2260         |\n",
      "|    policy_gradient_loss | -0.000389    |\n",
      "|    value_loss           | 2.38e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=525000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 525000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014397271 |\n",
      "|    clip_fraction        | 0.00398      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0808      |\n",
      "|    explained_variance   | 0.629        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.09e+03     |\n",
      "|    n_updates            | 2270         |\n",
      "|    policy_gradient_loss | -8.2e-05     |\n",
      "|    value_loss           | 2.77e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 609      |\n",
      "|    ep_rew_mean     | 4.44e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 288      |\n",
      "|    iterations      | 228      |\n",
      "|    time_elapsed    | 1818     |\n",
      "|    total_timesteps | 525312   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 612          |\n",
      "|    ep_rew_mean          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 289          |\n",
      "|    iterations           | 229          |\n",
      "|    time_elapsed         | 1821         |\n",
      "|    total_timesteps      | 527616       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004975406 |\n",
      "|    clip_fraction        | 0.0419       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0793      |\n",
      "|    explained_variance   | 0.626        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.15e+03     |\n",
      "|    n_updates            | 2280         |\n",
      "|    policy_gradient_loss | 0.00326      |\n",
      "|    value_loss           | 2.9e+03      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 615         |\n",
      "|    ep_rew_mean          | 4.48e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 230         |\n",
      "|    time_elapsed         | 1824        |\n",
      "|    total_timesteps      | 529920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002501673 |\n",
      "|    clip_fraction        | 0.018       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0836     |\n",
      "|    explained_variance   | 0.655       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.15e+03    |\n",
      "|    n_updates            | 2290        |\n",
      "|    policy_gradient_loss | -0.00182    |\n",
      "|    value_loss           | 2.35e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=530000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 530000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005963768 |\n",
      "|    clip_fraction        | 0.000547     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0813      |\n",
      "|    explained_variance   | 0.61         |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.02e+03     |\n",
      "|    n_updates            | 2300         |\n",
      "|    policy_gradient_loss | -0.000395    |\n",
      "|    value_loss           | 3.04e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 614      |\n",
      "|    ep_rew_mean     | 4.47e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 290      |\n",
      "|    iterations      | 231      |\n",
      "|    time_elapsed    | 1834     |\n",
      "|    total_timesteps | 532224   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 618           |\n",
      "|    ep_rew_mean          | 4.49e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 290           |\n",
      "|    iterations           | 232           |\n",
      "|    time_elapsed         | 1837          |\n",
      "|    total_timesteps      | 534528        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00026666775 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0817       |\n",
      "|    explained_variance   | 0.648         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 619           |\n",
      "|    n_updates            | 2310          |\n",
      "|    policy_gradient_loss | -9.53e-05     |\n",
      "|    value_loss           | 2.38e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=535000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 552           |\n",
      "|    mean_reward          | 4.45e+03      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 535000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.5842218e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0816       |\n",
      "|    explained_variance   | 0.613         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.74e+03      |\n",
      "|    n_updates            | 2320          |\n",
      "|    policy_gradient_loss | -6.05e-05     |\n",
      "|    value_loss           | 3.19e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 622      |\n",
      "|    ep_rew_mean     | 4.52e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 290      |\n",
      "|    iterations      | 233      |\n",
      "|    time_elapsed    | 1846     |\n",
      "|    total_timesteps | 536832   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 624         |\n",
      "|    ep_rew_mean          | 4.53e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 234         |\n",
      "|    time_elapsed         | 1849        |\n",
      "|    total_timesteps      | 539136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005240784 |\n",
      "|    clip_fraction        | 0.0355      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0844     |\n",
      "|    explained_variance   | 0.65        |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.37e+03    |\n",
      "|    n_updates            | 2330        |\n",
      "|    policy_gradient_loss | -0.00385    |\n",
      "|    value_loss           | 2.53e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=540000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 540000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004611187 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0828      |\n",
      "|    explained_variance   | 0.61         |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.98e+03     |\n",
      "|    n_updates            | 2340         |\n",
      "|    policy_gradient_loss | -7.86e-05    |\n",
      "|    value_loss           | 3.12e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 624      |\n",
      "|    ep_rew_mean     | 4.53e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 291      |\n",
      "|    iterations      | 235      |\n",
      "|    time_elapsed    | 1859     |\n",
      "|    total_timesteps | 541440   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 621          |\n",
      "|    ep_rew_mean          | 4.51e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 291          |\n",
      "|    iterations           | 236          |\n",
      "|    time_elapsed         | 1862         |\n",
      "|    total_timesteps      | 543744       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009784171 |\n",
      "|    clip_fraction        | 0.00453      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0838      |\n",
      "|    explained_variance   | 0.628        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.31e+03     |\n",
      "|    n_updates            | 2350         |\n",
      "|    policy_gradient_loss | -0.000652    |\n",
      "|    value_loss           | 3.11e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=545000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 545000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005185253 |\n",
      "|    clip_fraction        | 0.0163       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0868      |\n",
      "|    explained_variance   | 0.63         |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.2e+03      |\n",
      "|    n_updates            | 2360         |\n",
      "|    policy_gradient_loss | 0.000591     |\n",
      "|    value_loss           | 3.19e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 612      |\n",
      "|    ep_rew_mean     | 4.45e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 291      |\n",
      "|    iterations      | 237      |\n",
      "|    time_elapsed    | 1871     |\n",
      "|    total_timesteps | 546048   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 607          |\n",
      "|    ep_rew_mean          | 4.42e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 292          |\n",
      "|    iterations           | 238          |\n",
      "|    time_elapsed         | 1874         |\n",
      "|    total_timesteps      | 548352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011353418 |\n",
      "|    clip_fraction        | 0.0214       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0796      |\n",
      "|    explained_variance   | 0.558        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.25e+03     |\n",
      "|    n_updates            | 2370         |\n",
      "|    policy_gradient_loss | -0.00199     |\n",
      "|    value_loss           | 4.57e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=550000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 550000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013563584 |\n",
      "|    clip_fraction        | 0.00848      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0788      |\n",
      "|    explained_variance   | 0.579        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 897          |\n",
      "|    n_updates            | 2380         |\n",
      "|    policy_gradient_loss | -0.00136     |\n",
      "|    value_loss           | 3.63e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 605      |\n",
      "|    ep_rew_mean     | 4.41e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 292      |\n",
      "|    iterations      | 239      |\n",
      "|    time_elapsed    | 1884     |\n",
      "|    total_timesteps | 550656   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 600          |\n",
      "|    ep_rew_mean          | 4.38e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 292          |\n",
      "|    iterations           | 240          |\n",
      "|    time_elapsed         | 1887         |\n",
      "|    total_timesteps      | 552960       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011947892 |\n",
      "|    clip_fraction        | 0.00652      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0836      |\n",
      "|    explained_variance   | 0.639        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.59e+03     |\n",
      "|    n_updates            | 2390         |\n",
      "|    policy_gradient_loss | -0.000824    |\n",
      "|    value_loss           | 2.42e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=555000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 552           |\n",
      "|    mean_reward          | 4.45e+03      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 555000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00067399803 |\n",
      "|    clip_fraction        | 0.00332       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0782       |\n",
      "|    explained_variance   | 0.584         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.59e+03      |\n",
      "|    n_updates            | 2400          |\n",
      "|    policy_gradient_loss | -0.000755     |\n",
      "|    value_loss           | 3.67e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 600      |\n",
      "|    ep_rew_mean     | 4.37e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 292      |\n",
      "|    iterations      | 241      |\n",
      "|    time_elapsed    | 1896     |\n",
      "|    total_timesteps | 555264   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 598          |\n",
      "|    ep_rew_mean          | 4.35e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 293          |\n",
      "|    iterations           | 242          |\n",
      "|    time_elapsed         | 1899         |\n",
      "|    total_timesteps      | 557568       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.606563e-05 |\n",
      "|    clip_fraction        | 0.00508      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0804      |\n",
      "|    explained_variance   | 0.623        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.54e+03     |\n",
      "|    n_updates            | 2410         |\n",
      "|    policy_gradient_loss | 0.000176     |\n",
      "|    value_loss           | 3.19e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 595          |\n",
      "|    ep_rew_mean          | 4.34e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 294          |\n",
      "|    iterations           | 243          |\n",
      "|    time_elapsed         | 1903         |\n",
      "|    total_timesteps      | 559872       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007997214 |\n",
      "|    clip_fraction        | 0.00906      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0782      |\n",
      "|    explained_variance   | 0.619        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.2e+03      |\n",
      "|    n_updates            | 2420         |\n",
      "|    policy_gradient_loss | -0.000761    |\n",
      "|    value_loss           | 3.21e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=560000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 552           |\n",
      "|    mean_reward          | 4.45e+03      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 560000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00028424524 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0796       |\n",
      "|    explained_variance   | 0.632         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 2.19e+03      |\n",
      "|    n_updates            | 2430          |\n",
      "|    policy_gradient_loss | -8.84e-05     |\n",
      "|    value_loss           | 3.11e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 593      |\n",
      "|    ep_rew_mean     | 4.33e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 293      |\n",
      "|    iterations      | 244      |\n",
      "|    time_elapsed    | 1912     |\n",
      "|    total_timesteps | 562176   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 594           |\n",
      "|    ep_rew_mean          | 4.34e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 294           |\n",
      "|    iterations           | 245           |\n",
      "|    time_elapsed         | 1915          |\n",
      "|    total_timesteps      | 564480        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.8987673e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0824       |\n",
      "|    explained_variance   | 0.621         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.31e+03      |\n",
      "|    n_updates            | 2440          |\n",
      "|    policy_gradient_loss | -1.34e-05     |\n",
      "|    value_loss           | 3.07e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=565000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 552           |\n",
      "|    mean_reward          | 4.45e+03      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 565000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00069265143 |\n",
      "|    clip_fraction        | 0.00402       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0781       |\n",
      "|    explained_variance   | 0.646         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 2.03e+03      |\n",
      "|    n_updates            | 2450          |\n",
      "|    policy_gradient_loss | -0.00061      |\n",
      "|    value_loss           | 3.02e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 596      |\n",
      "|    ep_rew_mean     | 4.36e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 294      |\n",
      "|    iterations      | 246      |\n",
      "|    time_elapsed    | 1924     |\n",
      "|    total_timesteps | 566784   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 595          |\n",
      "|    ep_rew_mean          | 4.35e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 295          |\n",
      "|    iterations           | 247          |\n",
      "|    time_elapsed         | 1928         |\n",
      "|    total_timesteps      | 569088       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003151495 |\n",
      "|    clip_fraction        | 0.000156     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0809      |\n",
      "|    explained_variance   | 0.645        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.26e+03     |\n",
      "|    n_updates            | 2460         |\n",
      "|    policy_gradient_loss | -0.00015     |\n",
      "|    value_loss           | 3.08e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=570000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 552         |\n",
      "|    mean_reward          | 4.45e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 570000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001443427 |\n",
      "|    clip_fraction        | 0.00363     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0799     |\n",
      "|    explained_variance   | 0.657       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.07e+03    |\n",
      "|    n_updates            | 2470        |\n",
      "|    policy_gradient_loss | -0.000406   |\n",
      "|    value_loss           | 3.03e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 594      |\n",
      "|    ep_rew_mean     | 4.35e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 294      |\n",
      "|    iterations      | 248      |\n",
      "|    time_elapsed    | 1937     |\n",
      "|    total_timesteps | 571392   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 591          |\n",
      "|    ep_rew_mean          | 4.33e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 295          |\n",
      "|    iterations           | 249          |\n",
      "|    time_elapsed         | 1940         |\n",
      "|    total_timesteps      | 573696       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004562932 |\n",
      "|    clip_fraction        | 0.00562      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0787      |\n",
      "|    explained_variance   | 0.642        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.62e+03     |\n",
      "|    n_updates            | 2480         |\n",
      "|    policy_gradient_loss | -0.000383    |\n",
      "|    value_loss           | 2.85e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=575000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 575000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002860435 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0779      |\n",
      "|    explained_variance   | 0.638        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.77e+03     |\n",
      "|    n_updates            | 2490         |\n",
      "|    policy_gradient_loss | -0.0002      |\n",
      "|    value_loss           | 2.76e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 593      |\n",
      "|    ep_rew_mean     | 4.35e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 295      |\n",
      "|    iterations      | 250      |\n",
      "|    time_elapsed    | 1950     |\n",
      "|    total_timesteps | 576000   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 591          |\n",
      "|    ep_rew_mean          | 4.33e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 296          |\n",
      "|    iterations           | 251          |\n",
      "|    time_elapsed         | 1953         |\n",
      "|    total_timesteps      | 578304       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030658464 |\n",
      "|    clip_fraction        | 0.0105       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0811      |\n",
      "|    explained_variance   | 0.626        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 993          |\n",
      "|    n_updates            | 2500         |\n",
      "|    policy_gradient_loss | -0.000223    |\n",
      "|    value_loss           | 2.9e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=580000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 552         |\n",
      "|    mean_reward          | 4.45e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 580000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006755382 |\n",
      "|    clip_fraction        | 0.03        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0861     |\n",
      "|    explained_variance   | 0.596       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1e+03       |\n",
      "|    n_updates            | 2510        |\n",
      "|    policy_gradient_loss | -0.00223    |\n",
      "|    value_loss           | 3.01e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 585      |\n",
      "|    ep_rew_mean     | 4.27e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 295      |\n",
      "|    iterations      | 252      |\n",
      "|    time_elapsed    | 1962     |\n",
      "|    total_timesteps | 580608   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 581         |\n",
      "|    ep_rew_mean          | 4.24e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 296         |\n",
      "|    iterations           | 253         |\n",
      "|    time_elapsed         | 1965        |\n",
      "|    total_timesteps      | 582912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002062073 |\n",
      "|    clip_fraction        | 0.00957     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0809     |\n",
      "|    explained_variance   | 0.498       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 2.37e+03    |\n",
      "|    n_updates            | 2520        |\n",
      "|    policy_gradient_loss | -0.00127    |\n",
      "|    value_loss           | 4.62e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=585000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 552           |\n",
      "|    mean_reward          | 4.45e+03      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 585000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7023453e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0821       |\n",
      "|    explained_variance   | 0.608         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.46e+03      |\n",
      "|    n_updates            | 2530          |\n",
      "|    policy_gradient_loss | 8.66e-05      |\n",
      "|    value_loss           | 3.07e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 575      |\n",
      "|    ep_rew_mean     | 4.2e+03  |\n",
      "| time/              |          |\n",
      "|    fps             | 296      |\n",
      "|    iterations      | 254      |\n",
      "|    time_elapsed    | 1974     |\n",
      "|    total_timesteps | 585216   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 569           |\n",
      "|    ep_rew_mean          | 4.16e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 297           |\n",
      "|    iterations           | 255           |\n",
      "|    time_elapsed         | 1978          |\n",
      "|    total_timesteps      | 587520        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00033563067 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0812       |\n",
      "|    explained_variance   | 0.612         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.47e+03      |\n",
      "|    n_updates            | 2540          |\n",
      "|    policy_gradient_loss | 0.000108      |\n",
      "|    value_loss           | 3.06e+03      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 565         |\n",
      "|    ep_rew_mean          | 4.13e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 297         |\n",
      "|    iterations           | 256         |\n",
      "|    time_elapsed         | 1981        |\n",
      "|    total_timesteps      | 589824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001067399 |\n",
      "|    clip_fraction        | 0.00793     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0816     |\n",
      "|    explained_variance   | 0.589       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 2.05e+03    |\n",
      "|    n_updates            | 2550        |\n",
      "|    policy_gradient_loss | -0.000714   |\n",
      "|    value_loss           | 3.58e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=590000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 590000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007467931 |\n",
      "|    clip_fraction        | 0.00133      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0804      |\n",
      "|    explained_variance   | 0.643        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.15e+03     |\n",
      "|    n_updates            | 2560         |\n",
      "|    policy_gradient_loss | 0.000127     |\n",
      "|    value_loss           | 2.88e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 562      |\n",
      "|    ep_rew_mean     | 4.12e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 297      |\n",
      "|    iterations      | 257      |\n",
      "|    time_elapsed    | 1990     |\n",
      "|    total_timesteps | 592128   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 560           |\n",
      "|    ep_rew_mean          | 4.11e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 298           |\n",
      "|    iterations           | 258           |\n",
      "|    time_elapsed         | 1993          |\n",
      "|    total_timesteps      | 594432        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5893096e-05 |\n",
      "|    clip_fraction        | 0.00637       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0772       |\n",
      "|    explained_variance   | 0.615         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.64e+03      |\n",
      "|    n_updates            | 2570          |\n",
      "|    policy_gradient_loss | 0.000516      |\n",
      "|    value_loss           | 2.92e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=595000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 595000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009953483 |\n",
      "|    clip_fraction        | 0.00801      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0773      |\n",
      "|    explained_variance   | 0.618        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.61e+03     |\n",
      "|    n_updates            | 2580         |\n",
      "|    policy_gradient_loss | -0.000551    |\n",
      "|    value_loss           | 2.93e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 560      |\n",
      "|    ep_rew_mean     | 4.11e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 297      |\n",
      "|    iterations      | 259      |\n",
      "|    time_elapsed    | 2003     |\n",
      "|    total_timesteps | 596736   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 561           |\n",
      "|    ep_rew_mean          | 4.12e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 298           |\n",
      "|    iterations           | 260           |\n",
      "|    time_elapsed         | 2006          |\n",
      "|    total_timesteps      | 599040        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017783919 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0777       |\n",
      "|    explained_variance   | 0.635         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.49e+03      |\n",
      "|    n_updates            | 2590          |\n",
      "|    policy_gradient_loss | -6.85e-05     |\n",
      "|    value_loss           | 3.01e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=600000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 552           |\n",
      "|    mean_reward          | 4.45e+03      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 600000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020607293 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0791       |\n",
      "|    explained_variance   | 0.607         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.98e+03      |\n",
      "|    n_updates            | 2600          |\n",
      "|    policy_gradient_loss | -0.0002       |\n",
      "|    value_loss           | 3.42e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 564      |\n",
      "|    ep_rew_mean     | 4.15e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 298      |\n",
      "|    iterations      | 261      |\n",
      "|    time_elapsed    | 2015     |\n",
      "|    total_timesteps | 601344   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 567         |\n",
      "|    ep_rew_mean          | 4.18e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 299         |\n",
      "|    iterations           | 262         |\n",
      "|    time_elapsed         | 2018        |\n",
      "|    total_timesteps      | 603648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 6.64763e-06 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0784     |\n",
      "|    explained_variance   | 0.604       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.84e+03    |\n",
      "|    n_updates            | 2610        |\n",
      "|    policy_gradient_loss | 4.57e-05    |\n",
      "|    value_loss           | 3.09e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=605000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 552         |\n",
      "|    mean_reward          | 4.45e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 605000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000747787 |\n",
      "|    clip_fraction        | 0.00277     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0774     |\n",
      "|    explained_variance   | 0.593       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.72e+03    |\n",
      "|    n_updates            | 2620        |\n",
      "|    policy_gradient_loss | -0.000117   |\n",
      "|    value_loss           | 3.1e+03     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 569      |\n",
      "|    ep_rew_mean     | 4.19e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 298      |\n",
      "|    iterations      | 263      |\n",
      "|    time_elapsed    | 2028     |\n",
      "|    total_timesteps | 605952   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 569           |\n",
      "|    ep_rew_mean          | 4.19e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 299           |\n",
      "|    iterations           | 264           |\n",
      "|    time_elapsed         | 2031          |\n",
      "|    total_timesteps      | 608256        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012068961 |\n",
      "|    clip_fraction        | 0.00184       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0763       |\n",
      "|    explained_variance   | 0.618         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 2.3e+03       |\n",
      "|    n_updates            | 2630          |\n",
      "|    policy_gradient_loss | -0.000271     |\n",
      "|    value_loss           | 3.18e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=610000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 552           |\n",
      "|    mean_reward          | 4.45e+03      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 610000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020679741 |\n",
      "|    clip_fraction        | 0.00738       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.076        |\n",
      "|    explained_variance   | 0.533         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 2.02e+03      |\n",
      "|    n_updates            | 2640          |\n",
      "|    policy_gradient_loss | -0.000155     |\n",
      "|    value_loss           | 3.76e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 571      |\n",
      "|    ep_rew_mean     | 4.21e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 299      |\n",
      "|    iterations      | 265      |\n",
      "|    time_elapsed    | 2040     |\n",
      "|    total_timesteps | 610560   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 570          |\n",
      "|    ep_rew_mean          | 4.2e+03      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 299          |\n",
      "|    iterations           | 266          |\n",
      "|    time_elapsed         | 2043         |\n",
      "|    total_timesteps      | 612864       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005921958 |\n",
      "|    clip_fraction        | 0.000469     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0788      |\n",
      "|    explained_variance   | 0.525        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.06e+03     |\n",
      "|    n_updates            | 2650         |\n",
      "|    policy_gradient_loss | -0.000329    |\n",
      "|    value_loss           | 3.49e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=615000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 615000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015841562 |\n",
      "|    clip_fraction        | 0.00504      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0755      |\n",
      "|    explained_variance   | 0.558        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.37e+03     |\n",
      "|    n_updates            | 2660         |\n",
      "|    policy_gradient_loss | -9.01e-05    |\n",
      "|    value_loss           | 3.2e+03      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 572      |\n",
      "|    ep_rew_mean     | 4.22e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 299      |\n",
      "|    iterations      | 267      |\n",
      "|    time_elapsed    | 2052     |\n",
      "|    total_timesteps | 615168   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 574           |\n",
      "|    ep_rew_mean          | 4.23e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 300           |\n",
      "|    iterations           | 268           |\n",
      "|    time_elapsed         | 2056          |\n",
      "|    total_timesteps      | 617472        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00062934187 |\n",
      "|    clip_fraction        | 0.00527       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.079        |\n",
      "|    explained_variance   | 0.602         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 757           |\n",
      "|    n_updates            | 2670          |\n",
      "|    policy_gradient_loss | -0.000972     |\n",
      "|    value_loss           | 3.29e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 575           |\n",
      "|    ep_rew_mean          | 4.24e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 300           |\n",
      "|    iterations           | 269           |\n",
      "|    time_elapsed         | 2059          |\n",
      "|    total_timesteps      | 619776        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00018704546 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0753       |\n",
      "|    explained_variance   | 0.583         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.52e+03      |\n",
      "|    n_updates            | 2680          |\n",
      "|    policy_gradient_loss | -5.67e-05     |\n",
      "|    value_loss           | 3.24e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=620000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 552           |\n",
      "|    mean_reward          | 4.45e+03      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 620000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00030890992 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0766       |\n",
      "|    explained_variance   | 0.59          |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.48e+03      |\n",
      "|    n_updates            | 2690          |\n",
      "|    policy_gradient_loss | -0.000185     |\n",
      "|    value_loss           | 3.21e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 576      |\n",
      "|    ep_rew_mean     | 4.25e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 300      |\n",
      "|    iterations      | 270      |\n",
      "|    time_elapsed    | 2068     |\n",
      "|    total_timesteps | 622080   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 576           |\n",
      "|    ep_rew_mean          | 4.25e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 301           |\n",
      "|    iterations           | 271           |\n",
      "|    time_elapsed         | 2071          |\n",
      "|    total_timesteps      | 624384        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014647446 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0772       |\n",
      "|    explained_variance   | 0.623         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.51e+03      |\n",
      "|    n_updates            | 2700          |\n",
      "|    policy_gradient_loss | -0.000187     |\n",
      "|    value_loss           | 2.76e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=625000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 552         |\n",
      "|    mean_reward          | 4.45e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 625000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000639506 |\n",
      "|    clip_fraction        | 0.0057      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0748     |\n",
      "|    explained_variance   | 0.594       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.26e+03    |\n",
      "|    n_updates            | 2710        |\n",
      "|    policy_gradient_loss | -0.000597   |\n",
      "|    value_loss           | 3.15e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 575      |\n",
      "|    ep_rew_mean     | 4.25e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 301      |\n",
      "|    iterations      | 272      |\n",
      "|    time_elapsed    | 2081     |\n",
      "|    total_timesteps | 626688   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 572         |\n",
      "|    ep_rew_mean          | 4.23e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 301         |\n",
      "|    iterations           | 273         |\n",
      "|    time_elapsed         | 2084        |\n",
      "|    total_timesteps      | 628992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 9.57625e-05 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0739     |\n",
      "|    explained_variance   | 0.626       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.74e+03    |\n",
      "|    n_updates            | 2720        |\n",
      "|    policy_gradient_loss | 8.83e-06    |\n",
      "|    value_loss           | 3.14e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=630000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 630000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012976936 |\n",
      "|    clip_fraction        | 0.00848      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0753      |\n",
      "|    explained_variance   | 0.615        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.93e+03     |\n",
      "|    n_updates            | 2730         |\n",
      "|    policy_gradient_loss | -0.000588    |\n",
      "|    value_loss           | 3.24e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 569      |\n",
      "|    ep_rew_mean     | 4.21e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 301      |\n",
      "|    iterations      | 274      |\n",
      "|    time_elapsed    | 2093     |\n",
      "|    total_timesteps | 631296   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 568          |\n",
      "|    ep_rew_mean          | 4.21e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 302          |\n",
      "|    iterations           | 275          |\n",
      "|    time_elapsed         | 2096         |\n",
      "|    total_timesteps      | 633600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005039603 |\n",
      "|    clip_fraction        | 0.000703     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.074       |\n",
      "|    explained_variance   | 0.604        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.84e+03     |\n",
      "|    n_updates            | 2740         |\n",
      "|    policy_gradient_loss | -0.000621    |\n",
      "|    value_loss           | 4.12e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=635000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 552           |\n",
      "|    mean_reward          | 4.45e+03      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 635000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016107815 |\n",
      "|    clip_fraction        | 0.00391       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0736       |\n",
      "|    explained_variance   | 0.673         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.75e+03      |\n",
      "|    n_updates            | 2750          |\n",
      "|    policy_gradient_loss | -0.000645     |\n",
      "|    value_loss           | 2.63e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 569      |\n",
      "|    ep_rew_mean     | 4.22e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 301      |\n",
      "|    iterations      | 276      |\n",
      "|    time_elapsed    | 2106     |\n",
      "|    total_timesteps | 635904   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 573          |\n",
      "|    ep_rew_mean          | 4.27e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 302          |\n",
      "|    iterations           | 277          |\n",
      "|    time_elapsed         | 2109         |\n",
      "|    total_timesteps      | 638208       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006118522 |\n",
      "|    clip_fraction        | 0.00156      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0732      |\n",
      "|    explained_variance   | 0.6          |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.81e+03     |\n",
      "|    n_updates            | 2760         |\n",
      "|    policy_gradient_loss | -0.00046     |\n",
      "|    value_loss           | 3.52e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=640000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 640000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.779895e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0747      |\n",
      "|    explained_variance   | 0.63         |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.36e+03     |\n",
      "|    n_updates            | 2770         |\n",
      "|    policy_gradient_loss | -1.93e-05    |\n",
      "|    value_loss           | 3.21e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 575      |\n",
      "|    ep_rew_mean     | 4.29e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 302      |\n",
      "|    iterations      | 278      |\n",
      "|    time_elapsed    | 2118     |\n",
      "|    total_timesteps | 640512   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 577         |\n",
      "|    ep_rew_mean          | 4.31e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 302         |\n",
      "|    iterations           | 279         |\n",
      "|    time_elapsed         | 2121        |\n",
      "|    total_timesteps      | 642816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001190573 |\n",
      "|    clip_fraction        | 0.0121      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0759     |\n",
      "|    explained_variance   | 0.572       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 2.06e+03    |\n",
      "|    n_updates            | 2780        |\n",
      "|    policy_gradient_loss | -0.00068    |\n",
      "|    value_loss           | 3.43e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=645000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 645000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005752942 |\n",
      "|    clip_fraction        | 0.0135       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0729      |\n",
      "|    explained_variance   | 0.578        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.55e+03     |\n",
      "|    n_updates            | 2790         |\n",
      "|    policy_gradient_loss | -0.000603    |\n",
      "|    value_loss           | 3.72e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 580      |\n",
      "|    ep_rew_mean     | 4.34e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 302      |\n",
      "|    iterations      | 280      |\n",
      "|    time_elapsed    | 2130     |\n",
      "|    total_timesteps | 645120   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 580         |\n",
      "|    ep_rew_mean          | 4.34e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 303         |\n",
      "|    iterations           | 281         |\n",
      "|    time_elapsed         | 2134        |\n",
      "|    total_timesteps      | 647424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002761018 |\n",
      "|    clip_fraction        | 0.0173      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0779     |\n",
      "|    explained_variance   | 0.591       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.77e+03    |\n",
      "|    n_updates            | 2800        |\n",
      "|    policy_gradient_loss | -0.00141    |\n",
      "|    value_loss           | 3.49e+03    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 576           |\n",
      "|    ep_rew_mean          | 4.31e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 304           |\n",
      "|    iterations           | 282           |\n",
      "|    time_elapsed         | 2137          |\n",
      "|    total_timesteps      | 649728        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00032102354 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0756       |\n",
      "|    explained_variance   | 0.606         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.6e+03       |\n",
      "|    n_updates            | 2810          |\n",
      "|    policy_gradient_loss | -4.51e-05     |\n",
      "|    value_loss           | 3.29e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=650000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 650000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030576936 |\n",
      "|    clip_fraction        | 0.0224       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0822      |\n",
      "|    explained_variance   | 0.595        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.83e+03     |\n",
      "|    n_updates            | 2820         |\n",
      "|    policy_gradient_loss | 0.00307      |\n",
      "|    value_loss           | 4.11e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 572      |\n",
      "|    ep_rew_mean     | 4.27e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 303      |\n",
      "|    iterations      | 283      |\n",
      "|    time_elapsed    | 2146     |\n",
      "|    total_timesteps | 652032   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 568         |\n",
      "|    ep_rew_mean          | 4.24e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 304         |\n",
      "|    iterations           | 284         |\n",
      "|    time_elapsed         | 2149        |\n",
      "|    total_timesteps      | 654336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002108216 |\n",
      "|    clip_fraction        | 0.0183      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0753     |\n",
      "|    explained_variance   | 0.611       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 2.39e+03    |\n",
      "|    n_updates            | 2830        |\n",
      "|    policy_gradient_loss | -0.00176    |\n",
      "|    value_loss           | 4.15e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=655000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 655000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013512631 |\n",
      "|    clip_fraction        | 0.0191       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0712      |\n",
      "|    explained_variance   | 0.648        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.14e+03     |\n",
      "|    n_updates            | 2840         |\n",
      "|    policy_gradient_loss | -0.00125     |\n",
      "|    value_loss           | 3.3e+03      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 565      |\n",
      "|    ep_rew_mean     | 4.22e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 304      |\n",
      "|    iterations      | 285      |\n",
      "|    time_elapsed    | 2159     |\n",
      "|    total_timesteps | 656640   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 563          |\n",
      "|    ep_rew_mean          | 4.2e+03      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 304          |\n",
      "|    iterations           | 286          |\n",
      "|    time_elapsed         | 2162         |\n",
      "|    total_timesteps      | 658944       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002908575 |\n",
      "|    clip_fraction        | 0.00043      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0747      |\n",
      "|    explained_variance   | 0.6          |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 3.19e+03     |\n",
      "|    n_updates            | 2850         |\n",
      "|    policy_gradient_loss | -0.00028     |\n",
      "|    value_loss           | 3.94e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=660000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 660000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009720752 |\n",
      "|    clip_fraction        | 0.014        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0746      |\n",
      "|    explained_variance   | 0.631        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.01e+03     |\n",
      "|    n_updates            | 2860         |\n",
      "|    policy_gradient_loss | -0.00226     |\n",
      "|    value_loss           | 3.54e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 563      |\n",
      "|    ep_rew_mean     | 4.2e+03  |\n",
      "| time/              |          |\n",
      "|    fps             | 304      |\n",
      "|    iterations      | 287      |\n",
      "|    time_elapsed    | 2171     |\n",
      "|    total_timesteps | 661248   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 562           |\n",
      "|    ep_rew_mean          | 4.19e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 305           |\n",
      "|    iterations           | 288           |\n",
      "|    time_elapsed         | 2174          |\n",
      "|    total_timesteps      | 663552        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.4039875e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0716       |\n",
      "|    explained_variance   | 0.648         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.73e+03      |\n",
      "|    n_updates            | 2870          |\n",
      "|    policy_gradient_loss | -1.6e-05      |\n",
      "|    value_loss           | 3.22e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=665000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 552           |\n",
      "|    mean_reward          | 4.45e+03      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 665000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012483608 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0733       |\n",
      "|    explained_variance   | 0.624         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.05e+03      |\n",
      "|    n_updates            | 2880          |\n",
      "|    policy_gradient_loss | -0.00011      |\n",
      "|    value_loss           | 3.24e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 559      |\n",
      "|    ep_rew_mean     | 4.17e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 304      |\n",
      "|    iterations      | 289      |\n",
      "|    time_elapsed    | 2184     |\n",
      "|    total_timesteps | 665856   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 559           |\n",
      "|    ep_rew_mean          | 4.17e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 305           |\n",
      "|    iterations           | 290           |\n",
      "|    time_elapsed         | 2187          |\n",
      "|    total_timesteps      | 668160        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00074100203 |\n",
      "|    clip_fraction        | 0.00316       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0711       |\n",
      "|    explained_variance   | 0.635         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.48e+03      |\n",
      "|    n_updates            | 2890          |\n",
      "|    policy_gradient_loss | -0.000452     |\n",
      "|    value_loss           | 3.77e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=670000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 552           |\n",
      "|    mean_reward          | 4.45e+03      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 670000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00021995096 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0722       |\n",
      "|    explained_variance   | 0.672         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.67e+03      |\n",
      "|    n_updates            | 2900          |\n",
      "|    policy_gradient_loss | -0.000111     |\n",
      "|    value_loss           | 3.28e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 558      |\n",
      "|    ep_rew_mean     | 4.17e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 305      |\n",
      "|    iterations      | 291      |\n",
      "|    time_elapsed    | 2196     |\n",
      "|    total_timesteps | 670464   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 557         |\n",
      "|    ep_rew_mean          | 4.16e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 305         |\n",
      "|    iterations           | 292         |\n",
      "|    time_elapsed         | 2199        |\n",
      "|    total_timesteps      | 672768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000350374 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0738     |\n",
      "|    explained_variance   | 0.679       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.51e+03    |\n",
      "|    n_updates            | 2910        |\n",
      "|    policy_gradient_loss | -4.4e-05    |\n",
      "|    value_loss           | 3.06e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=675000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 552           |\n",
      "|    mean_reward          | 4.45e+03      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 675000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00040419507 |\n",
      "|    clip_fraction        | 0.00883       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.073        |\n",
      "|    explained_variance   | 0.618         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.48e+03      |\n",
      "|    n_updates            | 2920          |\n",
      "|    policy_gradient_loss | -0.000266     |\n",
      "|    value_loss           | 3.47e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 555      |\n",
      "|    ep_rew_mean     | 4.15e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 305      |\n",
      "|    iterations      | 293      |\n",
      "|    time_elapsed    | 2209     |\n",
      "|    total_timesteps | 675072   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 554          |\n",
      "|    ep_rew_mean          | 4.14e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 306          |\n",
      "|    iterations           | 294          |\n",
      "|    time_elapsed         | 2212         |\n",
      "|    total_timesteps      | 677376       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011369439 |\n",
      "|    clip_fraction        | 0.00504      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.075       |\n",
      "|    explained_variance   | 0.671        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.24e+03     |\n",
      "|    n_updates            | 2930         |\n",
      "|    policy_gradient_loss | -0.000301    |\n",
      "|    value_loss           | 3.1e+03      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 552           |\n",
      "|    ep_rew_mean          | 4.12e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 306           |\n",
      "|    iterations           | 295           |\n",
      "|    time_elapsed         | 2215          |\n",
      "|    total_timesteps      | 679680        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00027462767 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0733       |\n",
      "|    explained_variance   | 0.679         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.26e+03      |\n",
      "|    n_updates            | 2940          |\n",
      "|    policy_gradient_loss | -0.000166     |\n",
      "|    value_loss           | 3.26e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=680000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 680000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002255612 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0721      |\n",
      "|    explained_variance   | 0.643        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.93e+03     |\n",
      "|    n_updates            | 2950         |\n",
      "|    policy_gradient_loss | -0.000356    |\n",
      "|    value_loss           | 3.83e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 550      |\n",
      "|    ep_rew_mean     | 4.1e+03  |\n",
      "| time/              |          |\n",
      "|    fps             | 306      |\n",
      "|    iterations      | 296      |\n",
      "|    time_elapsed    | 2224     |\n",
      "|    total_timesteps | 681984   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 548          |\n",
      "|    ep_rew_mean          | 4.09e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 307          |\n",
      "|    iterations           | 297          |\n",
      "|    time_elapsed         | 2227         |\n",
      "|    total_timesteps      | 684288       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008087844 |\n",
      "|    clip_fraction        | 0.00469      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.07        |\n",
      "|    explained_variance   | 0.678        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.6e+03      |\n",
      "|    n_updates            | 2960         |\n",
      "|    policy_gradient_loss | -0.000759    |\n",
      "|    value_loss           | 2.91e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=685000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 552           |\n",
      "|    mean_reward          | 4.45e+03      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 685000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.5126275e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0727       |\n",
      "|    explained_variance   | 0.667         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 2.1e+03       |\n",
      "|    n_updates            | 2970          |\n",
      "|    policy_gradient_loss | -5.41e-05     |\n",
      "|    value_loss           | 3.16e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 549      |\n",
      "|    ep_rew_mean     | 4.1e+03  |\n",
      "| time/              |          |\n",
      "|    fps             | 306      |\n",
      "|    iterations      | 298      |\n",
      "|    time_elapsed    | 2237     |\n",
      "|    total_timesteps | 686592   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 549         |\n",
      "|    ep_rew_mean          | 4.09e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 299         |\n",
      "|    time_elapsed         | 2240        |\n",
      "|    total_timesteps      | 688896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 6.10491e-05 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0717     |\n",
      "|    explained_variance   | 0.68        |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.74e+03    |\n",
      "|    n_updates            | 2980        |\n",
      "|    policy_gradient_loss | -6.74e-05   |\n",
      "|    value_loss           | 3.39e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=690000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 552           |\n",
      "|    mean_reward          | 4.45e+03      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 690000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00010233528 |\n",
      "|    clip_fraction        | 0.000313      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0719       |\n",
      "|    explained_variance   | 0.674         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.31e+03      |\n",
      "|    n_updates            | 2990          |\n",
      "|    policy_gradient_loss | -3.47e-05     |\n",
      "|    value_loss           | 3.23e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 549      |\n",
      "|    ep_rew_mean     | 4.1e+03  |\n",
      "| time/              |          |\n",
      "|    fps             | 307      |\n",
      "|    iterations      | 300      |\n",
      "|    time_elapsed    | 2249     |\n",
      "|    total_timesteps | 691200   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 547           |\n",
      "|    ep_rew_mean          | 4.08e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 307           |\n",
      "|    iterations           | 301           |\n",
      "|    time_elapsed         | 2252          |\n",
      "|    total_timesteps      | 693504        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.2292811e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.073        |\n",
      "|    explained_variance   | 0.655         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.73e+03      |\n",
      "|    n_updates            | 3000          |\n",
      "|    policy_gradient_loss | -1.19e-05     |\n",
      "|    value_loss           | 3.31e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=695000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 552           |\n",
      "|    mean_reward          | 4.45e+03      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 695000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00045295508 |\n",
      "|    clip_fraction        | 0.000156      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.071        |\n",
      "|    explained_variance   | 0.676         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.6e+03       |\n",
      "|    n_updates            | 3010          |\n",
      "|    policy_gradient_loss | -0.000228     |\n",
      "|    value_loss           | 3.34e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 548      |\n",
      "|    ep_rew_mean     | 4.09e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 307      |\n",
      "|    iterations      | 302      |\n",
      "|    time_elapsed    | 2262     |\n",
      "|    total_timesteps | 695808   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 549           |\n",
      "|    ep_rew_mean          | 4.09e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 308           |\n",
      "|    iterations           | 303           |\n",
      "|    time_elapsed         | 2265          |\n",
      "|    total_timesteps      | 698112        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00040846196 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.075        |\n",
      "|    explained_variance   | 0.685         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 2.35e+03      |\n",
      "|    n_updates            | 3020          |\n",
      "|    policy_gradient_loss | 6.12e-05      |\n",
      "|    value_loss           | 3.1e+03       |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=700000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 552           |\n",
      "|    mean_reward          | 4.45e+03      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 700000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.6684996e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0711       |\n",
      "|    explained_variance   | 0.684         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.12e+03      |\n",
      "|    n_updates            | 3030          |\n",
      "|    policy_gradient_loss | -0.000166     |\n",
      "|    value_loss           | 3.01e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 548      |\n",
      "|    ep_rew_mean     | 4.09e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 307      |\n",
      "|    iterations      | 304      |\n",
      "|    time_elapsed    | 2274     |\n",
      "|    total_timesteps | 700416   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 551           |\n",
      "|    ep_rew_mean          | 4.11e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 308           |\n",
      "|    iterations           | 305           |\n",
      "|    time_elapsed         | 2277          |\n",
      "|    total_timesteps      | 702720        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013336402 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0713       |\n",
      "|    explained_variance   | 0.675         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 2.1e+03       |\n",
      "|    n_updates            | 3040          |\n",
      "|    policy_gradient_loss | 6.31e-06      |\n",
      "|    value_loss           | 3.61e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=705000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 552           |\n",
      "|    mean_reward          | 4.45e+03      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 705000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3342742e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0738       |\n",
      "|    explained_variance   | 0.667         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.52e+03      |\n",
      "|    n_updates            | 3050          |\n",
      "|    policy_gradient_loss | 7.43e-06      |\n",
      "|    value_loss           | 3.26e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 554      |\n",
      "|    ep_rew_mean     | 4.13e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 308      |\n",
      "|    iterations      | 306      |\n",
      "|    time_elapsed    | 2287     |\n",
      "|    total_timesteps | 705024   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 558           |\n",
      "|    ep_rew_mean          | 4.18e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 308           |\n",
      "|    iterations           | 307           |\n",
      "|    time_elapsed         | 2290          |\n",
      "|    total_timesteps      | 707328        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012812705 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0702       |\n",
      "|    explained_variance   | 0.703         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.62e+03      |\n",
      "|    n_updates            | 3060          |\n",
      "|    policy_gradient_loss | -1.79e-05     |\n",
      "|    value_loss           | 2.93e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 562          |\n",
      "|    ep_rew_mean          | 4.2e+03      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 309          |\n",
      "|    iterations           | 308          |\n",
      "|    time_elapsed         | 2293         |\n",
      "|    total_timesteps      | 709632       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012709223 |\n",
      "|    clip_fraction        | 0.014        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0724      |\n",
      "|    explained_variance   | 0.679        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.1e+03      |\n",
      "|    n_updates            | 3070         |\n",
      "|    policy_gradient_loss | -0.000791    |\n",
      "|    value_loss           | 3.32e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=710000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 552           |\n",
      "|    mean_reward          | 4.45e+03      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 710000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013653869 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0722       |\n",
      "|    explained_variance   | 0.674         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.01e+03      |\n",
      "|    n_updates            | 3080          |\n",
      "|    policy_gradient_loss | -8.04e-05     |\n",
      "|    value_loss           | 3.19e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 563      |\n",
      "|    ep_rew_mean     | 4.22e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 309      |\n",
      "|    iterations      | 309      |\n",
      "|    time_elapsed    | 2302     |\n",
      "|    total_timesteps | 711936   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 565           |\n",
      "|    ep_rew_mean          | 4.23e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 309           |\n",
      "|    iterations           | 310           |\n",
      "|    time_elapsed         | 2306          |\n",
      "|    total_timesteps      | 714240        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00053098786 |\n",
      "|    clip_fraction        | 0.00406       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0695       |\n",
      "|    explained_variance   | 0.677         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.72e+03      |\n",
      "|    n_updates            | 3090          |\n",
      "|    policy_gradient_loss | -0.000732     |\n",
      "|    value_loss           | 3.38e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=715000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 715000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010221272 |\n",
      "|    clip_fraction        | 0.0111       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0714      |\n",
      "|    explained_variance   | 0.682        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.52e+03     |\n",
      "|    n_updates            | 3100         |\n",
      "|    policy_gradient_loss | -0.000692    |\n",
      "|    value_loss           | 3.25e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 565      |\n",
      "|    ep_rew_mean     | 4.23e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 309      |\n",
      "|    iterations      | 311      |\n",
      "|    time_elapsed    | 2315     |\n",
      "|    total_timesteps | 716544   |\n",
      "---------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 565            |\n",
      "|    ep_rew_mean          | 4.23e+03       |\n",
      "| time/                   |                |\n",
      "|    fps                  | 310            |\n",
      "|    iterations           | 312            |\n",
      "|    time_elapsed         | 2318           |\n",
      "|    total_timesteps      | 718848         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.000109853434 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.0691        |\n",
      "|    explained_variance   | 0.68           |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 1.46e+03       |\n",
      "|    n_updates            | 3110           |\n",
      "|    policy_gradient_loss | -6.57e-05      |\n",
      "|    value_loss           | 3.17e+03       |\n",
      "--------------------------------------------\n",
      "Eval num_timesteps=720000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 552           |\n",
      "|    mean_reward          | 4.45e+03      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 720000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00021353763 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0706       |\n",
      "|    explained_variance   | 0.691         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 2.62e+03      |\n",
      "|    n_updates            | 3120          |\n",
      "|    policy_gradient_loss | -3.82e-05     |\n",
      "|    value_loss           | 2.99e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 567      |\n",
      "|    ep_rew_mean     | 4.24e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 309      |\n",
      "|    iterations      | 313      |\n",
      "|    time_elapsed    | 2327     |\n",
      "|    total_timesteps | 721152   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 569           |\n",
      "|    ep_rew_mean          | 4.26e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 310           |\n",
      "|    iterations           | 314           |\n",
      "|    time_elapsed         | 2331          |\n",
      "|    total_timesteps      | 723456        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0153963e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0706       |\n",
      "|    explained_variance   | 0.645         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.31e+03      |\n",
      "|    n_updates            | 3130          |\n",
      "|    policy_gradient_loss | -2.87e-06     |\n",
      "|    value_loss           | 3.14e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=725000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 552           |\n",
      "|    mean_reward          | 4.45e+03      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 725000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017421003 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0695       |\n",
      "|    explained_variance   | 0.628         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.79e+03      |\n",
      "|    n_updates            | 3140          |\n",
      "|    policy_gradient_loss | -7.54e-05     |\n",
      "|    value_loss           | 3.24e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 570      |\n",
      "|    ep_rew_mean     | 4.27e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 310      |\n",
      "|    iterations      | 315      |\n",
      "|    time_elapsed    | 2340     |\n",
      "|    total_timesteps | 725760   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 572          |\n",
      "|    ep_rew_mean          | 4.29e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 310          |\n",
      "|    iterations           | 316          |\n",
      "|    time_elapsed         | 2343         |\n",
      "|    total_timesteps      | 728064       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003046043 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0726      |\n",
      "|    explained_variance   | 0.68         |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.21e+03     |\n",
      "|    n_updates            | 3150         |\n",
      "|    policy_gradient_loss | -0.000184    |\n",
      "|    value_loss           | 3.17e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=730000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 552           |\n",
      "|    mean_reward          | 4.45e+03      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 730000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00074231706 |\n",
      "|    clip_fraction        | 0.00605       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0723       |\n",
      "|    explained_variance   | 0.652         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.89e+03      |\n",
      "|    n_updates            | 3160          |\n",
      "|    policy_gradient_loss | 1.18e-05      |\n",
      "|    value_loss           | 3.35e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 572      |\n",
      "|    ep_rew_mean     | 4.29e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 310      |\n",
      "|    iterations      | 317      |\n",
      "|    time_elapsed    | 2352     |\n",
      "|    total_timesteps | 730368   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 571           |\n",
      "|    ep_rew_mean          | 4.27e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 310           |\n",
      "|    iterations           | 318           |\n",
      "|    time_elapsed         | 2355          |\n",
      "|    total_timesteps      | 732672        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.1959236e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0704       |\n",
      "|    explained_variance   | 0.616         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.5e+03       |\n",
      "|    n_updates            | 3170          |\n",
      "|    policy_gradient_loss | -5.97e-05     |\n",
      "|    value_loss           | 3.38e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 572          |\n",
      "|    ep_rew_mean          | 4.29e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 311          |\n",
      "|    iterations           | 319          |\n",
      "|    time_elapsed         | 2359         |\n",
      "|    total_timesteps      | 734976       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.804623e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0694      |\n",
      "|    explained_variance   | 0.63         |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.41e+03     |\n",
      "|    n_updates            | 3180         |\n",
      "|    policy_gradient_loss | -3.52e-05    |\n",
      "|    value_loss           | 3.25e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=735000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 735000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004494131 |\n",
      "|    clip_fraction        | 0.00176      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0702      |\n",
      "|    explained_variance   | 0.578        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.6e+03      |\n",
      "|    n_updates            | 3190         |\n",
      "|    policy_gradient_loss | -0.000143    |\n",
      "|    value_loss           | 3.44e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 575      |\n",
      "|    ep_rew_mean     | 4.31e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 311      |\n",
      "|    iterations      | 320      |\n",
      "|    time_elapsed    | 2368     |\n",
      "|    total_timesteps | 737280   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 577           |\n",
      "|    ep_rew_mean          | 4.32e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 311           |\n",
      "|    iterations           | 321           |\n",
      "|    time_elapsed         | 2371          |\n",
      "|    total_timesteps      | 739584        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00038837455 |\n",
      "|    clip_fraction        | 3.91e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0725       |\n",
      "|    explained_variance   | 0.612         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.73e+03      |\n",
      "|    n_updates            | 3200          |\n",
      "|    policy_gradient_loss | -0.000576     |\n",
      "|    value_loss           | 3.37e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=740000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 740000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009356479 |\n",
      "|    clip_fraction        | 0.00461      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0711      |\n",
      "|    explained_variance   | 0.598        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.75e+03     |\n",
      "|    n_updates            | 3210         |\n",
      "|    policy_gradient_loss | -1.76e-05    |\n",
      "|    value_loss           | 3.32e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 578      |\n",
      "|    ep_rew_mean     | 4.33e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 311      |\n",
      "|    iterations      | 322      |\n",
      "|    time_elapsed    | 2381     |\n",
      "|    total_timesteps | 741888   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 576           |\n",
      "|    ep_rew_mean          | 4.32e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 312           |\n",
      "|    iterations           | 323           |\n",
      "|    time_elapsed         | 2384          |\n",
      "|    total_timesteps      | 744192        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00033736895 |\n",
      "|    clip_fraction        | 0.0153        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.072        |\n",
      "|    explained_variance   | 0.591         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.45e+03      |\n",
      "|    n_updates            | 3220          |\n",
      "|    policy_gradient_loss | 0.000114      |\n",
      "|    value_loss           | 3.6e+03       |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=745000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 552           |\n",
      "|    mean_reward          | 4.45e+03      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 745000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016703052 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0695       |\n",
      "|    explained_variance   | 0.559         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 2.36e+03      |\n",
      "|    n_updates            | 3230          |\n",
      "|    policy_gradient_loss | -0.000171     |\n",
      "|    value_loss           | 3.48e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 576      |\n",
      "|    ep_rew_mean     | 4.31e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 311      |\n",
      "|    iterations      | 324      |\n",
      "|    time_elapsed    | 2393     |\n",
      "|    total_timesteps | 746496   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 575           |\n",
      "|    ep_rew_mean          | 4.31e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 312           |\n",
      "|    iterations           | 325           |\n",
      "|    time_elapsed         | 2396          |\n",
      "|    total_timesteps      | 748800        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.3336667e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0694       |\n",
      "|    explained_variance   | 0.53          |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 2.51e+03      |\n",
      "|    n_updates            | 3240          |\n",
      "|    policy_gradient_loss | -5.58e-06     |\n",
      "|    value_loss           | 3.74e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=750000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 750000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003273254 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0697      |\n",
      "|    explained_variance   | 0.426        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 3.11e+03     |\n",
      "|    n_updates            | 3250         |\n",
      "|    policy_gradient_loss | -0.000111    |\n",
      "|    value_loss           | 4.15e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 576      |\n",
      "|    ep_rew_mean     | 4.32e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 312      |\n",
      "|    iterations      | 326      |\n",
      "|    time_elapsed    | 2405     |\n",
      "|    total_timesteps | 751104   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 574          |\n",
      "|    ep_rew_mean          | 4.3e+03      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 312          |\n",
      "|    iterations           | 327          |\n",
      "|    time_elapsed         | 2409         |\n",
      "|    total_timesteps      | 753408       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.385294e-05 |\n",
      "|    clip_fraction        | 0.00547      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.072       |\n",
      "|    explained_variance   | 0.462        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 933          |\n",
      "|    n_updates            | 3260         |\n",
      "|    policy_gradient_loss | -0.000268    |\n",
      "|    value_loss           | 3.53e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=755000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 755000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005587969 |\n",
      "|    clip_fraction        | 0.00277      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0686      |\n",
      "|    explained_variance   | 0.469        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.96e+03     |\n",
      "|    n_updates            | 3270         |\n",
      "|    policy_gradient_loss | -0.000277    |\n",
      "|    value_loss           | 3.6e+03      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 575      |\n",
      "|    ep_rew_mean     | 4.31e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 312      |\n",
      "|    iterations      | 328      |\n",
      "|    time_elapsed    | 2418     |\n",
      "|    total_timesteps | 755712   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 575           |\n",
      "|    ep_rew_mean          | 4.31e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 313           |\n",
      "|    iterations           | 329           |\n",
      "|    time_elapsed         | 2421          |\n",
      "|    total_timesteps      | 758016        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00019152435 |\n",
      "|    clip_fraction        | 0.000156      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0679       |\n",
      "|    explained_variance   | 0.506         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.87e+03      |\n",
      "|    n_updates            | 3280          |\n",
      "|    policy_gradient_loss | 4.46e-05      |\n",
      "|    value_loss           | 3.63e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=760000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 760000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030565273 |\n",
      "|    clip_fraction        | 0.0217       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0706      |\n",
      "|    explained_variance   | 0.504        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.57e+03     |\n",
      "|    n_updates            | 3290         |\n",
      "|    policy_gradient_loss | -0.000694    |\n",
      "|    value_loss           | 3.82e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 575      |\n",
      "|    ep_rew_mean     | 4.31e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 312      |\n",
      "|    iterations      | 330      |\n",
      "|    time_elapsed    | 2430     |\n",
      "|    total_timesteps | 760320   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 575          |\n",
      "|    ep_rew_mean          | 4.31e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 313          |\n",
      "|    iterations           | 331          |\n",
      "|    time_elapsed         | 2434         |\n",
      "|    total_timesteps      | 762624       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012862835 |\n",
      "|    clip_fraction        | 0.0104       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0675      |\n",
      "|    explained_variance   | 0.508        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.95e+03     |\n",
      "|    n_updates            | 3300         |\n",
      "|    policy_gradient_loss | -0.000519    |\n",
      "|    value_loss           | 3.63e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 573           |\n",
      "|    ep_rew_mean          | 4.3e+03       |\n",
      "| time/                   |               |\n",
      "|    fps                  | 313           |\n",
      "|    iterations           | 332           |\n",
      "|    time_elapsed         | 2437          |\n",
      "|    total_timesteps      | 764928        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4297391e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0667       |\n",
      "|    explained_variance   | 0.486         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.58e+03      |\n",
      "|    n_updates            | 3310          |\n",
      "|    policy_gradient_loss | -3.74e-06     |\n",
      "|    value_loss           | 3.59e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=765000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 765000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011182226 |\n",
      "|    clip_fraction        | 0.00328      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0712      |\n",
      "|    explained_variance   | 0.473        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.2e+03      |\n",
      "|    n_updates            | 3320         |\n",
      "|    policy_gradient_loss | 7.93e-05     |\n",
      "|    value_loss           | 3.61e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 575      |\n",
      "|    ep_rew_mean     | 4.31e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 313      |\n",
      "|    iterations      | 333      |\n",
      "|    time_elapsed    | 2446     |\n",
      "|    total_timesteps | 767232   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 574          |\n",
      "|    ep_rew_mean          | 4.31e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 314          |\n",
      "|    iterations           | 334          |\n",
      "|    time_elapsed         | 2449         |\n",
      "|    total_timesteps      | 769536       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036140413 |\n",
      "|    clip_fraction        | 0.0162       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0708      |\n",
      "|    explained_variance   | 0.447        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.37e+03     |\n",
      "|    n_updates            | 3330         |\n",
      "|    policy_gradient_loss | -0.000754    |\n",
      "|    value_loss           | 3.58e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=770000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 770000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004326664 |\n",
      "|    clip_fraction        | 0.000313     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.067       |\n",
      "|    explained_variance   | 0.512        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.16e+03     |\n",
      "|    n_updates            | 3340         |\n",
      "|    policy_gradient_loss | -0.000131    |\n",
      "|    value_loss           | 3.45e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 575      |\n",
      "|    ep_rew_mean     | 4.32e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 313      |\n",
      "|    iterations      | 335      |\n",
      "|    time_elapsed    | 2459     |\n",
      "|    total_timesteps | 771840   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 577           |\n",
      "|    ep_rew_mean          | 4.34e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 314           |\n",
      "|    iterations           | 336           |\n",
      "|    time_elapsed         | 2462          |\n",
      "|    total_timesteps      | 774144        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00057159935 |\n",
      "|    clip_fraction        | 0.00848       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0679       |\n",
      "|    explained_variance   | 0.452         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 2.54e+03      |\n",
      "|    n_updates            | 3350          |\n",
      "|    policy_gradient_loss | -0.000385     |\n",
      "|    value_loss           | 3.56e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=775000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 775000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009964902 |\n",
      "|    clip_fraction        | 0.00867      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.069       |\n",
      "|    explained_variance   | 0.459        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.49e+03     |\n",
      "|    n_updates            | 3360         |\n",
      "|    policy_gradient_loss | -0.000262    |\n",
      "|    value_loss           | 3.52e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 577      |\n",
      "|    ep_rew_mean     | 4.34e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 314      |\n",
      "|    iterations      | 337      |\n",
      "|    time_elapsed    | 2471     |\n",
      "|    total_timesteps | 776448   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 575           |\n",
      "|    ep_rew_mean          | 4.33e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 314           |\n",
      "|    iterations           | 338           |\n",
      "|    time_elapsed         | 2474          |\n",
      "|    total_timesteps      | 778752        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00047666323 |\n",
      "|    clip_fraction        | 0.0122        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.068        |\n",
      "|    explained_variance   | 0.408         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.37e+03      |\n",
      "|    n_updates            | 3370          |\n",
      "|    policy_gradient_loss | -0.000354     |\n",
      "|    value_loss           | 3.77e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=780000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 552           |\n",
      "|    mean_reward          | 4.45e+03      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 780000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00032355153 |\n",
      "|    clip_fraction        | 0.000156      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0676       |\n",
      "|    explained_variance   | 0.349         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.87e+03      |\n",
      "|    n_updates            | 3380          |\n",
      "|    policy_gradient_loss | 0.000101      |\n",
      "|    value_loss           | 3.84e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 574      |\n",
      "|    ep_rew_mean     | 4.33e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 314      |\n",
      "|    iterations      | 339      |\n",
      "|    time_elapsed    | 2484     |\n",
      "|    total_timesteps | 781056   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 570          |\n",
      "|    ep_rew_mean          | 4.29e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 314          |\n",
      "|    iterations           | 340          |\n",
      "|    time_elapsed         | 2487         |\n",
      "|    total_timesteps      | 783360       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016985389 |\n",
      "|    clip_fraction        | 0.0091       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0708      |\n",
      "|    explained_variance   | 0.371        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.35e+03     |\n",
      "|    n_updates            | 3390         |\n",
      "|    policy_gradient_loss | -0.000239    |\n",
      "|    value_loss           | 3.81e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=785000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 552           |\n",
      "|    mean_reward          | 4.45e+03      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 785000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.7530064e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.069        |\n",
      "|    explained_variance   | 0.284         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 2.66e+03      |\n",
      "|    n_updates            | 3400          |\n",
      "|    policy_gradient_loss | 9.43e-05      |\n",
      "|    value_loss           | 4.49e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 569      |\n",
      "|    ep_rew_mean     | 4.28e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 314      |\n",
      "|    iterations      | 341      |\n",
      "|    time_elapsed    | 2496     |\n",
      "|    total_timesteps | 785664   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 568          |\n",
      "|    ep_rew_mean          | 4.28e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 315          |\n",
      "|    iterations           | 342          |\n",
      "|    time_elapsed         | 2499         |\n",
      "|    total_timesteps      | 787968       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.540715e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0696      |\n",
      "|    explained_variance   | 0.297        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.88e+03     |\n",
      "|    n_updates            | 3410         |\n",
      "|    policy_gradient_loss | 6.98e-05     |\n",
      "|    value_loss           | 3.89e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=790000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 790000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005985326 |\n",
      "|    clip_fraction        | 0.0068       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0674      |\n",
      "|    explained_variance   | 0.215        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.16e+03     |\n",
      "|    n_updates            | 3420         |\n",
      "|    policy_gradient_loss | -0.000724    |\n",
      "|    value_loss           | 3.9e+03      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 566      |\n",
      "|    ep_rew_mean     | 4.26e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 314      |\n",
      "|    iterations      | 343      |\n",
      "|    time_elapsed    | 2509     |\n",
      "|    total_timesteps | 790272   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 564           |\n",
      "|    ep_rew_mean          | 4.25e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 315           |\n",
      "|    iterations           | 344           |\n",
      "|    time_elapsed         | 2512          |\n",
      "|    total_timesteps      | 792576        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00023727663 |\n",
      "|    clip_fraction        | 0.0126        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.067        |\n",
      "|    explained_variance   | 0.276         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 2.12e+03      |\n",
      "|    n_updates            | 3430          |\n",
      "|    policy_gradient_loss | -0.000632     |\n",
      "|    value_loss           | 4.19e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 561          |\n",
      "|    ep_rew_mean          | 4.22e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 316          |\n",
      "|    iterations           | 345          |\n",
      "|    time_elapsed         | 2515         |\n",
      "|    total_timesteps      | 794880       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045608855 |\n",
      "|    clip_fraction        | 0.0156       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0707      |\n",
      "|    explained_variance   | 0.497        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 892          |\n",
      "|    n_updates            | 3440         |\n",
      "|    policy_gradient_loss | 0.00131      |\n",
      "|    value_loss           | 3.08e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=795000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 795000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006174402 |\n",
      "|    clip_fraction        | 0.0158       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0669      |\n",
      "|    explained_variance   | 0.504        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.04e+03     |\n",
      "|    n_updates            | 3450         |\n",
      "|    policy_gradient_loss | -0.00126     |\n",
      "|    value_loss           | 3.21e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 558      |\n",
      "|    ep_rew_mean     | 4.19e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 315      |\n",
      "|    iterations      | 346      |\n",
      "|    time_elapsed    | 2524     |\n",
      "|    total_timesteps | 797184   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 557         |\n",
      "|    ep_rew_mean          | 4.18e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 347         |\n",
      "|    time_elapsed         | 2527        |\n",
      "|    total_timesteps      | 799488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002351739 |\n",
      "|    clip_fraction        | 0.0155      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0638     |\n",
      "|    explained_variance   | 0.546       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 2.56e+03    |\n",
      "|    n_updates            | 3460        |\n",
      "|    policy_gradient_loss | -0.00184    |\n",
      "|    value_loss           | 3.58e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=800000, episode_reward=4447.10 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 552          |\n",
      "|    mean_reward          | 4.45e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 800000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005672664 |\n",
      "|    clip_fraction        | 0.0127       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0667      |\n",
      "|    explained_variance   | 0.594        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.54e+03     |\n",
      "|    n_updates            | 3470         |\n",
      "|    policy_gradient_loss | -0.000652    |\n",
      "|    value_loss           | 2.87e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 559      |\n",
      "|    ep_rew_mean     | 4.2e+03  |\n",
      "| time/              |          |\n",
      "|    fps             | 315      |\n",
      "|    iterations      | 348      |\n",
      "|    time_elapsed    | 2537     |\n",
      "|    total_timesteps | 801792   |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sb3_contrib import MaskablePPO\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "import numpy as np\n",
    "import torch\n",
    "from environment3 import LifeStyleEnv\n",
    "import gymnasium as gym\n",
    "from sb3_contrib.common.wrappers import ActionMasker\n",
    "\n",
    "best_entropy_coef = 0.001\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def mask_fn(env: gym.Env) -> np.ndarray:\n",
    "    unwrapped_env = env\n",
    "    while hasattr(unwrapped_env, \"env\"):\n",
    "        unwrapped_env = unwrapped_env.env\n",
    "    return unwrapped_env.action_masks()\n",
    "\n",
    "def make_env(is_eval: bool = False):\n",
    "    env = LifeStyleEnv()\n",
    "    env = Monitor(env)\n",
    "    if not is_eval:\n",
    "        check_env(env, warn=True) \n",
    "    return env\n",
    "\n",
    "env = make_env()\n",
    "env = ActionMasker(env, mask_fn)\n",
    "\n",
    "eval_env = make_env(is_eval=True)\n",
    "eval_env = ActionMasker(eval_env, mask_fn)\n",
    "\n",
    "eval_callback = EvalCallback(\n",
    "    eval_env,\n",
    "    best_model_save_path=\"./logs/best_model\",\n",
    "    log_path=\"./logs/results\",\n",
    "    eval_freq=5000,\n",
    "    n_eval_episodes=10,\n",
    "    deterministic=True,\n",
    "    render=False\n",
    ")\n",
    "\n",
    "model = MaskablePPO(\n",
    "    \"MultiInputPolicy\",  \n",
    "    env,\n",
    "    learning_rate=0.003,\n",
    "    n_steps=2304,\n",
    "    batch_size=512,\n",
    "    n_epochs=10,\n",
    "    gamma=0.99,\n",
    "    gae_lambda=0.95,\n",
    "    clip_range=0.2,\n",
    "    ent_coef=best_entropy_coef,  \n",
    "    vf_coef=0.5,\n",
    "    max_grad_norm=0.5,\n",
    "    verbose=1,\n",
    "    device=device,\n",
    "    policy_kwargs=dict(net_arch=[128, 128])\n",
    ")\n",
    "\n",
    "model.learn(\n",
    "    total_timesteps=800000, \n",
    "    callback=eval_callback\n",
    ")\n",
    "\n",
    "model.save(\"../agent/ppo_lifestylecoach_best_entropy2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29392ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Final Evaluation...\n",
      "-------------------------------------------------------------------------------------------------------------------------------------\n",
      "| Day | Timeslot   | Action     | Event      | BMI      | Stress   | Energy   | Hunger   | Cal. Intake  | Cal. Burned  | Reward   |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------\n",
      "| 0   | 1          | 8          | sleep      | 24.22    | 46.00    | 54.00    | 48.00    | 0.00         | 66.15        | 0.42     |\n",
      "| 0   | 2          | 8          | sleep      | 24.22    | 42.00    | 58.00    | 46.00    | 0.00         | 132.30       | 1.04     |\n",
      "| 0   | 3          | 8          | sleep      | 24.22    | 38.00    | 62.00    | 44.00    | 0.00         | 198.45       | 1.63     |\n",
      "| 0   | 4          | 8          | sleep      | 24.22    | 34.00    | 66.00    | 42.00    | 0.00         | 264.60       | 2.20     |\n",
      "| 0   | 5          | 8          | sleep      | 24.22    | 30.00    | 70.00    | 40.00    | 0.00         | 330.75       | 2.75     |\n",
      "| 0   | 6          | 8          | sleep      | 24.22    | 26.00    | 74.00    | 38.00    | 0.00         | 396.90       | 3.27     |\n",
      "| 0   | 7          | 0          | action     | 24.22    | 26.00    | 94.00    | 18.00    | 350.00       | 396.90       | 1.89     |\n",
      "| 0   | 8          | 5          | action     | 24.22    | 26.00    | 79.00    | 33.00    | 350.00       | 1058.40      | 5.17     |\n",
      "| 0   | 9          | 5          | action     | 24.22    | 26.00    | 64.00    | 48.00    | 350.00       | 1719.90      | 7.51     |\n",
      "| 0   | 10         | 5          | action     | 24.22    | 26.00    | 49.00    | 63.00    | 350.00       | 2381.40      | 8.48     |\n",
      "| 0   | 11         | 8          | work       | 24.22    | 31.00    | 44.00    | 68.00    | 350.00       | 2528.40      | 8.02     |\n",
      "| 0   | 12         | 8          | work       | 24.22    | 36.00    | 39.00    | 73.00    | 350.00       | 2675.40      | 7.42     |\n",
      "| 0   | 13         | 0          | action     | 24.22    | 36.00    | 59.00    | 53.00    | 700.00       | 2675.40      | 9.88     |\n",
      "| 0   | 14         | 8          | work       | 24.22    | 41.00    | 54.00    | 58.00    | 700.00       | 2822.40      | 9.74     |\n",
      "| 0   | 15         | 8          | work       | 24.22    | 46.00    | 49.00    | 63.00    | 700.00       | 2969.40      | 9.44     |\n",
      "| 0   | 16         | 8          | work       | 24.22    | 51.00    | 44.00    | 68.00    | 700.00       | 3116.40      | 8.98     |\n",
      "| 0   | 17         | 8          | work       | 24.22    | 56.00    | 39.00    | 73.00    | 700.00       | 3263.40      | 8.38     |\n",
      "| 0   | 18         | 8          | work       | 24.22    | 61.00    | 34.00    | 78.00    | 700.00       | 3410.40      | 7.62     |\n",
      "| 0   | 19         | 0          | action     | 24.22    | 61.00    | 54.00    | 58.00    | 1050.00      | 3410.40      | 10.70    |\n",
      "| 0   | 20         | 5          | action     | 24.22    | 61.00    | 39.00    | 73.00    | 1050.00      | 4071.90      | 10.74    |\n",
      "| 0   | 21         | 0          | action     | 24.22    | 61.00    | 59.00    | 53.00    | 1400.00      | 4071.90      | 13.21    |\n",
      "| 0   | 22         | 0          | action     | 24.22    | 61.00    | 79.00    | 33.00    | 1750.00      | 4071.90      | 13.22    |\n",
      "| 0   | 23         | 8          | sleep      | 24.22    | 57.00    | 83.00    | 31.00    | 1750.00      | 4138.05      | 13.66    |\n",
      "| 1   | 0          | 8          | sleep      | 24.11    | 53.00    | 87.00    | 29.00    | 0.00         | 0.00         | 23.85    |\n",
      "| 1   | 1          | 8          | sleep      | 24.11    | 49.00    | 91.00    | 27.00    | 0.00         | 65.85        | 1.35     |\n",
      "| 1   | 2          | 8          | sleep      | 24.11    | 45.00    | 95.00    | 25.00    | 0.00         | 131.70       | 1.76     |\n",
      "| 1   | 3          | 8          | sleep      | 24.11    | 41.00    | 99.00    | 23.00    | 0.00         | 197.55       | 2.17     |\n",
      "| 1   | 4          | 8          | sleep      | 24.11    | 37.00    | 100.00   | 21.00    | 0.00         | 263.40       | 0.58     |\n",
      "| 1   | 5          | 8          | sleep      | 24.11    | 33.00    | 100.00   | 19.00    | 0.00         | 329.24       | -1.01    |\n",
      "| 1   | 6          | 8          | sleep      | 24.11    | 29.00    | 100.00   | 17.00    | 0.00         | 395.09       | -2.60    |\n",
      "| 1   | 7          | 0          | action     | 24.11    | 29.00    | 100.00   | 0.00     | 350.00       | 395.09       | 1.82     |\n",
      "| 1   | 8          | 5          | action     | 24.11    | 29.00    | 85.00    | 15.00    | 350.00       | 1053.58      | 5.11     |\n",
      "| 1   | 9          | 5          | action     | 24.11    | 29.00    | 70.00    | 30.00    | 350.00       | 1712.07      | 8.40     |\n",
      "| 1   | 10         | 5          | action     | 24.11    | 29.00    | 55.00    | 45.00    | 350.00       | 2370.56      | 11.01    |\n",
      "| 1   | 11         | 8          | work       | 24.11    | 34.00    | 50.00    | 50.00    | 350.00       | 2516.89      | 11.10    |\n",
      "| 1   | 12         | 8          | work       | 24.11    | 39.00    | 45.00    | 55.00    | 350.00       | 2663.22      | 11.05    |\n",
      "| 1   | 13         | 0          | action     | 24.11    | 39.00    | 65.00    | 35.00    | 700.00       | 2663.22      | 11.30    |\n",
      "| 1   | 14         | 8          | work       | 24.11    | 44.00    | 60.00    | 40.00    | 700.00       | 2809.55      | 11.71    |\n",
      "| 1   | 15         | 8          | work       | 24.11    | 49.00    | 55.00    | 45.00    | 700.00       | 2955.88      | 11.96    |\n",
      "| 1   | 16         | 8          | work       | 24.11    | 54.00    | 50.00    | 50.00    | 700.00       | 3102.21      | 12.05    |\n",
      "| 1   | 17         | 8          | work       | 24.11    | 59.00    | 45.00    | 55.00    | 700.00       | 3248.54      | 11.99    |\n",
      "| 1   | 18         | 8          | work       | 24.11    | 64.00    | 40.00    | 60.00    | 700.00       | 3394.87      | 11.78    |\n",
      "| 1   | 19         | 0          | action     | 24.11    | 64.00    | 60.00    | 40.00    | 1050.00      | 3394.87      | 12.66    |\n",
      "| 1   | 20         | 5          | action     | 24.11    | 64.00    | 45.00    | 55.00    | 1050.00      | 4053.36      | 14.34    |\n",
      "| 1   | 21         | 0          | action     | 24.11    | 64.00    | 65.00    | 35.00    | 1400.00      | 4053.36      | 14.60    |\n",
      "| 1   | 22         | 0          | action     | 24.11    | 64.00    | 85.00    | 15.00    | 1750.00      | 4053.36      | 13.10    |\n",
      "| 1   | 23         | 8          | sleep      | 24.11    | 60.00    | 89.00    | 13.00    | 1750.00      | 4119.21      | 13.51    |\n",
      "| 2   | 0          | 8          | sleep      | 24.00    | 56.00    | 93.00    | 11.00    | 0.00         | 0.00         | 23.71    |\n",
      "| 2   | 1          | 8          | sleep      | 24.00    | 52.00    | 97.00    | 9.00     | 0.00         | 65.55        | 1.29     |\n",
      "| 2   | 2          | 8          | sleep      | 24.00    | 48.00    | 100.00   | 7.00     | 0.00         | 131.10       | 1.70     |\n",
      "| 2   | 3          | 8          | sleep      | 24.00    | 44.00    | 100.00   | 5.00     | 0.00         | 196.65       | 2.10     |\n",
      "| 2   | 4          | 8          | sleep      | 24.00    | 40.00    | 100.00   | 3.00     | 0.00         | 262.20       | 0.51     |\n",
      "| 2   | 5          | 8          | sleep      | 24.00    | 36.00    | 100.00   | 1.00     | 0.00         | 327.75       | -1.08    |\n",
      "| 2   | 6          | 8          | sleep      | 24.00    | 32.00    | 100.00   | 0.00     | 0.00         | 393.30       | -2.67    |\n",
      "| 2   | 7          | 0          | action     | 24.00    | 32.00    | 100.00   | 0.00     | 350.00       | 393.30       | 1.75     |\n",
      "| 2   | 8          | 5          | action     | 24.00    | 32.00    | 85.00    | 15.00    | 350.00       | 1048.80      | 5.03     |\n",
      "| 2   | 9          | 5          | action     | 24.00    | 32.00    | 70.00    | 30.00    | 350.00       | 1704.30      | 8.30     |\n",
      "| 2   | 10         | 5          | action     | 24.00    | 32.00    | 55.00    | 45.00    | 350.00       | 2359.80      | 10.89    |\n",
      "| 2   | 11         | 8          | work       | 24.00    | 37.00    | 50.00    | 50.00    | 350.00       | 2505.46      | 10.99    |\n",
      "| 2   | 12         | 8          | work       | 24.00    | 42.00    | 45.00    | 55.00    | 350.00       | 2651.13      | 10.93    |\n",
      "| 2   | 13         | 0          | action     | 24.00    | 42.00    | 65.00    | 35.00    | 700.00       | 2651.13      | 11.19    |\n",
      "| 2   | 14         | 8          | work       | 24.00    | 47.00    | 60.00    | 40.00    | 700.00       | 2796.80      | 11.58    |\n",
      "| 2   | 15         | 8          | work       | 24.00    | 52.00    | 55.00    | 45.00    | 700.00       | 2942.46      | 11.83    |\n",
      "| 2   | 16         | 8          | work       | 24.00    | 57.00    | 50.00    | 50.00    | 700.00       | 3088.13      | 11.92    |\n",
      "| 2   | 17         | 8          | work       | 24.00    | 62.00    | 45.00    | 55.00    | 700.00       | 3233.80      | 11.86    |\n",
      "| 2   | 18         | 8          | work       | 24.00    | 67.00    | 40.00    | 60.00    | 700.00       | 3379.46      | 11.65    |\n",
      "| 2   | 19         | 0          | action     | 24.00    | 67.00    | 60.00    | 40.00    | 1050.00      | 3379.46      | 12.52    |\n",
      "| 2   | 20         | 5          | action     | 24.00    | 67.00    | 45.00    | 55.00    | 1050.00      | 4034.96      | 14.19    |\n",
      "| 2   | 21         | 0          | action     | 24.00    | 67.00    | 65.00    | 35.00    | 1400.00      | 4034.96      | 14.45    |\n",
      "| 2   | 22         | 0          | action     | 24.00    | 67.00    | 85.00    | 15.00    | 1750.00      | 4034.96      | 12.95    |\n",
      "| 2   | 23         | 8          | sleep      | 24.00    | 63.00    | 89.00    | 13.00    | 1750.00      | 4100.51      | 13.36    |\n",
      "| 3   | 0          | 8          | sleep      | 23.89    | 59.00    | 93.00    | 11.00    | 0.00         | 0.00         | 23.57    |\n",
      "| 3   | 1          | 8          | sleep      | 23.89    | 55.00    | 97.00    | 9.00     | 0.00         | 65.25        | 1.23     |\n",
      "| 3   | 2          | 8          | sleep      | 23.89    | 51.00    | 100.00   | 7.00     | 0.00         | 130.51       | 1.63     |\n",
      "| 3   | 3          | 8          | sleep      | 23.89    | 47.00    | 100.00   | 5.00     | 0.00         | 195.76       | 2.04     |\n",
      "| 3   | 4          | 8          | sleep      | 23.89    | 43.00    | 100.00   | 3.00     | 0.00         | 261.01       | 0.45     |\n",
      "| 3   | 5          | 8          | sleep      | 23.89    | 39.00    | 100.00   | 1.00     | 0.00         | 326.27       | -1.15    |\n",
      "| 3   | 6          | 8          | sleep      | 23.89    | 35.00    | 100.00   | 0.00     | 0.00         | 391.52       | -2.74    |\n",
      "| 3   | 7          | 0          | action     | 23.89    | 35.00    | 100.00   | 0.00     | 350.00       | 391.52       | 1.68     |\n",
      "| 3   | 8          | 5          | action     | 23.89    | 35.00    | 85.00    | 15.00    | 350.00       | 1044.06      | 4.94     |\n",
      "| 3   | 9          | 5          | action     | 23.89    | 35.00    | 70.00    | 30.00    | 350.00       | 1696.59      | 8.21     |\n",
      "| 3   | 10         | 5          | action     | 23.89    | 35.00    | 55.00    | 45.00    | 350.00       | 2349.12      | 10.78    |\n",
      "| 3   | 11         | 8          | work       | 23.89    | 40.00    | 50.00    | 50.00    | 350.00       | 2494.13      | 10.87    |\n",
      "| 3   | 12         | 8          | work       | 23.89    | 45.00    | 45.00    | 55.00    | 350.00       | 2639.14      | 10.81    |\n",
      "| 3   | 13         | 0          | action     | 23.89    | 45.00    | 65.00    | 35.00    | 700.00       | 2639.14      | 11.07    |\n",
      "| 3   | 14         | 8          | work       | 23.89    | 50.00    | 60.00    | 40.00    | 700.00       | 2784.15      | 11.46    |\n",
      "| 3   | 15         | 8          | work       | 23.89    | 55.00    | 55.00    | 45.00    | 700.00       | 2929.15      | 11.70    |\n",
      "| 3   | 16         | 8          | work       | 23.89    | 60.00    | 50.00    | 50.00    | 700.00       | 3074.16      | 11.79    |\n",
      "| 3   | 17         | 8          | work       | 23.89    | 65.00    | 45.00    | 55.00    | 700.00       | 3219.17      | 11.73    |\n",
      "| 3   | 18         | 8          | work       | 23.89    | 70.00    | 40.00    | 60.00    | 700.00       | 3364.18      | 11.51    |\n",
      "| 3   | 19         | 0          | action     | 23.89    | 70.00    | 60.00    | 40.00    | 1050.00      | 3364.18      | 12.39    |\n",
      "| 3   | 20         | 5          | action     | 23.89    | 70.00    | 45.00    | 55.00    | 1050.00      | 4016.71      | 14.04    |\n",
      "| 3   | 21         | 0          | action     | 23.89    | 70.00    | 65.00    | 35.00    | 1400.00      | 4016.71      | 14.30    |\n",
      "| 3   | 22         | 0          | action     | 23.89    | 70.00    | 85.00    | 15.00    | 1750.00      | 4016.71      | 12.80    |\n",
      "| 3   | 23         | 8          | sleep      | 23.89    | 66.00    | 89.00    | 13.00    | 1750.00      | 4081.97      | 13.21    |\n",
      "| 4   | 0          | 8          | sleep      | 23.79    | 62.00    | 93.00    | 11.00    | 0.00         | 0.00         | 23.43    |\n",
      "| 4   | 1          | 8          | sleep      | 23.79    | 58.00    | 97.00    | 9.00     | 0.00         | 64.96        | 1.16     |\n",
      "| 4   | 2          | 8          | sleep      | 23.79    | 54.00    | 100.00   | 7.00     | 0.00         | 129.92       | 1.57     |\n",
      "| 4   | 3          | 8          | sleep      | 23.79    | 50.00    | 100.00   | 5.00     | 0.00         | 194.88       | 1.97     |\n",
      "| 4   | 4          | 8          | sleep      | 23.79    | 46.00    | 100.00   | 3.00     | 0.00         | 259.84       | 0.38     |\n",
      "| 4   | 5          | 8          | sleep      | 23.79    | 42.00    | 100.00   | 1.00     | 0.00         | 324.80       | -1.22    |\n",
      "| 4   | 6          | 8          | sleep      | 23.79    | 38.00    | 100.00   | 0.00     | 0.00         | 389.76       | -2.81    |\n",
      "| 4   | 7          | 0          | action     | 23.79    | 38.00    | 100.00   | 0.00     | 350.00       | 389.76       | 1.61     |\n",
      "| 4   | 8          | 5          | action     | 23.79    | 38.00    | 85.00    | 15.00    | 350.00       | 1039.35      | 4.86     |\n",
      "| 4   | 9          | 5          | action     | 23.79    | 38.00    | 70.00    | 30.00    | 350.00       | 1688.94      | 8.11     |\n",
      "| 4   | 10         | 5          | action     | 23.79    | 38.00    | 55.00    | 45.00    | 350.00       | 2338.53      | 10.67    |\n",
      "| 4   | 11         | 8          | work       | 23.79    | 43.00    | 50.00    | 50.00    | 350.00       | 2482.89      | 10.75    |\n",
      "| 4   | 12         | 8          | work       | 23.79    | 48.00    | 45.00    | 55.00    | 350.00       | 2627.24      | 10.69    |\n",
      "| 4   | 13         | 0          | action     | 23.79    | 48.00    | 65.00    | 35.00    | 700.00       | 2627.24      | 10.95    |\n",
      "| 4   | 14         | 8          | work       | 23.79    | 53.00    | 60.00    | 40.00    | 700.00       | 2771.59      | 11.34    |\n",
      "| 4   | 15         | 8          | work       | 23.79    | 58.00    | 55.00    | 45.00    | 700.00       | 2915.95      | 11.58    |\n",
      "| 4   | 16         | 8          | work       | 23.79    | 63.00    | 50.00    | 50.00    | 700.00       | 3060.30      | 11.67    |\n",
      "| 4   | 17         | 8          | work       | 23.79    | 68.00    | 45.00    | 55.00    | 700.00       | 3204.66      | 11.60    |\n",
      "| 4   | 18         | 8          | work       | 23.79    | 73.00    | 40.00    | 60.00    | 700.00       | 3349.01      | 11.38    |\n",
      "| 4   | 19         | 0          | action     | 23.79    | 73.00    | 60.00    | 40.00    | 1050.00      | 3349.01      | 12.25    |\n",
      "| 4   | 20         | 5          | action     | 23.79    | 73.00    | 45.00    | 55.00    | 1050.00      | 3998.60      | 13.89    |\n",
      "| 4   | 21         | 0          | action     | 23.79    | 73.00    | 65.00    | 35.00    | 1400.00      | 3998.60      | 14.15    |\n",
      "| 4   | 22         | 0          | action     | 23.79    | 73.00    | 85.00    | 15.00    | 1750.00      | 3998.60      | 12.65    |\n",
      "| 4   | 23         | 8          | sleep      | 23.79    | 69.00    | 89.00    | 13.00    | 1750.00      | 4063.56      | 13.06    |\n",
      "| 5   | 0          | 8          | sleep      | 23.68    | 65.00    | 93.00    | 11.00    | 0.00         | 0.00         | 23.29    |\n",
      "| 5   | 1          | 8          | sleep      | 23.68    | 61.00    | 97.00    | 9.00     | 0.00         | 64.67        | 1.10     |\n",
      "| 5   | 2          | 8          | sleep      | 23.68    | 57.00    | 100.00   | 7.00     | 0.00         | 129.33       | 1.51     |\n",
      "| 5   | 3          | 8          | sleep      | 23.68    | 53.00    | 100.00   | 5.00     | 0.00         | 194.00       | 1.91     |\n",
      "| 5   | 4          | 8          | sleep      | 23.68    | 49.00    | 100.00   | 3.00     | 0.00         | 258.67       | 0.31     |\n",
      "| 5   | 5          | 8          | sleep      | 23.68    | 45.00    | 100.00   | 1.00     | 0.00         | 323.34       | -1.28    |\n",
      "| 5   | 6          | 8          | sleep      | 23.68    | 41.00    | 100.00   | 0.00     | 0.00         | 388.00       | -2.88    |\n",
      "| 5   | 7          | 0          | action     | 23.68    | 41.00    | 100.00   | 0.00     | 350.00       | 388.00       | 1.54     |\n",
      "| 5   | 8          | 5          | action     | 23.68    | 41.00    | 85.00    | 15.00    | 350.00       | 1034.68      | 4.78     |\n",
      "| 5   | 9          | 5          | action     | 23.68    | 41.00    | 70.00    | 30.00    | 350.00       | 1681.35      | 8.01     |\n",
      "| 5   | 10         | 5          | action     | 23.68    | 41.00    | 55.00    | 45.00    | 350.00       | 2328.02      | 10.56    |\n",
      "| 5   | 11         | 8          | work       | 23.68    | 46.00    | 50.00    | 50.00    | 350.00       | 2471.73      | 10.64    |\n",
      "| 5   | 12         | 8          | work       | 23.68    | 51.00    | 45.00    | 55.00    | 350.00       | 2615.43      | 10.57    |\n",
      "| 5   | 13         | 0          | action     | 23.68    | 51.00    | 65.00    | 35.00    | 700.00       | 2615.43      | 10.83    |\n",
      "| 5   | 14         | 8          | work       | 23.68    | 56.00    | 60.00    | 40.00    | 700.00       | 2759.14      | 11.22    |\n",
      "| 5   | 15         | 8          | work       | 23.68    | 61.00    | 55.00    | 45.00    | 700.00       | 2902.84      | 11.46    |\n",
      "| 5   | 16         | 8          | work       | 23.68    | 66.00    | 50.00    | 50.00    | 700.00       | 3046.55      | 11.54    |\n",
      "| 5   | 17         | 8          | work       | 23.68    | 71.00    | 45.00    | 55.00    | 700.00       | 3190.25      | 11.47    |\n",
      "| 5   | 18         | 8          | work       | 23.68    | 76.00    | 40.00    | 60.00    | 700.00       | 3333.96      | 11.24    |\n",
      "| 5   | 19         | 0          | action     | 23.68    | 76.00    | 60.00    | 40.00    | 1050.00      | 3333.96      | 12.12    |\n",
      "| 5   | 20         | 5          | action     | 23.68    | 76.00    | 45.00    | 55.00    | 1050.00      | 3980.63      | 13.74    |\n",
      "| 5   | 21         | 0          | action     | 23.68    | 76.00    | 65.00    | 35.00    | 1400.00      | 3980.63      | 14.01    |\n",
      "| 5   | 22         | 0          | action     | 23.68    | 76.00    | 85.00    | 15.00    | 1750.00      | 3980.63      | 12.51    |\n",
      "| 5   | 23         | 8          | sleep      | 23.68    | 72.00    | 89.00    | 13.00    | 1750.00      | 4045.30      | 12.91    |\n",
      "| 6   | 0          | 8          | sleep      | 23.57    | 68.00    | 93.00    | 11.00    | 0.00         | 0.00         | 23.15    |\n",
      "| 6   | 1          | 8          | sleep      | 23.57    | 64.00    | 97.00    | 9.00     | 0.00         | 64.38        | 1.04     |\n",
      "| 6   | 2          | 8          | sleep      | 23.57    | 60.00    | 100.00   | 7.00     | 0.00         | 128.76       | 1.44     |\n",
      "| 6   | 3          | 8          | sleep      | 23.57    | 56.00    | 100.00   | 5.00     | 0.00         | 193.13       | 1.85     |\n",
      "| 6   | 4          | 8          | sleep      | 23.57    | 52.00    | 100.00   | 3.00     | 0.00         | 257.51       | 0.25     |\n",
      "| 6   | 5          | 8          | sleep      | 23.57    | 48.00    | 100.00   | 1.00     | 0.00         | 321.89       | -1.35    |\n",
      "| 6   | 6          | 8          | sleep      | 23.57    | 44.00    | 100.00   | 0.00     | 0.00         | 386.27       | -2.95    |\n",
      "| 6   | 7          | 0          | action     | 23.57    | 44.00    | 100.00   | 0.00     | 350.00       | 386.27       | 1.48     |\n",
      "| 6   | 8          | 5          | action     | 23.57    | 44.00    | 85.00    | 15.00    | 350.00       | 1030.04      | 4.70     |\n",
      "| 6   | 9          | 5          | action     | 23.57    | 44.00    | 70.00    | 30.00    | 350.00       | 1673.82      | 7.91     |\n",
      "| 6   | 10         | 5          | action     | 23.57    | 44.00    | 55.00    | 45.00    | 350.00       | 2317.60      | 10.44    |\n",
      "| 6   | 11         | 8          | work       | 23.57    | 49.00    | 50.00    | 50.00    | 350.00       | 2460.66      | 10.52    |\n",
      "| 6   | 12         | 8          | work       | 23.57    | 54.00    | 45.00    | 55.00    | 350.00       | 2603.72      | 10.45    |\n",
      "| 6   | 13         | 0          | action     | 23.57    | 54.00    | 65.00    | 35.00    | 700.00       | 2603.72      | 10.71    |\n",
      "| 6   | 14         | 8          | work       | 23.57    | 59.00    | 60.00    | 40.00    | 700.00       | 2746.78      | 11.10    |\n",
      "| 6   | 15         | 8          | work       | 23.57    | 64.00    | 55.00    | 45.00    | 700.00       | 2889.84      | 11.33    |\n",
      "| 6   | 16         | 8          | work       | 23.57    | 69.00    | 50.00    | 50.00    | 700.00       | 3032.90      | 11.41    |\n",
      "| 6   | 17         | 8          | work       | 23.57    | 74.00    | 45.00    | 55.00    | 700.00       | 3175.97      | 11.34    |\n",
      "| 6   | 18         | 8          | work       | 23.57    | 79.00    | 40.00    | 60.00    | 700.00       | 3319.03      | 11.11    |\n",
      "| 6   | 19         | 0          | action     | 23.57    | 79.00    | 60.00    | 40.00    | 1050.00      | 3319.03      | 11.99    |\n",
      "| 6   | 20         | 5          | action     | 23.57    | 79.00    | 45.00    | 55.00    | 1050.00      | 3962.80      | 13.60    |\n",
      "| 6   | 21         | 0          | action     | 23.57    | 79.00    | 65.00    | 35.00    | 1400.00      | 3962.80      | 13.86    |\n",
      "| 6   | 22         | 0          | action     | 23.57    | 79.00    | 85.00    | 15.00    | 1750.00      | 3962.80      | 12.36    |\n",
      "| 6   | 23         | 8          | sleep      | 23.57    | 75.00    | 89.00    | 13.00    | 1750.00      | 4027.18      | 12.76    |\n",
      "| 7   | 0          | 8          | sleep      | 23.47    | 71.00    | 93.00    | 11.00    | 0.00         | 0.00         | 23.01    |\n",
      "| 7   | 1          | 8          | sleep      | 23.47    | 67.00    | 97.00    | 9.00     | 0.00         | 64.09        | 0.98     |\n",
      "| 7   | 2          | 8          | sleep      | 23.47    | 63.00    | 100.00   | 7.00     | 0.00         | 128.18       | 1.38     |\n",
      "| 7   | 3          | 8          | sleep      | 23.47    | 59.00    | 100.00   | 5.00     | 0.00         | 192.27       | 1.78     |\n",
      "| 7   | 4          | 8          | sleep      | 23.47    | 55.00    | 100.00   | 3.00     | 0.00         | 256.36       | 0.18     |\n",
      "| 7   | 5          | 8          | sleep      | 23.47    | 51.00    | 100.00   | 1.00     | 0.00         | 320.45       | -1.42    |\n",
      "| 7   | 6          | 8          | sleep      | 23.47    | 47.00    | 100.00   | 0.00     | 0.00         | 384.54       | -3.02    |\n",
      "| 7   | 7          | 0          | action     | 23.47    | 47.00    | 100.00   | 0.00     | 350.00       | 384.54       | 1.41     |\n",
      "| 7   | 8          | 5          | action     | 23.47    | 47.00    | 85.00    | 15.00    | 350.00       | 1025.45      | 4.61     |\n",
      "| 7   | 9          | 5          | action     | 23.47    | 47.00    | 70.00    | 30.00    | 350.00       | 1666.35      | 7.82     |\n",
      "| 7   | 10         | 5          | action     | 23.47    | 47.00    | 55.00    | 45.00    | 350.00       | 2307.25      | 10.33    |\n",
      "| 7   | 11         | 8          | work       | 23.47    | 52.00    | 50.00    | 50.00    | 350.00       | 2449.67      | 10.41    |\n",
      "| 7   | 12         | 8          | work       | 23.47    | 57.00    | 45.00    | 55.00    | 350.00       | 2592.10      | 10.33    |\n",
      "| 7   | 13         | 0          | action     | 23.47    | 57.00    | 65.00    | 35.00    | 700.00       | 2592.10      | 10.60    |\n",
      "| 7   | 14         | 8          | work       | 23.47    | 62.00    | 60.00    | 40.00    | 700.00       | 2734.52      | 10.98    |\n",
      "| 7   | 15         | 8          | work       | 23.47    | 67.00    | 55.00    | 45.00    | 700.00       | 2876.94      | 11.21    |\n",
      "| 7   | 16         | 8          | work       | 23.47    | 72.00    | 50.00    | 50.00    | 700.00       | 3019.37      | 11.28    |\n",
      "| 7   | 17         | 8          | work       | 23.47    | 77.00    | 45.00    | 55.00    | 700.00       | 3161.79      | 11.21    |\n",
      "| 7   | 18         | 8          | work       | 23.47    | 82.00    | 40.00    | 60.00    | 700.00       | 3304.21      | 10.98    |\n",
      "| 7   | 19         | 0          | action     | 23.47    | 82.00    | 60.00    | 40.00    | 1050.00      | 3304.21      | 11.85    |\n",
      "| 7   | 20         | 5          | action     | 23.47    | 82.00    | 45.00    | 55.00    | 1050.00      | 3945.12      | 13.45    |\n",
      "| 7   | 21         | 0          | action     | 23.47    | 82.00    | 65.00    | 35.00    | 1400.00      | 3945.12      | 13.71    |\n",
      "| 7   | 22         | 0          | action     | 23.47    | 82.00    | 85.00    | 15.00    | 1750.00      | 3945.12      | 12.22    |\n",
      "| 7   | 23         | 8          | sleep      | 23.47    | 78.00    | 89.00    | 13.00    | 1750.00      | 4009.21      | 12.62    |\n",
      "| 8   | 0          | 8          | sleep      | 23.36    | 74.00    | 93.00    | 11.00    | 0.00         | 0.00         | 22.87    |\n",
      "| 8   | 1          | 8          | sleep      | 23.36    | 70.00    | 97.00    | 9.00     | 0.00         | 63.81        | 0.92     |\n",
      "| 8   | 2          | 8          | sleep      | 23.36    | 66.00    | 100.00   | 7.00     | 0.00         | 127.61       | 1.32     |\n",
      "| 8   | 3          | 8          | sleep      | 23.36    | 62.00    | 100.00   | 5.00     | 0.00         | 191.42       | 1.72     |\n",
      "| 8   | 4          | 8          | sleep      | 23.36    | 58.00    | 100.00   | 3.00     | 0.00         | 255.22       | 0.12     |\n",
      "| 8   | 5          | 8          | sleep      | 23.36    | 54.00    | 100.00   | 1.00     | 0.00         | 319.03       | -1.48    |\n",
      "| 8   | 6          | 8          | sleep      | 23.36    | 50.00    | 100.00   | 0.00     | 0.00         | 382.83       | -3.09    |\n",
      "| 8   | 7          | 0          | action     | 23.36    | 50.00    | 100.00   | 0.00     | 350.00       | 382.83       | 1.34     |\n",
      "| 8   | 8          | 5          | action     | 23.36    | 50.00    | 85.00    | 15.00    | 350.00       | 1020.88      | 4.53     |\n",
      "| 8   | 9          | 5          | action     | 23.36    | 50.00    | 70.00    | 30.00    | 350.00       | 1658.93      | 7.72     |\n",
      "| 8   | 10         | 5          | action     | 23.36    | 50.00    | 55.00    | 45.00    | 350.00       | 2296.99      | 10.22    |\n",
      "| 8   | 11         | 8          | work       | 23.36    | 55.00    | 50.00    | 50.00    | 350.00       | 2438.78      | 10.30    |\n",
      "| 8   | 12         | 8          | work       | 23.36    | 60.00    | 45.00    | 55.00    | 350.00       | 2580.57      | 10.22    |\n",
      "| 8   | 13         | 0          | action     | 23.36    | 60.00    | 65.00    | 35.00    | 700.00       | 2580.57      | 10.48    |\n",
      "| 8   | 14         | 8          | work       | 23.36    | 65.00    | 60.00    | 40.00    | 700.00       | 2722.35      | 10.86    |\n",
      "| 8   | 15         | 8          | work       | 23.36    | 70.00    | 55.00    | 45.00    | 700.00       | 2864.14      | 11.09    |\n",
      "| 8   | 16         | 8          | work       | 23.36    | 75.00    | 50.00    | 50.00    | 700.00       | 3005.93      | 11.16    |\n",
      "| 8   | 17         | 8          | work       | 23.36    | 80.00    | 45.00    | 55.00    | 700.00       | 3147.72      | 11.08    |\n",
      "| 8   | 18         | 8          | work       | 23.36    | 85.00    | 40.00    | 60.00    | 700.00       | 3289.51      | 10.85    |\n",
      "| 8   | 19         | 0          | action     | 23.36    | 85.00    | 60.00    | 40.00    | 1050.00      | 3289.51      | 11.72    |\n",
      "| 8   | 20         | 5          | action     | 23.36    | 85.00    | 45.00    | 55.00    | 1050.00      | 3927.56      | 13.30    |\n",
      "| 8   | 21         | 0          | action     | 23.36    | 85.00    | 65.00    | 35.00    | 1400.00      | 3927.56      | 13.57    |\n",
      "| 8   | 22         | 0          | action     | 23.36    | 85.00    | 85.00    | 15.00    | 1750.00      | 3927.56      | 12.07    |\n",
      "| 8   | 23         | 8          | sleep      | 23.36    | 81.00    | 89.00    | 13.00    | 1750.00      | 3991.37      | 12.47    |\n",
      "| 9   | 0          | 8          | sleep      | 23.26    | 77.00    | 93.00    | 11.00    | 0.00         | 0.00         | 22.73    |\n",
      "| 9   | 1          | 8          | sleep      | 23.26    | 73.00    | 97.00    | 9.00     | 0.00         | 63.52        | 0.86     |\n",
      "| 9   | 2          | 8          | sleep      | 23.26    | 69.00    | 100.00   | 7.00     | 0.00         | 127.04       | 1.26     |\n",
      "| 9   | 3          | 8          | sleep      | 23.26    | 65.00    | 100.00   | 5.00     | 0.00         | 190.57       | 1.65     |\n",
      "| 9   | 4          | 8          | sleep      | 23.26    | 61.00    | 100.00   | 3.00     | 0.00         | 254.09       | 0.05     |\n",
      "| 9   | 5          | 8          | sleep      | 23.26    | 57.00    | 100.00   | 1.00     | 0.00         | 317.61       | -1.55    |\n",
      "| 9   | 6          | 8          | sleep      | 23.26    | 53.00    | 100.00   | 0.00     | 0.00         | 381.13       | -3.15    |\n",
      "| 9   | 7          | 0          | action     | 23.26    | 53.00    | 100.00   | 0.00     | 350.00       | 381.13       | 1.27     |\n",
      "| 9   | 8          | 5          | action     | 23.26    | 53.00    | 85.00    | 15.00    | 350.00       | 1016.36      | 4.45     |\n",
      "| 9   | 9          | 5          | action     | 23.26    | 53.00    | 70.00    | 30.00    | 350.00       | 1651.58      | 7.63     |\n",
      "| 9   | 10         | 5          | action     | 23.26    | 53.00    | 55.00    | 45.00    | 350.00       | 2286.80      | 10.11    |\n",
      "| 9   | 11         | 8          | work       | 23.26    | 58.00    | 50.00    | 50.00    | 350.00       | 2427.96      | 10.18    |\n",
      "| 9   | 12         | 8          | work       | 23.26    | 63.00    | 45.00    | 55.00    | 350.00       | 2569.12      | 10.10    |\n",
      "| 9   | 13         | 0          | action     | 23.26    | 63.00    | 65.00    | 35.00    | 700.00       | 2569.12      | 10.36    |\n",
      "| 9   | 14         | 8          | work       | 23.26    | 68.00    | 60.00    | 40.00    | 700.00       | 2710.28      | 10.74    |\n",
      "| 9   | 15         | 8          | work       | 23.26    | 73.00    | 55.00    | 45.00    | 700.00       | 2851.44      | 10.96    |\n",
      "| 9   | 16         | 8          | work       | 23.26    | 78.00    | 50.00    | 50.00    | 700.00       | 2992.61      | 11.03    |\n",
      "| 9   | 17         | 8          | work       | 23.26    | 83.00    | 45.00    | 55.00    | 700.00       | 3133.77      | 10.95    |\n",
      "| 9   | 18         | 8          | work       | 23.26    | 88.00    | 40.00    | 60.00    | 700.00       | 3274.93      | 10.71    |\n",
      "| 9   | 19         | 0          | action     | 23.26    | 88.00    | 60.00    | 40.00    | 1050.00      | 3274.93      | 11.59    |\n",
      "| 9   | 20         | 5          | action     | 23.26    | 88.00    | 45.00    | 55.00    | 1050.00      | 3910.15      | 13.16    |\n",
      "| 9   | 21         | 0          | action     | 23.26    | 88.00    | 65.00    | 35.00    | 1400.00      | 3910.15      | 13.42    |\n",
      "| 9   | 22         | 0          | action     | 23.26    | 88.00    | 85.00    | 15.00    | 1750.00      | 3910.15      | 11.93    |\n",
      "| 9   | 23         | 8          | sleep      | 23.26    | 84.00    | 89.00    | 13.00    | 1750.00      | 3973.67      | 12.33    |\n",
      "| 10  | 0          | 8          | sleep      | 23.16    | 80.00    | 93.00    | 11.00    | 0.00         | 0.00         | 22.59    |\n",
      "| 10  | 1          | 8          | sleep      | 23.16    | 76.00    | 97.00    | 9.00     | 0.00         | 63.24        | 0.80     |\n",
      "| 10  | 2          | 8          | sleep      | 23.16    | 72.00    | 100.00   | 7.00     | 0.00         | 126.48       | 1.19     |\n",
      "| 10  | 3          | 8          | sleep      | 23.16    | 68.00    | 100.00   | 5.00     | 0.00         | 189.72       | 1.59     |\n",
      "| 10  | 4          | 8          | sleep      | 23.16    | 64.00    | 100.00   | 3.00     | 0.00         | 252.97       | -0.02    |\n",
      "| 10  | 5          | 8          | sleep      | 23.16    | 60.00    | 100.00   | 1.00     | 0.00         | 316.21       | -1.62    |\n",
      "| 10  | 6          | 8          | sleep      | 23.16    | 56.00    | 100.00   | 0.00     | 0.00         | 379.45       | -3.22    |\n",
      "| 10  | 7          | 0          | action     | 23.16    | 56.00    | 100.00   | 0.00     | 350.00       | 379.45       | 1.21     |\n",
      "| 10  | 8          | 5          | action     | 23.16    | 56.00    | 85.00    | 15.00    | 350.00       | 1011.87      | 4.37     |\n",
      "| 10  | 9          | 5          | action     | 23.16    | 56.00    | 70.00    | 30.00    | 350.00       | 1644.28      | 7.53     |\n",
      "| 10  | 10         | 5          | action     | 23.16    | 56.00    | 55.00    | 45.00    | 350.00       | 2276.70      | 10.00    |\n",
      "| 10  | 11         | 8          | work       | 23.16    | 61.00    | 50.00    | 50.00    | 350.00       | 2417.23      | 10.07    |\n",
      "| 10  | 12         | 8          | work       | 23.16    | 66.00    | 45.00    | 55.00    | 350.00       | 2557.77      | 9.98     |\n",
      "| 10  | 13         | 0          | action     | 23.16    | 66.00    | 65.00    | 35.00    | 700.00       | 2557.77      | 10.25    |\n",
      "| 10  | 14         | 8          | work       | 23.16    | 71.00    | 60.00    | 40.00    | 700.00       | 2698.31      | 10.62    |\n",
      "| 10  | 15         | 8          | work       | 23.16    | 76.00    | 55.00    | 45.00    | 700.00       | 2838.84      | 10.84    |\n",
      "| 10  | 16         | 8          | work       | 23.16    | 81.00    | 50.00    | 50.00    | 700.00       | 2979.38      | 10.91    |\n",
      "| 10  | 17         | 8          | work       | 23.16    | 86.00    | 45.00    | 55.00    | 700.00       | 3119.92      | 10.82    |\n",
      "| 10  | 18         | 8          | work       | 23.16    | 91.00    | 40.00    | 60.00    | 700.00       | 3260.45      | 10.58    |\n",
      "| 10  | 19         | 0          | action     | 23.16    | 91.00    | 60.00    | 40.00    | 1050.00      | 3260.45      | 11.46    |\n",
      "| 10  | 20         | 5          | action     | 23.16    | 91.00    | 45.00    | 55.00    | 1050.00      | 3892.87      | 13.02    |\n",
      "| 10  | 21         | 0          | action     | 23.16    | 91.00    | 65.00    | 35.00    | 1400.00      | 3892.87      | 13.28    |\n",
      "| 10  | 22         | 0          | action     | 23.16    | 91.00    | 85.00    | 15.00    | 1750.00      | 3892.87      | 11.78    |\n",
      "| 10  | 23         | 8          | sleep      | 23.16    | 87.00    | 89.00    | 13.00    | 1750.00      | 3956.11      | 12.18    |\n",
      "| 11  | 0          | 8          | sleep      | 23.05    | 83.00    | 93.00    | 11.00    | 0.00         | 0.00         | 22.46    |\n",
      "| 11  | 1          | 8          | sleep      | 23.05    | 79.00    | 97.00    | 9.00     | 0.00         | 62.96        | 0.73     |\n",
      "| 11  | 2          | 8          | sleep      | 23.05    | 75.00    | 100.00   | 7.00     | 0.00         | 125.93       | 1.13     |\n",
      "| 11  | 3          | 8          | sleep      | 23.05    | 71.00    | 100.00   | 5.00     | 0.00         | 188.89       | 1.52     |\n",
      "| 11  | 4          | 8          | sleep      | 23.05    | 67.00    | 100.00   | 3.00     | 0.00         | 251.85       | -0.08    |\n",
      "| 11  | 5          | 8          | sleep      | 23.05    | 63.00    | 100.00   | 1.00     | 0.00         | 314.82       | -1.69    |\n",
      "| 11  | 6          | 8          | sleep      | 23.05    | 59.00    | 100.00   | 0.00     | 0.00         | 377.78       | -3.29    |\n",
      "| 11  | 7          | 0          | action     | 23.05    | 59.00    | 100.00   | 0.00     | 350.00       | 377.78       | 1.14     |\n",
      "| 11  | 8          | 5          | action     | 23.05    | 59.00    | 85.00    | 15.00    | 350.00       | 1007.41      | 4.29     |\n",
      "| 11  | 9          | 5          | action     | 23.05    | 59.00    | 70.00    | 30.00    | 350.00       | 1637.04      | 7.43     |\n",
      "| 11  | 10         | 5          | action     | 23.05    | 59.00    | 55.00    | 45.00    | 350.00       | 2266.67      | 9.89     |\n",
      "| 11  | 11         | 8          | work       | 23.05    | 64.00    | 50.00    | 50.00    | 350.00       | 2406.59      | 9.96     |\n",
      "| 11  | 12         | 8          | work       | 23.05    | 69.00    | 45.00    | 55.00    | 350.00       | 2546.51      | 9.87     |\n",
      "| 11  | 13         | 0          | action     | 23.05    | 69.00    | 65.00    | 35.00    | 700.00       | 2546.51      | 10.13    |\n",
      "| 11  | 14         | 8          | work       | 23.05    | 74.00    | 60.00    | 40.00    | 700.00       | 2686.42      | 10.50    |\n",
      "| 11  | 15         | 8          | work       | 23.05    | 79.00    | 55.00    | 45.00    | 700.00       | 2826.34      | 10.72    |\n",
      "| 11  | 16         | 8          | work       | 23.05    | 84.00    | 50.00    | 50.00    | 700.00       | 2966.26      | 10.78    |\n",
      "| 11  | 17         | 8          | work       | 23.05    | 89.00    | 45.00    | 55.00    | 700.00       | 3106.18      | 10.70    |\n",
      "| 11  | 18         | 8          | work       | 23.05    | 94.00    | 40.00    | 60.00    | 700.00       | 3246.10      | 10.45    |\n",
      "| 11  | 19         | 0          | action     | 23.05    | 94.00    | 60.00    | 40.00    | 1050.00      | 3246.10      | 11.33    |\n",
      "| 11  | 20         | 5          | action     | 23.05    | 94.00    | 45.00    | 55.00    | 1050.00      | 3875.73      | 12.87    |\n",
      "| 11  | 21         | 0          | action     | 23.05    | 94.00    | 65.00    | 35.00    | 1400.00      | 3875.73      | 13.14    |\n",
      "| 11  | 22         | 0          | action     | 23.05    | 94.00    | 85.00    | 15.00    | 1750.00      | 3875.73      | 11.64    |\n",
      "| 11  | 23         | 8          | sleep      | 23.05    | 90.00    | 89.00    | 13.00    | 1750.00      | 3938.69      | 12.04    |\n",
      "| 12  | 0          | 8          | sleep      | 22.95    | 86.00    | 93.00    | 11.00    | 0.00         | 0.00         | 22.32    |\n",
      "| 12  | 1          | 8          | sleep      | 22.95    | 82.00    | 97.00    | 9.00     | 0.00         | 62.69        | 0.67     |\n",
      "| 12  | 2          | 8          | sleep      | 22.95    | 78.00    | 100.00   | 7.00     | 0.00         | 125.37       | 1.07     |\n",
      "| 12  | 3          | 8          | sleep      | 22.95    | 74.00    | 100.00   | 5.00     | 0.00         | 188.06       | 1.46     |\n",
      "| 12  | 4          | 8          | sleep      | 22.95    | 70.00    | 100.00   | 3.00     | 0.00         | 250.75       | -0.15    |\n",
      "| 12  | 5          | 8          | sleep      | 22.95    | 66.00    | 100.00   | 1.00     | 0.00         | 313.43       | -1.75    |\n",
      "| 12  | 6          | 8          | sleep      | 22.95    | 62.00    | 100.00   | 0.00     | 0.00         | 376.12       | -3.36    |\n",
      "| 12  | 7          | 0          | action     | 22.95    | 62.00    | 100.00   | 0.00     | 350.00       | 376.12       | 1.07     |\n",
      "| 12  | 8          | 5          | action     | 22.95    | 62.00    | 85.00    | 15.00    | 350.00       | 1002.99      | 4.20     |\n",
      "| 12  | 9          | 5          | action     | 22.95    | 62.00    | 70.00    | 30.00    | 350.00       | 1629.85      | 7.34     |\n",
      "| 12  | 10         | 5          | action     | 22.95    | 62.00    | 55.00    | 45.00    | 350.00       | 2256.72      | 9.78     |\n",
      "| 12  | 11         | 8          | work       | 22.95    | 67.00    | 50.00    | 50.00    | 350.00       | 2396.03      | 9.84     |\n",
      "| 12  | 12         | 8          | work       | 22.95    | 72.00    | 45.00    | 55.00    | 350.00       | 2535.33      | 9.75     |\n",
      "| 12  | 13         | 0          | action     | 22.95    | 72.00    | 65.00    | 35.00    | 700.00       | 2535.33      | 10.02    |\n",
      "| 12  | 14         | 8          | work       | 22.95    | 77.00    | 60.00    | 40.00    | 700.00       | 2674.63      | 10.39    |\n",
      "| 12  | 15         | 8          | work       | 22.95    | 82.00    | 55.00    | 45.00    | 700.00       | 2813.94      | 10.60    |\n",
      "| 12  | 16         | 8          | work       | 22.95    | 87.00    | 50.00    | 50.00    | 700.00       | 2953.24      | 10.66    |\n",
      "| 12  | 17         | 8          | work       | 22.95    | 92.00    | 45.00    | 55.00    | 700.00       | 3092.55      | 10.57    |\n",
      "| 12  | 18         | 8          | work       | 22.95    | 97.00    | 40.00    | 60.00    | 700.00       | 3231.85      | 10.32    |\n",
      "| 12  | 19         | 0          | action     | 22.95    | 97.00    | 60.00    | 40.00    | 1050.00      | 3231.85      | 11.20    |\n",
      "| 12  | 20         | 5          | action     | 22.95    | 97.00    | 45.00    | 55.00    | 1050.00      | 3858.72      | 12.73    |\n",
      "| 12  | 21         | 0          | action     | 22.95    | 97.00    | 65.00    | 35.00    | 1400.00      | 3858.72      | 12.99    |\n",
      "| 12  | 22         | 0          | action     | 22.95    | 97.00    | 85.00    | 15.00    | 1750.00      | 3858.72      | 11.50    |\n",
      "| 12  | 23         | 8          | sleep      | 22.95    | 93.00    | 89.00    | 13.00    | 1750.00      | 3921.40      | 11.89    |\n",
      "| 13  | 0          | 8          | sleep      | 22.85    | 89.00    | 93.00    | 11.00    | 0.00         | 0.00         | 22.19    |\n",
      "| 13  | 1          | 8          | sleep      | 22.85    | 85.00    | 97.00    | 9.00     | 0.00         | 62.41        | 0.61     |\n",
      "| 13  | 2          | 8          | sleep      | 22.85    | 81.00    | 100.00   | 7.00     | 0.00         | 124.83       | 1.00     |\n",
      "| 13  | 3          | 8          | sleep      | 22.85    | 77.00    | 100.00   | 5.00     | 0.00         | 187.24       | 1.40     |\n",
      "| 13  | 4          | 8          | sleep      | 22.85    | 73.00    | 100.00   | 3.00     | 0.00         | 249.65       | -0.21    |\n",
      "| 13  | 5          | 8          | sleep      | 22.85    | 69.00    | 100.00   | 1.00     | 0.00         | 312.06       | -1.82    |\n",
      "| 13  | 6          | 8          | sleep      | 22.85    | 65.00    | 100.00   | 0.00     | 0.00         | 374.48       | -3.43    |\n",
      "| 13  | 7          | 0          | action     | 22.85    | 65.00    | 100.00   | 0.00     | 350.00       | 374.48       | 1.00     |\n",
      "| 13  | 8          | 5          | action     | 22.85    | 65.00    | 85.00    | 15.00    | 350.00       | 998.60       | 4.12     |\n",
      "| 13  | 9          | 5          | action     | 22.85    | 65.00    | 70.00    | 30.00    | 350.00       | 1622.73      | 7.24     |\n",
      "| 13  | 10         | 5          | action     | 22.85    | 65.00    | 55.00    | 45.00    | 350.00       | 2246.85      | 9.68     |\n",
      "| 13  | 11         | 8          | work       | 22.85    | 70.00    | 50.00    | 50.00    | 350.00       | 2385.55      | 9.73     |\n",
      "| 13  | 12         | 8          | work       | 22.85    | 75.00    | 45.00    | 55.00    | 350.00       | 2524.24      | 9.64     |\n",
      "| 13  | 13         | 0          | action     | 22.85    | 75.00    | 65.00    | 35.00    | 700.00       | 2524.24      | 9.90     |\n",
      "| 13  | 14         | 8          | work       | 22.85    | 80.00    | 60.00    | 40.00    | 700.00       | 2662.94      | 10.27    |\n",
      "| 13  | 15         | 8          | work       | 22.85    | 85.00    | 55.00    | 45.00    | 700.00       | 2801.63      | 10.48    |\n",
      "| 13  | 16         | 8          | work       | 22.85    | 90.00    | 50.00    | 50.00    | 700.00       | 2940.32      | 10.54    |\n",
      "| 13  | 17         | 8          | work       | 22.85    | 95.00    | 45.00    | 55.00    | 700.00       | 3079.02      | 10.44    |\n",
      "| 13  | 18         | 8          | work       | 22.85    | 100.00   | 40.00    | 60.00    | 700.00       | 3217.71      | 10.19    |\n",
      "| 13  | 19         | 0          | action     | 22.85    | 100.00   | 60.00    | 40.00    | 1050.00      | 3217.71      | 11.07    |\n",
      "| 13  | 20         | 5          | action     | 22.85    | 100.00   | 45.00    | 55.00    | 1050.00      | 3841.84      | 12.59    |\n",
      "| 13  | 21         | 0          | action     | 22.85    | 100.00   | 65.00    | 35.00    | 1400.00      | 3841.84      | 12.85    |\n",
      "| 13  | 22         | 0          | action     | 22.85    | 100.00   | 85.00    | 15.00    | 1750.00      | 3841.84      | 11.36    |\n",
      "| 13  | 23         | 8          | sleep      | 22.85    | 96.00    | 89.00    | 13.00    | 1750.00      | 3904.25      | 11.75    |\n",
      "| 14  | 0          | 8          | sleep      | 22.75    | 92.00    | 93.00    | 11.00    | 0.00         | 0.00         | 22.05    |\n",
      "| 14  | 1          | 8          | sleep      | 22.75    | 88.00    | 97.00    | 9.00     | 0.00         | 62.14        | 0.55     |\n",
      "| 14  | 2          | 8          | sleep      | 22.75    | 84.00    | 100.00   | 7.00     | 0.00         | 124.28       | 0.94     |\n",
      "| 14  | 3          | 8          | sleep      | 22.75    | 80.00    | 100.00   | 5.00     | 0.00         | 186.42       | 1.33     |\n",
      "| 14  | 4          | 8          | sleep      | 22.75    | 76.00    | 100.00   | 3.00     | 0.00         | 248.56       | -0.28    |\n",
      "| 14  | 5          | 8          | sleep      | 22.75    | 72.00    | 100.00   | 1.00     | 0.00         | 310.70       | -1.89    |\n",
      "| 14  | 6          | 8          | sleep      | 22.75    | 68.00    | 100.00   | 0.00     | 0.00         | 372.84       | -3.50    |\n",
      "| 14  | 7          | 0          | action     | 22.75    | 68.00    | 100.00   | 0.00     | 350.00       | 372.84       | 0.93     |\n",
      "| 14  | 8          | 5          | action     | 22.75    | 68.00    | 85.00    | 15.00    | 350.00       | 994.25       | 4.04     |\n",
      "| 14  | 9          | 5          | action     | 22.75    | 68.00    | 70.00    | 30.00    | 350.00       | 1615.65      | 7.15     |\n",
      "| 14  | 10         | 5          | action     | 22.75    | 68.00    | 55.00    | 45.00    | 350.00       | 2237.06      | 9.57     |\n",
      "| 14  | 11         | 8          | work       | 22.75    | 73.00    | 50.00    | 50.00    | 350.00       | 2375.15      | 9.62     |\n",
      "| 14  | 12         | 8          | work       | 22.75    | 78.00    | 45.00    | 55.00    | 350.00       | 2513.24      | 9.52     |\n",
      "| 14  | 13         | 0          | action     | 22.75    | 78.00    | 65.00    | 35.00    | 700.00       | 2513.24      | 9.79     |\n",
      "| 14  | 14         | 8          | work       | 22.75    | 83.00    | 60.00    | 40.00    | 700.00       | 2651.33      | 10.15    |\n",
      "| 14  | 15         | 8          | work       | 22.75    | 88.00    | 55.00    | 45.00    | 700.00       | 2789.42      | 10.36    |\n",
      "| 14  | 16         | 8          | work       | 22.75    | 93.00    | 50.00    | 50.00    | 700.00       | 2927.51      | 10.41    |\n",
      "| 14  | 17         | 8          | work       | 22.75    | 98.00    | 45.00    | 55.00    | 700.00       | 3065.60      | 10.32    |\n",
      "| 14  | 18         | 8          | work       | 22.75    | 100.00   | 40.00    | 60.00    | 700.00       | 3203.69      | 10.12    |\n",
      "| 14  | 19         | 0          | action     | 22.75    | 100.00   | 60.00    | 40.00    | 1050.00      | 3203.69      | 11.00    |\n",
      "| 14  | 20         | 5          | action     | 22.75    | 100.00   | 45.00    | 55.00    | 1050.00      | 3825.09      | 12.50    |\n",
      "| 14  | 21         | 0          | action     | 22.75    | 100.00   | 65.00    | 35.00    | 1400.00      | 3825.09      | 12.77    |\n",
      "| 14  | 22         | 0          | action     | 22.75    | 100.00   | 85.00    | 15.00    | 1750.00      | 3825.09      | 11.28    |\n",
      "| 14  | 23         | 8          | sleep      | 22.75    | 96.00    | 89.00    | 13.00    | 1750.00      | 3887.23      | 11.67    |\n",
      "| 15  | 0          | 8          | sleep      | 22.65    | 92.00    | 93.00    | 11.00    | 0.00         | 0.00         | 21.98    |\n",
      "| 15  | 1          | 8          | sleep      | 22.65    | 88.00    | 97.00    | 9.00     | 0.00         | 61.87        | 0.55     |\n",
      "| 15  | 2          | 8          | sleep      | 22.65    | 84.00    | 100.00   | 7.00     | 0.00         | 123.74       | 0.94     |\n",
      "| 15  | 3          | 8          | sleep      | 22.65    | 80.00    | 100.00   | 5.00     | 0.00         | 185.61       | 1.33     |\n",
      "| 15  | 4          | 8          | sleep      | 22.65    | 76.00    | 100.00   | 3.00     | 0.00         | 247.48       | -0.28    |\n",
      "| 15  | 5          | 8          | sleep      | 22.65    | 72.00    | 100.00   | 1.00     | 0.00         | 309.35       | -1.89    |\n",
      "| 15  | 6          | 8          | sleep      | 22.65    | 68.00    | 100.00   | 0.00     | 0.00         | 371.22       | -3.50    |\n",
      "| 15  | 7          | 0          | action     | 22.65    | 68.00    | 100.00   | 0.00     | 350.00       | 371.22       | 0.93     |\n",
      "| 15  | 8          | 5          | action     | 22.65    | 68.00    | 85.00    | 15.00    | 350.00       | 989.93       | 4.02     |\n",
      "| 15  | 9          | 5          | action     | 22.65    | 68.00    | 70.00    | 30.00    | 350.00       | 1608.63      | 7.11     |\n",
      "| 15  | 10         | 5          | action     | 22.65    | 68.00    | 55.00    | 45.00    | 350.00       | 2227.34      | 9.52     |\n",
      "| 15  | 11         | 8          | work       | 22.65    | 73.00    | 50.00    | 50.00    | 350.00       | 2364.83      | 9.57     |\n",
      "| 15  | 12         | 8          | work       | 22.65    | 78.00    | 45.00    | 55.00    | 350.00       | 2502.32      | 9.47     |\n",
      "| 15  | 13         | 0          | action     | 22.65    | 78.00    | 65.00    | 35.00    | 700.00       | 2502.32      | 9.74     |\n",
      "| 15  | 14         | 8          | work       | 22.65    | 83.00    | 60.00    | 40.00    | 700.00       | 2639.81      | 10.10    |\n",
      "| 15  | 15         | 8          | work       | 22.65    | 88.00    | 55.00    | 45.00    | 700.00       | 2777.30      | 10.30    |\n",
      "| 15  | 16         | 8          | work       | 22.65    | 93.00    | 50.00    | 50.00    | 700.00       | 2914.79      | 10.35    |\n",
      "| 15  | 17         | 8          | work       | 22.65    | 98.00    | 45.00    | 55.00    | 700.00       | 3052.28      | 10.25    |\n",
      "| 15  | 18         | 8          | work       | 22.65    | 100.00   | 40.00    | 60.00    | 700.00       | 3189.77      | 10.06    |\n",
      "| 15  | 19         | 0          | action     | 22.65    | 100.00   | 60.00    | 40.00    | 1050.00      | 3189.77      | 10.94    |\n",
      "| 15  | 20         | 5          | action     | 22.65    | 100.00   | 45.00    | 55.00    | 1050.00      | 3808.48      | 12.42    |\n",
      "| 15  | 21         | 0          | action     | 22.65    | 100.00   | 65.00    | 35.00    | 1400.00      | 3808.48      | 12.69    |\n",
      "| 15  | 22         | 0          | action     | 22.65    | 100.00   | 85.00    | 15.00    | 1750.00      | 3808.48      | 11.20    |\n",
      "| 15  | 23         | 8          | sleep      | 22.65    | 96.00    | 89.00    | 13.00    | 1750.00      | 3870.35      | 11.59    |\n",
      "| 16  | 0          | 8          | sleep      | 22.56    | 92.00    | 93.00    | 11.00    | 0.00         | 0.00         | 21.90    |\n",
      "| 16  | 1          | 8          | sleep      | 22.56    | 88.00    | 97.00    | 9.00     | 0.00         | 61.60        | 0.55     |\n",
      "| 16  | 2          | 8          | sleep      | 22.56    | 84.00    | 100.00   | 7.00     | 0.00         | 123.21       | 0.94     |\n",
      "| 16  | 3          | 8          | sleep      | 22.56    | 80.00    | 100.00   | 5.00     | 0.00         | 184.81       | 1.32     |\n",
      "| 16  | 4          | 8          | sleep      | 22.56    | 76.00    | 100.00   | 3.00     | 0.00         | 246.41       | -0.29    |\n",
      "| 16  | 5          | 8          | sleep      | 22.56    | 72.00    | 100.00   | 1.00     | 0.00         | 308.01       | -1.90    |\n",
      "| 16  | 6          | 8          | sleep      | 22.56    | 68.00    | 100.00   | 0.00     | 0.00         | 369.62       | -3.51    |\n",
      "| 16  | 7          | 0          | action     | 22.56    | 68.00    | 100.00   | 0.00     | 350.00       | 369.62       | 0.92     |\n",
      "| 16  | 8          | 5          | action     | 22.56    | 68.00    | 85.00    | 15.00    | 350.00       | 985.64       | 4.00     |\n",
      "| 16  | 9          | 5          | action     | 22.56    | 68.00    | 70.00    | 30.00    | 350.00       | 1601.67      | 7.08     |\n",
      "| 16  | 10         | 5          | action     | 22.56    | 68.00    | 55.00    | 45.00    | 350.00       | 2217.70      | 9.47     |\n",
      "| 16  | 11         | 8          | work       | 22.56    | 73.00    | 50.00    | 50.00    | 350.00       | 2354.59      | 9.52     |\n",
      "| 16  | 12         | 8          | work       | 22.56    | 78.00    | 45.00    | 55.00    | 350.00       | 2491.49      | 9.42     |\n",
      "| 16  | 13         | 0          | action     | 22.56    | 78.00    | 65.00    | 35.00    | 700.00       | 2491.49      | 9.68     |\n",
      "| 16  | 14         | 8          | work       | 22.56    | 83.00    | 60.00    | 40.00    | 700.00       | 2628.38      | 10.04    |\n",
      "| 16  | 15         | 8          | work       | 22.56    | 88.00    | 55.00    | 45.00    | 700.00       | 2765.28      | 10.24    |\n",
      "| 16  | 16         | 8          | work       | 22.56    | 93.00    | 50.00    | 50.00    | 700.00       | 2902.17      | 10.29    |\n",
      "| 16  | 17         | 8          | work       | 22.56    | 98.00    | 45.00    | 55.00    | 700.00       | 3039.07      | 10.19    |\n",
      "| 16  | 18         | 8          | work       | 22.56    | 100.00   | 40.00    | 60.00    | 700.00       | 3175.96      | 9.99     |\n",
      "| 16  | 19         | 0          | action     | 22.56    | 100.00   | 60.00    | 40.00    | 1050.00      | 3175.96      | 10.87    |\n",
      "| 16  | 20         | 5          | action     | 22.56    | 100.00   | 45.00    | 55.00    | 1050.00      | 3791.99      | 12.34    |\n",
      "| 16  | 21         | 0          | action     | 22.56    | 100.00   | 65.00    | 35.00    | 1400.00      | 3791.99      | 12.61    |\n",
      "| 16  | 22         | 0          | action     | 22.56    | 100.00   | 85.00    | 15.00    | 1750.00      | 3791.99      | 11.12    |\n",
      "| 16  | 23         | 8          | sleep      | 22.56    | 96.00    | 89.00    | 13.00    | 1750.00      | 3853.59      | 11.51    |\n",
      "| 17  | 0          | 8          | sleep      | 22.46    | 92.00    | 93.00    | 11.00    | 0.00         | 0.00         | 21.83    |\n",
      "| 17  | 1          | 8          | sleep      | 22.46    | 88.00    | 97.00    | 9.00     | 0.00         | 61.34        | 0.55     |\n",
      "| 17  | 2          | 8          | sleep      | 22.46    | 84.00    | 100.00   | 7.00     | 0.00         | 122.67       | 0.93     |\n",
      "| 17  | 3          | 8          | sleep      | 22.46    | 80.00    | 100.00   | 5.00     | 0.00         | 184.01       | 1.32     |\n",
      "| 17  | 4          | 8          | sleep      | 22.46    | 76.00    | 100.00   | 3.00     | 0.00         | 245.35       | -0.29    |\n",
      "| 17  | 5          | 8          | sleep      | 22.46    | 72.00    | 100.00   | 1.00     | 0.00         | 306.69       | -1.91    |\n",
      "| 17  | 6          | 8          | sleep      | 22.46    | 68.00    | 100.00   | 0.00     | 0.00         | 368.02       | -3.52    |\n",
      "| 17  | 7          | 0          | action     | 22.46    | 68.00    | 100.00   | 0.00     | 350.00       | 368.02       | 0.91     |\n",
      "| 17  | 8          | 5          | action     | 22.46    | 68.00    | 85.00    | 15.00    | 350.00       | 981.39       | 3.98     |\n",
      "| 17  | 9          | 5          | action     | 22.46    | 68.00    | 70.00    | 30.00    | 350.00       | 1594.76      | 7.05     |\n",
      "| 17  | 10         | 5          | action     | 22.46    | 68.00    | 55.00    | 45.00    | 350.00       | 2208.13      | 9.42     |\n",
      "| 17  | 11         | 8          | work       | 22.46    | 73.00    | 50.00    | 50.00    | 350.00       | 2344.44      | 9.47     |\n",
      "| 17  | 12         | 8          | work       | 22.46    | 78.00    | 45.00    | 55.00    | 350.00       | 2480.74      | 9.36     |\n",
      "| 17  | 13         | 0          | action     | 22.46    | 78.00    | 65.00    | 35.00    | 700.00       | 2480.74      | 9.63     |\n",
      "| 17  | 14         | 8          | work       | 22.46    | 83.00    | 60.00    | 40.00    | 700.00       | 2617.05      | 9.98     |\n",
      "| 17  | 15         | 8          | work       | 22.46    | 88.00    | 55.00    | 45.00    | 700.00       | 2753.35      | 10.18    |\n",
      "| 17  | 16         | 8          | work       | 22.46    | 93.00    | 50.00    | 50.00    | 700.00       | 2889.66      | 10.23    |\n",
      "| 17  | 17         | 8          | work       | 22.46    | 98.00    | 45.00    | 55.00    | 700.00       | 3025.96      | 10.12    |\n",
      "| 17  | 18         | 8          | work       | 22.46    | 100.00   | 40.00    | 60.00    | 700.00       | 3162.26      | 9.92     |\n",
      "| 17  | 19         | 0          | action     | 22.46    | 100.00   | 60.00    | 40.00    | 1050.00      | 3162.26      | 10.80    |\n",
      "| 17  | 20         | 5          | action     | 22.46    | 100.00   | 45.00    | 55.00    | 1050.00      | 3775.63      | 12.26    |\n",
      "| 17  | 21         | 0          | action     | 22.46    | 100.00   | 65.00    | 35.00    | 1400.00      | 3775.63      | 12.53    |\n",
      "| 17  | 22         | 0          | action     | 22.46    | 100.00   | 85.00    | 15.00    | 1750.00      | 3775.63      | 11.04    |\n",
      "| 17  | 23         | 8          | sleep      | 22.46    | 96.00    | 89.00    | 13.00    | 1750.00      | 3836.97      | 11.43    |\n",
      "| 18  | 0          | 8          | sleep      | 22.36    | 92.00    | 93.00    | 11.00    | 0.00         | 0.00         | 21.76    |\n",
      "| 18  | 1          | 8          | sleep      | 22.36    | 88.00    | 97.00    | 9.00     | 0.00         | 61.07        | 0.55     |\n",
      "| 18  | 2          | 8          | sleep      | 22.36    | 84.00    | 100.00   | 7.00     | 0.00         | 122.15       | 0.93     |\n",
      "| 18  | 3          | 8          | sleep      | 22.36    | 80.00    | 100.00   | 5.00     | 0.00         | 183.22       | 1.32     |\n",
      "| 18  | 4          | 8          | sleep      | 22.36    | 76.00    | 100.00   | 3.00     | 0.00         | 244.29       | -0.30    |\n",
      "| 18  | 5          | 8          | sleep      | 22.36    | 72.00    | 100.00   | 1.00     | 0.00         | 305.37       | -1.91    |\n",
      "| 18  | 6          | 8          | sleep      | 22.36    | 68.00    | 100.00   | 0.00     | 0.00         | 366.44       | -3.53    |\n",
      "| 18  | 7          | 0          | action     | 22.36    | 68.00    | 100.00   | 0.00     | 350.00       | 366.44       | 0.91     |\n",
      "| 18  | 8          | 5          | action     | 22.36    | 68.00    | 85.00    | 15.00    | 350.00       | 977.17       | 3.96     |\n",
      "| 18  | 9          | 5          | action     | 22.36    | 68.00    | 70.00    | 30.00    | 350.00       | 1587.91      | 7.01     |\n",
      "| 18  | 10         | 5          | action     | 22.36    | 68.00    | 55.00    | 45.00    | 350.00       | 2198.64      | 9.38     |\n",
      "| 18  | 11         | 8          | work       | 22.36    | 73.00    | 50.00    | 50.00    | 350.00       | 2334.36      | 9.42     |\n",
      "| 18  | 12         | 8          | work       | 22.36    | 78.00    | 45.00    | 55.00    | 350.00       | 2470.08      | 9.31     |\n",
      "| 18  | 13         | 0          | action     | 22.36    | 78.00    | 65.00    | 35.00    | 700.00       | 2470.08      | 9.58     |\n",
      "| 18  | 14         | 8          | work       | 22.36    | 83.00    | 60.00    | 40.00    | 700.00       | 2605.80      | 9.93     |\n",
      "| 18  | 15         | 8          | work       | 22.36    | 88.00    | 55.00    | 45.00    | 700.00       | 2741.52      | 10.13    |\n",
      "| 18  | 16         | 8          | work       | 22.36    | 93.00    | 50.00    | 50.00    | 700.00       | 2877.23      | 10.17    |\n",
      "| 18  | 17         | 8          | work       | 22.36    | 98.00    | 45.00    | 55.00    | 700.00       | 3012.95      | 10.06    |\n",
      "| 18  | 18         | 8          | work       | 22.36    | 100.00   | 40.00    | 60.00    | 700.00       | 3148.67      | 9.85     |\n",
      "| 18  | 19         | 0          | action     | 22.36    | 100.00   | 60.00    | 40.00    | 1050.00      | 3148.67      | 10.74    |\n",
      "| 18  | 20         | 5          | action     | 22.36    | 100.00   | 45.00    | 55.00    | 1050.00      | 3759.41      | 12.18    |\n",
      "| 18  | 21         | 0          | action     | 22.36    | 100.00   | 65.00    | 35.00    | 1400.00      | 3759.41      | 12.45    |\n",
      "| 18  | 22         | 0          | action     | 22.36    | 100.00   | 85.00    | 15.00    | 1750.00      | 3759.41      | 10.96    |\n",
      "| 18  | 23         | 8          | sleep      | 22.36    | 96.00    | 89.00    | 13.00    | 1750.00      | 3820.48      | 11.35    |\n",
      "| 19  | 0          | 8          | sleep      | 22.27    | 92.00    | 93.00    | 11.00    | 0.00         | 0.00         | 21.69    |\n",
      "| 19  | 1          | 8          | sleep      | 22.27    | 88.00    | 97.00    | 9.00     | 0.00         | 60.81        | 0.54     |\n",
      "| 19  | 2          | 8          | sleep      | 22.27    | 84.00    | 100.00   | 7.00     | 0.00         | 121.62       | 0.93     |\n",
      "| 19  | 3          | 8          | sleep      | 22.27    | 80.00    | 100.00   | 5.00     | 0.00         | 182.44       | 1.31     |\n",
      "| 19  | 4          | 8          | sleep      | 22.27    | 76.00    | 100.00   | 3.00     | 0.00         | 243.25       | -0.30    |\n",
      "| 19  | 5          | 8          | sleep      | 22.27    | 72.00    | 100.00   | 1.00     | 0.00         | 304.06       | -1.92    |\n",
      "| 19  | 6          | 8          | sleep      | 22.27    | 68.00    | 100.00   | 0.00     | 0.00         | 364.87       | -3.54    |\n",
      "| 19  | 7          | 0          | action     | 22.27    | 68.00    | 100.00   | 0.00     | 350.00       | 364.87       | 0.90     |\n",
      "| 19  | 8          | 5          | action     | 22.27    | 68.00    | 85.00    | 15.00    | 350.00       | 972.99       | 3.94     |\n",
      "| 19  | 9          | 5          | action     | 22.27    | 68.00    | 70.00    | 30.00    | 350.00       | 1581.11      | 6.98     |\n",
      "| 19  | 10         | 5          | action     | 22.27    | 68.00    | 55.00    | 45.00    | 350.00       | 2189.22      | 9.33     |\n",
      "| 19  | 11         | 8          | work       | 22.27    | 73.00    | 50.00    | 50.00    | 350.00       | 2324.36      | 9.37     |\n",
      "| 19  | 12         | 8          | work       | 22.27    | 78.00    | 45.00    | 55.00    | 350.00       | 2459.50      | 9.26     |\n",
      "| 19  | 13         | 0          | action     | 22.27    | 78.00    | 65.00    | 35.00    | 700.00       | 2459.50      | 9.53     |\n",
      "| 19  | 14         | 8          | work       | 22.27    | 83.00    | 60.00    | 40.00    | 700.00       | 2594.64      | 9.87     |\n",
      "| 19  | 15         | 8          | work       | 22.27    | 88.00    | 55.00    | 45.00    | 700.00       | 2729.77      | 10.07    |\n",
      "| 19  | 16         | 8          | work       | 22.27    | 93.00    | 50.00    | 50.00    | 700.00       | 2864.91      | 10.11    |\n",
      "| 19  | 17         | 8          | work       | 22.27    | 98.00    | 45.00    | 55.00    | 700.00       | 3000.05      | 9.99     |\n",
      "| 19  | 18         | 8          | work       | 22.27    | 100.00   | 40.00    | 60.00    | 700.00       | 3135.18      | 9.79     |\n",
      "| 19  | 19         | 0          | action     | 22.27    | 100.00   | 60.00    | 40.00    | 1050.00      | 3135.18      | 10.67    |\n",
      "| 19  | 20         | 5          | action     | 22.27    | 100.00   | 45.00    | 55.00    | 1050.00      | 3743.30      | 12.10    |\n",
      "| 19  | 21         | 0          | action     | 22.27    | 100.00   | 65.00    | 35.00    | 1400.00      | 3743.30      | 12.38    |\n",
      "| 19  | 22         | 0          | action     | 22.27    | 100.00   | 85.00    | 15.00    | 1750.00      | 3743.30      | 10.88    |\n",
      "| 19  | 23         | 8          | sleep      | 22.27    | 96.00    | 89.00    | 13.00    | 1750.00      | 3804.11      | 11.27    |\n",
      "| 20  | 0          | 8          | sleep      | 22.17    | 92.00    | 93.00    | 11.00    | 0.00         | 0.00         | 21.61    |\n",
      "| 20  | 1          | 8          | sleep      | 22.17    | 88.00    | 97.00    | 9.00     | 0.00         | 60.55        | 0.54     |\n",
      "| 20  | 2          | 8          | sleep      | 22.17    | 84.00    | 100.00   | 7.00     | 0.00         | 121.10       | 0.93     |\n",
      "| 20  | 3          | 8          | sleep      | 22.17    | 80.00    | 100.00   | 5.00     | 0.00         | 181.66       | 1.31     |\n",
      "| 20  | 4          | 8          | sleep      | 22.17    | 76.00    | 100.00   | 3.00     | 0.00         | 242.21       | -0.31    |\n",
      "| 20  | 5          | 8          | sleep      | 22.17    | 72.00    | 100.00   | 1.00     | 0.00         | 302.76       | -1.93    |\n",
      "| 20  | 6          | 8          | sleep      | 22.17    | 68.00    | 100.00   | 0.00     | 0.00         | 363.31       | -3.54    |\n",
      "| 20  | 7          | 0          | action     | 22.17    | 68.00    | 100.00   | 0.00     | 350.00       | 363.31       | 0.89     |\n",
      "| 20  | 8          | 5          | action     | 22.17    | 68.00    | 85.00    | 15.00    | 350.00       | 968.84       | 3.92     |\n",
      "| 20  | 9          | 5          | action     | 22.17    | 68.00    | 70.00    | 30.00    | 350.00       | 1574.36      | 6.95     |\n",
      "| 20  | 10         | 5          | action     | 22.17    | 68.00    | 55.00    | 45.00    | 350.00       | 2179.88      | 9.29     |\n",
      "| 20  | 11         | 8          | work       | 22.17    | 73.00    | 50.00    | 50.00    | 350.00       | 2314.44      | 9.32     |\n",
      "| 20  | 12         | 8          | work       | 22.17    | 78.00    | 45.00    | 55.00    | 350.00       | 2449.00      | 9.21     |\n",
      "| 20  | 13         | 0          | action     | 22.17    | 78.00    | 65.00    | 35.00    | 700.00       | 2449.00      | 9.48     |\n",
      "| 20  | 14         | 8          | work       | 22.17    | 83.00    | 60.00    | 40.00    | 700.00       | 2583.56      | 9.82     |\n",
      "| 20  | 15         | 8          | work       | 22.17    | 88.00    | 55.00    | 45.00    | 700.00       | 2718.12      | 10.01    |\n",
      "| 20  | 16         | 8          | work       | 22.17    | 93.00    | 50.00    | 50.00    | 700.00       | 2852.68      | 10.05    |\n",
      "| 20  | 17         | 8          | work       | 22.17    | 98.00    | 45.00    | 55.00    | 700.00       | 2987.24      | 9.93     |\n",
      "| 20  | 18         | 8          | work       | 22.17    | 100.00   | 40.00    | 60.00    | 700.00       | 3121.80      | 9.72     |\n",
      "| 20  | 19         | 0          | action     | 22.17    | 100.00   | 60.00    | 40.00    | 1050.00      | 3121.80      | 10.61    |\n",
      "| 20  | 20         | 5          | action     | 22.17    | 100.00   | 45.00    | 55.00    | 1050.00      | 3727.33      | 12.03    |\n",
      "| 20  | 21         | 0          | action     | 22.17    | 100.00   | 65.00    | 35.00    | 1400.00      | 3727.33      | 12.30    |\n",
      "| 20  | 22         | 0          | action     | 22.17    | 100.00   | 85.00    | 15.00    | 1750.00      | 3727.33      | 10.80    |\n",
      "| 20  | 23         | 8          | sleep      | 22.17    | 96.00    | 89.00    | 13.00    | 1750.00      | 3787.88      | 11.19    |\n",
      "| 21  | 0          | 8          | sleep      | 22.08    | 92.00    | 93.00    | 11.00    | 0.00         | 0.00         | 21.54    |\n",
      "| 21  | 1          | 8          | sleep      | 22.08    | 88.00    | 97.00    | 9.00     | 0.00         | 60.29        | 0.54     |\n",
      "| 21  | 2          | 8          | sleep      | 22.08    | 84.00    | 100.00   | 7.00     | 0.00         | 120.59       | 0.92     |\n",
      "| 21  | 3          | 8          | sleep      | 22.08    | 80.00    | 100.00   | 5.00     | 0.00         | 180.88       | 1.30     |\n",
      "| 21  | 4          | 8          | sleep      | 22.08    | 76.00    | 100.00   | 3.00     | 0.00         | 241.18       | -0.31    |\n",
      "| 21  | 5          | 8          | sleep      | 22.08    | 72.00    | 100.00   | 1.00     | 0.00         | 301.47       | -1.93    |\n",
      "| 21  | 6          | 8          | sleep      | 22.08    | 68.00    | 100.00   | 0.00     | 0.00         | 361.77       | -3.55    |\n",
      "| 21  | 7          | 0          | action     | 22.08    | 68.00    | 100.00   | 0.00     | 350.00       | 361.77       | 0.88     |\n",
      "| 21  | 8          | 5          | action     | 22.08    | 68.00    | 85.00    | 15.00    | 350.00       | 964.71       | 3.90     |\n",
      "| 21  | 9          | 5          | action     | 22.08    | 68.00    | 70.00    | 30.00    | 350.00       | 1567.66      | 6.91     |\n",
      "| 21  | 10         | 5          | action     | 22.08    | 68.00    | 55.00    | 45.00    | 350.00       | 2170.61      | 9.24     |\n",
      "| 21  | 11         | 8          | work       | 22.08    | 73.00    | 50.00    | 50.00    | 350.00       | 2304.60      | 9.27     |\n",
      "| 21  | 12         | 8          | work       | 22.08    | 78.00    | 45.00    | 55.00    | 350.00       | 2438.58      | 9.15     |\n",
      "| 21  | 13         | 0          | action     | 22.08    | 78.00    | 65.00    | 35.00    | 700.00       | 2438.58      | 9.43     |\n",
      "| 21  | 14         | 8          | work       | 22.08    | 83.00    | 60.00    | 40.00    | 700.00       | 2572.57      | 9.77     |\n",
      "| 21  | 15         | 8          | work       | 22.08    | 88.00    | 55.00    | 45.00    | 700.00       | 2706.56      | 9.95     |\n",
      "| 21  | 16         | 8          | work       | 22.08    | 93.00    | 50.00    | 50.00    | 700.00       | 2840.55      | 9.99     |\n",
      "| 21  | 17         | 8          | work       | 22.08    | 98.00    | 45.00    | 55.00    | 700.00       | 2974.54      | 9.87     |\n",
      "| 21  | 18         | 8          | work       | 22.08    | 100.00   | 40.00    | 60.00    | 700.00       | 3108.53      | 9.66     |\n",
      "| 21  | 19         | 0          | action     | 22.08    | 100.00   | 60.00    | 40.00    | 1050.00      | 3108.53      | 10.54    |\n",
      "| 21  | 20         | 5          | action     | 22.08    | 100.00   | 45.00    | 55.00    | 1050.00      | 3711.47      | 11.95    |\n",
      "| 21  | 21         | 0          | action     | 22.08    | 100.00   | 65.00    | 35.00    | 1400.00      | 3711.47      | 12.22    |\n",
      "| 21  | 22         | 0          | action     | 22.08    | 100.00   | 85.00    | 15.00    | 1750.00      | 3711.47      | 10.73    |\n",
      "| 21  | 23         | 8          | sleep      | 22.08    | 96.00    | 89.00    | 13.00    | 1750.00      | 3771.77      | 11.11    |\n",
      "| 22  | 0          | 8          | sleep      | 21.98    | 92.00    | 93.00    | 11.00    | 0.00         | 0.00         | 21.47    |\n",
      "| 22  | 1          | 8          | sleep      | 21.98    | 88.00    | 97.00    | 9.00     | 0.00         | 60.04        | 0.54     |\n",
      "| 22  | 2          | 8          | sleep      | 21.98    | 84.00    | 100.00   | 7.00     | 0.00         | 120.08       | 0.92     |\n",
      "| 22  | 3          | 8          | sleep      | 21.98    | 80.00    | 100.00   | 5.00     | 0.00         | 180.12       | 1.30     |\n",
      "| 22  | 4          | 8          | sleep      | 21.98    | 76.00    | 100.00   | 3.00     | 0.00         | 240.16       | -0.32    |\n",
      "| 22  | 5          | 8          | sleep      | 21.98    | 72.00    | 100.00   | 1.00     | 0.00         | 300.20       | -1.94    |\n",
      "| 22  | 6          | 8          | sleep      | 21.98    | 68.00    | 100.00   | 0.00     | 0.00         | 360.23       | -3.56    |\n",
      "| 22  | 7          | 0          | action     | 21.98    | 68.00    | 100.00   | 0.00     | 350.00       | 360.23       | 0.88     |\n",
      "| 22  | 8          | 5          | action     | 21.98    | 68.00    | 85.00    | 15.00    | 350.00       | 960.63       | 3.88     |\n",
      "| 22  | 9          | 5          | action     | 21.98    | 68.00    | 70.00    | 30.00    | 350.00       | 1561.02      | 6.88     |\n",
      "| 22  | 10         | 5          | action     | 21.98    | 68.00    | 55.00    | 45.00    | 350.00       | 2161.41      | 9.19     |\n",
      "| 22  | 11         | 8          | work       | 21.98    | 73.00    | 50.00    | 50.00    | 350.00       | 2294.83      | 9.23     |\n",
      "| 22  | 12         | 8          | work       | 21.98    | 78.00    | 45.00    | 55.00    | 350.00       | 2428.25      | 9.10     |\n",
      "| 22  | 13         | 0          | action     | 21.98    | 78.00    | 65.00    | 35.00    | 700.00       | 2428.25      | 9.38     |\n",
      "| 22  | 14         | 8          | work       | 21.98    | 83.00    | 60.00    | 40.00    | 700.00       | 2561.67      | 9.71     |\n",
      "| 22  | 15         | 8          | work       | 21.98    | 88.00    | 55.00    | 45.00    | 700.00       | 2695.09      | 9.90     |\n",
      "| 22  | 16         | 8          | work       | 21.98    | 93.00    | 50.00    | 50.00    | 700.00       | 2828.51      | 9.93     |\n",
      "| 22  | 17         | 8          | work       | 21.98    | 98.00    | 45.00    | 55.00    | 700.00       | 2961.93      | 9.81     |\n",
      "| 22  | 18         | 8          | work       | 21.98    | 100.00   | 40.00    | 60.00    | 700.00       | 3095.35      | 9.59     |\n",
      "| 22  | 19         | 0          | action     | 21.98    | 100.00   | 60.00    | 40.00    | 1050.00      | 3095.35      | 10.48    |\n",
      "| 22  | 20         | 5          | action     | 21.98    | 100.00   | 45.00    | 55.00    | 1050.00      | 3695.74      | 11.87    |\n",
      "| 22  | 21         | 0          | action     | 21.98    | 100.00   | 65.00    | 35.00    | 1400.00      | 3695.74      | 12.15    |\n",
      "| 22  | 22         | 0          | action     | 21.98    | 100.00   | 85.00    | 15.00    | 1750.00      | 3695.74      | 10.65    |\n",
      "| 22  | 23         | 8          | sleep      | 21.98    | 96.00    | 89.00    | 13.00    | 1750.00      | 3755.78      | 11.03    |\n",
      "| 23  | 0          | 8          | sleep      | 21.89    | 92.00    | 93.00    | 11.00    | 0.00         | 0.00         | 121.40   |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------\n",
      "Mean evaluation reward: 8.055243798778735\n",
      "Std deviation: 7.596286069986941\n"
     ]
    }
   ],
   "source": [
    "from environment3 import LifeStyleEnv\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from sb3_contrib.common.maskable.utils import get_action_masks\n",
    "import numpy as np\n",
    "from sb3_contrib import MaskablePPO\n",
    "\n",
    "def make_env(is_eval: bool = False):\n",
    "    env = LifeStyleEnv()\n",
    "    env = Monitor(env)\n",
    "    if not is_eval:\n",
    "        check_env(env, warn=True)\n",
    "    return env\n",
    "\n",
    "eval_env = make_env(is_eval=True)\n",
    "\n",
    "\n",
    "model = MaskablePPO.load(\"../agent/ppo_lifestylecoach_best_entropy2.zip\")\n",
    "\n",
    "print(\"Starting Final Evaluation...\")\n",
    "print(\"-------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "print(f\"| {'Day':<3} | {'Timeslot':<10} | {'Action':<10} | {'Event':<10} | {'BMI':<8} | {'Stress':<8} | {'Energy':<8} | {'Hunger':<8} | {'Cal. Intake':<12} | {'Cal. Burned':<12} | {'Reward':<8} |\")\n",
    "print(\"-------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "episode_rewards = []\n",
    "for episode in range(1):  \n",
    "    obs, info = eval_env.reset()\n",
    "    unwrapped_env = eval_env.unwrapped\n",
    "    \n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        action_masks = get_action_masks(unwrapped_env)\n",
    "        action, _ = model.predict(obs, deterministic=True, action_masks=action_masks)\n",
    "        obs, reward, terminated, truncated, info = eval_env.step(action)\n",
    "        done = terminated or truncated\n",
    "        total_reward += reward\n",
    "        \n",
    "        timeslot_applied = unwrapped_env.state['current_timeslot'] - 1\n",
    "        timeslot_applied = max(timeslot_applied, 0)  \n",
    "        event_applied = unwrapped_env.daily_schedule[timeslot_applied]\n",
    "\n",
    "        print(\n",
    "            f\"| {unwrapped_env.state['day_of_episode']:<3} | \"\n",
    "            f\"{unwrapped_env.state['current_timeslot']:<10} | \"\n",
    "            f\"{action:<10} | \"\n",
    "            f\"{event_applied:<10} | \"\n",
    "            f\"{unwrapped_env.state['current_bmi']:<8.2f} | \"\n",
    "            f\"{unwrapped_env.state['current_stress_level']:<8.2f} | \"\n",
    "            f\"{unwrapped_env.state['current_energy_level']:<8.2f} | \"\n",
    "            f\"{unwrapped_env.state['current_hunger_level']:<8.2f} | \"\n",
    "            f\"{unwrapped_env.state['daily_calories_intake']:<12.2f} | \"\n",
    "            f\"{unwrapped_env.state['daily_calories_burned']:<12.2f} | \"\n",
    "            f\"{reward:<8.2f} |\"\n",
    "        )\n",
    "        \n",
    "        episode_rewards.append(reward)\n",
    "\n",
    "print(\"-------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "print(\"Mean evaluation reward:\", np.mean(episode_rewards))\n",
    "print(\"Std deviation:\", np.std(episode_rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27015967",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.15)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
