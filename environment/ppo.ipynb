{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92349e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# print(torch.cuda.is_available())\n",
    "# print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c026e5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "Training with ent_coef=0.0\n",
      "Using cuda device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.3e+03   |\n",
      "|    ep_rew_mean     | -3.88e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 674       |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 3         |\n",
      "|    total_timesteps | 2304      |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.3e+03    |\n",
      "|    ep_rew_mean          | -1.82e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 675        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 6          |\n",
      "|    total_timesteps      | 4608       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00901426 |\n",
      "|    clip_fraction        | 0.118      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.774     |\n",
      "|    explained_variance   | -0.000383  |\n",
      "|    learning_rate        | 0.003      |\n",
      "|    loss                 | 2.11e+03   |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.0169    |\n",
      "|    value_loss           | 4.28e+03   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.18e+03     |\n",
      "|    ep_rew_mean          | -755         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 690          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 6912         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065118694 |\n",
      "|    clip_fraction        | 0.107        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.761       |\n",
      "|    explained_variance   | 0.0146       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.35e+03     |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0137      |\n",
      "|    value_loss           | 2.78e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.04e+03     |\n",
      "|    ep_rew_mean          | -199         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 700          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 9216         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062571317 |\n",
      "|    clip_fraction        | 0.101        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.744       |\n",
      "|    explained_variance   | 0.0232       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.15e+03     |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.015       |\n",
      "|    value_loss           | 2.28e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.09e+03     |\n",
      "|    ep_rew_mean          | 892          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 704          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 11520        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075057102 |\n",
      "|    clip_fraction        | 0.0961       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.722       |\n",
      "|    explained_variance   | 0.0448       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.03e+03     |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0138      |\n",
      "|    value_loss           | 2.24e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.89e+03    |\n",
      "|    ep_rew_mean          | 2.13e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 710         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 13824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022017676 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.689      |\n",
      "|    explained_variance   | 0.055       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 483         |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    value_loss           | 1.72e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.7e+03     |\n",
      "|    ep_rew_mean          | 2.63e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 714         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 22          |\n",
      "|    total_timesteps      | 16128       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010349425 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.636      |\n",
      "|    explained_variance   | 0.00154     |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 840         |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    value_loss           | 2.78e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.5e+03     |\n",
      "|    ep_rew_mean          | 3.1e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 716         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011076367 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.594      |\n",
      "|    explained_variance   | 0.00547     |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.3e+03     |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    value_loss           | 3.55e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.38e+03     |\n",
      "|    ep_rew_mean          | 3.49e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 717          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 28           |\n",
      "|    total_timesteps      | 20736        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0114605175 |\n",
      "|    clip_fraction        | 0.14         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.542       |\n",
      "|    explained_variance   | 0.00925      |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.37e+03     |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.0101      |\n",
      "|    value_loss           | 4.2e+03      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.31e+03    |\n",
      "|    ep_rew_mean          | 3.62e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 718         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 23040       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010081879 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.492      |\n",
      "|    explained_variance   | 9.64e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.42e+03    |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00944    |\n",
      "|    value_loss           | 4.09e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.24e+03    |\n",
      "|    ep_rew_mean          | 3.82e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 719         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 35          |\n",
      "|    total_timesteps      | 25344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009953347 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.444      |\n",
      "|    explained_variance   | 0.000266    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.52e+03    |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00645    |\n",
      "|    value_loss           | 4.16e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | 3.96e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 720         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 27648       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019943302 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.399      |\n",
      "|    explained_variance   | 0.000887    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.5e+03     |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00622    |\n",
      "|    value_loss           | 4.31e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 4.03e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 721         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 29952       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009704486 |\n",
      "|    clip_fraction        | 0.0743      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.383      |\n",
      "|    explained_variance   | 7.55e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.59e+03    |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00624    |\n",
      "|    value_loss           | 4.42e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 4.06e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 721         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 44          |\n",
      "|    total_timesteps      | 32256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008044673 |\n",
      "|    clip_fraction        | 0.0615      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.336      |\n",
      "|    explained_variance   | 6.56e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.53e+03    |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0031     |\n",
      "|    value_loss           | 4.36e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 4.08e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 722         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 47          |\n",
      "|    total_timesteps      | 34560       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005211429 |\n",
      "|    clip_fraction        | 0.0486      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.332      |\n",
      "|    explained_variance   | 3.59e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.55e+03    |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00288    |\n",
      "|    value_loss           | 4.21e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 945         |\n",
      "|    ep_rew_mean          | 4e+03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 722         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015697911 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.316      |\n",
      "|    explained_variance   | 2.86e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.48e+03    |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | 0.00986     |\n",
      "|    value_loss           | 3.94e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 908         |\n",
      "|    ep_rew_mean          | 3.97e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 723         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 54          |\n",
      "|    total_timesteps      | 39168       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007880267 |\n",
      "|    clip_fraction        | 0.0956      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.297      |\n",
      "|    explained_variance   | 0.000179    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.31e+03    |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.000601   |\n",
      "|    value_loss           | 3.11e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 891         |\n",
      "|    ep_rew_mean          | 3.99e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 724         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 57          |\n",
      "|    total_timesteps      | 41472       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004209389 |\n",
      "|    clip_fraction        | 0.0547      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.282      |\n",
      "|    explained_variance   | 0.0322      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.19e+03    |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0018     |\n",
      "|    value_loss           | 3.49e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 868         |\n",
      "|    ep_rew_mean          | 4e+03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 725         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 60          |\n",
      "|    total_timesteps      | 43776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004690514 |\n",
      "|    clip_fraction        | 0.0578      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.259      |\n",
      "|    explained_variance   | 2.26e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 971         |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00118    |\n",
      "|    value_loss           | 2.67e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 851          |\n",
      "|    ep_rew_mean          | 3.99e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 725          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 63           |\n",
      "|    total_timesteps      | 46080        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057106987 |\n",
      "|    clip_fraction        | 0.0545       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.279       |\n",
      "|    explained_variance   | 1.34e-05     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 956          |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | 0.000553     |\n",
      "|    value_loss           | 2.51e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 852         |\n",
      "|    ep_rew_mean          | 4.04e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 726         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 66          |\n",
      "|    total_timesteps      | 48384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010192624 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.245      |\n",
      "|    explained_variance   | 1e-05       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.12e+03    |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | 0.00623     |\n",
      "|    value_loss           | 2.11e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 854         |\n",
      "|    ep_rew_mean          | 4.1e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 727         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 50688       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011970339 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.224      |\n",
      "|    explained_variance   | 1.54e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 430         |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | 0.00442     |\n",
      "|    value_loss           | 1.3e+03     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 852        |\n",
      "|    ep_rew_mean          | 4.14e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 727        |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 72         |\n",
      "|    total_timesteps      | 52992      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04894164 |\n",
      "|    clip_fraction        | 0.0925     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.245     |\n",
      "|    explained_variance   | 8.34e-06   |\n",
      "|    learning_rate        | 0.003      |\n",
      "|    loss                 | 698        |\n",
      "|    n_updates            | 220        |\n",
      "|    policy_gradient_loss | 0.00117    |\n",
      "|    value_loss           | 1.46e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 856         |\n",
      "|    ep_rew_mean          | 4.22e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 727         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 75          |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012932989 |\n",
      "|    clip_fraction        | 0.0952      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.226      |\n",
      "|    explained_variance   | 8.05e-06    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 692         |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | 0.00405     |\n",
      "|    value_loss           | 1.8e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 855         |\n",
      "|    ep_rew_mean          | 4.28e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 727         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 79          |\n",
      "|    total_timesteps      | 57600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019845482 |\n",
      "|    clip_fraction        | 0.059       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.242      |\n",
      "|    explained_variance   | 1.01e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 730         |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | 0.000107    |\n",
      "|    value_loss           | 1.59e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 857        |\n",
      "|    ep_rew_mean          | 4.33e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 727        |\n",
      "|    iterations           | 26         |\n",
      "|    time_elapsed         | 82         |\n",
      "|    total_timesteps      | 59904      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00948528 |\n",
      "|    clip_fraction        | 0.0538     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.269     |\n",
      "|    explained_variance   | 7.39e-06   |\n",
      "|    learning_rate        | 0.003      |\n",
      "|    loss                 | 689        |\n",
      "|    n_updates            | 250        |\n",
      "|    policy_gradient_loss | 0.0013     |\n",
      "|    value_loss           | 2e+03      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 862         |\n",
      "|    ep_rew_mean          | 4.38e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 727         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 85          |\n",
      "|    total_timesteps      | 62208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019783443 |\n",
      "|    clip_fraction        | 0.0602      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.221      |\n",
      "|    explained_variance   | 9.12e-06    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 518         |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | 0.00224     |\n",
      "|    value_loss           | 1.44e+03    |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 806      |\n",
      "|    ep_rew_mean          | 3.49e+03 |\n",
      "| time/                   |          |\n",
      "|    fps                  | 727      |\n",
      "|    iterations           | 28       |\n",
      "|    time_elapsed         | 88       |\n",
      "|    total_timesteps      | 64512    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 4.022545 |\n",
      "|    clip_fraction        | 0.246    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -0.0351  |\n",
      "|    explained_variance   | 8.05e-06 |\n",
      "|    learning_rate        | 0.003    |\n",
      "|    loss                 | 647      |\n",
      "|    n_updates            | 270      |\n",
      "|    policy_gradient_loss | 0.0976   |\n",
      "|    value_loss           | 1.88e+03 |\n",
      "--------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 765          |\n",
      "|    ep_rew_mean          | 2.84e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 727          |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 91           |\n",
      "|    total_timesteps      | 66816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014527764 |\n",
      "|    clip_fraction        | 0.0032       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.216       |\n",
      "|    explained_variance   | 0.0288       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.47e+03     |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.00206     |\n",
      "|    value_loss           | 5.92e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 725         |\n",
      "|    ep_rew_mean          | 2.23e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 726         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 95          |\n",
      "|    total_timesteps      | 69120       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003372512 |\n",
      "|    clip_fraction        | 0.0103      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.231      |\n",
      "|    explained_variance   | 0.012       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 4.51e+03    |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.00431    |\n",
      "|    value_loss           | 3.47e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 648          |\n",
      "|    ep_rew_mean          | 1.79e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 725          |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 98           |\n",
      "|    total_timesteps      | 71424        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024880958 |\n",
      "|    clip_fraction        | 0.0271       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.242       |\n",
      "|    explained_variance   | 0.00701      |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 7.82e+03     |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.00454     |\n",
      "|    value_loss           | 3.42e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 575         |\n",
      "|    ep_rew_mean          | 1.26e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 725         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 101         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009405948 |\n",
      "|    clip_fraction        | 0.0517      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.261      |\n",
      "|    explained_variance   | 0.00466     |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.41e+04    |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.00767    |\n",
      "|    value_loss           | 3.16e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 542          |\n",
      "|    ep_rew_mean          | 830          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 725          |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 104          |\n",
      "|    total_timesteps      | 76032        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057026483 |\n",
      "|    clip_fraction        | 0.0622       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.262       |\n",
      "|    explained_variance   | -0.000131    |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 8.04e+03     |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.00851     |\n",
      "|    value_loss           | 1.79e+04     |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 520       |\n",
      "|    ep_rew_mean          | 559       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 726       |\n",
      "|    iterations           | 34        |\n",
      "|    time_elapsed         | 107       |\n",
      "|    total_timesteps      | 78336     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7743772 |\n",
      "|    clip_fraction        | 0.145     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.108    |\n",
      "|    explained_variance   | -3.58e-07 |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 5.34e+03  |\n",
      "|    n_updates            | 330       |\n",
      "|    policy_gradient_loss | 0.0248    |\n",
      "|    value_loss           | 1.35e+04  |\n",
      "---------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 506           |\n",
      "|    ep_rew_mean          | 353           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 725           |\n",
      "|    iterations           | 35            |\n",
      "|    time_elapsed         | 111           |\n",
      "|    total_timesteps      | 80640         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.7804038e-05 |\n",
      "|    clip_fraction        | 0.000937      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0153       |\n",
      "|    explained_variance   | 0.0285        |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 7.96e+03      |\n",
      "|    n_updates            | 340           |\n",
      "|    policy_gradient_loss | -0.000534     |\n",
      "|    value_loss           | 1.7e+04       |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 494            |\n",
      "|    ep_rew_mean          | 131            |\n",
      "| time/                   |                |\n",
      "|    fps                  | 725            |\n",
      "|    iterations           | 36             |\n",
      "|    time_elapsed         | 114            |\n",
      "|    total_timesteps      | 82944          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.000104767576 |\n",
      "|    clip_fraction        | 0.000703       |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.0172        |\n",
      "|    explained_variance   | 6.56e-07       |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 7.56e+03       |\n",
      "|    n_updates            | 350            |\n",
      "|    policy_gradient_loss | -0.000192      |\n",
      "|    value_loss           | 1.33e+04       |\n",
      "--------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 486          |\n",
      "|    ep_rew_mean          | -26.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 725          |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 117          |\n",
      "|    total_timesteps      | 85248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.613187e-05 |\n",
      "|    clip_fraction        | 0.000625     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0159      |\n",
      "|    explained_variance   | 2.98e-07     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 9.41e+03     |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.000498    |\n",
      "|    value_loss           | 1.43e+04     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 477           |\n",
      "|    ep_rew_mean          | -226          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 725           |\n",
      "|    iterations           | 38            |\n",
      "|    time_elapsed         | 120           |\n",
      "|    total_timesteps      | 87552         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.8887658e-05 |\n",
      "|    clip_fraction        | 0.000195      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0154       |\n",
      "|    explained_variance   | 4.77e-07      |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 4.79e+03      |\n",
      "|    n_updates            | 370           |\n",
      "|    policy_gradient_loss | -0.000137     |\n",
      "|    value_loss           | 1.13e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 468           |\n",
      "|    ep_rew_mean          | -400          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 725           |\n",
      "|    iterations           | 39            |\n",
      "|    time_elapsed         | 123           |\n",
      "|    total_timesteps      | 89856         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7982962e-05 |\n",
      "|    clip_fraction        | 0.000156      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0146       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 4.55e+03      |\n",
      "|    n_updates            | 380           |\n",
      "|    policy_gradient_loss | -0.000106     |\n",
      "|    value_loss           | 1.15e+04      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 452          |\n",
      "|    ep_rew_mean          | -625         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 724          |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 127          |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.201059e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0134      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 4.22e+03     |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -5.85e-05    |\n",
      "|    value_loss           | 1e+04        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 430           |\n",
      "|    ep_rew_mean          | -854          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 725           |\n",
      "|    iterations           | 41            |\n",
      "|    time_elapsed         | 130           |\n",
      "|    total_timesteps      | 94464         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.1416372e-05 |\n",
      "|    clip_fraction        | 0.000117      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0136       |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 5.2e+03       |\n",
      "|    n_updates            | 400           |\n",
      "|    policy_gradient_loss | -8.78e-05     |\n",
      "|    value_loss           | 9.67e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 402           |\n",
      "|    ep_rew_mean          | -1.17e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 725           |\n",
      "|    iterations           | 42            |\n",
      "|    time_elapsed         | 133           |\n",
      "|    total_timesteps      | 96768         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.2536022e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0123       |\n",
      "|    explained_variance   | 2.98e-07      |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 4.45e+03      |\n",
      "|    n_updates            | 410           |\n",
      "|    policy_gradient_loss | -3.36e-05     |\n",
      "|    value_loss           | 8.24e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 378          |\n",
      "|    ep_rew_mean          | -1.43e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 726          |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 136          |\n",
      "|    total_timesteps      | 99072        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.954358e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0117      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 3.37e+03     |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -2.99e-05    |\n",
      "|    value_loss           | 8.31e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 377           |\n",
      "|    ep_rew_mean          | -1.28e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 726           |\n",
      "|    iterations           | 44            |\n",
      "|    time_elapsed         | 139           |\n",
      "|    total_timesteps      | 101376        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.1957562e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0113       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 2.42e+03      |\n",
      "|    n_updates            | 430           |\n",
      "|    policy_gradient_loss | -2.28e-05     |\n",
      "|    value_loss           | 6.77e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 384          |\n",
      "|    ep_rew_mean          | -969         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 726          |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 142          |\n",
      "|    total_timesteps      | 103680       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.676872e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0111      |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.05e+03     |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -4.03e-05    |\n",
      "|    value_loss           | 6e+03        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 391          |\n",
      "|    ep_rew_mean          | -713         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 726          |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 145          |\n",
      "|    total_timesteps      | 105984       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.898307e-05 |\n",
      "|    clip_fraction        | 0.000234     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0111      |\n",
      "|    explained_variance   | 4.17e-07     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.78e+03     |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -9.37e-05    |\n",
      "|    value_loss           | 5.78e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 399           |\n",
      "|    ep_rew_mean          | -416          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 726           |\n",
      "|    iterations           | 47            |\n",
      "|    time_elapsed         | 149           |\n",
      "|    total_timesteps      | 108288        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3652314e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0112       |\n",
      "|    explained_variance   | 2.98e-07      |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.79e+03      |\n",
      "|    n_updates            | 460           |\n",
      "|    policy_gradient_loss | -6.73e-06     |\n",
      "|    value_loss           | 4.58e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 405           |\n",
      "|    ep_rew_mean          | -168          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 726           |\n",
      "|    iterations           | 48            |\n",
      "|    time_elapsed         | 152           |\n",
      "|    total_timesteps      | 110592        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017075229 |\n",
      "|    clip_fraction        | 0.000781      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0107       |\n",
      "|    explained_variance   | 1.79e-07      |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.72e+03      |\n",
      "|    n_updates            | 470           |\n",
      "|    policy_gradient_loss | -0.000309     |\n",
      "|    value_loss           | 4.76e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 412           |\n",
      "|    ep_rew_mean          | 116           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 726           |\n",
      "|    iterations           | 49            |\n",
      "|    time_elapsed         | 155           |\n",
      "|    total_timesteps      | 112896        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.3423108e-05 |\n",
      "|    clip_fraction        | 7.81e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0111       |\n",
      "|    explained_variance   | 1.79e-07      |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.89e+03      |\n",
      "|    n_updates            | 480           |\n",
      "|    policy_gradient_loss | -5.41e-05     |\n",
      "|    value_loss           | 3.85e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 416          |\n",
      "|    ep_rew_mean          | 312          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 726          |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 158          |\n",
      "|    total_timesteps      | 115200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.458657e-05 |\n",
      "|    clip_fraction        | 0.00043      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0114      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.34e+03     |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.000187    |\n",
      "|    value_loss           | 3.66e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 420          |\n",
      "|    ep_rew_mean          | 449          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 727          |\n",
      "|    iterations           | 51           |\n",
      "|    time_elapsed         | 161          |\n",
      "|    total_timesteps      | 117504       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.488159e-05 |\n",
      "|    clip_fraction        | 0.000547     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0126      |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.13e+03     |\n",
      "|    n_updates            | 500          |\n",
      "|    policy_gradient_loss | -0.000178    |\n",
      "|    value_loss           | 2.93e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 423           |\n",
      "|    ep_rew_mean          | 523           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 727           |\n",
      "|    iterations           | 52            |\n",
      "|    time_elapsed         | 164           |\n",
      "|    total_timesteps      | 119808        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 9.6280026e-05 |\n",
      "|    clip_fraction        | 0.00105       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0147       |\n",
      "|    explained_variance   | 2.38e-07      |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 702           |\n",
      "|    n_updates            | 510           |\n",
      "|    policy_gradient_loss | -0.000156     |\n",
      "|    value_loss           | 2.19e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 424           |\n",
      "|    ep_rew_mean          | 526           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 727           |\n",
      "|    iterations           | 53            |\n",
      "|    time_elapsed         | 167           |\n",
      "|    total_timesteps      | 122112        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016962289 |\n",
      "|    clip_fraction        | 0.000625      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0167       |\n",
      "|    explained_variance   | 2.38e-07      |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 825           |\n",
      "|    n_updates            | 520           |\n",
      "|    policy_gradient_loss | -9.91e-05     |\n",
      "|    value_loss           | 2.3e+03       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 424          |\n",
      "|    ep_rew_mean          | 522          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 728          |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 170          |\n",
      "|    total_timesteps      | 124416       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020966688 |\n",
      "|    clip_fraction        | 0.00184      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0276      |\n",
      "|    explained_variance   | 1.79e-07     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 668          |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | -0.000738    |\n",
      "|    value_loss           | 1.87e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 425          |\n",
      "|    ep_rew_mean          | 516          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 728          |\n",
      "|    iterations           | 55           |\n",
      "|    time_elapsed         | 173          |\n",
      "|    total_timesteps      | 126720       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016258238 |\n",
      "|    clip_fraction        | 0.00477      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0469      |\n",
      "|    explained_variance   | 1.79e-07     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 599          |\n",
      "|    n_updates            | 540          |\n",
      "|    policy_gradient_loss | -0.000715    |\n",
      "|    value_loss           | 1.51e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 426         |\n",
      "|    ep_rew_mean          | 514         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 729         |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 176         |\n",
      "|    total_timesteps      | 129024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008395044 |\n",
      "|    clip_fraction        | 0.0243      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0601     |\n",
      "|    explained_variance   | 3.58e-07    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 376         |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.000304   |\n",
      "|    value_loss           | 1.12e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 426          |\n",
      "|    ep_rew_mean          | 507          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 729          |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 180          |\n",
      "|    total_timesteps      | 131328       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050522867 |\n",
      "|    clip_fraction        | 0.0239       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0404      |\n",
      "|    explained_variance   | 5.29e-05     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 339          |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.00119     |\n",
      "|    value_loss           | 963          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 426          |\n",
      "|    ep_rew_mean          | 507          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 729          |\n",
      "|    iterations           | 58           |\n",
      "|    time_elapsed         | 183          |\n",
      "|    total_timesteps      | 133632       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055279057 |\n",
      "|    clip_fraction        | 0.0277       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0514      |\n",
      "|    explained_variance   | 0.21         |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 327          |\n",
      "|    n_updates            | 570          |\n",
      "|    policy_gradient_loss | -0.00216     |\n",
      "|    value_loss           | 769          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 426         |\n",
      "|    ep_rew_mean          | 504         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 730         |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 186         |\n",
      "|    total_timesteps      | 135936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027275205 |\n",
      "|    clip_fraction        | 0.0333      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0571     |\n",
      "|    explained_variance   | 0.333       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 224         |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | -0.000516   |\n",
      "|    value_loss           | 515         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 427         |\n",
      "|    ep_rew_mean          | 502         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 729         |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 189         |\n",
      "|    total_timesteps      | 138240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001543972 |\n",
      "|    clip_fraction        | 0.0324      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0459     |\n",
      "|    explained_variance   | 0.24        |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 285         |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.000569   |\n",
      "|    value_loss           | 626         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 427           |\n",
      "|    ep_rew_mean          | 505           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 730           |\n",
      "|    iterations           | 61            |\n",
      "|    time_elapsed         | 192           |\n",
      "|    total_timesteps      | 140544        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00042642807 |\n",
      "|    clip_fraction        | 0.0048        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0415       |\n",
      "|    explained_variance   | 0.292         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 211           |\n",
      "|    n_updates            | 600           |\n",
      "|    policy_gradient_loss | -0.000936     |\n",
      "|    value_loss           | 475           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 427          |\n",
      "|    ep_rew_mean          | 507          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 729          |\n",
      "|    iterations           | 62           |\n",
      "|    time_elapsed         | 195          |\n",
      "|    total_timesteps      | 142848       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004465012 |\n",
      "|    clip_fraction        | 0.0105       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.035       |\n",
      "|    explained_variance   | 0.287        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 193          |\n",
      "|    n_updates            | 610          |\n",
      "|    policy_gradient_loss | -0.00103     |\n",
      "|    value_loss           | 428          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 427          |\n",
      "|    ep_rew_mean          | 507          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 729          |\n",
      "|    iterations           | 63           |\n",
      "|    time_elapsed         | 198          |\n",
      "|    total_timesteps      | 145152       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005661413 |\n",
      "|    clip_fraction        | 0.00227      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0334      |\n",
      "|    explained_variance   | 0.329        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 137          |\n",
      "|    n_updates            | 620          |\n",
      "|    policy_gradient_loss | -6.69e-05    |\n",
      "|    value_loss           | 386          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 428          |\n",
      "|    ep_rew_mean          | 510          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 729          |\n",
      "|    iterations           | 64           |\n",
      "|    time_elapsed         | 201          |\n",
      "|    total_timesteps      | 147456       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015656162 |\n",
      "|    clip_fraction        | 0.00449      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0319      |\n",
      "|    explained_variance   | 0.29         |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 162          |\n",
      "|    n_updates            | 630          |\n",
      "|    policy_gradient_loss | -0.000716    |\n",
      "|    value_loss           | 398          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 428           |\n",
      "|    ep_rew_mean          | 512           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 730           |\n",
      "|    iterations           | 65            |\n",
      "|    time_elapsed         | 205           |\n",
      "|    total_timesteps      | 149760        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00047071016 |\n",
      "|    clip_fraction        | 0.00586       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0363       |\n",
      "|    explained_variance   | 0.253         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 379           |\n",
      "|    n_updates            | 640           |\n",
      "|    policy_gradient_loss | -0.000962     |\n",
      "|    value_loss           | 598           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 429         |\n",
      "|    ep_rew_mean          | 511         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 730         |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 208         |\n",
      "|    total_timesteps      | 152064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004406334 |\n",
      "|    clip_fraction        | 0.00664     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.042      |\n",
      "|    explained_variance   | 0.349       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 201         |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | -0.0017     |\n",
      "|    value_loss           | 378         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 429          |\n",
      "|    ep_rew_mean          | 500          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 730          |\n",
      "|    iterations           | 67           |\n",
      "|    time_elapsed         | 211          |\n",
      "|    total_timesteps      | 154368       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005507193 |\n",
      "|    clip_fraction        | 0.00879      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0624      |\n",
      "|    explained_variance   | 0.269        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 264          |\n",
      "|    n_updates            | 660          |\n",
      "|    policy_gradient_loss | -0.00063     |\n",
      "|    value_loss           | 577          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 430          |\n",
      "|    ep_rew_mean          | 483          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 730          |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 214          |\n",
      "|    total_timesteps      | 156672       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043336065 |\n",
      "|    clip_fraction        | 0.029        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0607      |\n",
      "|    explained_variance   | 0.242        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 355          |\n",
      "|    n_updates            | 670          |\n",
      "|    policy_gradient_loss | 0.00203      |\n",
      "|    value_loss           | 748          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 431          |\n",
      "|    ep_rew_mean          | 481          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 730          |\n",
      "|    iterations           | 69           |\n",
      "|    time_elapsed         | 217          |\n",
      "|    total_timesteps      | 158976       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065311245 |\n",
      "|    clip_fraction        | 0.00953      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0886      |\n",
      "|    explained_variance   | 0.179        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 621          |\n",
      "|    n_updates            | 680          |\n",
      "|    policy_gradient_loss | -0.000521    |\n",
      "|    value_loss           | 1.35e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 433         |\n",
      "|    ep_rew_mean          | 481         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 730         |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 220         |\n",
      "|    total_timesteps      | 161280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006879075 |\n",
      "|    clip_fraction        | 0.0282      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.118      |\n",
      "|    explained_variance   | 0.164       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 690         |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | 0.00106     |\n",
      "|    value_loss           | 1.45e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 438         |\n",
      "|    ep_rew_mean          | 507         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 731         |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 223         |\n",
      "|    total_timesteps      | 163584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019851184 |\n",
      "|    clip_fraction        | 0.0433      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.142      |\n",
      "|    explained_variance   | 0.152       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 772         |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.0011     |\n",
      "|    value_loss           | 1.54e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 446          |\n",
      "|    ep_rew_mean          | 566          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 731          |\n",
      "|    iterations           | 72           |\n",
      "|    time_elapsed         | 226          |\n",
      "|    total_timesteps      | 165888       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043612337 |\n",
      "|    clip_fraction        | 0.15         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.165       |\n",
      "|    explained_variance   | 0.145        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 796          |\n",
      "|    n_updates            | 710          |\n",
      "|    policy_gradient_loss | 0.00325      |\n",
      "|    value_loss           | 1.81e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 458         |\n",
      "|    ep_rew_mean          | 643         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 731         |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 229         |\n",
      "|    total_timesteps      | 168192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003723932 |\n",
      "|    clip_fraction        | 0.0634      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.176      |\n",
      "|    explained_variance   | 0.158       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 831         |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.00566    |\n",
      "|    value_loss           | 2.18e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 466         |\n",
      "|    ep_rew_mean          | 705         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 731         |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 233         |\n",
      "|    total_timesteps      | 170496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001321866 |\n",
      "|    clip_fraction        | 0.0255      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.173      |\n",
      "|    explained_variance   | 0.135       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 588         |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | -0.00348    |\n",
      "|    value_loss           | 1.83e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 481          |\n",
      "|    ep_rew_mean          | 809          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 731          |\n",
      "|    iterations           | 75           |\n",
      "|    time_elapsed         | 236          |\n",
      "|    total_timesteps      | 172800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029536732 |\n",
      "|    clip_fraction        | 0.0481       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.168       |\n",
      "|    explained_variance   | 0.127        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 539          |\n",
      "|    n_updates            | 740          |\n",
      "|    policy_gradient_loss | -0.00638     |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 491         |\n",
      "|    ep_rew_mean          | 879         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 731         |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 239         |\n",
      "|    total_timesteps      | 175104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005472481 |\n",
      "|    clip_fraction        | 0.0288      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.16       |\n",
      "|    explained_variance   | 0.0523      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 637         |\n",
      "|    n_updates            | 750         |\n",
      "|    policy_gradient_loss | -0.00541    |\n",
      "|    value_loss           | 1.95e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 952         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 731         |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 242         |\n",
      "|    total_timesteps      | 177408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003617195 |\n",
      "|    clip_fraction        | 0.0326      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.154      |\n",
      "|    explained_variance   | 0.115       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 677         |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.00352    |\n",
      "|    value_loss           | 1.68e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 511          |\n",
      "|    ep_rew_mean          | 1.05e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 731          |\n",
      "|    iterations           | 78           |\n",
      "|    time_elapsed         | 245          |\n",
      "|    total_timesteps      | 179712       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017680794 |\n",
      "|    clip_fraction        | 0.0306       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.148       |\n",
      "|    explained_variance   | 0.0566       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 488          |\n",
      "|    n_updates            | 770          |\n",
      "|    policy_gradient_loss | -0.00385     |\n",
      "|    value_loss           | 1.69e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 523          |\n",
      "|    ep_rew_mean          | 1.15e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 731          |\n",
      "|    iterations           | 79           |\n",
      "|    time_elapsed         | 248          |\n",
      "|    total_timesteps      | 182016       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014169484 |\n",
      "|    clip_fraction        | 0.0157       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.143       |\n",
      "|    explained_variance   | 0.068        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 559          |\n",
      "|    n_updates            | 780          |\n",
      "|    policy_gradient_loss | -0.00136     |\n",
      "|    value_loss           | 1.67e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 533          |\n",
      "|    ep_rew_mean          | 1.25e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 731          |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 251          |\n",
      "|    total_timesteps      | 184320       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020743501 |\n",
      "|    clip_fraction        | 0.036        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.137       |\n",
      "|    explained_variance   | 0.0641       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 513          |\n",
      "|    n_updates            | 790          |\n",
      "|    policy_gradient_loss | -0.001       |\n",
      "|    value_loss           | 1.42e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 545          |\n",
      "|    ep_rew_mean          | 1.37e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 731          |\n",
      "|    iterations           | 81           |\n",
      "|    time_elapsed         | 255          |\n",
      "|    total_timesteps      | 186624       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017790276 |\n",
      "|    clip_fraction        | 0.0193       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.13        |\n",
      "|    explained_variance   | 0.0868       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 584          |\n",
      "|    n_updates            | 800          |\n",
      "|    policy_gradient_loss | -0.00118     |\n",
      "|    value_loss           | 1.38e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 554          |\n",
      "|    ep_rew_mean          | 1.46e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 731          |\n",
      "|    iterations           | 82           |\n",
      "|    time_elapsed         | 258          |\n",
      "|    total_timesteps      | 188928       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068662404 |\n",
      "|    clip_fraction        | 0.053        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.119       |\n",
      "|    explained_variance   | 0.0854       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 593          |\n",
      "|    n_updates            | 810          |\n",
      "|    policy_gradient_loss | -0.00257     |\n",
      "|    value_loss           | 1.69e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 564          |\n",
      "|    ep_rew_mean          | 1.54e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 731          |\n",
      "|    iterations           | 83           |\n",
      "|    time_elapsed         | 261          |\n",
      "|    total_timesteps      | 191232       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026996234 |\n",
      "|    clip_fraction        | 0.0296       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.113       |\n",
      "|    explained_variance   | 0.125        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 540          |\n",
      "|    n_updates            | 820          |\n",
      "|    policy_gradient_loss | 0.00146      |\n",
      "|    value_loss           | 1.49e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 576          |\n",
      "|    ep_rew_mean          | 1.65e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 731          |\n",
      "|    iterations           | 84           |\n",
      "|    time_elapsed         | 264          |\n",
      "|    total_timesteps      | 193536       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035428323 |\n",
      "|    clip_fraction        | 0.0246       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.104       |\n",
      "|    explained_variance   | 0.00393      |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 339          |\n",
      "|    n_updates            | 830          |\n",
      "|    policy_gradient_loss | -0.00107     |\n",
      "|    value_loss           | 987          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 588         |\n",
      "|    ep_rew_mean          | 1.76e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 731         |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 267         |\n",
      "|    total_timesteps      | 195840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002229241 |\n",
      "|    clip_fraction        | 0.0286      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.103      |\n",
      "|    explained_variance   | 0.00719     |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 612         |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | 0.00146     |\n",
      "|    value_loss           | 1.12e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 599          |\n",
      "|    ep_rew_mean          | 1.86e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 731          |\n",
      "|    iterations           | 86           |\n",
      "|    time_elapsed         | 270          |\n",
      "|    total_timesteps      | 198144       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032413981 |\n",
      "|    clip_fraction        | 0.0221       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0959      |\n",
      "|    explained_variance   | 0.0256       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 635          |\n",
      "|    n_updates            | 850          |\n",
      "|    policy_gradient_loss | -0.00224     |\n",
      "|    value_loss           | 1.36e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 609          |\n",
      "|    ep_rew_mean          | 1.97e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 731          |\n",
      "|    iterations           | 87           |\n",
      "|    time_elapsed         | 274          |\n",
      "|    total_timesteps      | 200448       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021891878 |\n",
      "|    clip_fraction        | 0.0141       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0937      |\n",
      "|    explained_variance   | 0.0599       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 655          |\n",
      "|    n_updates            | 860          |\n",
      "|    policy_gradient_loss | 3.34e-05     |\n",
      "|    value_loss           | 1.24e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 617         |\n",
      "|    ep_rew_mean          | 2.06e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 731         |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 277         |\n",
      "|    total_timesteps      | 202752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010443834 |\n",
      "|    clip_fraction        | 0.0219      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0893     |\n",
      "|    explained_variance   | 0.0517      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 430         |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | 0.000662    |\n",
      "|    value_loss           | 1.18e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 629         |\n",
      "|    ep_rew_mean          | 2.17e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 731         |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 280         |\n",
      "|    total_timesteps      | 205056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038582414 |\n",
      "|    clip_fraction        | 0.078       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0872     |\n",
      "|    explained_variance   | 0.105       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 613         |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | 0.0059      |\n",
      "|    value_loss           | 1.27e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 639         |\n",
      "|    ep_rew_mean          | 2.27e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 731         |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 283         |\n",
      "|    total_timesteps      | 207360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009685267 |\n",
      "|    clip_fraction        | 0.0281      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0716     |\n",
      "|    explained_variance   | 0.0677      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 291         |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | -0.00316    |\n",
      "|    value_loss           | 1.16e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 646         |\n",
      "|    ep_rew_mean          | 2.34e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 731         |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 286         |\n",
      "|    total_timesteps      | 209664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008900766 |\n",
      "|    clip_fraction        | 0.0481      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0922     |\n",
      "|    explained_variance   | 0.0746      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 741         |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | -0.00246    |\n",
      "|    value_loss           | 1.36e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 664        |\n",
      "|    ep_rew_mean          | 2.4e+03    |\n",
      "| time/                   |            |\n",
      "|    fps                  | 731        |\n",
      "|    iterations           | 92         |\n",
      "|    time_elapsed         | 289        |\n",
      "|    total_timesteps      | 211968     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.37718463 |\n",
      "|    clip_fraction        | 0.0712     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0929    |\n",
      "|    explained_variance   | 0.115      |\n",
      "|    learning_rate        | 0.003      |\n",
      "|    loss                 | 903        |\n",
      "|    n_updates            | 910        |\n",
      "|    policy_gradient_loss | 0.0155     |\n",
      "|    value_loss           | 2.52e+03   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 683        |\n",
      "|    ep_rew_mean          | 2.47e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 731        |\n",
      "|    iterations           | 93         |\n",
      "|    time_elapsed         | 292        |\n",
      "|    total_timesteps      | 214272     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01632015 |\n",
      "|    clip_fraction        | 0.0796     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0876    |\n",
      "|    explained_variance   | -0.23      |\n",
      "|    learning_rate        | 0.003      |\n",
      "|    loss                 | 170        |\n",
      "|    n_updates            | 920        |\n",
      "|    policy_gradient_loss | -0.00723   |\n",
      "|    value_loss           | 497        |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 682      |\n",
      "|    ep_rew_mean          | 2.45e+03 |\n",
      "| time/                   |          |\n",
      "|    fps                  | 731      |\n",
      "|    iterations           | 94       |\n",
      "|    time_elapsed         | 296      |\n",
      "|    total_timesteps      | 216576   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 2.706056 |\n",
      "|    clip_fraction        | 0.132    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -0.0872  |\n",
      "|    explained_variance   | 0.0765   |\n",
      "|    learning_rate        | 0.003    |\n",
      "|    loss                 | 164      |\n",
      "|    n_updates            | 930      |\n",
      "|    policy_gradient_loss | 0.0119   |\n",
      "|    value_loss           | 318      |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 681         |\n",
      "|    ep_rew_mean          | 2.44e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 731         |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 299         |\n",
      "|    total_timesteps      | 218880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017430333 |\n",
      "|    clip_fraction        | 0.0789      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.115      |\n",
      "|    explained_variance   | 0.0874      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.66e+03    |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | 0.00933     |\n",
      "|    value_loss           | 4.45e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 680          |\n",
      "|    ep_rew_mean          | 2.42e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 731          |\n",
      "|    iterations           | 96           |\n",
      "|    time_elapsed         | 302          |\n",
      "|    total_timesteps      | 221184       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009794343 |\n",
      "|    clip_fraction        | 0.00816      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0518      |\n",
      "|    explained_variance   | 2.14e-05     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 864          |\n",
      "|    n_updates            | 950          |\n",
      "|    policy_gradient_loss | -0.00128     |\n",
      "|    value_loss           | 2.78e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 679         |\n",
      "|    ep_rew_mean          | 2.42e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 731         |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 305         |\n",
      "|    total_timesteps      | 223488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000785104 |\n",
      "|    clip_fraction        | 0.00555     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0506     |\n",
      "|    explained_variance   | 5.3e-05     |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.2e+03     |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.000543   |\n",
      "|    value_loss           | 3.85e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 678        |\n",
      "|    ep_rew_mean          | 2.43e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 731        |\n",
      "|    iterations           | 98         |\n",
      "|    time_elapsed         | 308        |\n",
      "|    total_timesteps      | 225792     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00112863 |\n",
      "|    clip_fraction        | 0.00504    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0352    |\n",
      "|    explained_variance   | 6.56e-07   |\n",
      "|    learning_rate        | 0.003      |\n",
      "|    loss                 | 940        |\n",
      "|    n_updates            | 970        |\n",
      "|    policy_gradient_loss | -0.000423  |\n",
      "|    value_loss           | 2.73e+03   |\n",
      "----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 676           |\n",
      "|    ep_rew_mean          | 2.42e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 731           |\n",
      "|    iterations           | 99            |\n",
      "|    time_elapsed         | 311           |\n",
      "|    total_timesteps      | 228096        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00031085388 |\n",
      "|    clip_fraction        | 0.00242       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0227       |\n",
      "|    explained_variance   | 0.234         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 389           |\n",
      "|    n_updates            | 980           |\n",
      "|    policy_gradient_loss | -0.000425     |\n",
      "|    value_loss           | 920           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 671          |\n",
      "|    ep_rew_mean          | 2.4e+03      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 731          |\n",
      "|    iterations           | 100          |\n",
      "|    time_elapsed         | 315          |\n",
      "|    total_timesteps      | 230400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009700954 |\n",
      "|    clip_fraction        | 0.00227      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0225      |\n",
      "|    explained_variance   | 0.194        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 535          |\n",
      "|    n_updates            | 990          |\n",
      "|    policy_gradient_loss | -0.000845    |\n",
      "|    value_loss           | 1.4e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 659          |\n",
      "|    ep_rew_mean          | 2.32e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 731          |\n",
      "|    iterations           | 101          |\n",
      "|    time_elapsed         | 318          |\n",
      "|    total_timesteps      | 232704       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038093824 |\n",
      "|    clip_fraction        | 0.0034       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.00698     |\n",
      "|    explained_variance   | 0.326        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 288          |\n",
      "|    n_updates            | 1000         |\n",
      "|    policy_gradient_loss | -0.000827    |\n",
      "|    value_loss           | 695          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 633          |\n",
      "|    ep_rew_mean          | 2.13e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 730          |\n",
      "|    iterations           | 102          |\n",
      "|    time_elapsed         | 321          |\n",
      "|    total_timesteps      | 235008       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020682272 |\n",
      "|    clip_fraction        | 0.012        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0124      |\n",
      "|    explained_variance   | 0.203        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.1e+03      |\n",
      "|    n_updates            | 1010         |\n",
      "|    policy_gradient_loss | -0.00557     |\n",
      "|    value_loss           | 2.05e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 614           |\n",
      "|    ep_rew_mean          | 2e+03         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 730           |\n",
      "|    iterations           | 103           |\n",
      "|    time_elapsed         | 324           |\n",
      "|    total_timesteps      | 237312        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.9121043e-06 |\n",
      "|    clip_fraction        | 0.000234      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00145      |\n",
      "|    explained_variance   | 0.358         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 332           |\n",
      "|    n_updates            | 1020          |\n",
      "|    policy_gradient_loss | -1.99e-05     |\n",
      "|    value_loss           | 642           |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 594            |\n",
      "|    ep_rew_mean          | 1.83e+03       |\n",
      "| time/                   |                |\n",
      "|    fps                  | 729            |\n",
      "|    iterations           | 104            |\n",
      "|    time_elapsed         | 328            |\n",
      "|    total_timesteps      | 239616         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -1.6854073e-12 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.00046       |\n",
      "|    explained_variance   | 0.383          |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 411            |\n",
      "|    n_updates            | 1030           |\n",
      "|    policy_gradient_loss | -8.11e-06      |\n",
      "|    value_loss           | 614            |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 574           |\n",
      "|    ep_rew_mean          | 1.65e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 728           |\n",
      "|    iterations           | 105           |\n",
      "|    time_elapsed         | 331           |\n",
      "|    total_timesteps      | 241920        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -6.032508e-13 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.000369     |\n",
      "|    explained_variance   | 0.45          |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 233           |\n",
      "|    n_updates            | 1040          |\n",
      "|    policy_gradient_loss | -1.03e-06     |\n",
      "|    value_loss           | 497           |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 559            |\n",
      "|    ep_rew_mean          | 1.51e+03       |\n",
      "| time/                   |                |\n",
      "|    fps                  | 728            |\n",
      "|    iterations           | 106            |\n",
      "|    time_elapsed         | 335            |\n",
      "|    total_timesteps      | 244224         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -1.5389912e-12 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000323      |\n",
      "|    explained_variance   | 0.531          |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 251            |\n",
      "|    n_updates            | 1050           |\n",
      "|    policy_gradient_loss | -1.12e-06      |\n",
      "|    value_loss           | 483            |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 537            |\n",
      "|    ep_rew_mean          | 1.33e+03       |\n",
      "| time/                   |                |\n",
      "|    fps                  | 728            |\n",
      "|    iterations           | 107            |\n",
      "|    time_elapsed         | 338            |\n",
      "|    total_timesteps      | 246528         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -2.1394442e-12 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000279      |\n",
      "|    explained_variance   | 0.55           |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 240            |\n",
      "|    n_updates            | 1060           |\n",
      "|    policy_gradient_loss | -1e-06         |\n",
      "|    value_loss           | 457            |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 515            |\n",
      "|    ep_rew_mean          | 1.12e+03       |\n",
      "| time/                   |                |\n",
      "|    fps                  | 728            |\n",
      "|    iterations           | 108            |\n",
      "|    time_elapsed         | 341            |\n",
      "|    total_timesteps      | 248832         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -2.9846791e-12 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000245      |\n",
      "|    explained_variance   | 0.552          |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 239            |\n",
      "|    n_updates            | 1070           |\n",
      "|    policy_gradient_loss | -7.37e-07      |\n",
      "|    value_loss           | 457            |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 499            |\n",
      "|    ep_rew_mean          | 950            |\n",
      "| time/                   |                |\n",
      "|    fps                  | 728            |\n",
      "|    iterations           | 109            |\n",
      "|    time_elapsed         | 344            |\n",
      "|    total_timesteps      | 251136         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -3.2493563e-12 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000222      |\n",
      "|    explained_variance   | 0.546          |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 262            |\n",
      "|    n_updates            | 1080           |\n",
      "|    policy_gradient_loss | -4.25e-07      |\n",
      "|    value_loss           | 470            |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 481            |\n",
      "|    ep_rew_mean          | 782            |\n",
      "| time/                   |                |\n",
      "|    fps                  | 728            |\n",
      "|    iterations           | 110            |\n",
      "|    time_elapsed         | 347            |\n",
      "|    total_timesteps      | 253440         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -4.4934724e-12 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000205      |\n",
      "|    explained_variance   | 0.561          |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 216            |\n",
      "|    n_updates            | 1090           |\n",
      "|    policy_gradient_loss | -4.19e-07      |\n",
      "|    value_loss           | 448            |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 467           |\n",
      "|    ep_rew_mean          | 629           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 728           |\n",
      "|    iterations           | 111           |\n",
      "|    time_elapsed         | 351           |\n",
      "|    total_timesteps      | 255744        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -6.262102e-12 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.000191     |\n",
      "|    explained_variance   | 0.56          |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 232           |\n",
      "|    n_updates            | 1100          |\n",
      "|    policy_gradient_loss | -4.16e-07     |\n",
      "|    value_loss           | 450           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 427           |\n",
      "|    ep_rew_mean          | 492           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 728           |\n",
      "|    iterations           | 112           |\n",
      "|    time_elapsed         | 354           |\n",
      "|    total_timesteps      | 258048        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -7.580381e-12 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.000181     |\n",
      "|    explained_variance   | 0.552         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 207           |\n",
      "|    n_updates            | 1110          |\n",
      "|    policy_gradient_loss | -3.16e-07     |\n",
      "|    value_loss           | 465           |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 428            |\n",
      "|    ep_rew_mean          | 504            |\n",
      "| time/                   |                |\n",
      "|    fps                  | 728            |\n",
      "|    iterations           | 113            |\n",
      "|    time_elapsed         | 357            |\n",
      "|    total_timesteps      | 260352         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -1.3112978e-11 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000175      |\n",
      "|    explained_variance   | 0.566          |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 214            |\n",
      "|    n_updates            | 1120           |\n",
      "|    policy_gradient_loss | -4.39e-07      |\n",
      "|    value_loss           | 441            |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 430            |\n",
      "|    ep_rew_mean          | 519            |\n",
      "| time/                   |                |\n",
      "|    fps                  | 728            |\n",
      "|    iterations           | 114            |\n",
      "|    time_elapsed         | 360            |\n",
      "|    total_timesteps      | 262656         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -1.9961454e-11 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000166      |\n",
      "|    explained_variance   | 0.564          |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 236            |\n",
      "|    n_updates            | 1130           |\n",
      "|    policy_gradient_loss | -4.12e-07      |\n",
      "|    value_loss           | 447            |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 431            |\n",
      "|    ep_rew_mean          | 546            |\n",
      "| time/                   |                |\n",
      "|    fps                  | 728            |\n",
      "|    iterations           | 115            |\n",
      "|    time_elapsed         | 363            |\n",
      "|    total_timesteps      | 264960         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -2.7308756e-11 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000163      |\n",
      "|    explained_variance   | 0.556          |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 237            |\n",
      "|    n_updates            | 1140           |\n",
      "|    policy_gradient_loss | -4.28e-07      |\n",
      "|    value_loss           | 460            |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 431           |\n",
      "|    ep_rew_mean          | 562           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 728           |\n",
      "|    iterations           | 116           |\n",
      "|    time_elapsed         | 366           |\n",
      "|    total_timesteps      | 267264        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -5.448597e-11 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.000161     |\n",
      "|    explained_variance   | 0.57          |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 210           |\n",
      "|    n_updates            | 1150          |\n",
      "|    policy_gradient_loss | -6.14e-07     |\n",
      "|    value_loss           | 440           |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 432            |\n",
      "|    ep_rew_mean          | 570            |\n",
      "| time/                   |                |\n",
      "|    fps                  | 728            |\n",
      "|    iterations           | 117            |\n",
      "|    time_elapsed         | 369            |\n",
      "|    total_timesteps      | 269568         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -1.0860539e-10 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000163      |\n",
      "|    explained_variance   | 0.566          |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 226            |\n",
      "|    n_updates            | 1160           |\n",
      "|    policy_gradient_loss | -8.36e-07      |\n",
      "|    value_loss           | 446            |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 432            |\n",
      "|    ep_rew_mean          | 576            |\n",
      "| time/                   |                |\n",
      "|    fps                  | 728            |\n",
      "|    iterations           | 118            |\n",
      "|    time_elapsed         | 373            |\n",
      "|    total_timesteps      | 271872         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -2.2043851e-10 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000171      |\n",
      "|    explained_variance   | 0.558          |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 233            |\n",
      "|    n_updates            | 1170           |\n",
      "|    policy_gradient_loss | -1.28e-06      |\n",
      "|    value_loss           | 461            |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 432            |\n",
      "|    ep_rew_mean          | 578            |\n",
      "| time/                   |                |\n",
      "|    fps                  | 728            |\n",
      "|    iterations           | 119            |\n",
      "|    time_elapsed         | 376            |\n",
      "|    total_timesteps      | 274176         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -5.2305327e-10 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000186      |\n",
      "|    explained_variance   | 0.572          |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 207            |\n",
      "|    n_updates            | 1180           |\n",
      "|    policy_gradient_loss | -1.99e-06      |\n",
      "|    value_loss           | 441            |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 432           |\n",
      "|    ep_rew_mean          | 597           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 728           |\n",
      "|    iterations           | 120           |\n",
      "|    time_elapsed         | 379           |\n",
      "|    total_timesteps      | 276480        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7368903e-09 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.000243     |\n",
      "|    explained_variance   | 0.568         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 227           |\n",
      "|    n_updates            | 1190          |\n",
      "|    policy_gradient_loss | -7.96e-06     |\n",
      "|    value_loss           | 446           |\n",
      "-------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 432       |\n",
      "|    ep_rew_mean          | 592       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 728       |\n",
      "|    iterations           | 121       |\n",
      "|    time_elapsed         | 382       |\n",
      "|    total_timesteps      | 278784    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 2.6393788 |\n",
      "|    clip_fraction        | 0.0241    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.0174   |\n",
      "|    explained_variance   | 0.557     |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 239       |\n",
      "|    n_updates            | 1200      |\n",
      "|    policy_gradient_loss | -0.00523  |\n",
      "|    value_loss           | 459       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 432         |\n",
      "|    ep_rew_mean          | 589         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 728         |\n",
      "|    iterations           | 122         |\n",
      "|    time_elapsed         | 385         |\n",
      "|    total_timesteps      | 281088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017970815 |\n",
      "|    clip_fraction        | 0.0234      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0222     |\n",
      "|    explained_variance   | 0.314       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 199         |\n",
      "|    n_updates            | 1210        |\n",
      "|    policy_gradient_loss | -0.00111    |\n",
      "|    value_loss           | 390         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 432           |\n",
      "|    ep_rew_mean          | 586           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 728           |\n",
      "|    iterations           | 123           |\n",
      "|    time_elapsed         | 388           |\n",
      "|    total_timesteps      | 283392        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00010629357 |\n",
      "|    clip_fraction        | 0.000586      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00923      |\n",
      "|    explained_variance   | 0.389         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 141           |\n",
      "|    n_updates            | 1220          |\n",
      "|    policy_gradient_loss | -0.000432     |\n",
      "|    value_loss           | 306           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 432          |\n",
      "|    ep_rew_mean          | 583          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 728          |\n",
      "|    iterations           | 124          |\n",
      "|    time_elapsed         | 391          |\n",
      "|    total_timesteps      | 285696       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020332814 |\n",
      "|    clip_fraction        | 0.00297      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0072      |\n",
      "|    explained_variance   | 0.345        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 197          |\n",
      "|    n_updates            | 1230         |\n",
      "|    policy_gradient_loss | -0.000658    |\n",
      "|    value_loss           | 380          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 432         |\n",
      "|    ep_rew_mean          | 581         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 728         |\n",
      "|    iterations           | 125         |\n",
      "|    time_elapsed         | 395         |\n",
      "|    total_timesteps      | 288000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012543194 |\n",
      "|    clip_fraction        | 0.00187     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0127     |\n",
      "|    explained_variance   | 0.348       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 193         |\n",
      "|    n_updates            | 1240        |\n",
      "|    policy_gradient_loss | 0.00113     |\n",
      "|    value_loss           | 386         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 432          |\n",
      "|    ep_rew_mean          | 580          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 728          |\n",
      "|    iterations           | 126          |\n",
      "|    time_elapsed         | 398          |\n",
      "|    total_timesteps      | 290304       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015140374 |\n",
      "|    clip_fraction        | 0.00129      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.00855     |\n",
      "|    explained_variance   | 0.382        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 183          |\n",
      "|    n_updates            | 1250         |\n",
      "|    policy_gradient_loss | 0.000666     |\n",
      "|    value_loss           | 333          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 432          |\n",
      "|    ep_rew_mean          | 583          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 729          |\n",
      "|    iterations           | 127          |\n",
      "|    time_elapsed         | 401          |\n",
      "|    total_timesteps      | 292608       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044197794 |\n",
      "|    clip_fraction        | 0.0134       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.039       |\n",
      "|    explained_variance   | 0.214        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 318          |\n",
      "|    n_updates            | 1260         |\n",
      "|    policy_gradient_loss | -0.00158     |\n",
      "|    value_loss           | 714          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 434         |\n",
      "|    ep_rew_mean          | 607         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 729         |\n",
      "|    iterations           | 128         |\n",
      "|    time_elapsed         | 404         |\n",
      "|    total_timesteps      | 294912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035181407 |\n",
      "|    clip_fraction        | 0.0232      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0381     |\n",
      "|    explained_variance   | 0.249       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 309         |\n",
      "|    n_updates            | 1270        |\n",
      "|    policy_gradient_loss | -0.00126    |\n",
      "|    value_loss           | 600         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 434        |\n",
      "|    ep_rew_mean          | 607        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 729        |\n",
      "|    iterations           | 129        |\n",
      "|    time_elapsed         | 407        |\n",
      "|    total_timesteps      | 297216     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08574663 |\n",
      "|    clip_fraction        | 0.0591     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0841    |\n",
      "|    explained_variance   | 0.0913     |\n",
      "|    learning_rate        | 0.003      |\n",
      "|    loss                 | 844        |\n",
      "|    n_updates            | 1280       |\n",
      "|    policy_gradient_loss | -0.00075   |\n",
      "|    value_loss           | 1.7e+03    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 434         |\n",
      "|    ep_rew_mean          | 603         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 729         |\n",
      "|    iterations           | 130         |\n",
      "|    time_elapsed         | 410         |\n",
      "|    total_timesteps      | 299520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026814748 |\n",
      "|    clip_fraction        | 0.048       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.021      |\n",
      "|    explained_variance   | 0.383       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 176         |\n",
      "|    n_updates            | 1290        |\n",
      "|    policy_gradient_loss | 0.00288     |\n",
      "|    value_loss           | 341         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 434         |\n",
      "|    ep_rew_mean          | 601         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 729         |\n",
      "|    iterations           | 131         |\n",
      "|    time_elapsed         | 413         |\n",
      "|    total_timesteps      | 301824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009635431 |\n",
      "|    clip_fraction        | 0.0411      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0339     |\n",
      "|    explained_variance   | 0.342       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 182         |\n",
      "|    n_updates            | 1300        |\n",
      "|    policy_gradient_loss | 0.0115      |\n",
      "|    value_loss           | 333         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 434         |\n",
      "|    ep_rew_mean          | 599         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 729         |\n",
      "|    iterations           | 132         |\n",
      "|    time_elapsed         | 416         |\n",
      "|    total_timesteps      | 304128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.064057425 |\n",
      "|    clip_fraction        | 0.0437      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.042      |\n",
      "|    explained_variance   | 0.355       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 132         |\n",
      "|    n_updates            | 1310        |\n",
      "|    policy_gradient_loss | 0.00233     |\n",
      "|    value_loss           | 294         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 434          |\n",
      "|    ep_rew_mean          | 598          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 729          |\n",
      "|    iterations           | 133          |\n",
      "|    time_elapsed         | 419          |\n",
      "|    total_timesteps      | 306432       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018388696 |\n",
      "|    clip_fraction        | 0.00637      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0402      |\n",
      "|    explained_variance   | 0.184        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 216          |\n",
      "|    n_updates            | 1320         |\n",
      "|    policy_gradient_loss | 0.000104     |\n",
      "|    value_loss           | 520          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 435          |\n",
      "|    ep_rew_mean          | 603          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 729          |\n",
      "|    iterations           | 134          |\n",
      "|    time_elapsed         | 423          |\n",
      "|    total_timesteps      | 308736       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007781383 |\n",
      "|    clip_fraction        | 0.0131       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.046       |\n",
      "|    explained_variance   | 0.211        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 234          |\n",
      "|    n_updates            | 1330         |\n",
      "|    policy_gradient_loss | 4.39e-06     |\n",
      "|    value_loss           | 491          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 435         |\n",
      "|    ep_rew_mean          | 601         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 729         |\n",
      "|    iterations           | 135         |\n",
      "|    time_elapsed         | 426         |\n",
      "|    total_timesteps      | 311040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005238385 |\n",
      "|    clip_fraction        | 0.0296      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0633     |\n",
      "|    explained_variance   | 0.178       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 304         |\n",
      "|    n_updates            | 1340        |\n",
      "|    policy_gradient_loss | 0.000487    |\n",
      "|    value_loss           | 640         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 435         |\n",
      "|    ep_rew_mean          | 600         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 729         |\n",
      "|    iterations           | 136         |\n",
      "|    time_elapsed         | 429         |\n",
      "|    total_timesteps      | 313344      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031039413 |\n",
      "|    clip_fraction        | 0.0807      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0525     |\n",
      "|    explained_variance   | 0.165       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 390         |\n",
      "|    n_updates            | 1350        |\n",
      "|    policy_gradient_loss | 0.0144      |\n",
      "|    value_loss           | 743         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 435          |\n",
      "|    ep_rew_mean          | 599          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 730          |\n",
      "|    iterations           | 137          |\n",
      "|    time_elapsed         | 432          |\n",
      "|    total_timesteps      | 315648       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051052175 |\n",
      "|    clip_fraction        | 0.00602      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0312      |\n",
      "|    explained_variance   | 0.295        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 179          |\n",
      "|    n_updates            | 1360         |\n",
      "|    policy_gradient_loss | -9.33e-05    |\n",
      "|    value_loss           | 310          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 436          |\n",
      "|    ep_rew_mean          | 603          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 730          |\n",
      "|    iterations           | 138          |\n",
      "|    time_elapsed         | 435          |\n",
      "|    total_timesteps      | 317952       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050042183 |\n",
      "|    clip_fraction        | 0.0073       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.047       |\n",
      "|    explained_variance   | 0.295        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 207          |\n",
      "|    n_updates            | 1370         |\n",
      "|    policy_gradient_loss | -0.000869    |\n",
      "|    value_loss           | 410          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 437          |\n",
      "|    ep_rew_mean          | 605          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 730          |\n",
      "|    iterations           | 139          |\n",
      "|    time_elapsed         | 438          |\n",
      "|    total_timesteps      | 320256       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023796633 |\n",
      "|    clip_fraction        | 0.0293       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0748      |\n",
      "|    explained_variance   | 0.209        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 465          |\n",
      "|    n_updates            | 1380         |\n",
      "|    policy_gradient_loss | -0.00341     |\n",
      "|    value_loss           | 922          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 438          |\n",
      "|    ep_rew_mean          | 613          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 730          |\n",
      "|    iterations           | 140          |\n",
      "|    time_elapsed         | 441          |\n",
      "|    total_timesteps      | 322560       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006868233 |\n",
      "|    clip_fraction        | 0.0126       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.075       |\n",
      "|    explained_variance   | 0.225        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 346          |\n",
      "|    n_updates            | 1390         |\n",
      "|    policy_gradient_loss | -0.000753    |\n",
      "|    value_loss           | 832          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 440          |\n",
      "|    ep_rew_mean          | 624          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 730          |\n",
      "|    iterations           | 141          |\n",
      "|    time_elapsed         | 444          |\n",
      "|    total_timesteps      | 324864       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011413544 |\n",
      "|    clip_fraction        | 0.0279       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.09        |\n",
      "|    explained_variance   | 0.226        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 575          |\n",
      "|    n_updates            | 1400         |\n",
      "|    policy_gradient_loss | -0.00184     |\n",
      "|    value_loss           | 909          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 444         |\n",
      "|    ep_rew_mean          | 660         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 730         |\n",
      "|    iterations           | 142         |\n",
      "|    time_elapsed         | 448         |\n",
      "|    total_timesteps      | 327168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009809269 |\n",
      "|    clip_fraction        | 0.0657      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.104      |\n",
      "|    explained_variance   | 0.212       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 362         |\n",
      "|    n_updates            | 1410        |\n",
      "|    policy_gradient_loss | -0.00266    |\n",
      "|    value_loss           | 989         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 453          |\n",
      "|    ep_rew_mean          | 725          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 730          |\n",
      "|    iterations           | 143          |\n",
      "|    time_elapsed         | 451          |\n",
      "|    total_timesteps      | 329472       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050002635 |\n",
      "|    clip_fraction        | 0.0796       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.13        |\n",
      "|    explained_variance   | 0.188        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 862          |\n",
      "|    n_updates            | 1420         |\n",
      "|    policy_gradient_loss | -0.00736     |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 460         |\n",
      "|    ep_rew_mean          | 784         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 730         |\n",
      "|    iterations           | 144         |\n",
      "|    time_elapsed         | 454         |\n",
      "|    total_timesteps      | 331776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010358606 |\n",
      "|    clip_fraction        | 0.0908      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.135      |\n",
      "|    explained_variance   | 0.176       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 627         |\n",
      "|    n_updates            | 1430        |\n",
      "|    policy_gradient_loss | -0.00461    |\n",
      "|    value_loss           | 1.78e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 476         |\n",
      "|    ep_rew_mean          | 891         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 730         |\n",
      "|    iterations           | 145         |\n",
      "|    time_elapsed         | 457         |\n",
      "|    total_timesteps      | 334080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002327941 |\n",
      "|    clip_fraction        | 0.0383      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.134      |\n",
      "|    explained_variance   | 0.13        |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 686         |\n",
      "|    n_updates            | 1440        |\n",
      "|    policy_gradient_loss | -0.00419    |\n",
      "|    value_loss           | 2.42e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 488         |\n",
      "|    ep_rew_mean          | 976         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 730         |\n",
      "|    iterations           | 146         |\n",
      "|    time_elapsed         | 460         |\n",
      "|    total_timesteps      | 336384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003913843 |\n",
      "|    clip_fraction        | 0.0395      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.125      |\n",
      "|    explained_variance   | 0.0933      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 527         |\n",
      "|    n_updates            | 1450        |\n",
      "|    policy_gradient_loss | -0.00306    |\n",
      "|    value_loss           | 1.82e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 498          |\n",
      "|    ep_rew_mean          | 1.07e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 730          |\n",
      "|    iterations           | 147          |\n",
      "|    time_elapsed         | 463          |\n",
      "|    total_timesteps      | 338688       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026371453 |\n",
      "|    clip_fraction        | 0.0445       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.124       |\n",
      "|    explained_variance   | 0.0239       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 241          |\n",
      "|    n_updates            | 1460         |\n",
      "|    policy_gradient_loss | -0.00422     |\n",
      "|    value_loss           | 1.05e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 510         |\n",
      "|    ep_rew_mean          | 1.18e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 730         |\n",
      "|    iterations           | 148         |\n",
      "|    time_elapsed         | 467         |\n",
      "|    total_timesteps      | 340992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006411954 |\n",
      "|    clip_fraction        | 0.0445      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.109      |\n",
      "|    explained_variance   | 0.0458      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 594         |\n",
      "|    n_updates            | 1470        |\n",
      "|    policy_gradient_loss | -0.00153    |\n",
      "|    value_loss           | 1.49e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 519          |\n",
      "|    ep_rew_mean          | 1.27e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 729          |\n",
      "|    iterations           | 149          |\n",
      "|    time_elapsed         | 470          |\n",
      "|    total_timesteps      | 343296       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015612196 |\n",
      "|    clip_fraction        | 0.0242       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.106       |\n",
      "|    explained_variance   | 0.0111       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 356          |\n",
      "|    n_updates            | 1480         |\n",
      "|    policy_gradient_loss | -0.000846    |\n",
      "|    value_loss           | 1.3e+03      |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 538        |\n",
      "|    ep_rew_mean          | 1.34e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 729        |\n",
      "|    iterations           | 150        |\n",
      "|    time_elapsed         | 473        |\n",
      "|    total_timesteps      | 345600     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.13443682 |\n",
      "|    clip_fraction        | 0.0889     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0995    |\n",
      "|    explained_variance   | 0.0425     |\n",
      "|    learning_rate        | 0.003      |\n",
      "|    loss                 | 714        |\n",
      "|    n_updates            | 1490       |\n",
      "|    policy_gradient_loss | 0.00778    |\n",
      "|    value_loss           | 1.69e+03   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 539       |\n",
      "|    ep_rew_mean          | 1.34e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 729       |\n",
      "|    iterations           | 151       |\n",
      "|    time_elapsed         | 476       |\n",
      "|    total_timesteps      | 347904    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 4.1130295 |\n",
      "|    clip_fraction        | 0.211     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.0245   |\n",
      "|    explained_variance   | -0.0113   |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 186       |\n",
      "|    n_updates            | 1500      |\n",
      "|    policy_gradient_loss | 0.0632    |\n",
      "|    value_loss           | 375       |\n",
      "---------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 538           |\n",
      "|    ep_rew_mean          | 1.33e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 729           |\n",
      "|    iterations           | 152           |\n",
      "|    time_elapsed         | 479           |\n",
      "|    total_timesteps      | 350208        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00027404557 |\n",
      "|    clip_fraction        | 0.000352      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00662      |\n",
      "|    explained_variance   | 0.113         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 610           |\n",
      "|    n_updates            | 1510          |\n",
      "|    policy_gradient_loss | -0.000109     |\n",
      "|    value_loss           | 1.65e+03      |\n",
      "-------------------------------------------\n",
      "\n",
      "Training with ent_coef=0.001\n",
      "Using cuda device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.3e+03   |\n",
      "|    ep_rew_mean     | -3.86e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 740       |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 3         |\n",
      "|    total_timesteps | 2304      |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.3e+03      |\n",
      "|    ep_rew_mean          | -1.4e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 726          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 6            |\n",
      "|    total_timesteps      | 4608         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071598478 |\n",
      "|    clip_fraction        | 0.129        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.771       |\n",
      "|    explained_variance   | -0.00125     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.5e+03      |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0164      |\n",
      "|    value_loss           | 3.91e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.3e+03      |\n",
      "|    ep_rew_mean          | -523         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 723          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 6912         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065846825 |\n",
      "|    clip_fraction        | 0.12         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.763       |\n",
      "|    explained_variance   | 0.00809      |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.44e+03     |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.013       |\n",
      "|    value_loss           | 2.41e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.3e+03      |\n",
      "|    ep_rew_mean          | 757          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 723          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 9216         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072313957 |\n",
      "|    clip_fraction        | 0.0954       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.746       |\n",
      "|    explained_variance   | 0.0413       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.2e+03      |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.0145      |\n",
      "|    value_loss           | 2.58e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.3e+03     |\n",
      "|    ep_rew_mean          | 1.85e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 723         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 11520       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010053611 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.723      |\n",
      "|    explained_variance   | 0.089       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 652         |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    value_loss           | 1.68e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.18e+03    |\n",
      "|    ep_rew_mean          | 2.5e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 724         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 13824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011355327 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.7        |\n",
      "|    explained_variance   | 0.0116      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 523         |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    value_loss           | 1.9e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.99e+03    |\n",
      "|    ep_rew_mean          | 3.24e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 724         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 22          |\n",
      "|    total_timesteps      | 16128       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010633138 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.661      |\n",
      "|    explained_variance   | 0.000166    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 784         |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    value_loss           | 2.51e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.79e+03    |\n",
      "|    ep_rew_mean          | 3.51e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 726         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012282601 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.613      |\n",
      "|    explained_variance   | 0.000167    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 655         |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    value_loss           | 2.23e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.59e+03    |\n",
      "|    ep_rew_mean          | 3.75e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 728         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 20736       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013694515 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.558      |\n",
      "|    explained_variance   | 0.000116    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 773         |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00847    |\n",
      "|    value_loss           | 2.72e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.5e+03     |\n",
      "|    ep_rew_mean          | 3.96e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 728         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 23040       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010899669 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.505      |\n",
      "|    explained_variance   | 8.49e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.31e+03    |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0098     |\n",
      "|    value_loss           | 3.7e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.33e+03    |\n",
      "|    ep_rew_mean          | 3.97e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 728         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 25344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013120713 |\n",
      "|    clip_fraction        | 0.0938      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.462      |\n",
      "|    explained_variance   | 8.67e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.45e+03    |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00722    |\n",
      "|    value_loss           | 4.14e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.29e+03    |\n",
      "|    ep_rew_mean          | 4.07e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 728         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 27648       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006702116 |\n",
      "|    clip_fraction        | 0.0755      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.422      |\n",
      "|    explained_variance   | 7.53e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.52e+03    |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00333    |\n",
      "|    value_loss           | 3.86e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.22e+03    |\n",
      "|    ep_rew_mean          | 4.14e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 729         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 29952       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012070729 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.389      |\n",
      "|    explained_variance   | 7.56e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.14e+03    |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00481    |\n",
      "|    value_loss           | 3.26e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.14e+03    |\n",
      "|    ep_rew_mean          | 4.15e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 730         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 44          |\n",
      "|    total_timesteps      | 32256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011729309 |\n",
      "|    clip_fraction        | 0.0895      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.352      |\n",
      "|    explained_variance   | 6.01e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.22e+03    |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | 0.00331     |\n",
      "|    value_loss           | 3.46e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 4.17e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 730         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 47          |\n",
      "|    total_timesteps      | 34560       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007447881 |\n",
      "|    clip_fraction        | 0.0828      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.326      |\n",
      "|    explained_variance   | 4.21e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.36e+03    |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | 9.98e-06    |\n",
      "|    value_loss           | 3.61e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 4.16e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 730          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 50           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065962644 |\n",
      "|    clip_fraction        | 0.0629       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.326       |\n",
      "|    explained_variance   | 3.86e-05     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.3e+03      |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.0021      |\n",
      "|    value_loss           | 3.48e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 991          |\n",
      "|    ep_rew_mean          | 4.1e+03      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 729          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 53           |\n",
      "|    total_timesteps      | 39168        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032206557 |\n",
      "|    clip_fraction        | 0.0708       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.294       |\n",
      "|    explained_variance   | 3.23e-05     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.35e+03     |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.000283    |\n",
      "|    value_loss           | 3.54e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 955         |\n",
      "|    ep_rew_mean          | 4.1e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 729         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 56          |\n",
      "|    total_timesteps      | 41472       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009591136 |\n",
      "|    clip_fraction        | 0.0884      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.285      |\n",
      "|    explained_variance   | 3.21e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.12e+03    |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.000467   |\n",
      "|    value_loss           | 2.79e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 926          |\n",
      "|    ep_rew_mean          | 4.07e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 728          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 60           |\n",
      "|    total_timesteps      | 43776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055713034 |\n",
      "|    clip_fraction        | 0.0756       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.272       |\n",
      "|    explained_variance   | 2.97e-05     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 843          |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | 0.00166      |\n",
      "|    value_loss           | 2.69e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 914          |\n",
      "|    ep_rew_mean          | 4.11e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 729          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 63           |\n",
      "|    total_timesteps      | 46080        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050206324 |\n",
      "|    clip_fraction        | 0.0423       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.263       |\n",
      "|    explained_variance   | 2.35e-05     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.14e+03     |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | 0.00254      |\n",
      "|    value_loss           | 2.41e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 909          |\n",
      "|    ep_rew_mean          | 4.18e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 729          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 66           |\n",
      "|    total_timesteps      | 48384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040316195 |\n",
      "|    clip_fraction        | 0.0416       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.266       |\n",
      "|    explained_variance   | 2.13e-05     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 816          |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | 0.000288     |\n",
      "|    value_loss           | 1.96e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 912        |\n",
      "|    ep_rew_mean          | 4.26e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 729        |\n",
      "|    iterations           | 22         |\n",
      "|    time_elapsed         | 69         |\n",
      "|    total_timesteps      | 50688      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01010124 |\n",
      "|    clip_fraction        | 0.031      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.243     |\n",
      "|    explained_variance   | 2e-05      |\n",
      "|    learning_rate        | 0.003      |\n",
      "|    loss                 | 933        |\n",
      "|    n_updates            | 210        |\n",
      "|    policy_gradient_loss | -0.00098   |\n",
      "|    value_loss           | 1.92e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 905         |\n",
      "|    ep_rew_mean          | 4.3e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 729         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 72          |\n",
      "|    total_timesteps      | 52992       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020777358 |\n",
      "|    clip_fraction        | 0.0701      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.251      |\n",
      "|    explained_variance   | 1.53e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 659         |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00199    |\n",
      "|    value_loss           | 1.66e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 888         |\n",
      "|    ep_rew_mean          | 4.31e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 730         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 75          |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007635293 |\n",
      "|    clip_fraction        | 0.061       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.275      |\n",
      "|    explained_variance   | 1.29e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.04e+03    |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.00159    |\n",
      "|    value_loss           | 2.03e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 878         |\n",
      "|    ep_rew_mean          | 4.31e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 730         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 78          |\n",
      "|    total_timesteps      | 57600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011166174 |\n",
      "|    clip_fraction        | 0.0753      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.257      |\n",
      "|    explained_variance   | 1.94e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.03e+03    |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | 0.00248     |\n",
      "|    value_loss           | 2.43e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 880         |\n",
      "|    ep_rew_mean          | 4.39e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 730         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 81          |\n",
      "|    total_timesteps      | 59904       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019500263 |\n",
      "|    clip_fraction        | 0.0862      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.265      |\n",
      "|    explained_variance   | 0.00155     |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 811         |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | 0.00242     |\n",
      "|    value_loss           | 2.04e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 874        |\n",
      "|    ep_rew_mean          | 4.4e+03    |\n",
      "| time/                   |            |\n",
      "|    fps                  | 730        |\n",
      "|    iterations           | 27         |\n",
      "|    time_elapsed         | 85         |\n",
      "|    total_timesteps      | 62208      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.13538663 |\n",
      "|    clip_fraction        | 0.126      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.285     |\n",
      "|    explained_variance   | 0.0175     |\n",
      "|    learning_rate        | 0.003      |\n",
      "|    loss                 | 491        |\n",
      "|    n_updates            | 260        |\n",
      "|    policy_gradient_loss | 0.00211    |\n",
      "|    value_loss           | 1.86e+03   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 894       |\n",
      "|    ep_rew_mean          | 4.3e+03   |\n",
      "| time/                   |           |\n",
      "|    fps                  | 730       |\n",
      "|    iterations           | 28        |\n",
      "|    time_elapsed         | 88        |\n",
      "|    total_timesteps      | 64512     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.9080362 |\n",
      "|    clip_fraction        | 0.213     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.118    |\n",
      "|    explained_variance   | 0.00839   |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 1.06e+03  |\n",
      "|    n_updates            | 270       |\n",
      "|    policy_gradient_loss | 0.0482    |\n",
      "|    value_loss           | 2.24e+03  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 914        |\n",
      "|    ep_rew_mean          | 4.27e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 730        |\n",
      "|    iterations           | 29         |\n",
      "|    time_elapsed         | 91         |\n",
      "|    total_timesteps      | 66816      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08323257 |\n",
      "|    clip_fraction        | 0.0286     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0285    |\n",
      "|    explained_variance   | -0.236     |\n",
      "|    learning_rate        | 0.003      |\n",
      "|    loss                 | 51         |\n",
      "|    n_updates            | 280        |\n",
      "|    policy_gradient_loss | -0.00421   |\n",
      "|    value_loss           | 2.42e+03   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 932        |\n",
      "|    ep_rew_mean          | 4.28e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 730        |\n",
      "|    iterations           | 30         |\n",
      "|    time_elapsed         | 94         |\n",
      "|    total_timesteps      | 69120      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.53706723 |\n",
      "|    clip_fraction        | 0.0855     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0626    |\n",
      "|    explained_variance   | -0.418     |\n",
      "|    learning_rate        | 0.003      |\n",
      "|    loss                 | 26.2       |\n",
      "|    n_updates            | 290        |\n",
      "|    policy_gradient_loss | 0.00381    |\n",
      "|    value_loss           | 428        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 951        |\n",
      "|    ep_rew_mean          | 4.17e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 729        |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 97         |\n",
      "|    total_timesteps      | 71424      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.30393583 |\n",
      "|    clip_fraction        | 0.0582     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.00479   |\n",
      "|    explained_variance   | 0.0155     |\n",
      "|    learning_rate        | 0.003      |\n",
      "|    loss                 | 189        |\n",
      "|    n_updates            | 300        |\n",
      "|    policy_gradient_loss | 0.0431     |\n",
      "|    value_loss           | 423        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 969         |\n",
      "|    ep_rew_mean          | 4.15e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 729         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 101         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004182165 |\n",
      "|    clip_fraction        | 0.0399      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0465     |\n",
      "|    explained_variance   | 0.00538     |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 32.4        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.00613    |\n",
      "|    value_loss           | 1.3e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 986         |\n",
      "|    ep_rew_mean          | 4.16e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 728         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 104         |\n",
      "|    total_timesteps      | 76032       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015687456 |\n",
      "|    clip_fraction        | 0.0871      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.14       |\n",
      "|    explained_variance   | 0.0109      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 322         |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    value_loss           | 750         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 4.2e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 728         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 107         |\n",
      "|    total_timesteps      | 78336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013971573 |\n",
      "|    clip_fraction        | 0.0975      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.145      |\n",
      "|    explained_variance   | 0.063       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 207         |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    value_loss           | 465         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.02e+03   |\n",
      "|    ep_rew_mean          | 4.26e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 728        |\n",
      "|    iterations           | 35         |\n",
      "|    time_elapsed         | 110        |\n",
      "|    total_timesteps      | 80640      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05129717 |\n",
      "|    clip_fraction        | 0.135      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.162     |\n",
      "|    explained_variance   | 0.102      |\n",
      "|    learning_rate        | 0.003      |\n",
      "|    loss                 | 264        |\n",
      "|    n_updates            | 340        |\n",
      "|    policy_gradient_loss | -0.0137    |\n",
      "|    value_loss           | 711        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.02e+03    |\n",
      "|    ep_rew_mean          | 4.28e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 728         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 113         |\n",
      "|    total_timesteps      | 82944       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028995056 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.181      |\n",
      "|    explained_variance   | 0.0819      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 222         |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    value_loss           | 623         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.01e+03    |\n",
      "|    ep_rew_mean          | 4.3e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 728         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 116         |\n",
      "|    total_timesteps      | 85248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037433006 |\n",
      "|    clip_fraction        | 0.0939      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.186      |\n",
      "|    explained_variance   | 0.0252      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 314         |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.00741    |\n",
      "|    value_loss           | 1.19e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 4.29e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 729         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 120         |\n",
      "|    total_timesteps      | 87552       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014031854 |\n",
      "|    clip_fraction        | 0.0982      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.178      |\n",
      "|    explained_variance   | 3.85e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 451         |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.00591    |\n",
      "|    value_loss           | 1.6e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 986         |\n",
      "|    ep_rew_mean          | 4.27e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 729         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 123         |\n",
      "|    total_timesteps      | 89856       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004326152 |\n",
      "|    clip_fraction        | 0.0318      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.171      |\n",
      "|    explained_variance   | 0.000855    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 538         |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.00297    |\n",
      "|    value_loss           | 1.79e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 969          |\n",
      "|    ep_rew_mean          | 4.25e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 729          |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 126          |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042587137 |\n",
      "|    clip_fraction        | 0.0631       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.163       |\n",
      "|    explained_variance   | 4.65e-06     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 827          |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.00386     |\n",
      "|    value_loss           | 2.13e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 952          |\n",
      "|    ep_rew_mean          | 4.23e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 729          |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 129          |\n",
      "|    total_timesteps      | 94464        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018263716 |\n",
      "|    clip_fraction        | 0.0348       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.147       |\n",
      "|    explained_variance   | 4.41e-06     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 938          |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | -0.00306     |\n",
      "|    value_loss           | 2.42e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 896          |\n",
      "|    ep_rew_mean          | 4.36e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 729          |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 132          |\n",
      "|    total_timesteps      | 96768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025200217 |\n",
      "|    clip_fraction        | 0.0168       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.145       |\n",
      "|    explained_variance   | 3.58e-06     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 972          |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.00148     |\n",
      "|    value_loss           | 2.35e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 838          |\n",
      "|    ep_rew_mean          | 4.28e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 730          |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 135          |\n",
      "|    total_timesteps      | 99072        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020769355 |\n",
      "|    clip_fraction        | 0.0387       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.141       |\n",
      "|    explained_variance   | 3.04e-06     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.18e+03     |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.00275     |\n",
      "|    value_loss           | 2.46e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 820         |\n",
      "|    ep_rew_mean          | 4.26e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 730         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 138         |\n",
      "|    total_timesteps      | 101376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001569581 |\n",
      "|    clip_fraction        | 0.0312      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.132      |\n",
      "|    explained_variance   | 2.56e-06    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.17e+03    |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.00259    |\n",
      "|    value_loss           | 2.84e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 803          |\n",
      "|    ep_rew_mean          | 4.22e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 730          |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 141          |\n",
      "|    total_timesteps      | 103680       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043372717 |\n",
      "|    clip_fraction        | 0.0457       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.122       |\n",
      "|    explained_variance   | 2.44e-06     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 947          |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | 0.000765     |\n",
      "|    value_loss           | 2.74e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 796          |\n",
      "|    ep_rew_mean          | 4.22e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 730          |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 145          |\n",
      "|    total_timesteps      | 105984       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041107046 |\n",
      "|    clip_fraction        | 0.0295       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.115       |\n",
      "|    explained_variance   | 1.49e-06     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.63e+03     |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.000552    |\n",
      "|    value_loss           | 3.46e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 786         |\n",
      "|    ep_rew_mean          | 4.2e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 731         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 148         |\n",
      "|    total_timesteps      | 108288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008312871 |\n",
      "|    clip_fraction        | 0.0387      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.108      |\n",
      "|    explained_variance   | 1.61e-06    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.32e+03    |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | 0.00178     |\n",
      "|    value_loss           | 3.24e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 779         |\n",
      "|    ep_rew_mean          | 4.19e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 731         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 151         |\n",
      "|    total_timesteps      | 110592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008557251 |\n",
      "|    clip_fraction        | 0.0413      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.118      |\n",
      "|    explained_variance   | 1.67e-06    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.47e+03    |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.00199    |\n",
      "|    value_loss           | 3.34e+03    |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 778      |\n",
      "|    ep_rew_mean          | 4.2e+03  |\n",
      "| time/                   |          |\n",
      "|    fps                  | 731      |\n",
      "|    iterations           | 49       |\n",
      "|    time_elapsed         | 154      |\n",
      "|    total_timesteps      | 112896   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.265678 |\n",
      "|    clip_fraction        | 0.0779   |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -0.0951  |\n",
      "|    explained_variance   | 1.01e-06 |\n",
      "|    learning_rate        | 0.003    |\n",
      "|    loss                 | 1.78e+03 |\n",
      "|    n_updates            | 480      |\n",
      "|    policy_gradient_loss | 0.0143   |\n",
      "|    value_loss           | 4.08e+03 |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 786         |\n",
      "|    ep_rew_mean          | 4.27e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 731         |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 157         |\n",
      "|    total_timesteps      | 115200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.098725244 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0327     |\n",
      "|    explained_variance   | 2.26e-06    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 712         |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | 0.0243      |\n",
      "|    value_loss           | 3.11e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 788        |\n",
      "|    ep_rew_mean          | 4.3e+03    |\n",
      "| time/                   |            |\n",
      "|    fps                  | 731        |\n",
      "|    iterations           | 51         |\n",
      "|    time_elapsed         | 160        |\n",
      "|    total_timesteps      | 117504     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03553054 |\n",
      "|    clip_fraction        | 0.0725     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0645    |\n",
      "|    explained_variance   | 2.26e-06   |\n",
      "|    learning_rate        | 0.003      |\n",
      "|    loss                 | 1.89e+03   |\n",
      "|    n_updates            | 500        |\n",
      "|    policy_gradient_loss | -0.0028    |\n",
      "|    value_loss           | 2.8e+03    |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 787          |\n",
      "|    ep_rew_mean          | 4.33e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 732          |\n",
      "|    iterations           | 52           |\n",
      "|    time_elapsed         | 163          |\n",
      "|    total_timesteps      | 119808       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021152992 |\n",
      "|    clip_fraction        | 0.0213       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.062       |\n",
      "|    explained_variance   | 0.0264       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 872          |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | -0.000221    |\n",
      "|    value_loss           | 2.98e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 785          |\n",
      "|    ep_rew_mean          | 4.35e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 732          |\n",
      "|    iterations           | 53           |\n",
      "|    time_elapsed         | 166          |\n",
      "|    total_timesteps      | 122112       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011696753 |\n",
      "|    clip_fraction        | 0.034        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0605      |\n",
      "|    explained_variance   | 0.0144       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.16e+03     |\n",
      "|    n_updates            | 520          |\n",
      "|    policy_gradient_loss | -0.000611    |\n",
      "|    value_loss           | 4.67e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 778          |\n",
      "|    ep_rew_mean          | 4.34e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 732          |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 169          |\n",
      "|    total_timesteps      | 124416       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007509828 |\n",
      "|    clip_fraction        | 0.00418      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0634      |\n",
      "|    explained_variance   | 0.0227       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.52e+03     |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | -5e-05       |\n",
      "|    value_loss           | 3.98e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 765          |\n",
      "|    ep_rew_mean          | 4.29e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 732          |\n",
      "|    iterations           | 55           |\n",
      "|    time_elapsed         | 172          |\n",
      "|    total_timesteps      | 126720       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016781278 |\n",
      "|    clip_fraction        | 0.00961      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0755      |\n",
      "|    explained_variance   | 0.017        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.52e+03     |\n",
      "|    n_updates            | 540          |\n",
      "|    policy_gradient_loss | -0.000819    |\n",
      "|    value_loss           | 4.07e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 755          |\n",
      "|    ep_rew_mean          | 4.24e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 732          |\n",
      "|    iterations           | 56           |\n",
      "|    time_elapsed         | 176          |\n",
      "|    total_timesteps      | 129024       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071272426 |\n",
      "|    clip_fraction        | 0.0162       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.101       |\n",
      "|    explained_variance   | 0.0205       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.22e+03     |\n",
      "|    n_updates            | 550          |\n",
      "|    policy_gradient_loss | -0.00122     |\n",
      "|    value_loss           | 4.11e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 748         |\n",
      "|    ep_rew_mean          | 4.23e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 732         |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 179         |\n",
      "|    total_timesteps      | 131328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001453154 |\n",
      "|    clip_fraction        | 0.0116      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.123      |\n",
      "|    explained_variance   | 0.0185      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 2.71e+03    |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.00074    |\n",
      "|    value_loss           | 4.31e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 729        |\n",
      "|    ep_rew_mean          | 4.09e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 732        |\n",
      "|    iterations           | 58         |\n",
      "|    time_elapsed         | 182        |\n",
      "|    total_timesteps      | 133632     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01623779 |\n",
      "|    clip_fraction        | 0.0514     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.137     |\n",
      "|    explained_variance   | 0.015      |\n",
      "|    learning_rate        | 0.003      |\n",
      "|    loss                 | 2.4e+03    |\n",
      "|    n_updates            | 570        |\n",
      "|    policy_gradient_loss | 0.00259    |\n",
      "|    value_loss           | 5.18e+03   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 712       |\n",
      "|    ep_rew_mean          | 4.19e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 732       |\n",
      "|    iterations           | 59        |\n",
      "|    time_elapsed         | 185       |\n",
      "|    total_timesteps      | 135936    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1095921 |\n",
      "|    clip_fraction        | 0.084     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.14     |\n",
      "|    explained_variance   | 0.0199    |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.93e+03  |\n",
      "|    n_updates            | 580       |\n",
      "|    policy_gradient_loss | 0.00152   |\n",
      "|    value_loss           | 5.93e+03  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 642         |\n",
      "|    ep_rew_mean          | 4.31e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 733         |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 188         |\n",
      "|    total_timesteps      | 138240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037033387 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.181      |\n",
      "|    explained_variance   | 0.0342      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.54e+03    |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | 0.00972     |\n",
      "|    value_loss           | 3.1e+03     |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 593       |\n",
      "|    ep_rew_mean          | 4.26e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 733       |\n",
      "|    iterations           | 61        |\n",
      "|    time_elapsed         | 191       |\n",
      "|    total_timesteps      | 140544    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1233487 |\n",
      "|    clip_fraction        | 0.127     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.127    |\n",
      "|    explained_variance   | 0.0169    |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.47e+03  |\n",
      "|    n_updates            | 600       |\n",
      "|    policy_gradient_loss | 0.00951   |\n",
      "|    value_loss           | 4.36e+03  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 582         |\n",
      "|    ep_rew_mean          | 4.29e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 733         |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 194         |\n",
      "|    total_timesteps      | 142848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008191195 |\n",
      "|    clip_fraction        | 0.0283      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.135      |\n",
      "|    explained_variance   | 0.0192      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 2.25e+03    |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | 0.000244    |\n",
      "|    value_loss           | 3.47e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 577         |\n",
      "|    ep_rew_mean          | 4.32e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 733         |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 197         |\n",
      "|    total_timesteps      | 145152      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013559264 |\n",
      "|    clip_fraction        | 0.0359      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.135      |\n",
      "|    explained_variance   | 0.0159      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 2.14e+03    |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | 0.00173     |\n",
      "|    value_loss           | 4.55e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 574         |\n",
      "|    ep_rew_mean          | 4.34e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 733         |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 200         |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011092434 |\n",
      "|    clip_fraction        | 0.0633      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.18       |\n",
      "|    explained_variance   | 0.02        |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 2.07e+03    |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | 0.0018      |\n",
      "|    value_loss           | 4.91e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 571         |\n",
      "|    ep_rew_mean          | 4.36e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 733         |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 204         |\n",
      "|    total_timesteps      | 149760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008889556 |\n",
      "|    clip_fraction        | 0.0414      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.165      |\n",
      "|    explained_variance   | 0.0211      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.86e+03    |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | 0.00141     |\n",
      "|    value_loss           | 4.98e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 570         |\n",
      "|    ep_rew_mean          | 4.39e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 733         |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 207         |\n",
      "|    total_timesteps      | 152064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003427925 |\n",
      "|    clip_fraction        | 0.0329      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.177      |\n",
      "|    explained_variance   | 0.0194      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 4.4e+03     |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | -0.00214    |\n",
      "|    value_loss           | 6.21e+03    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 570           |\n",
      "|    ep_rew_mean          | 4.41e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 733           |\n",
      "|    iterations           | 67            |\n",
      "|    time_elapsed         | 210           |\n",
      "|    total_timesteps      | 154368        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00071347645 |\n",
      "|    clip_fraction        | 0.0127        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.166        |\n",
      "|    explained_variance   | 0.0249        |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 2.39e+03      |\n",
      "|    n_updates            | 660           |\n",
      "|    policy_gradient_loss | -0.000508     |\n",
      "|    value_loss           | 4.88e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 572          |\n",
      "|    ep_rew_mean          | 4.46e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 734          |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 213          |\n",
      "|    total_timesteps      | 156672       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044293725 |\n",
      "|    clip_fraction        | 0.0197       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.161       |\n",
      "|    explained_variance   | 0.0256       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.53e+03     |\n",
      "|    n_updates            | 670          |\n",
      "|    policy_gradient_loss | -0.000546    |\n",
      "|    value_loss           | 4.98e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 575          |\n",
      "|    ep_rew_mean          | 4.51e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 734          |\n",
      "|    iterations           | 69           |\n",
      "|    time_elapsed         | 216          |\n",
      "|    total_timesteps      | 158976       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016624114 |\n",
      "|    clip_fraction        | 0.0312       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.164       |\n",
      "|    explained_variance   | 0.0227       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 3.1e+03      |\n",
      "|    n_updates            | 680          |\n",
      "|    policy_gradient_loss | 0.00158      |\n",
      "|    value_loss           | 4.83e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 576         |\n",
      "|    ep_rew_mean          | 4.55e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 733         |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 219         |\n",
      "|    total_timesteps      | 161280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004556036 |\n",
      "|    clip_fraction        | 0.0443      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.157      |\n",
      "|    explained_variance   | 0.0387      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 2.44e+03    |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.00312    |\n",
      "|    value_loss           | 4.88e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 579         |\n",
      "|    ep_rew_mean          | 4.58e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 734         |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 222         |\n",
      "|    total_timesteps      | 163584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011661792 |\n",
      "|    clip_fraction        | 0.0556      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.138      |\n",
      "|    explained_variance   | 0.0346      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 4.11e+03    |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | 0.00371     |\n",
      "|    value_loss           | 4.96e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 582         |\n",
      "|    ep_rew_mean          | 4.6e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 734         |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 226         |\n",
      "|    total_timesteps      | 165888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008613527 |\n",
      "|    clip_fraction        | 0.0756      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.122      |\n",
      "|    explained_variance   | 0.037       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.71e+03    |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | 0.00024     |\n",
      "|    value_loss           | 3.86e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 585       |\n",
      "|    ep_rew_mean          | 4.62e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 733       |\n",
      "|    iterations           | 73        |\n",
      "|    time_elapsed         | 229       |\n",
      "|    total_timesteps      | 168192    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0130749 |\n",
      "|    clip_fraction        | 0.0388    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.0828   |\n",
      "|    explained_variance   | 0.0408    |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.5e+03   |\n",
      "|    n_updates            | 720       |\n",
      "|    policy_gradient_loss | 0.00281   |\n",
      "|    value_loss           | 4.78e+03  |\n",
      "---------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 587           |\n",
      "|    ep_rew_mean          | 4.64e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 734           |\n",
      "|    iterations           | 74            |\n",
      "|    time_elapsed         | 232           |\n",
      "|    total_timesteps      | 170496        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00048126606 |\n",
      "|    clip_fraction        | 0.0109        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0866       |\n",
      "|    explained_variance   | 0.0603        |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 3.39e+03      |\n",
      "|    n_updates            | 730           |\n",
      "|    policy_gradient_loss | -0.000341     |\n",
      "|    value_loss           | 4.75e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 582          |\n",
      "|    ep_rew_mean          | 4.61e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 733          |\n",
      "|    iterations           | 75           |\n",
      "|    time_elapsed         | 235          |\n",
      "|    total_timesteps      | 172800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.226269e-05 |\n",
      "|    clip_fraction        | 0.000234     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0884      |\n",
      "|    explained_variance   | 0.0592       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.56e+03     |\n",
      "|    n_updates            | 740          |\n",
      "|    policy_gradient_loss | -3.96e-05    |\n",
      "|    value_loss           | 4.66e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 579          |\n",
      "|    ep_rew_mean          | 4.59e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 734          |\n",
      "|    iterations           | 76           |\n",
      "|    time_elapsed         | 238          |\n",
      "|    total_timesteps      | 175104       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010424617 |\n",
      "|    clip_fraction        | 0.0154       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.085       |\n",
      "|    explained_variance   | 0.0852       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.17e+03     |\n",
      "|    n_updates            | 750          |\n",
      "|    policy_gradient_loss | -0.00045     |\n",
      "|    value_loss           | 3.52e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 583          |\n",
      "|    ep_rew_mean          | 4.62e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 734          |\n",
      "|    iterations           | 77           |\n",
      "|    time_elapsed         | 241          |\n",
      "|    total_timesteps      | 177408       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014133553 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0881      |\n",
      "|    explained_variance   | 0.0714       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 3.38e+03     |\n",
      "|    n_updates            | 760          |\n",
      "|    policy_gradient_loss | -0.000187    |\n",
      "|    value_loss           | 4.72e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 587          |\n",
      "|    ep_rew_mean          | 4.65e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 734          |\n",
      "|    iterations           | 78           |\n",
      "|    time_elapsed         | 244          |\n",
      "|    total_timesteps      | 179712       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002649063 |\n",
      "|    clip_fraction        | 0.0253       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.098       |\n",
      "|    explained_variance   | 0.0778       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.92e+03     |\n",
      "|    n_updates            | 770          |\n",
      "|    policy_gradient_loss | -0.00093     |\n",
      "|    value_loss           | 3.58e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 591          |\n",
      "|    ep_rew_mean          | 4.67e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 734          |\n",
      "|    iterations           | 79           |\n",
      "|    time_elapsed         | 247          |\n",
      "|    total_timesteps      | 182016       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013942132 |\n",
      "|    clip_fraction        | 0.0101       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0957      |\n",
      "|    explained_variance   | 0.0633       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.47e+03     |\n",
      "|    n_updates            | 780          |\n",
      "|    policy_gradient_loss | -0.000271    |\n",
      "|    value_loss           | 4.65e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 594          |\n",
      "|    ep_rew_mean          | 4.71e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 734          |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 250          |\n",
      "|    total_timesteps      | 184320       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006996992 |\n",
      "|    clip_fraction        | 0.0313       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.111       |\n",
      "|    explained_variance   | 0.0924       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.52e+03     |\n",
      "|    n_updates            | 790          |\n",
      "|    policy_gradient_loss | -0.00105     |\n",
      "|    value_loss           | 3.71e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 597          |\n",
      "|    ep_rew_mean          | 4.74e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 734          |\n",
      "|    iterations           | 81           |\n",
      "|    time_elapsed         | 254          |\n",
      "|    total_timesteps      | 186624       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054778354 |\n",
      "|    clip_fraction        | 0.035        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.117       |\n",
      "|    explained_variance   | 0.0947       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 714          |\n",
      "|    n_updates            | 800          |\n",
      "|    policy_gradient_loss | -0.0024      |\n",
      "|    value_loss           | 3.72e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 600         |\n",
      "|    ep_rew_mean          | 4.77e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 734         |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 257         |\n",
      "|    total_timesteps      | 188928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010736791 |\n",
      "|    clip_fraction        | 0.0191      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.133      |\n",
      "|    explained_variance   | 0.036       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 2.47e+03    |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | -0.00231    |\n",
      "|    value_loss           | 4.69e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 601         |\n",
      "|    ep_rew_mean          | 4.79e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 734         |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 260         |\n",
      "|    total_timesteps      | 191232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011594267 |\n",
      "|    clip_fraction        | 0.07        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.173      |\n",
      "|    explained_variance   | 0.0412      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.77e+03    |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.00204    |\n",
      "|    value_loss           | 4.97e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 606          |\n",
      "|    ep_rew_mean          | 4.87e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 734          |\n",
      "|    iterations           | 84           |\n",
      "|    time_elapsed         | 263          |\n",
      "|    total_timesteps      | 193536       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026781636 |\n",
      "|    clip_fraction        | 0.00801      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.167       |\n",
      "|    explained_variance   | 0.0241       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.51e+03     |\n",
      "|    n_updates            | 830          |\n",
      "|    policy_gradient_loss | -0.000948    |\n",
      "|    value_loss           | 5e+03        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 607          |\n",
      "|    ep_rew_mean          | 4.92e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 734          |\n",
      "|    iterations           | 85           |\n",
      "|    time_elapsed         | 266          |\n",
      "|    total_timesteps      | 195840       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031804834 |\n",
      "|    clip_fraction        | 0.0488       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.15        |\n",
      "|    explained_variance   | 0.0348       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.54e+03     |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.00118     |\n",
      "|    value_loss           | 4.92e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 608          |\n",
      "|    ep_rew_mean          | 4.93e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 734          |\n",
      "|    iterations           | 86           |\n",
      "|    time_elapsed         | 269          |\n",
      "|    total_timesteps      | 198144       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040537226 |\n",
      "|    clip_fraction        | 0.0569       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.169       |\n",
      "|    explained_variance   | 0.042        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.14e+03     |\n",
      "|    n_updates            | 850          |\n",
      "|    policy_gradient_loss | 0.00344      |\n",
      "|    value_loss           | 5.02e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 609           |\n",
      "|    ep_rew_mean          | 4.95e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 734           |\n",
      "|    iterations           | 87            |\n",
      "|    time_elapsed         | 272           |\n",
      "|    total_timesteps      | 200448        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00024136149 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.165        |\n",
      "|    explained_variance   | 0.0892        |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.35e+03      |\n",
      "|    n_updates            | 860           |\n",
      "|    policy_gradient_loss | -0.000322     |\n",
      "|    value_loss           | 4.71e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 605          |\n",
      "|    ep_rew_mean          | 4.92e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 734          |\n",
      "|    iterations           | 88           |\n",
      "|    time_elapsed         | 276          |\n",
      "|    total_timesteps      | 202752       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.631768e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.165       |\n",
      "|    explained_variance   | 0.172        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.88e+03     |\n",
      "|    n_updates            | 870          |\n",
      "|    policy_gradient_loss | -9.53e-05    |\n",
      "|    value_loss           | 3.65e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 605           |\n",
      "|    ep_rew_mean          | 4.92e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 734           |\n",
      "|    iterations           | 89            |\n",
      "|    time_elapsed         | 279           |\n",
      "|    total_timesteps      | 205056        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00027514185 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.168        |\n",
      "|    explained_variance   | 0.154         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 2.36e+03      |\n",
      "|    n_updates            | 880           |\n",
      "|    policy_gradient_loss | -0.000165     |\n",
      "|    value_loss           | 4.65e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 608           |\n",
      "|    ep_rew_mean          | 4.94e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 734           |\n",
      "|    iterations           | 90            |\n",
      "|    time_elapsed         | 282           |\n",
      "|    total_timesteps      | 207360        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00074285304 |\n",
      "|    clip_fraction        | 0.0165        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.16         |\n",
      "|    explained_variance   | 0.184         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 3.63e+03      |\n",
      "|    n_updates            | 890           |\n",
      "|    policy_gradient_loss | -0.00285      |\n",
      "|    value_loss           | 5.26e+03      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 613         |\n",
      "|    ep_rew_mean          | 4.98e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 734         |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 285         |\n",
      "|    total_timesteps      | 209664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.049518187 |\n",
      "|    clip_fraction        | 0.0616      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.138      |\n",
      "|    explained_variance   | 0.0601      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.99e+03    |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | 0.00104     |\n",
      "|    value_loss           | 4.28e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 616         |\n",
      "|    ep_rew_mean          | 5.02e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 734         |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 288         |\n",
      "|    total_timesteps      | 211968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003068618 |\n",
      "|    clip_fraction        | 0.0235      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.11       |\n",
      "|    explained_variance   | 0.04        |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 2.41e+03    |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.00132    |\n",
      "|    value_loss           | 5.19e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 616         |\n",
      "|    ep_rew_mean          | 5.02e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 734         |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 291         |\n",
      "|    total_timesteps      | 214272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008107847 |\n",
      "|    clip_fraction        | 0.0411      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.143      |\n",
      "|    explained_variance   | 0.037       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 2.29e+03    |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.00152    |\n",
      "|    value_loss           | 5.21e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 614          |\n",
      "|    ep_rew_mean          | 4.97e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 734          |\n",
      "|    iterations           | 94           |\n",
      "|    time_elapsed         | 294          |\n",
      "|    total_timesteps      | 216576       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018023679 |\n",
      "|    clip_fraction        | 0.0234       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.167       |\n",
      "|    explained_variance   | 0.0539       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.9e+03      |\n",
      "|    n_updates            | 930          |\n",
      "|    policy_gradient_loss | 0.00147      |\n",
      "|    value_loss           | 5.17e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 611         |\n",
      "|    ep_rew_mean          | 4.94e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 735         |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 297         |\n",
      "|    total_timesteps      | 218880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001028939 |\n",
      "|    clip_fraction        | 0.000391    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.158      |\n",
      "|    explained_variance   | 0.154       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 2.11e+03    |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.00184    |\n",
      "|    value_loss           | 6.1e+03     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 608          |\n",
      "|    ep_rew_mean          | 4.9e+03      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 735          |\n",
      "|    iterations           | 96           |\n",
      "|    time_elapsed         | 300          |\n",
      "|    total_timesteps      | 221184       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012639284 |\n",
      "|    clip_fraction        | 0.00152      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.145       |\n",
      "|    explained_variance   | 0.226        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.85e+03     |\n",
      "|    n_updates            | 950          |\n",
      "|    policy_gradient_loss | -0.000893    |\n",
      "|    value_loss           | 4.81e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 607          |\n",
      "|    ep_rew_mean          | 4.89e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 735          |\n",
      "|    iterations           | 97           |\n",
      "|    time_elapsed         | 304          |\n",
      "|    total_timesteps      | 223488       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008275139 |\n",
      "|    clip_fraction        | 0.00102      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.138       |\n",
      "|    explained_variance   | 0.22         |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 3.07e+03     |\n",
      "|    n_updates            | 960          |\n",
      "|    policy_gradient_loss | -0.000871    |\n",
      "|    value_loss           | 4.98e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 606           |\n",
      "|    ep_rew_mean          | 4.91e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 735           |\n",
      "|    iterations           | 98            |\n",
      "|    time_elapsed         | 307           |\n",
      "|    total_timesteps      | 225792        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.9400448e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.132        |\n",
      "|    explained_variance   | 0.217         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.3e+03       |\n",
      "|    n_updates            | 970           |\n",
      "|    policy_gradient_loss | -0.000104     |\n",
      "|    value_loss           | 4.64e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 606          |\n",
      "|    ep_rew_mean          | 4.92e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 734          |\n",
      "|    iterations           | 99           |\n",
      "|    time_elapsed         | 310          |\n",
      "|    total_timesteps      | 228096       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013172062 |\n",
      "|    clip_fraction        | 0.00828      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.128       |\n",
      "|    explained_variance   | 0.22         |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.08e+03     |\n",
      "|    n_updates            | 980          |\n",
      "|    policy_gradient_loss | -0.00112     |\n",
      "|    value_loss           | 4.44e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 608           |\n",
      "|    ep_rew_mean          | 4.93e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 734           |\n",
      "|    iterations           | 100           |\n",
      "|    time_elapsed         | 313           |\n",
      "|    total_timesteps      | 230400        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.8401886e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.122        |\n",
      "|    explained_variance   | 0.234         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.39e+03      |\n",
      "|    n_updates            | 990           |\n",
      "|    policy_gradient_loss | -9.2e-05      |\n",
      "|    value_loss           | 3.29e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 607          |\n",
      "|    ep_rew_mean          | 4.94e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 734          |\n",
      "|    iterations           | 101          |\n",
      "|    time_elapsed         | 316          |\n",
      "|    total_timesteps      | 232704       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010611914 |\n",
      "|    clip_fraction        | 0.0041       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.121       |\n",
      "|    explained_variance   | 0.229        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2e+03        |\n",
      "|    n_updates            | 1000         |\n",
      "|    policy_gradient_loss | -0.000744    |\n",
      "|    value_loss           | 4.34e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 607          |\n",
      "|    ep_rew_mean          | 4.96e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 734          |\n",
      "|    iterations           | 102          |\n",
      "|    time_elapsed         | 319          |\n",
      "|    total_timesteps      | 235008       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003651203 |\n",
      "|    clip_fraction        | 0.000664     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.121       |\n",
      "|    explained_variance   | 0.238        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.17e+03     |\n",
      "|    n_updates            | 1010         |\n",
      "|    policy_gradient_loss | -0.000245    |\n",
      "|    value_loss           | 4.5e+03      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 604           |\n",
      "|    ep_rew_mean          | 4.96e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 734           |\n",
      "|    iterations           | 103           |\n",
      "|    time_elapsed         | 322           |\n",
      "|    total_timesteps      | 237312        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.2418945e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.122        |\n",
      "|    explained_variance   | 0.178         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 2.14e+03      |\n",
      "|    n_updates            | 1020          |\n",
      "|    policy_gradient_loss | -0.000105     |\n",
      "|    value_loss           | 4.53e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 600          |\n",
      "|    ep_rew_mean          | 4.94e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 734          |\n",
      "|    iterations           | 104          |\n",
      "|    time_elapsed         | 326          |\n",
      "|    total_timesteps      | 239616       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005034808 |\n",
      "|    clip_fraction        | 0.000352     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.128       |\n",
      "|    explained_variance   | 0.221        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.67e+03     |\n",
      "|    n_updates            | 1030         |\n",
      "|    policy_gradient_loss | -0.000857    |\n",
      "|    value_loss           | 4.7e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 595          |\n",
      "|    ep_rew_mean          | 4.91e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 734          |\n",
      "|    iterations           | 105          |\n",
      "|    time_elapsed         | 329          |\n",
      "|    total_timesteps      | 241920       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.372931e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.129       |\n",
      "|    explained_variance   | 0.211        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.25e+03     |\n",
      "|    n_updates            | 1040         |\n",
      "|    policy_gradient_loss | 1.35e-05     |\n",
      "|    value_loss           | 4.45e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 592          |\n",
      "|    ep_rew_mean          | 4.89e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 734          |\n",
      "|    iterations           | 106          |\n",
      "|    time_elapsed         | 332          |\n",
      "|    total_timesteps      | 244224       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008793416 |\n",
      "|    clip_fraction        | 0.00141      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.122       |\n",
      "|    explained_variance   | 0.176        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.46e+03     |\n",
      "|    n_updates            | 1050         |\n",
      "|    policy_gradient_loss | -0.000984    |\n",
      "|    value_loss           | 4.53e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 593          |\n",
      "|    ep_rew_mean          | 4.9e+03      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 734          |\n",
      "|    iterations           | 107          |\n",
      "|    time_elapsed         | 335          |\n",
      "|    total_timesteps      | 246528       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007588563 |\n",
      "|    clip_fraction        | 0.00176      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.114       |\n",
      "|    explained_variance   | 0.235        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.1e+03      |\n",
      "|    n_updates            | 1060         |\n",
      "|    policy_gradient_loss | -0.00109     |\n",
      "|    value_loss           | 3.51e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 596           |\n",
      "|    ep_rew_mean          | 4.92e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 734           |\n",
      "|    iterations           | 108           |\n",
      "|    time_elapsed         | 338           |\n",
      "|    total_timesteps      | 248832        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00071045605 |\n",
      "|    clip_fraction        | 0.00453       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.104        |\n",
      "|    explained_variance   | 0.238         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.65e+03      |\n",
      "|    n_updates            | 1070          |\n",
      "|    policy_gradient_loss | -0.00123      |\n",
      "|    value_loss           | 4.27e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 599          |\n",
      "|    ep_rew_mean          | 4.94e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 734          |\n",
      "|    iterations           | 109          |\n",
      "|    time_elapsed         | 341          |\n",
      "|    total_timesteps      | 251136       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010887723 |\n",
      "|    clip_fraction        | 0.0134       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.1         |\n",
      "|    explained_variance   | 0.244        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.67e+03     |\n",
      "|    n_updates            | 1080         |\n",
      "|    policy_gradient_loss | -0.00227     |\n",
      "|    value_loss           | 4.42e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 603          |\n",
      "|    ep_rew_mean          | 4.96e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 734          |\n",
      "|    iterations           | 110          |\n",
      "|    time_elapsed         | 344          |\n",
      "|    total_timesteps      | 253440       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.120937e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0987      |\n",
      "|    explained_variance   | 0.21         |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.67e+03     |\n",
      "|    n_updates            | 1090         |\n",
      "|    policy_gradient_loss | -2.05e-05    |\n",
      "|    value_loss           | 3.55e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 602          |\n",
      "|    ep_rew_mean          | 4.94e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 734          |\n",
      "|    iterations           | 111          |\n",
      "|    time_elapsed         | 348          |\n",
      "|    total_timesteps      | 255744       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022213492 |\n",
      "|    clip_fraction        | 0.0082       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.108       |\n",
      "|    explained_variance   | 0.229        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.27e+03     |\n",
      "|    n_updates            | 1100         |\n",
      "|    policy_gradient_loss | -0.00111     |\n",
      "|    value_loss           | 4.38e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 605         |\n",
      "|    ep_rew_mean          | 4.96e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 734         |\n",
      "|    iterations           | 112         |\n",
      "|    time_elapsed         | 351         |\n",
      "|    total_timesteps      | 258048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012096286 |\n",
      "|    clip_fraction        | 0.0323      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.1        |\n",
      "|    explained_variance   | 0.14        |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.97e+03    |\n",
      "|    n_updates            | 1110        |\n",
      "|    policy_gradient_loss | 0.00346     |\n",
      "|    value_loss           | 3.47e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 606          |\n",
      "|    ep_rew_mean          | 4.96e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 734          |\n",
      "|    iterations           | 113          |\n",
      "|    time_elapsed         | 354          |\n",
      "|    total_timesteps      | 260352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006526474 |\n",
      "|    clip_fraction        | 0.00465      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.104       |\n",
      "|    explained_variance   | 0.242        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.83e+03     |\n",
      "|    n_updates            | 1120         |\n",
      "|    policy_gradient_loss | -0.000167    |\n",
      "|    value_loss           | 4.34e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 607         |\n",
      "|    ep_rew_mean          | 4.96e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 734         |\n",
      "|    iterations           | 114         |\n",
      "|    time_elapsed         | 357         |\n",
      "|    total_timesteps      | 262656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000601399 |\n",
      "|    clip_fraction        | 0.00621     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.107      |\n",
      "|    explained_variance   | 0.253       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.29e+03    |\n",
      "|    n_updates            | 1130        |\n",
      "|    policy_gradient_loss | -1.85e-05   |\n",
      "|    value_loss           | 3.42e+03    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 609           |\n",
      "|    ep_rew_mean          | 4.98e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 734           |\n",
      "|    iterations           | 115           |\n",
      "|    time_elapsed         | 360           |\n",
      "|    total_timesteps      | 264960        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014825938 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.104        |\n",
      "|    explained_variance   | 0.21          |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.71e+03      |\n",
      "|    n_updates            | 1140          |\n",
      "|    policy_gradient_loss | -0.000164     |\n",
      "|    value_loss           | 4.53e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 611          |\n",
      "|    ep_rew_mean          | 4.99e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 734          |\n",
      "|    iterations           | 116          |\n",
      "|    time_elapsed         | 363          |\n",
      "|    total_timesteps      | 267264       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015272142 |\n",
      "|    clip_fraction        | 0.0121       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.117       |\n",
      "|    explained_variance   | 0.252        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.9e+03      |\n",
      "|    n_updates            | 1150         |\n",
      "|    policy_gradient_loss | -0.0006      |\n",
      "|    value_loss           | 3.54e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 612           |\n",
      "|    ep_rew_mean          | 4.99e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 734           |\n",
      "|    iterations           | 117           |\n",
      "|    time_elapsed         | 366           |\n",
      "|    total_timesteps      | 269568        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00037779094 |\n",
      "|    clip_fraction        | 3.91e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.116        |\n",
      "|    explained_variance   | 0.256         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.68e+03      |\n",
      "|    n_updates            | 1160          |\n",
      "|    policy_gradient_loss | 6.58e-05      |\n",
      "|    value_loss           | 3.46e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 612          |\n",
      "|    ep_rew_mean          | 4.99e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 734          |\n",
      "|    iterations           | 118          |\n",
      "|    time_elapsed         | 370          |\n",
      "|    total_timesteps      | 271872       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.947156e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.112       |\n",
      "|    explained_variance   | 0.246        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.91e+03     |\n",
      "|    n_updates            | 1170         |\n",
      "|    policy_gradient_loss | 1.28e-05     |\n",
      "|    value_loss           | 4.53e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 615          |\n",
      "|    ep_rew_mean          | 5.01e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 734          |\n",
      "|    iterations           | 119          |\n",
      "|    time_elapsed         | 373          |\n",
      "|    total_timesteps      | 274176       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.708965e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.109       |\n",
      "|    explained_variance   | 0.224        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.72e+03     |\n",
      "|    n_updates            | 1180         |\n",
      "|    policy_gradient_loss | -5.6e-05     |\n",
      "|    value_loss           | 4.48e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 618       |\n",
      "|    ep_rew_mean          | 5.04e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 734       |\n",
      "|    iterations           | 120       |\n",
      "|    time_elapsed         | 376       |\n",
      "|    total_timesteps      | 276480    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0045475 |\n",
      "|    clip_fraction        | 0.0237    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.121    |\n",
      "|    explained_variance   | 0.252     |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.18e+03  |\n",
      "|    n_updates            | 1190      |\n",
      "|    policy_gradient_loss | -0.00259  |\n",
      "|    value_loss           | 3.71e+03  |\n",
      "---------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 619           |\n",
      "|    ep_rew_mean          | 5.07e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 734           |\n",
      "|    iterations           | 121           |\n",
      "|    time_elapsed         | 379           |\n",
      "|    total_timesteps      | 278784        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.4731415e-05 |\n",
      "|    clip_fraction        | 0.000313      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.126        |\n",
      "|    explained_variance   | 0.0393        |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 2.11e+03      |\n",
      "|    n_updates            | 1200          |\n",
      "|    policy_gradient_loss | 1.69e-05      |\n",
      "|    value_loss           | 4.47e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 621          |\n",
      "|    ep_rew_mean          | 5.08e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 734          |\n",
      "|    iterations           | 122          |\n",
      "|    time_elapsed         | 382          |\n",
      "|    total_timesteps      | 281088       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005883326 |\n",
      "|    clip_fraction        | 0.000313     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.121       |\n",
      "|    explained_variance   | 0.166        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.75e+03     |\n",
      "|    n_updates            | 1210         |\n",
      "|    policy_gradient_loss | -0.000687    |\n",
      "|    value_loss           | 4.46e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 624           |\n",
      "|    ep_rew_mean          | 5.11e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 734           |\n",
      "|    iterations           | 123           |\n",
      "|    time_elapsed         | 385           |\n",
      "|    total_timesteps      | 283392        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00025164062 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.124        |\n",
      "|    explained_variance   | 0.223         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.99e+03      |\n",
      "|    n_updates            | 1220          |\n",
      "|    policy_gradient_loss | -0.000283     |\n",
      "|    value_loss           | 4.67e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 624           |\n",
      "|    ep_rew_mean          | 5.11e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 734           |\n",
      "|    iterations           | 124           |\n",
      "|    time_elapsed         | 389           |\n",
      "|    total_timesteps      | 285696        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00040971074 |\n",
      "|    clip_fraction        | 0.00262       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.122        |\n",
      "|    explained_variance   | 0.247         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 2.45e+03      |\n",
      "|    n_updates            | 1230          |\n",
      "|    policy_gradient_loss | -0.000885     |\n",
      "|    value_loss           | 4.52e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 621          |\n",
      "|    ep_rew_mean          | 5.09e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 734          |\n",
      "|    iterations           | 125          |\n",
      "|    time_elapsed         | 392          |\n",
      "|    total_timesteps      | 288000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019588592 |\n",
      "|    clip_fraction        | 0.017        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.125       |\n",
      "|    explained_variance   | 0.199        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.1e+03      |\n",
      "|    n_updates            | 1240         |\n",
      "|    policy_gradient_loss | -0.000531    |\n",
      "|    value_loss           | 4.69e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 618           |\n",
      "|    ep_rew_mean          | 5.05e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 734           |\n",
      "|    iterations           | 126           |\n",
      "|    time_elapsed         | 395           |\n",
      "|    total_timesteps      | 290304        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011267918 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.128        |\n",
      "|    explained_variance   | 0.192         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 3.07e+03      |\n",
      "|    n_updates            | 1250          |\n",
      "|    policy_gradient_loss | -0.000188     |\n",
      "|    value_loss           | 4.6e+03       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 614          |\n",
      "|    ep_rew_mean          | 5.03e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 734          |\n",
      "|    iterations           | 127          |\n",
      "|    time_elapsed         | 398          |\n",
      "|    total_timesteps      | 292608       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017544385 |\n",
      "|    clip_fraction        | 0.0073       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.124       |\n",
      "|    explained_variance   | 0.241        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.24e+03     |\n",
      "|    n_updates            | 1260         |\n",
      "|    policy_gradient_loss | -0.000125    |\n",
      "|    value_loss           | 4.72e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 613           |\n",
      "|    ep_rew_mean          | 5.02e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 734           |\n",
      "|    iterations           | 128           |\n",
      "|    time_elapsed         | 401           |\n",
      "|    total_timesteps      | 294912        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00054115185 |\n",
      "|    clip_fraction        | 3.91e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.113        |\n",
      "|    explained_variance   | 0.245         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 3.15e+03      |\n",
      "|    n_updates            | 1270          |\n",
      "|    policy_gradient_loss | -0.000423     |\n",
      "|    value_loss           | 5.54e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 613           |\n",
      "|    ep_rew_mean          | 5.01e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 734           |\n",
      "|    iterations           | 129           |\n",
      "|    time_elapsed         | 404           |\n",
      "|    total_timesteps      | 297216        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 9.2578994e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.107        |\n",
      "|    explained_variance   | 0.273         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 989           |\n",
      "|    n_updates            | 1280          |\n",
      "|    policy_gradient_loss | -4.04e-05     |\n",
      "|    value_loss           | 3.49e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 613          |\n",
      "|    ep_rew_mean          | 5.01e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 734          |\n",
      "|    iterations           | 130          |\n",
      "|    time_elapsed         | 407          |\n",
      "|    total_timesteps      | 299520       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005058149 |\n",
      "|    clip_fraction        | 0.00434      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.108       |\n",
      "|    explained_variance   | 0.233        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.91e+03     |\n",
      "|    n_updates            | 1290         |\n",
      "|    policy_gradient_loss | -0.000299    |\n",
      "|    value_loss           | 4.46e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 614          |\n",
      "|    ep_rew_mean          | 5.01e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 734          |\n",
      "|    iterations           | 131          |\n",
      "|    time_elapsed         | 410          |\n",
      "|    total_timesteps      | 301824       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007086915 |\n",
      "|    clip_fraction        | 0.000547     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.103       |\n",
      "|    explained_variance   | 0.26         |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.64e+03     |\n",
      "|    n_updates            | 1300         |\n",
      "|    policy_gradient_loss | -0.000171    |\n",
      "|    value_loss           | 4.29e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 616           |\n",
      "|    ep_rew_mean          | 5.02e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 734           |\n",
      "|    iterations           | 132           |\n",
      "|    time_elapsed         | 414           |\n",
      "|    total_timesteps      | 304128        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00070751354 |\n",
      "|    clip_fraction        | 0.000781      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0988       |\n",
      "|    explained_variance   | 0.264         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.7e+03       |\n",
      "|    n_updates            | 1310          |\n",
      "|    policy_gradient_loss | -0.000346     |\n",
      "|    value_loss           | 4.43e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 619           |\n",
      "|    ep_rew_mean          | 5.02e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 734           |\n",
      "|    iterations           | 133           |\n",
      "|    time_elapsed         | 417           |\n",
      "|    total_timesteps      | 306432        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015193564 |\n",
      "|    clip_fraction        | 0.000859      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0992       |\n",
      "|    explained_variance   | 0.255         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 2.77e+03      |\n",
      "|    n_updates            | 1320          |\n",
      "|    policy_gradient_loss | -0.000227     |\n",
      "|    value_loss           | 4.41e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 618           |\n",
      "|    ep_rew_mean          | 5.01e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 734           |\n",
      "|    iterations           | 134           |\n",
      "|    time_elapsed         | 420           |\n",
      "|    total_timesteps      | 308736        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00024065867 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.1          |\n",
      "|    explained_variance   | 0.28          |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 2.79e+03      |\n",
      "|    n_updates            | 1330          |\n",
      "|    policy_gradient_loss | -0.00056      |\n",
      "|    value_loss           | 3.38e+03      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 618         |\n",
      "|    ep_rew_mean          | 5e+03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 734         |\n",
      "|    iterations           | 135         |\n",
      "|    time_elapsed         | 423         |\n",
      "|    total_timesteps      | 311040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001182344 |\n",
      "|    clip_fraction        | 0.00285     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0924     |\n",
      "|    explained_variance   | 0.0864      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 3.11e+03    |\n",
      "|    n_updates            | 1340        |\n",
      "|    policy_gradient_loss | -0.000682   |\n",
      "|    value_loss           | 4.22e+03    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 620           |\n",
      "|    ep_rew_mean          | 5.01e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 734           |\n",
      "|    iterations           | 136           |\n",
      "|    time_elapsed         | 426           |\n",
      "|    total_timesteps      | 313344        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00074963074 |\n",
      "|    clip_fraction        | 0.00523       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0927       |\n",
      "|    explained_variance   | 0.277         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.38e+03      |\n",
      "|    n_updates            | 1350          |\n",
      "|    policy_gradient_loss | -0.000707     |\n",
      "|    value_loss           | 3.47e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 621           |\n",
      "|    ep_rew_mean          | 5.02e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 734           |\n",
      "|    iterations           | 137           |\n",
      "|    time_elapsed         | 429           |\n",
      "|    total_timesteps      | 315648        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00047048315 |\n",
      "|    clip_fraction        | 0.00484       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0881       |\n",
      "|    explained_variance   | 0.282         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.26e+03      |\n",
      "|    n_updates            | 1360          |\n",
      "|    policy_gradient_loss | -0.000386     |\n",
      "|    value_loss           | 3.37e+03      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 625         |\n",
      "|    ep_rew_mean          | 5.05e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 734         |\n",
      "|    iterations           | 138         |\n",
      "|    time_elapsed         | 432         |\n",
      "|    total_timesteps      | 317952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000324383 |\n",
      "|    clip_fraction        | 0.00699     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0847     |\n",
      "|    explained_variance   | 0.267       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 2.21e+03    |\n",
      "|    n_updates            | 1370        |\n",
      "|    policy_gradient_loss | -8.81e-05   |\n",
      "|    value_loss           | 4.62e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 629          |\n",
      "|    ep_rew_mean          | 5.07e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 734          |\n",
      "|    iterations           | 139          |\n",
      "|    time_elapsed         | 435          |\n",
      "|    total_timesteps      | 320256       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062258774 |\n",
      "|    clip_fraction        | 0.0172       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0794      |\n",
      "|    explained_variance   | 0.275        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.27e+03     |\n",
      "|    n_updates            | 1380         |\n",
      "|    policy_gradient_loss | 0.00355      |\n",
      "|    value_loss           | 3.47e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 630         |\n",
      "|    ep_rew_mean          | 5.09e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 734         |\n",
      "|    iterations           | 140         |\n",
      "|    time_elapsed         | 438         |\n",
      "|    total_timesteps      | 322560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004129413 |\n",
      "|    clip_fraction        | 0.0177      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0914     |\n",
      "|    explained_variance   | 0.28        |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 2.36e+03    |\n",
      "|    n_updates            | 1390        |\n",
      "|    policy_gradient_loss | -0.00178    |\n",
      "|    value_loss           | 3.54e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 628          |\n",
      "|    ep_rew_mean          | 5.08e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 734          |\n",
      "|    iterations           | 141          |\n",
      "|    time_elapsed         | 442          |\n",
      "|    total_timesteps      | 324864       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060871583 |\n",
      "|    clip_fraction        | 0.0141       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.108       |\n",
      "|    explained_variance   | 0.176        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 812          |\n",
      "|    n_updates            | 1400         |\n",
      "|    policy_gradient_loss | -0.000893    |\n",
      "|    value_loss           | 3.8e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 627          |\n",
      "|    ep_rew_mean          | 5.08e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 735          |\n",
      "|    iterations           | 142          |\n",
      "|    time_elapsed         | 445          |\n",
      "|    total_timesteps      | 327168       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021267112 |\n",
      "|    clip_fraction        | 0.00602      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.129       |\n",
      "|    explained_variance   | 0.0826       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.86e+03     |\n",
      "|    n_updates            | 1410         |\n",
      "|    policy_gradient_loss | -0.00023     |\n",
      "|    value_loss           | 4.41e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 624          |\n",
      "|    ep_rew_mean          | 5.06e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 735          |\n",
      "|    iterations           | 143          |\n",
      "|    time_elapsed         | 448          |\n",
      "|    total_timesteps      | 329472       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032441802 |\n",
      "|    clip_fraction        | 0.019        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.14        |\n",
      "|    explained_variance   | 0.158        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.6e+03      |\n",
      "|    n_updates            | 1420         |\n",
      "|    policy_gradient_loss | -0.00112     |\n",
      "|    value_loss           | 3.67e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 621           |\n",
      "|    ep_rew_mean          | 5.05e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 735           |\n",
      "|    iterations           | 144           |\n",
      "|    time_elapsed         | 451           |\n",
      "|    total_timesteps      | 331776        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014253028 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.128        |\n",
      "|    explained_variance   | 0.221         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.83e+03      |\n",
      "|    n_updates            | 1430          |\n",
      "|    policy_gradient_loss | -8.04e-05     |\n",
      "|    value_loss           | 4.52e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 619           |\n",
      "|    ep_rew_mean          | 5.03e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 735           |\n",
      "|    iterations           | 145           |\n",
      "|    time_elapsed         | 454           |\n",
      "|    total_timesteps      | 334080        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013420485 |\n",
      "|    clip_fraction        | 0.000156      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.133        |\n",
      "|    explained_variance   | 0.185         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.97e+03      |\n",
      "|    n_updates            | 1440          |\n",
      "|    policy_gradient_loss | -0.000215     |\n",
      "|    value_loss           | 4.55e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 616          |\n",
      "|    ep_rew_mean          | 5.01e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 735          |\n",
      "|    iterations           | 146          |\n",
      "|    time_elapsed         | 457          |\n",
      "|    total_timesteps      | 336384       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015066874 |\n",
      "|    clip_fraction        | 0.00926      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.129       |\n",
      "|    explained_variance   | 0.26         |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.84e+03     |\n",
      "|    n_updates            | 1450         |\n",
      "|    policy_gradient_loss | -0.00063     |\n",
      "|    value_loss           | 4.59e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 618          |\n",
      "|    ep_rew_mean          | 5.04e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 735          |\n",
      "|    iterations           | 147          |\n",
      "|    time_elapsed         | 460          |\n",
      "|    total_timesteps      | 338688       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013386566 |\n",
      "|    clip_fraction        | 0.00301      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.121       |\n",
      "|    explained_variance   | 0.234        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.93e+03     |\n",
      "|    n_updates            | 1460         |\n",
      "|    policy_gradient_loss | -0.000642    |\n",
      "|    value_loss           | 4.64e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 622          |\n",
      "|    ep_rew_mean          | 5.08e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 735          |\n",
      "|    iterations           | 148          |\n",
      "|    time_elapsed         | 463          |\n",
      "|    total_timesteps      | 340992       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006815197 |\n",
      "|    clip_fraction        | 0.0043       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.127       |\n",
      "|    explained_variance   | 0.273        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.12e+03     |\n",
      "|    n_updates            | 1470         |\n",
      "|    policy_gradient_loss | -0.000509    |\n",
      "|    value_loss           | 3.54e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 623         |\n",
      "|    ep_rew_mean          | 5.09e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 735         |\n",
      "|    iterations           | 149         |\n",
      "|    time_elapsed         | 466         |\n",
      "|    total_timesteps      | 343296      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004697077 |\n",
      "|    clip_fraction        | 0.0283      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.142      |\n",
      "|    explained_variance   | 0.252       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.72e+03    |\n",
      "|    n_updates            | 1480        |\n",
      "|    policy_gradient_loss | -0.00274    |\n",
      "|    value_loss           | 4.71e+03    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 621           |\n",
      "|    ep_rew_mean          | 5.08e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 735           |\n",
      "|    iterations           | 150           |\n",
      "|    time_elapsed         | 469           |\n",
      "|    total_timesteps      | 345600        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00058454165 |\n",
      "|    clip_fraction        | 0.000156      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.151        |\n",
      "|    explained_variance   | 0.246         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 3.06e+03      |\n",
      "|    n_updates            | 1490          |\n",
      "|    policy_gradient_loss | -0.000415     |\n",
      "|    value_loss           | 4.67e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 619           |\n",
      "|    ep_rew_mean          | 5.07e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 735           |\n",
      "|    iterations           | 151           |\n",
      "|    time_elapsed         | 472           |\n",
      "|    total_timesteps      | 347904        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00045279087 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.156        |\n",
      "|    explained_variance   | 0.243         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.49e+03      |\n",
      "|    n_updates            | 1500          |\n",
      "|    policy_gradient_loss | -0.000417     |\n",
      "|    value_loss           | 4.92e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 620          |\n",
      "|    ep_rew_mean          | 5.08e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 735          |\n",
      "|    iterations           | 152          |\n",
      "|    time_elapsed         | 475          |\n",
      "|    total_timesteps      | 350208       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002623414 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.148       |\n",
      "|    explained_variance   | 0.255        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.6e+03      |\n",
      "|    n_updates            | 1510         |\n",
      "|    policy_gradient_loss | -0.000293    |\n",
      "|    value_loss           | 4.84e+03     |\n",
      "------------------------------------------\n",
      "\n",
      "Training with ent_coef=0.01\n",
      "Using cuda device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.63e+03  |\n",
      "|    ep_rew_mean     | -1.94e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 760       |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 3         |\n",
      "|    total_timesteps | 2304      |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.97e+03    |\n",
      "|    ep_rew_mean          | -2.94e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 741         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 4608        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007054777 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.769      |\n",
      "|    explained_variance   | -0.00032    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.82e+03    |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0193     |\n",
      "|    value_loss           | 4.74e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.08e+03    |\n",
      "|    ep_rew_mean          | -1.5e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 733         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 6912        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006707292 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.762      |\n",
      "|    explained_variance   | 0.0103      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.86e+03    |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    value_loss           | 3.97e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.14e+03    |\n",
      "|    ep_rew_mean          | -312        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 730         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 9216        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006587112 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.746      |\n",
      "|    explained_variance   | 0.0387      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 922         |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    value_loss           | 2.18e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.17e+03    |\n",
      "|    ep_rew_mean          | 729         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 727         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 11520       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010580944 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.721      |\n",
      "|    explained_variance   | 0.0554      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.14e+03    |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    value_loss           | 2.27e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.1e+03     |\n",
      "|    ep_rew_mean          | 1.75e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 727         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 13824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008192955 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.687      |\n",
      "|    explained_variance   | 0.0627      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 807         |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    value_loss           | 2.26e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.94e+03    |\n",
      "|    ep_rew_mean          | 2.85e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 728         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 22          |\n",
      "|    total_timesteps      | 16128       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013143623 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.663      |\n",
      "|    explained_variance   | 0.0241      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 793         |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    value_loss           | 2.62e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.63e+03    |\n",
      "|    ep_rew_mean          | 3.17e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 728         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016777638 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.605      |\n",
      "|    explained_variance   | 0.00159     |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.13e+03    |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    value_loss           | 3.71e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.45e+03    |\n",
      "|    ep_rew_mean          | 3.39e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 729         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 20736       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010226631 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.557      |\n",
      "|    explained_variance   | 0.000392    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.46e+03    |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00953    |\n",
      "|    value_loss           | 3.95e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.32e+03     |\n",
      "|    ep_rew_mean          | 3.54e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 729          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 31           |\n",
      "|    total_timesteps      | 23040        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0084267305 |\n",
      "|    clip_fraction        | 0.13         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.532       |\n",
      "|    explained_variance   | 0.00555      |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.46e+03     |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00603     |\n",
      "|    value_loss           | 4.06e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.23e+03    |\n",
      "|    ep_rew_mean          | 3.76e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 730         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 25344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011307817 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.482      |\n",
      "|    explained_variance   | 0.00342     |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.41e+03    |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    value_loss           | 4.29e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.14e+03    |\n",
      "|    ep_rew_mean          | 3.93e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 731         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 27648       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009640843 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.417      |\n",
      "|    explained_variance   | 0.000622    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 2.09e+03    |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00965    |\n",
      "|    value_loss           | 5.71e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.06e+03     |\n",
      "|    ep_rew_mean          | 3.99e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 732          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 40           |\n",
      "|    total_timesteps      | 29952        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075519523 |\n",
      "|    clip_fraction        | 0.075        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.385       |\n",
      "|    explained_variance   | 1.74e-05     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.87e+03     |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00408     |\n",
      "|    value_loss           | 5.36e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 4.01e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 733          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 43           |\n",
      "|    total_timesteps      | 32256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068978057 |\n",
      "|    clip_fraction        | 0.0695       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.338       |\n",
      "|    explained_variance   | 1.2e-05      |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.16e+03     |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00376     |\n",
      "|    value_loss           | 5.54e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 973        |\n",
      "|    ep_rew_mean          | 4.08e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 733        |\n",
      "|    iterations           | 15         |\n",
      "|    time_elapsed         | 47         |\n",
      "|    total_timesteps      | 34560      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01472221 |\n",
      "|    clip_fraction        | 0.0648     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.306     |\n",
      "|    explained_variance   | 1.04e-05   |\n",
      "|    learning_rate        | 0.003      |\n",
      "|    loss                 | 1.68e+03   |\n",
      "|    n_updates            | 140        |\n",
      "|    policy_gradient_loss | 0.00118    |\n",
      "|    value_loss           | 4.93e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 939         |\n",
      "|    ep_rew_mean          | 4.17e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 732         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 50          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005160036 |\n",
      "|    clip_fraction        | 0.0551      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.323      |\n",
      "|    explained_variance   | 1.16e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.86e+03    |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -4.22e-05   |\n",
      "|    value_loss           | 5.01e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 902         |\n",
      "|    ep_rew_mean          | 4.15e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 732         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 53          |\n",
      "|    total_timesteps      | 39168       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013078639 |\n",
      "|    clip_fraction        | 0.0843      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.3        |\n",
      "|    explained_variance   | 8.11e-06    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.85e+03    |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00375    |\n",
      "|    value_loss           | 5.25e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 874       |\n",
      "|    ep_rew_mean          | 4.18e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 732       |\n",
      "|    iterations           | 18        |\n",
      "|    time_elapsed         | 56        |\n",
      "|    total_timesteps      | 41472     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0029783 |\n",
      "|    clip_fraction        | 0.0446    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.275    |\n",
      "|    explained_variance   | 4.53e-06  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 1.89e+03  |\n",
      "|    n_updates            | 170       |\n",
      "|    policy_gradient_loss | -0.00111  |\n",
      "|    value_loss           | 4.81e+03  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 851         |\n",
      "|    ep_rew_mean          | 4.22e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 732         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 59          |\n",
      "|    total_timesteps      | 43776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008494556 |\n",
      "|    clip_fraction        | 0.0432      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.28       |\n",
      "|    explained_variance   | -1.55e-06   |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.92e+03    |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00315    |\n",
      "|    value_loss           | 4.73e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 831         |\n",
      "|    ep_rew_mean          | 4.25e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 732         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 62          |\n",
      "|    total_timesteps      | 46080       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029445183 |\n",
      "|    clip_fraction        | 0.0884      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.254      |\n",
      "|    explained_variance   | 4.83e-06    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.9e+03     |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | 0.00121     |\n",
      "|    value_loss           | 4.7e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 820         |\n",
      "|    ep_rew_mean          | 4.32e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 732         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 66          |\n",
      "|    total_timesteps      | 48384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023169046 |\n",
      "|    clip_fraction        | 0.0934      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.214      |\n",
      "|    explained_variance   | 3.28e-06    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.69e+03    |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | 0.00127     |\n",
      "|    value_loss           | 4.46e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 811         |\n",
      "|    ep_rew_mean          | 4.36e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 733         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 50688       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008368257 |\n",
      "|    clip_fraction        | 0.055       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.199      |\n",
      "|    explained_variance   | 3.46e-06    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.34e+03    |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | 0.000933    |\n",
      "|    value_loss           | 4.1e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 800         |\n",
      "|    ep_rew_mean          | 4.41e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 733         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 72          |\n",
      "|    total_timesteps      | 52992       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015173271 |\n",
      "|    clip_fraction        | 0.0507      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.254      |\n",
      "|    explained_variance   | 4.17e-06    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.44e+03    |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | 0.00132     |\n",
      "|    value_loss           | 3.76e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 787         |\n",
      "|    ep_rew_mean          | 4.41e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 733         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 75          |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021063542 |\n",
      "|    clip_fraction        | 0.0606      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.243      |\n",
      "|    explained_variance   | 2.92e-06    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.28e+03    |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | 0.00336     |\n",
      "|    value_loss           | 4.08e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 775         |\n",
      "|    ep_rew_mean          | 4.41e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 733         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 78          |\n",
      "|    total_timesteps      | 57600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004652747 |\n",
      "|    clip_fraction        | 0.0352      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.236      |\n",
      "|    explained_variance   | 2.09e-06    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 2.15e+03    |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00149    |\n",
      "|    value_loss           | 3.97e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 771          |\n",
      "|    ep_rew_mean          | 4.44e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 733          |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 81           |\n",
      "|    total_timesteps      | 59904        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070349453 |\n",
      "|    clip_fraction        | 0.0594       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.225       |\n",
      "|    explained_variance   | 1.91e-06     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.85e+03     |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.00264     |\n",
      "|    value_loss           | 3.63e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 765         |\n",
      "|    ep_rew_mean          | 4.49e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 733         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 84          |\n",
      "|    total_timesteps      | 62208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016438056 |\n",
      "|    clip_fraction        | 0.0804      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.244      |\n",
      "|    explained_variance   | 2.68e-06    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.23e+03    |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | 0.00188     |\n",
      "|    value_loss           | 3.42e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 761        |\n",
      "|    ep_rew_mean          | 4.52e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 733        |\n",
      "|    iterations           | 28         |\n",
      "|    time_elapsed         | 87         |\n",
      "|    total_timesteps      | 64512      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01074139 |\n",
      "|    clip_fraction        | 0.0551     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.259     |\n",
      "|    explained_variance   | 1.97e-06   |\n",
      "|    learning_rate        | 0.003      |\n",
      "|    loss                 | 1.05e+03   |\n",
      "|    n_updates            | 270        |\n",
      "|    policy_gradient_loss | 0.000929   |\n",
      "|    value_loss           | 4.02e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 761         |\n",
      "|    ep_rew_mean          | 4.58e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 733         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 91          |\n",
      "|    total_timesteps      | 66816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014405668 |\n",
      "|    clip_fraction        | 0.0454      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.243      |\n",
      "|    explained_variance   | 2.03e-06    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 896         |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | 0.0047      |\n",
      "|    value_loss           | 3.37e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 755         |\n",
      "|    ep_rew_mean          | 4.58e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 733         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 94          |\n",
      "|    total_timesteps      | 69120       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034705173 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.225      |\n",
      "|    explained_variance   | 1.55e-06    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.52e+03    |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0043     |\n",
      "|    value_loss           | 3.17e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 726       |\n",
      "|    ep_rew_mean          | 3.88e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 733       |\n",
      "|    iterations           | 31        |\n",
      "|    time_elapsed         | 97        |\n",
      "|    total_timesteps      | 71424     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 2.2988102 |\n",
      "|    clip_fraction        | 0.242     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.22     |\n",
      "|    explained_variance   | 1.61e-06  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.56e+03  |\n",
      "|    n_updates            | 300       |\n",
      "|    policy_gradient_loss | 0.101     |\n",
      "|    value_loss           | 5.2e+03   |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 611         |\n",
      "|    ep_rew_mean          | 3.21e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 733         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 100         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011794241 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.3        |\n",
      "|    explained_variance   | 0.0452      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.11e+03    |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | 0.000661    |\n",
      "|    value_loss           | 4.69e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 562        |\n",
      "|    ep_rew_mean          | 2.49e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 733        |\n",
      "|    iterations           | 33         |\n",
      "|    time_elapsed         | 103        |\n",
      "|    total_timesteps      | 76032      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00521258 |\n",
      "|    clip_fraction        | 0.024      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.314     |\n",
      "|    explained_variance   | 0.0515     |\n",
      "|    learning_rate        | 0.003      |\n",
      "|    loss                 | 3.56e+03   |\n",
      "|    n_updates            | 320        |\n",
      "|    policy_gradient_loss | 0.0017     |\n",
      "|    value_loss           | 4.73e+04   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 527         |\n",
      "|    ep_rew_mean          | 1.7e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 733         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 106         |\n",
      "|    total_timesteps      | 78336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002216554 |\n",
      "|    clip_fraction        | 0.0124      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.271      |\n",
      "|    explained_variance   | 0.00935     |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 7.91e+03    |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.00108    |\n",
      "|    value_loss           | 3.88e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 501          |\n",
      "|    ep_rew_mean          | 935          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 734          |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 109          |\n",
      "|    total_timesteps      | 80640        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024180755 |\n",
      "|    clip_fraction        | 0.00691      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.254       |\n",
      "|    explained_variance   | 1.32e-05     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.63e+04     |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.000889    |\n",
      "|    value_loss           | 4.94e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 475          |\n",
      "|    ep_rew_mean          | 164          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 734          |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 112          |\n",
      "|    total_timesteps      | 82944        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033713565 |\n",
      "|    clip_fraction        | 0.0279       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.23        |\n",
      "|    explained_variance   | 4.17e-07     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.9e+04      |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.0019      |\n",
      "|    value_loss           | 4.89e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 452          |\n",
      "|    ep_rew_mean          | -589         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 734          |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 116          |\n",
      "|    total_timesteps      | 85248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033437894 |\n",
      "|    clip_fraction        | 0.0309       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.214       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.08e+04     |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.00323     |\n",
      "|    value_loss           | 4.84e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 429          |\n",
      "|    ep_rew_mean          | -1.36e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 734          |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 119          |\n",
      "|    total_timesteps      | 87552        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011945012 |\n",
      "|    clip_fraction        | 0.00977      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.223       |\n",
      "|    explained_variance   | -2.11e-05    |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.87e+04     |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.00172     |\n",
      "|    value_loss           | 4.34e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 402          |\n",
      "|    ep_rew_mean          | -2.1e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 734          |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 122          |\n",
      "|    total_timesteps      | 89856        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026721586 |\n",
      "|    clip_fraction        | 0.0198       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.236       |\n",
      "|    explained_variance   | 1.79e-07     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.04e+04     |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.0018      |\n",
      "|    value_loss           | 4.41e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 380          |\n",
      "|    ep_rew_mean          | -2.72e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 735          |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 125          |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037945434 |\n",
      "|    clip_fraction        | 0.0375       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.23        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.96e+04     |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.00507     |\n",
      "|    value_loss           | 3.63e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 357          |\n",
      "|    ep_rew_mean          | -3.38e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 735          |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 128          |\n",
      "|    total_timesteps      | 94464        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025310833 |\n",
      "|    clip_fraction        | 0.0376       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.229       |\n",
      "|    explained_variance   | 7.75e-07     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.33e+04     |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | -0.00458     |\n",
      "|    value_loss           | 2.99e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 332          |\n",
      "|    ep_rew_mean          | -3.99e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 735          |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 131          |\n",
      "|    total_timesteps      | 96768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027302704 |\n",
      "|    clip_fraction        | 0.0402       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.231       |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.16e+04     |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.00427     |\n",
      "|    value_loss           | 2.9e+04      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 302         |\n",
      "|    ep_rew_mean          | -4.67e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 735         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 134         |\n",
      "|    total_timesteps      | 99072       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011107752 |\n",
      "|    clip_fraction        | 0.0577      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.223      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.49e+04    |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.00201    |\n",
      "|    value_loss           | 2.42e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 295         |\n",
      "|    ep_rew_mean          | -4.57e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 735         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 137         |\n",
      "|    total_timesteps      | 101376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025263047 |\n",
      "|    clip_fraction        | 0.073       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.189      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.54e+04    |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.00438    |\n",
      "|    value_loss           | 2.91e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 292         |\n",
      "|    ep_rew_mean          | -4.46e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 735         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 140         |\n",
      "|    total_timesteps      | 103680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024517018 |\n",
      "|    clip_fraction        | 0.0238      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0394     |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.63e+04    |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | 0.00102     |\n",
      "|    value_loss           | 4.19e+04    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 289           |\n",
      "|    ep_rew_mean          | -4.36e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 735           |\n",
      "|    iterations           | 46            |\n",
      "|    time_elapsed         | 144           |\n",
      "|    total_timesteps      | 105984        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.1235082e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0406       |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.84e+04      |\n",
      "|    n_updates            | 450           |\n",
      "|    policy_gradient_loss | 1.28e-05      |\n",
      "|    value_loss           | 4.06e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 287           |\n",
      "|    ep_rew_mean          | -4.29e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 736           |\n",
      "|    iterations           | 47            |\n",
      "|    time_elapsed         | 147           |\n",
      "|    total_timesteps      | 108288        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017109292 |\n",
      "|    clip_fraction        | 0.00406       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0416       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 2.03e+04      |\n",
      "|    n_updates            | 460           |\n",
      "|    policy_gradient_loss | -0.000307     |\n",
      "|    value_loss           | 4.18e+04      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 284          |\n",
      "|    ep_rew_mean          | -4.22e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 736          |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 150          |\n",
      "|    total_timesteps      | 110592       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.847337e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0426      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.34e+04     |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -5.56e-05    |\n",
      "|    value_loss           | 4.23e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 281          |\n",
      "|    ep_rew_mean          | -4.17e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 736          |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 153          |\n",
      "|    total_timesteps      | 112896       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.874284e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0402      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.24e+04     |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -2.01e-05    |\n",
      "|    value_loss           | 4.25e+04     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 279           |\n",
      "|    ep_rew_mean          | -4.12e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 736           |\n",
      "|    iterations           | 50            |\n",
      "|    time_elapsed         | 156           |\n",
      "|    total_timesteps      | 115200        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00031026854 |\n",
      "|    clip_fraction        | 0.00422       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0402       |\n",
      "|    explained_variance   | 2.38e-07      |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.86e+04      |\n",
      "|    n_updates            | 490           |\n",
      "|    policy_gradient_loss | -0.000296     |\n",
      "|    value_loss           | 4.06e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 276           |\n",
      "|    ep_rew_mean          | -4.14e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 736           |\n",
      "|    iterations           | 51            |\n",
      "|    time_elapsed         | 159           |\n",
      "|    total_timesteps      | 117504        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011554562 |\n",
      "|    clip_fraction        | 0.00187       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0411       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 1.96e+04      |\n",
      "|    n_updates            | 500           |\n",
      "|    policy_gradient_loss | -0.000108     |\n",
      "|    value_loss           | 4.3e+04       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 273           |\n",
      "|    ep_rew_mean          | -4.2e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 736           |\n",
      "|    iterations           | 52            |\n",
      "|    time_elapsed         | 162           |\n",
      "|    total_timesteps      | 119808        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00045754263 |\n",
      "|    clip_fraction        | 0.00891       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0362       |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 2.2e+04       |\n",
      "|    n_updates            | 510           |\n",
      "|    policy_gradient_loss | -0.000549     |\n",
      "|    value_loss           | 4.37e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 270           |\n",
      "|    ep_rew_mean          | -4.23e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 736           |\n",
      "|    iterations           | 53            |\n",
      "|    time_elapsed         | 165           |\n",
      "|    total_timesteps      | 122112        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1083275e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0355       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 2.01e+04      |\n",
      "|    n_updates            | 520           |\n",
      "|    policy_gradient_loss | 7.05e-06      |\n",
      "|    value_loss           | 4.48e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 266           |\n",
      "|    ep_rew_mean          | -4.35e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 736           |\n",
      "|    iterations           | 54            |\n",
      "|    time_elapsed         | 168           |\n",
      "|    total_timesteps      | 124416        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020851269 |\n",
      "|    clip_fraction        | 0.00348       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0338       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 2.29e+04      |\n",
      "|    n_updates            | 530           |\n",
      "|    policy_gradient_loss | -0.000177     |\n",
      "|    value_loss           | 4.2e+04       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 264          |\n",
      "|    ep_rew_mean          | -4.41e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 736          |\n",
      "|    iterations           | 55           |\n",
      "|    time_elapsed         | 171          |\n",
      "|    total_timesteps      | 126720       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.517487e-05 |\n",
      "|    clip_fraction        | 0.00355      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.036       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.5e+04      |\n",
      "|    n_updates            | 540          |\n",
      "|    policy_gradient_loss | -0.000311    |\n",
      "|    value_loss           | 4.55e+04     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 264           |\n",
      "|    ep_rew_mean          | -4.41e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 736           |\n",
      "|    iterations           | 56            |\n",
      "|    time_elapsed         | 175           |\n",
      "|    total_timesteps      | 129024        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013168625 |\n",
      "|    clip_fraction        | 0.00043       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0326       |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 2.52e+04      |\n",
      "|    n_updates            | 550           |\n",
      "|    policy_gradient_loss | -0.000122     |\n",
      "|    value_loss           | 4.67e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 264           |\n",
      "|    ep_rew_mean          | -4.41e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 737           |\n",
      "|    iterations           | 57            |\n",
      "|    time_elapsed         | 178           |\n",
      "|    total_timesteps      | 131328        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.1570616e-05 |\n",
      "|    clip_fraction        | 0.00117       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0335       |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 2.03e+04      |\n",
      "|    n_updates            | 560           |\n",
      "|    policy_gradient_loss | -0.00021      |\n",
      "|    value_loss           | 4.38e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 264           |\n",
      "|    ep_rew_mean          | -4.41e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 737           |\n",
      "|    iterations           | 58            |\n",
      "|    time_elapsed         | 181           |\n",
      "|    total_timesteps      | 133632        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014108086 |\n",
      "|    clip_fraction        | 0.00109       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0331       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 2.04e+04      |\n",
      "|    n_updates            | 570           |\n",
      "|    policy_gradient_loss | -0.000207     |\n",
      "|    value_loss           | 4.74e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 264           |\n",
      "|    ep_rew_mean          | -4.41e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 737           |\n",
      "|    iterations           | 59            |\n",
      "|    time_elapsed         | 184           |\n",
      "|    total_timesteps      | 135936        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00022659707 |\n",
      "|    clip_fraction        | 0.000781      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.03         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 2.73e+04      |\n",
      "|    n_updates            | 580           |\n",
      "|    policy_gradient_loss | -0.000123     |\n",
      "|    value_loss           | 4.78e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 264           |\n",
      "|    ep_rew_mean          | -4.41e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 737           |\n",
      "|    iterations           | 60            |\n",
      "|    time_elapsed         | 187           |\n",
      "|    total_timesteps      | 138240        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014787388 |\n",
      "|    clip_fraction        | 0.00375       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0317       |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 2.6e+04       |\n",
      "|    n_updates            | 590           |\n",
      "|    policy_gradient_loss | -0.000236     |\n",
      "|    value_loss           | 4.96e+04      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 264          |\n",
      "|    ep_rew_mean          | -4.41e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 737          |\n",
      "|    iterations           | 61           |\n",
      "|    time_elapsed         | 190          |\n",
      "|    total_timesteps      | 140544       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.091569e-05 |\n",
      "|    clip_fraction        | 0.00121      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0343      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.67e+04     |\n",
      "|    n_updates            | 600          |\n",
      "|    policy_gradient_loss | -0.00012     |\n",
      "|    value_loss           | 4.56e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 264          |\n",
      "|    ep_rew_mean          | -4.4e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 737          |\n",
      "|    iterations           | 62           |\n",
      "|    time_elapsed         | 193          |\n",
      "|    total_timesteps      | 142848       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.113671e-05 |\n",
      "|    clip_fraction        | 0.00277      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0437      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.56e+04     |\n",
      "|    n_updates            | 610          |\n",
      "|    policy_gradient_loss | 0.000311     |\n",
      "|    value_loss           | 5.06e+04     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 264           |\n",
      "|    ep_rew_mean          | -4.4e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 737           |\n",
      "|    iterations           | 63            |\n",
      "|    time_elapsed         | 196           |\n",
      "|    total_timesteps      | 145152        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5270009e-05 |\n",
      "|    clip_fraction        | 0.00313       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0324       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 2.66e+04      |\n",
      "|    n_updates            | 620           |\n",
      "|    policy_gradient_loss | -5.73e-05     |\n",
      "|    value_loss           | 5.21e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 264           |\n",
      "|    ep_rew_mean          | -4.4e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 737           |\n",
      "|    iterations           | 64            |\n",
      "|    time_elapsed         | 199           |\n",
      "|    total_timesteps      | 147456        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011211498 |\n",
      "|    clip_fraction        | 0.00187       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0389       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 2.25e+04      |\n",
      "|    n_updates            | 630           |\n",
      "|    policy_gradient_loss | -1.57e-05     |\n",
      "|    value_loss           | 5.27e+04      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 264          |\n",
      "|    ep_rew_mean          | -4.4e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 737          |\n",
      "|    iterations           | 65           |\n",
      "|    time_elapsed         | 203          |\n",
      "|    total_timesteps      | 149760       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.964285e-06 |\n",
      "|    clip_fraction        | 0.00207      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0436      |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.19e+04     |\n",
      "|    n_updates            | 640          |\n",
      "|    policy_gradient_loss | 2.53e-05     |\n",
      "|    value_loss           | 4.93e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 264          |\n",
      "|    ep_rew_mean          | -4.4e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 737          |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 206          |\n",
      "|    total_timesteps      | 152064       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012522836 |\n",
      "|    clip_fraction        | 0.00937      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.037       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.4e+04      |\n",
      "|    n_updates            | 650          |\n",
      "|    policy_gradient_loss | -0.000612    |\n",
      "|    value_loss           | 5.61e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 264         |\n",
      "|    ep_rew_mean          | -4.4e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 737         |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 209         |\n",
      "|    total_timesteps      | 154368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032122493 |\n",
      "|    clip_fraction        | 0.0116      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0351     |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 2.06e+04    |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | 0.00188     |\n",
      "|    value_loss           | 5.6e+04     |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 264           |\n",
      "|    ep_rew_mean          | -4.4e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 738           |\n",
      "|    iterations           | 68            |\n",
      "|    time_elapsed         | 212           |\n",
      "|    total_timesteps      | 156672        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.6811833e-10 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00212      |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 3.25e+04      |\n",
      "|    n_updates            | 670           |\n",
      "|    policy_gradient_loss | 8.55e-06      |\n",
      "|    value_loss           | 5.23e+04      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 264          |\n",
      "|    ep_rew_mean          | -4.39e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 738          |\n",
      "|    iterations           | 69           |\n",
      "|    time_elapsed         | 215          |\n",
      "|    total_timesteps      | 158976       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.687054e-05 |\n",
      "|    clip_fraction        | 0.000234     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.00191     |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.74e+04     |\n",
      "|    n_updates            | 680          |\n",
      "|    policy_gradient_loss | -1.46e-05    |\n",
      "|    value_loss           | 5.8e+04      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 264           |\n",
      "|    ep_rew_mean          | -4.39e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 738           |\n",
      "|    iterations           | 70            |\n",
      "|    time_elapsed         | 218           |\n",
      "|    total_timesteps      | 161280        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0056309e-05 |\n",
      "|    clip_fraction        | 0.000273      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00207      |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 2.89e+04      |\n",
      "|    n_updates            | 690           |\n",
      "|    policy_gradient_loss | -2.29e-05     |\n",
      "|    value_loss           | 5.87e+04      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 264         |\n",
      "|    ep_rew_mean          | -4.39e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 738         |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 221         |\n",
      "|    total_timesteps      | 163584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010151665 |\n",
      "|    clip_fraction        | 0.000703    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0052     |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 3.67e+04    |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | 0.00104     |\n",
      "|    value_loss           | 5.85e+04    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 264           |\n",
      "|    ep_rew_mean          | -4.39e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 738           |\n",
      "|    iterations           | 72            |\n",
      "|    time_elapsed         | 224           |\n",
      "|    total_timesteps      | 165888        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.1632586e-05 |\n",
      "|    clip_fraction        | 0.000703      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0163       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 3.26e+04      |\n",
      "|    n_updates            | 710           |\n",
      "|    policy_gradient_loss | 2.92e-06      |\n",
      "|    value_loss           | 5.4e+04       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 264          |\n",
      "|    ep_rew_mean          | -4.39e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 738          |\n",
      "|    iterations           | 73           |\n",
      "|    time_elapsed         | 227          |\n",
      "|    total_timesteps      | 168192       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0132177025 |\n",
      "|    clip_fraction        | 0.00309      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.00256     |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.62e+04     |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | -0.000132    |\n",
      "|    value_loss           | 6.03e+04     |\n",
      "------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 264            |\n",
      "|    ep_rew_mean          | -4.38e+03      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 738            |\n",
      "|    iterations           | 74             |\n",
      "|    time_elapsed         | 230            |\n",
      "|    total_timesteps      | 170496         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -1.5286901e-10 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000299      |\n",
      "|    explained_variance   | -1.19e-07      |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 2.5e+04        |\n",
      "|    n_updates            | 730            |\n",
      "|    policy_gradient_loss | -3.23e-09      |\n",
      "|    value_loss           | 6.04e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 264            |\n",
      "|    ep_rew_mean          | -4.38e+03      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 738            |\n",
      "|    iterations           | 75             |\n",
      "|    time_elapsed         | 233            |\n",
      "|    total_timesteps      | 172800         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -2.8259706e-10 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000324      |\n",
      "|    explained_variance   | -1.19e-07      |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 3.13e+04       |\n",
      "|    n_updates            | 740            |\n",
      "|    policy_gradient_loss | -2.33e-08      |\n",
      "|    value_loss           | 6.01e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 264            |\n",
      "|    ep_rew_mean          | -4.38e+03      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 738            |\n",
      "|    iterations           | 76             |\n",
      "|    time_elapsed         | 237            |\n",
      "|    total_timesteps      | 175104         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -2.0282868e-10 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000334      |\n",
      "|    explained_variance   | -1.19e-07      |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 3.84e+04       |\n",
      "|    n_updates            | 750            |\n",
      "|    policy_gradient_loss | -8.64e-09      |\n",
      "|    value_loss           | 5.57e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 264            |\n",
      "|    ep_rew_mean          | -4.37e+03      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 738            |\n",
      "|    iterations           | 77             |\n",
      "|    time_elapsed         | 240            |\n",
      "|    total_timesteps      | 177408         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -2.2945415e-10 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000349      |\n",
      "|    explained_variance   | 1.19e-07       |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 2.71e+04       |\n",
      "|    n_updates            | 760            |\n",
      "|    policy_gradient_loss | -1.67e-08      |\n",
      "|    value_loss           | 6.15e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 264            |\n",
      "|    ep_rew_mean          | -4.37e+03      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 738            |\n",
      "|    iterations           | 78             |\n",
      "|    time_elapsed         | 243            |\n",
      "|    total_timesteps      | 179712         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -2.1064465e-10 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000359      |\n",
      "|    explained_variance   | -1.19e-07      |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 2.94e+04       |\n",
      "|    n_updates            | 770            |\n",
      "|    policy_gradient_loss | -8.07e-09      |\n",
      "|    value_loss           | 6.06e+04       |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 264           |\n",
      "|    ep_rew_mean          | -4.37e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 738           |\n",
      "|    iterations           | 79            |\n",
      "|    time_elapsed         | 246           |\n",
      "|    total_timesteps      | 182016        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -3.068635e-10 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.000377     |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 2.67e+04      |\n",
      "|    n_updates            | 780           |\n",
      "|    policy_gradient_loss | -1.59e-08     |\n",
      "|    value_loss           | 5.48e+04      |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 264            |\n",
      "|    ep_rew_mean          | -4.38e+03      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 738            |\n",
      "|    iterations           | 80             |\n",
      "|    time_elapsed         | 249            |\n",
      "|    total_timesteps      | 184320         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -3.8297115e-10 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.00039       |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 3.12e+04       |\n",
      "|    n_updates            | 790            |\n",
      "|    policy_gradient_loss | -2.16e-08      |\n",
      "|    value_loss           | 6.13e+04       |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 264           |\n",
      "|    ep_rew_mean          | -4.38e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 738           |\n",
      "|    iterations           | 81            |\n",
      "|    time_elapsed         | 252           |\n",
      "|    total_timesteps      | 186624        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -4.894559e-10 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.000413     |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 2.27e+04      |\n",
      "|    n_updates            | 800           |\n",
      "|    policy_gradient_loss | -3.01e-08     |\n",
      "|    value_loss           | 6.09e+04      |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 264            |\n",
      "|    ep_rew_mean          | -4.38e+03      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 738            |\n",
      "|    iterations           | 82             |\n",
      "|    time_elapsed         | 255            |\n",
      "|    total_timesteps      | 188928         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -6.4988515e-10 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000436      |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 2.2e+04        |\n",
      "|    n_updates            | 810            |\n",
      "|    policy_gradient_loss | -3.16e-08      |\n",
      "|    value_loss           | 6.18e+04       |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 264           |\n",
      "|    ep_rew_mean          | -4.38e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 738           |\n",
      "|    iterations           | 83            |\n",
      "|    time_elapsed         | 258           |\n",
      "|    total_timesteps      | 191232        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -5.163258e-10 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.000457     |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 4.01e+04      |\n",
      "|    n_updates            | 820           |\n",
      "|    policy_gradient_loss | -1.5e-08      |\n",
      "|    value_loss           | 5.51e+04      |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 264            |\n",
      "|    ep_rew_mean          | -4.38e+03      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 738            |\n",
      "|    iterations           | 84             |\n",
      "|    time_elapsed         | 262            |\n",
      "|    total_timesteps      | 193536         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -1.9720232e-09 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000501      |\n",
      "|    explained_variance   | 5.96e-08       |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 2.86e+04       |\n",
      "|    n_updates            | 830            |\n",
      "|    policy_gradient_loss | -7.35e-08      |\n",
      "|    value_loss           | 6.19e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 264            |\n",
      "|    ep_rew_mean          | -4.38e+03      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 738            |\n",
      "|    iterations           | 85             |\n",
      "|    time_elapsed         | 265            |\n",
      "|    total_timesteps      | 195840         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -2.9615421e-09 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000618      |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 2.78e+04       |\n",
      "|    n_updates            | 840            |\n",
      "|    policy_gradient_loss | -1.05e-07      |\n",
      "|    value_loss           | 6.15e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 264            |\n",
      "|    ep_rew_mean          | -4.38e+03      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 738            |\n",
      "|    iterations           | 86             |\n",
      "|    time_elapsed         | 268            |\n",
      "|    total_timesteps      | 198144         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -3.5640142e-09 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000737      |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 3.33e+04       |\n",
      "|    n_updates            | 850            |\n",
      "|    policy_gradient_loss | -7.6e-08       |\n",
      "|    value_loss           | 6.19e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 264            |\n",
      "|    ep_rew_mean          | -4.38e+03      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 738            |\n",
      "|    iterations           | 87             |\n",
      "|    time_elapsed         | 271            |\n",
      "|    total_timesteps      | 200448         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -4.0618375e-09 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000894      |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 2.75e+04       |\n",
      "|    n_updates            | 860            |\n",
      "|    policy_gradient_loss | -9.32e-08      |\n",
      "|    value_loss           | 5.53e+04       |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 264           |\n",
      "|    ep_rew_mean          | -4.38e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 738           |\n",
      "|    iterations           | 88            |\n",
      "|    time_elapsed         | 274           |\n",
      "|    total_timesteps      | 202752        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.1503646e-09 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.000865     |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 4.5e+04       |\n",
      "|    n_updates            | 870           |\n",
      "|    policy_gradient_loss | 1.98e-07      |\n",
      "|    value_loss           | 6.2e+04       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 264           |\n",
      "|    ep_rew_mean          | -4.38e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 738           |\n",
      "|    iterations           | 89            |\n",
      "|    time_elapsed         | 277           |\n",
      "|    total_timesteps      | 205056        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7941024e-05 |\n",
      "|    clip_fraction        | 0.000313      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00108      |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 3.98e+04      |\n",
      "|    n_updates            | 880           |\n",
      "|    policy_gradient_loss | -2.31e-06     |\n",
      "|    value_loss           | 6.21e+04      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 264          |\n",
      "|    ep_rew_mean          | -4.38e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 738          |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 280          |\n",
      "|    total_timesteps      | 207360       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.804056e-09 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.00147     |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.81e+04     |\n",
      "|    n_updates            | 890          |\n",
      "|    policy_gradient_loss | -2.53e-07    |\n",
      "|    value_loss           | 5.57e+04     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 264           |\n",
      "|    ep_rew_mean          | -4.38e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 738           |\n",
      "|    iterations           | 91            |\n",
      "|    time_elapsed         | 283           |\n",
      "|    total_timesteps      | 209664        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012742725 |\n",
      "|    clip_fraction        | 0.000352      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.000943     |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 2.14e+04      |\n",
      "|    n_updates            | 900           |\n",
      "|    policy_gradient_loss | -2.64e-05     |\n",
      "|    value_loss           | 6.12e+04      |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 264            |\n",
      "|    ep_rew_mean          | -4.38e+03      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 738            |\n",
      "|    iterations           | 92             |\n",
      "|    time_elapsed         | 286            |\n",
      "|    total_timesteps      | 211968         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -3.3793413e-09 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000806      |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 4.17e+04       |\n",
      "|    n_updates            | 910            |\n",
      "|    policy_gradient_loss | -1.1e-07       |\n",
      "|    value_loss           | 6.16e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 264            |\n",
      "|    ep_rew_mean          | -4.38e+03      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 738            |\n",
      "|    iterations           | 93             |\n",
      "|    time_elapsed         | 290            |\n",
      "|    total_timesteps      | 214272         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -1.1102429e-09 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.00093       |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 2.18e+04       |\n",
      "|    n_updates            | 920            |\n",
      "|    policy_gradient_loss | -1.91e-07      |\n",
      "|    value_loss           | 6.13e+04       |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 264           |\n",
      "|    ep_rew_mean          | -4.38e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 738           |\n",
      "|    iterations           | 94            |\n",
      "|    time_elapsed         | 293           |\n",
      "|    total_timesteps      | 216576        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0897299e-05 |\n",
      "|    clip_fraction        | 0.000273      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.000842     |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 4.13e+04      |\n",
      "|    n_updates            | 930           |\n",
      "|    policy_gradient_loss | -1.65e-05     |\n",
      "|    value_loss           | 5.59e+04      |\n",
      "-------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 264        |\n",
      "|    ep_rew_mean          | -4.4e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 738        |\n",
      "|    iterations           | 95         |\n",
      "|    time_elapsed         | 296        |\n",
      "|    total_timesteps      | 218880     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10530285 |\n",
      "|    clip_fraction        | 0.00305    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0228    |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.003      |\n",
      "|    loss                 | 2.27e+04   |\n",
      "|    n_updates            | 940        |\n",
      "|    policy_gradient_loss | -0.000218  |\n",
      "|    value_loss           | 6.19e+04   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 264       |\n",
      "|    ep_rew_mean          | -4.4e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 738       |\n",
      "|    iterations           | 96        |\n",
      "|    time_elapsed         | 299       |\n",
      "|    total_timesteps      | 221184    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4813505 |\n",
      "|    clip_fraction        | 0.234     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.0149   |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.07e+04  |\n",
      "|    n_updates            | 950       |\n",
      "|    policy_gradient_loss | 0.00787   |\n",
      "|    value_loss           | 6.4e+04   |\n",
      "---------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 264            |\n",
      "|    ep_rew_mean          | -4.4e+03       |\n",
      "| time/                   |                |\n",
      "|    fps                  | 738            |\n",
      "|    iterations           | 97             |\n",
      "|    time_elapsed         | 302            |\n",
      "|    total_timesteps      | 223488         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -1.1723955e-13 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000127      |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 1.99e+04       |\n",
      "|    n_updates            | 960            |\n",
      "|    policy_gradient_loss | -4.33e-10      |\n",
      "|    value_loss           | 6.34e+04       |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 264           |\n",
      "|    ep_rew_mean          | -4.4e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 738           |\n",
      "|    iterations           | 98            |\n",
      "|    time_elapsed         | 305           |\n",
      "|    total_timesteps      | 225792        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -4.260414e-12 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.000125     |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 2.31e+04      |\n",
      "|    n_updates            | 970           |\n",
      "|    policy_gradient_loss | -1.7e-08      |\n",
      "|    value_loss           | 5.61e+04      |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 264            |\n",
      "|    ep_rew_mean          | -4.4e+03       |\n",
      "| time/                   |                |\n",
      "|    fps                  | 738            |\n",
      "|    iterations           | 99             |\n",
      "|    time_elapsed         | 308            |\n",
      "|    total_timesteps      | 228096         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -1.0750512e-12 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000125      |\n",
      "|    explained_variance   | 1.19e-07       |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 3.08e+04       |\n",
      "|    n_updates            | 980            |\n",
      "|    policy_gradient_loss | -1.04e-09      |\n",
      "|    value_loss           | 6.27e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 264            |\n",
      "|    ep_rew_mean          | -4.4e+03       |\n",
      "| time/                   |                |\n",
      "|    fps                  | 738            |\n",
      "|    iterations           | 100            |\n",
      "|    time_elapsed         | 311            |\n",
      "|    total_timesteps      | 230400         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -3.9108274e-12 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000125      |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 2.84e+04       |\n",
      "|    n_updates            | 990            |\n",
      "|    policy_gradient_loss | -2.16e-08      |\n",
      "|    value_loss           | 6.14e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 264            |\n",
      "|    ep_rew_mean          | -4.4e+03       |\n",
      "| time/                   |                |\n",
      "|    fps                  | 738            |\n",
      "|    iterations           | 101            |\n",
      "|    time_elapsed         | 314            |\n",
      "|    total_timesteps      | 232704         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -5.1038284e-12 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000125      |\n",
      "|    explained_variance   | -1.19e-07      |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 3.17e+04       |\n",
      "|    n_updates            | 1000           |\n",
      "|    policy_gradient_loss | -3.4e-08       |\n",
      "|    value_loss           | 5.6e+04        |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 264            |\n",
      "|    ep_rew_mean          | -4.4e+03       |\n",
      "| time/                   |                |\n",
      "|    fps                  | 739            |\n",
      "|    iterations           | 102            |\n",
      "|    time_elapsed         | 317            |\n",
      "|    total_timesteps      | 235008         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -1.0295764e-12 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000125      |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 2.87e+04       |\n",
      "|    n_updates            | 1010           |\n",
      "|    policy_gradient_loss | -5.59e-11      |\n",
      "|    value_loss           | 6.25e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 264            |\n",
      "|    ep_rew_mean          | -4.4e+03       |\n",
      "| time/                   |                |\n",
      "|    fps                  | 739            |\n",
      "|    iterations           | 103            |\n",
      "|    time_elapsed         | 321            |\n",
      "|    total_timesteps      | 237312         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -7.5743855e-13 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000125      |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 4.38e+04       |\n",
      "|    n_updates            | 1020           |\n",
      "|    policy_gradient_loss | -1.47e-08      |\n",
      "|    value_loss           | 6.2e+04        |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 264            |\n",
      "|    ep_rew_mean          | -4.4e+03       |\n",
      "| time/                   |                |\n",
      "|    fps                  | 739            |\n",
      "|    iterations           | 104            |\n",
      "|    time_elapsed         | 324            |\n",
      "|    total_timesteps      | 239616         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -2.6034285e-12 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000125      |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 2.37e+04       |\n",
      "|    n_updates            | 1030           |\n",
      "|    policy_gradient_loss | -1.29e-09      |\n",
      "|    value_loss           | 6.25e+04       |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 264           |\n",
      "|    ep_rew_mean          | -4.4e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 739           |\n",
      "|    iterations           | 105           |\n",
      "|    time_elapsed         | 327           |\n",
      "|    total_timesteps      | 241920        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -7.716494e-12 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.000125     |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 2.62e+04      |\n",
      "|    n_updates            | 1040          |\n",
      "|    policy_gradient_loss | -2.3e-08      |\n",
      "|    value_loss           | 5.54e+04      |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 264            |\n",
      "|    ep_rew_mean          | -4.39e+03      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 739            |\n",
      "|    iterations           | 106            |\n",
      "|    time_elapsed         | 330            |\n",
      "|    total_timesteps      | 244224         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -2.4030556e-12 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000125      |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 2.06e+04       |\n",
      "|    n_updates            | 1050           |\n",
      "|    policy_gradient_loss | -2.26e-09      |\n",
      "|    value_loss           | 6.17e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 264            |\n",
      "|    ep_rew_mean          | -4.38e+03      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 739            |\n",
      "|    iterations           | 107            |\n",
      "|    time_elapsed         | 333            |\n",
      "|    total_timesteps      | 246528         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -2.0591528e-12 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000124      |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 2.78e+04       |\n",
      "|    n_updates            | 1060           |\n",
      "|    policy_gradient_loss | 3.91e-10       |\n",
      "|    value_loss           | 6.2e+04        |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 264            |\n",
      "|    ep_rew_mean          | -4.38e+03      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 739            |\n",
      "|    iterations           | 108            |\n",
      "|    time_elapsed         | 336            |\n",
      "|    total_timesteps      | 248832         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -2.8556712e-12 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000125      |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 2.32e+04       |\n",
      "|    n_updates            | 1070           |\n",
      "|    policy_gradient_loss | -8.29e-10      |\n",
      "|    value_loss           | 6.1e+04        |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 264            |\n",
      "|    ep_rew_mean          | -4.38e+03      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 739            |\n",
      "|    iterations           | 109            |\n",
      "|    time_elapsed         | 339            |\n",
      "|    total_timesteps      | 251136         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -2.3483437e-12 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000125      |\n",
      "|    explained_variance   | 1.19e-07       |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 2.64e+04       |\n",
      "|    n_updates            | 1080           |\n",
      "|    policy_gradient_loss | -1.08e-09      |\n",
      "|    value_loss           | 5.57e+04       |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 264           |\n",
      "|    ep_rew_mean          | -4.38e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 739           |\n",
      "|    iterations           | 110           |\n",
      "|    time_elapsed         | 342           |\n",
      "|    total_timesteps      | 253440        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -7.149481e-12 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.000126     |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 2.86e+04      |\n",
      "|    n_updates            | 1090          |\n",
      "|    policy_gradient_loss | -6.63e-09     |\n",
      "|    value_loss           | 6.22e+04      |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 264            |\n",
      "|    ep_rew_mean          | -4.38e+03      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 739            |\n",
      "|    iterations           | 111            |\n",
      "|    time_elapsed         | 346            |\n",
      "|    total_timesteps      | 255744         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -4.4330763e-12 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000127      |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 3.27e+04       |\n",
      "|    n_updates            | 1100           |\n",
      "|    policy_gradient_loss | -1.14e-08      |\n",
      "|    value_loss           | 6.22e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 264            |\n",
      "|    ep_rew_mean          | -4.38e+03      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 739            |\n",
      "|    iterations           | 112            |\n",
      "|    time_elapsed         | 349            |\n",
      "|    total_timesteps      | 258048         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -1.3846346e-11 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000129      |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 2.85e+04       |\n",
      "|    n_updates            | 1110           |\n",
      "|    policy_gradient_loss | -2.52e-08      |\n",
      "|    value_loss           | 5.6e+04        |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 264            |\n",
      "|    ep_rew_mean          | -4.38e+03      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 739            |\n",
      "|    iterations           | 113            |\n",
      "|    time_elapsed         | 352            |\n",
      "|    total_timesteps      | 260352         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -2.9437785e-12 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.00013       |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 3.49e+04       |\n",
      "|    n_updates            | 1120           |\n",
      "|    policy_gradient_loss | -2.06e-09      |\n",
      "|    value_loss           | 6.25e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 264            |\n",
      "|    ep_rew_mean          | -4.38e+03      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 739            |\n",
      "|    iterations           | 114            |\n",
      "|    time_elapsed         | 355            |\n",
      "|    total_timesteps      | 262656         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -4.2589933e-12 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.00013       |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 3.23e+04       |\n",
      "|    n_updates            | 1130           |\n",
      "|    policy_gradient_loss | -9.45e-10      |\n",
      "|    value_loss           | 6.18e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 264            |\n",
      "|    ep_rew_mean          | -4.38e+03      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 739            |\n",
      "|    iterations           | 115            |\n",
      "|    time_elapsed         | 358            |\n",
      "|    total_timesteps      | 264960         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -2.9451996e-12 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000131      |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 2.24e+04       |\n",
      "|    n_updates            | 1140           |\n",
      "|    policy_gradient_loss | -3.18e-09      |\n",
      "|    value_loss           | 6.15e+04       |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 264           |\n",
      "|    ep_rew_mean          | -4.38e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 739           |\n",
      "|    iterations           | 116           |\n",
      "|    time_elapsed         | 361           |\n",
      "|    total_timesteps      | 267264        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -4.439471e-12 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.000132     |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 2.09e+04      |\n",
      "|    n_updates            | 1150          |\n",
      "|    policy_gradient_loss | -1.83e-09     |\n",
      "|    value_loss           | 5.53e+04      |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 264            |\n",
      "|    ep_rew_mean          | -4.38e+03      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 739            |\n",
      "|    iterations           | 117            |\n",
      "|    time_elapsed         | 364            |\n",
      "|    total_timesteps      | 269568         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -1.2209256e-11 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000133      |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 2.37e+04       |\n",
      "|    n_updates            | 1160           |\n",
      "|    policy_gradient_loss | -1.3e-10       |\n",
      "|    value_loss           | 6.18e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 264            |\n",
      "|    ep_rew_mean          | -4.38e+03      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 739            |\n",
      "|    iterations           | 118            |\n",
      "|    time_elapsed         | 367            |\n",
      "|    total_timesteps      | 271872         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -8.6004094e-12 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000136      |\n",
      "|    explained_variance   | -1.19e-07      |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 2.67e+04       |\n",
      "|    n_updates            | 1170           |\n",
      "|    policy_gradient_loss | -1.73e-09      |\n",
      "|    value_loss           | 6.18e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 264            |\n",
      "|    ep_rew_mean          | -4.38e+03      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 739            |\n",
      "|    iterations           | 119            |\n",
      "|    time_elapsed         | 370            |\n",
      "|    total_timesteps      | 274176         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -1.3291412e-11 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000139      |\n",
      "|    explained_variance   | 1.19e-07       |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 2.43e+04       |\n",
      "|    n_updates            | 1180           |\n",
      "|    policy_gradient_loss | -1.41e-08      |\n",
      "|    value_loss           | 6.16e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 264            |\n",
      "|    ep_rew_mean          | -4.38e+03      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 739            |\n",
      "|    iterations           | 120            |\n",
      "|    time_elapsed         | 374            |\n",
      "|    total_timesteps      | 276480         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -1.2040857e-11 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000141      |\n",
      "|    explained_variance   | -1.19e-07      |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 2.37e+04       |\n",
      "|    n_updates            | 1190           |\n",
      "|    policy_gradient_loss | -4.33e-09      |\n",
      "|    value_loss           | 5.61e+04       |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 264           |\n",
      "|    ep_rew_mean          | -4.38e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 739           |\n",
      "|    iterations           | 121           |\n",
      "|    time_elapsed         | 377           |\n",
      "|    total_timesteps      | 278784        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -9.258372e-12 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.000142     |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 2.59e+04      |\n",
      "|    n_updates            | 1200          |\n",
      "|    policy_gradient_loss | -1.69e-09     |\n",
      "|    value_loss           | 6.18e+04      |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 264            |\n",
      "|    ep_rew_mean          | -4.38e+03      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 738            |\n",
      "|    iterations           | 122            |\n",
      "|    time_elapsed         | 380            |\n",
      "|    total_timesteps      | 281088         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -1.0426504e-11 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000145      |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 3.14e+04       |\n",
      "|    n_updates            | 1210           |\n",
      "|    policy_gradient_loss | -4.01e-09      |\n",
      "|    value_loss           | 6.19e+04       |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 264           |\n",
      "|    ep_rew_mean          | -4.38e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 738           |\n",
      "|    iterations           | 123           |\n",
      "|    time_elapsed         | 383           |\n",
      "|    total_timesteps      | 283392        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -1.713687e-11 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.000147     |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 2.7e+04       |\n",
      "|    n_updates            | 1220          |\n",
      "|    policy_gradient_loss | -6.88e-09     |\n",
      "|    value_loss           | 5.53e+04      |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 264            |\n",
      "|    ep_rew_mean          | -4.38e+03      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 738            |\n",
      "|    iterations           | 124            |\n",
      "|    time_elapsed         | 386            |\n",
      "|    total_timesteps      | 285696         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -1.3911006e-11 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000149      |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 2.66e+04       |\n",
      "|    n_updates            | 1230           |\n",
      "|    policy_gradient_loss | -1.71e-09      |\n",
      "|    value_loss           | 6.21e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 264            |\n",
      "|    ep_rew_mean          | -4.38e+03      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 738            |\n",
      "|    iterations           | 125            |\n",
      "|    time_elapsed         | 389            |\n",
      "|    total_timesteps      | 288000         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -2.5440271e-11 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000155      |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 3.14e+04       |\n",
      "|    n_updates            | 1240           |\n",
      "|    policy_gradient_loss | -2.12e-08      |\n",
      "|    value_loss           | 6.19e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 264            |\n",
      "|    ep_rew_mean          | -4.38e+03      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 739            |\n",
      "|    iterations           | 126            |\n",
      "|    time_elapsed         | 392            |\n",
      "|    total_timesteps      | 290304         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -1.9267078e-11 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000157      |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 2.88e+04       |\n",
      "|    n_updates            | 1250           |\n",
      "|    policy_gradient_loss | -9.34e-09      |\n",
      "|    value_loss           | 6.13e+04       |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 264           |\n",
      "|    ep_rew_mean          | -4.38e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 738           |\n",
      "|    iterations           | 127           |\n",
      "|    time_elapsed         | 395           |\n",
      "|    total_timesteps      | 292608        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -1.112852e-11 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.000161     |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 2.76e+04      |\n",
      "|    n_updates            | 1260          |\n",
      "|    policy_gradient_loss | -7.92e-10     |\n",
      "|    value_loss           | 5.55e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 264           |\n",
      "|    ep_rew_mean          | -4.38e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 738           |\n",
      "|    iterations           | 128           |\n",
      "|    time_elapsed         | 399           |\n",
      "|    total_timesteps      | 294912        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -3.949907e-11 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.000163     |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 3.73e+04      |\n",
      "|    n_updates            | 1270          |\n",
      "|    policy_gradient_loss | -1.8e-08      |\n",
      "|    value_loss           | 6.26e+04      |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 264            |\n",
      "|    ep_rew_mean          | -4.38e+03      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 739            |\n",
      "|    iterations           | 129            |\n",
      "|    time_elapsed         | 402            |\n",
      "|    total_timesteps      | 297216         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -1.7277558e-11 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000168      |\n",
      "|    explained_variance   | -1.19e-07      |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 2.55e+04       |\n",
      "|    n_updates            | 1280           |\n",
      "|    policy_gradient_loss | -3.19e-09      |\n",
      "|    value_loss           | 6.14e+04       |\n",
      "--------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 264         |\n",
      "|    ep_rew_mean          | -4.38e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 739         |\n",
      "|    iterations           | 130         |\n",
      "|    time_elapsed         | 405         |\n",
      "|    total_timesteps      | 299520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | -2.9506e-11 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.000172   |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 3.32e+04    |\n",
      "|    n_updates            | 1290        |\n",
      "|    policy_gradient_loss | -1.37e-08   |\n",
      "|    value_loss           | 6.23e+04    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 264           |\n",
      "|    ep_rew_mean          | -4.38e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 739           |\n",
      "|    iterations           | 131           |\n",
      "|    time_elapsed         | 408           |\n",
      "|    total_timesteps      | 301824        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -1.810605e-11 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.000175     |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 2.28e+04      |\n",
      "|    n_updates            | 1300          |\n",
      "|    policy_gradient_loss | -9.31e-11     |\n",
      "|    value_loss           | 5.56e+04      |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 264            |\n",
      "|    ep_rew_mean          | -4.38e+03      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 739            |\n",
      "|    iterations           | 132            |\n",
      "|    time_elapsed         | 411            |\n",
      "|    total_timesteps      | 304128         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -4.2618353e-11 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000178      |\n",
      "|    explained_variance   | 1.19e-07       |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 2.65e+04       |\n",
      "|    n_updates            | 1310           |\n",
      "|    policy_gradient_loss | -1.78e-08      |\n",
      "|    value_loss           | 6.18e+04       |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 264           |\n",
      "|    ep_rew_mean          | -4.38e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 739           |\n",
      "|    iterations           | 133           |\n",
      "|    time_elapsed         | 414           |\n",
      "|    total_timesteps      | 306432        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -5.860841e-11 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.000184     |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 3.34e+04      |\n",
      "|    n_updates            | 1320          |\n",
      "|    policy_gradient_loss | -3.1e-09      |\n",
      "|    value_loss           | 6.2e+04       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 264          |\n",
      "|    ep_rew_mean          | -4.38e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 739          |\n",
      "|    iterations           | 134          |\n",
      "|    time_elapsed         | 417          |\n",
      "|    total_timesteps      | 308736       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.922249e-05 |\n",
      "|    clip_fraction        | 0.000469     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.000142    |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.53e+04     |\n",
      "|    n_updates            | 1330         |\n",
      "|    policy_gradient_loss | -3.33e-05    |\n",
      "|    value_loss           | 5.57e+04     |\n",
      "------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 264            |\n",
      "|    ep_rew_mean          | -4.38e+03      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 739            |\n",
      "|    iterations           | 135            |\n",
      "|    time_elapsed         | 420            |\n",
      "|    total_timesteps      | 311040         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -1.1676349e-11 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.00013       |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 3.49e+04       |\n",
      "|    n_updates            | 1340           |\n",
      "|    policy_gradient_loss | -2.4e-08       |\n",
      "|    value_loss           | 6.23e+04       |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 264           |\n",
      "|    ep_rew_mean          | -4.38e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 739           |\n",
      "|    iterations           | 136           |\n",
      "|    time_elapsed         | 423           |\n",
      "|    total_timesteps      | 313344        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -6.455991e-12 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.000132     |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 3.53e+04      |\n",
      "|    n_updates            | 1350          |\n",
      "|    policy_gradient_loss | -1.44e-08     |\n",
      "|    value_loss           | 6.14e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 264           |\n",
      "|    ep_rew_mean          | -4.38e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 739           |\n",
      "|    iterations           | 137           |\n",
      "|    time_elapsed         | 426           |\n",
      "|    total_timesteps      | 315648        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -9.408296e-12 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.000134     |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 3.66e+04      |\n",
      "|    n_updates            | 1360          |\n",
      "|    policy_gradient_loss | -1.28e-08     |\n",
      "|    value_loss           | 6.18e+04      |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 264            |\n",
      "|    ep_rew_mean          | -4.38e+03      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 739            |\n",
      "|    iterations           | 138            |\n",
      "|    time_elapsed         | 429            |\n",
      "|    total_timesteps      | 317952         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -1.1109336e-11 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000135      |\n",
      "|    explained_variance   | -1.19e-07      |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 2.5e+04        |\n",
      "|    n_updates            | 1370           |\n",
      "|    policy_gradient_loss | -3.05e-09      |\n",
      "|    value_loss           | 5.56e+04       |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 264           |\n",
      "|    ep_rew_mean          | -4.38e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 739           |\n",
      "|    iterations           | 139           |\n",
      "|    time_elapsed         | 433           |\n",
      "|    total_timesteps      | 320256        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -4.942535e-12 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.000136     |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 2.48e+04      |\n",
      "|    n_updates            | 1380          |\n",
      "|    policy_gradient_loss | -4.1e-10      |\n",
      "|    value_loss           | 6.16e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 264           |\n",
      "|    ep_rew_mean          | -4.38e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 739           |\n",
      "|    iterations           | 140           |\n",
      "|    time_elapsed         | 436           |\n",
      "|    total_timesteps      | 322560        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -9.825385e-12 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.000137     |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 2.5e+04       |\n",
      "|    n_updates            | 1390          |\n",
      "|    policy_gradient_loss | -9.98e-09     |\n",
      "|    value_loss           | 6.21e+04      |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 264            |\n",
      "|    ep_rew_mean          | -4.38e+03      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 739            |\n",
      "|    iterations           | 141            |\n",
      "|    time_elapsed         | 439            |\n",
      "|    total_timesteps      | 324864         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -2.3564439e-11 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.00014       |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 3.36e+04       |\n",
      "|    n_updates            | 1400           |\n",
      "|    policy_gradient_loss | -1.05e-08      |\n",
      "|    value_loss           | 6.24e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 264            |\n",
      "|    ep_rew_mean          | -4.38e+03      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 739            |\n",
      "|    iterations           | 142            |\n",
      "|    time_elapsed         | 442            |\n",
      "|    total_timesteps      | 327168         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -1.0618351e-11 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000144      |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 2.22e+04       |\n",
      "|    n_updates            | 1410           |\n",
      "|    policy_gradient_loss | -8.99e-09      |\n",
      "|    value_loss           | 5.6e+04        |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 264           |\n",
      "|    ep_rew_mean          | -4.38e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 739           |\n",
      "|    iterations           | 143           |\n",
      "|    time_elapsed         | 445           |\n",
      "|    total_timesteps      | 329472        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -8.468249e-12 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.000146     |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 2.35e+04      |\n",
      "|    n_updates            | 1420          |\n",
      "|    policy_gradient_loss | -9.83e-09     |\n",
      "|    value_loss           | 6.22e+04      |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 264            |\n",
      "|    ep_rew_mean          | -4.38e+03      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 739            |\n",
      "|    iterations           | 144            |\n",
      "|    time_elapsed         | 448            |\n",
      "|    total_timesteps      | 331776         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -1.0663826e-11 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000147      |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 2.8e+04        |\n",
      "|    n_updates            | 1430           |\n",
      "|    policy_gradient_loss | -7.45e-10      |\n",
      "|    value_loss           | 6.17e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 264            |\n",
      "|    ep_rew_mean          | -4.38e+03      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 739            |\n",
      "|    iterations           | 145            |\n",
      "|    time_elapsed         | 451            |\n",
      "|    total_timesteps      | 334080         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -5.2175153e-11 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000153      |\n",
      "|    explained_variance   | 5.96e-08       |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 3.34e+04       |\n",
      "|    n_updates            | 1440           |\n",
      "|    policy_gradient_loss | -1.97e-08      |\n",
      "|    value_loss           | 5.6e+04        |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 264           |\n",
      "|    ep_rew_mean          | -4.38e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 739           |\n",
      "|    iterations           | 146           |\n",
      "|    time_elapsed         | 454           |\n",
      "|    total_timesteps      | 336384        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -7.537437e-11 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.000163     |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 3.41e+04      |\n",
      "|    n_updates            | 1450          |\n",
      "|    policy_gradient_loss | -2.43e-08     |\n",
      "|    value_loss           | 6.2e+04       |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 264            |\n",
      "|    ep_rew_mean          | -4.38e+03      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 739            |\n",
      "|    iterations           | 147            |\n",
      "|    time_elapsed         | 458            |\n",
      "|    total_timesteps      | 338688         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -1.5393197e-11 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.00017       |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 2.75e+04       |\n",
      "|    n_updates            | 1460           |\n",
      "|    policy_gradient_loss | -1.69e-09      |\n",
      "|    value_loss           | 6.16e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 264            |\n",
      "|    ep_rew_mean          | -4.38e+03      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 739            |\n",
      "|    iterations           | 148            |\n",
      "|    time_elapsed         | 461            |\n",
      "|    total_timesteps      | 340992         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -1.2584138e-10 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000179      |\n",
      "|    explained_variance   | -1.19e-07      |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 3.14e+04       |\n",
      "|    n_updates            | 1470           |\n",
      "|    policy_gradient_loss | -3.02e-08      |\n",
      "|    value_loss           | 6.21e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 264            |\n",
      "|    ep_rew_mean          | -4.38e+03      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 739            |\n",
      "|    iterations           | 149            |\n",
      "|    time_elapsed         | 464            |\n",
      "|    total_timesteps      | 343296         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -7.6066445e-11 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000195      |\n",
      "|    explained_variance   | -1.19e-07      |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 3.25e+04       |\n",
      "|    n_updates            | 1480           |\n",
      "|    policy_gradient_loss | -2.28e-08      |\n",
      "|    value_loss           | 5.54e+04       |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 264           |\n",
      "|    ep_rew_mean          | -4.38e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 739           |\n",
      "|    iterations           | 150           |\n",
      "|    time_elapsed         | 467           |\n",
      "|    total_timesteps      | 345600        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -8.296439e-11 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0002       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 2.88e+04      |\n",
      "|    n_updates            | 1490          |\n",
      "|    policy_gradient_loss | -8.76e-09     |\n",
      "|    value_loss           | 6.16e+04      |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 264            |\n",
      "|    ep_rew_mean          | -4.38e+03      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 739            |\n",
      "|    iterations           | 151            |\n",
      "|    time_elapsed         | 470            |\n",
      "|    total_timesteps      | 347904         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -7.6346394e-11 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000209      |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 3.22e+04       |\n",
      "|    n_updates            | 1500           |\n",
      "|    policy_gradient_loss | -1.16e-08      |\n",
      "|    value_loss           | 6.2e+04        |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 264            |\n",
      "|    ep_rew_mean          | -4.38e+03      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 739            |\n",
      "|    iterations           | 152            |\n",
      "|    time_elapsed         | 473            |\n",
      "|    total_timesteps      | 350208         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -3.0508715e-10 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000225      |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 3.2e+04        |\n",
      "|    n_updates            | 1510           |\n",
      "|    policy_gradient_loss | -9e-09         |\n",
      "|    value_loss           | 6.08e+04       |\n",
      "--------------------------------------------\n",
      "\n",
      "=== Final Results ===\n",
      "Entropy: 0.0 | Mean reward: 597.50  0.02\n",
      "Entropy: 0.001 | Mean reward: 4422.34  0.00\n",
      "Entropy: 0.01 | Mean reward: -4375.95  0.00\n",
      "The best entropy coefficient: 0.001\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from sb3_contrib import MaskablePPO\n",
    "from sb3_contrib.common.maskable.evaluation import evaluate_policy\n",
    "import torch\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from environment3 import LifeStyleEnv\n",
    "from sb3_contrib.common.wrappers import ActionMasker\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "def mask_fn(env: gym.Env) -> np.ndarray:\n",
    "    unwrapped_env = env\n",
    "    while hasattr(unwrapped_env, \"env\"):\n",
    "        unwrapped_env = unwrapped_env.env\n",
    "    return unwrapped_env.action_masks()\n",
    "\n",
    "def make_env():\n",
    "    env = LifeStyleEnv()\n",
    "    env = Monitor(env)\n",
    "    check_env(env, warn=True) \n",
    "    return env \n",
    "\n",
    "lr = 0.003\n",
    "ent_coefs = [0.0, 0.001, 0.01]\n",
    "results = []\n",
    "\n",
    "env = make_env()\n",
    "env = ActionMasker(env, mask_fn)\n",
    "\n",
    "eval_env = make_env()\n",
    "eval_env = ActionMasker(eval_env, mask_fn)\n",
    "\n",
    "for ent_coef in ent_coefs:\n",
    "    print(f\"\\nTraining with ent_coef={ent_coef}\")\n",
    "\n",
    "    model = MaskablePPO(\n",
    "        \"MultiInputPolicy\",\n",
    "        env,\n",
    "        learning_rate=lr,\n",
    "        n_steps=2304,\n",
    "        batch_size=512,\n",
    "        n_epochs=10,\n",
    "        gamma=0.99,\n",
    "        gae_lambda=0.95,\n",
    "        clip_range=0.2,\n",
    "        ent_coef=ent_coef,\n",
    "        vf_coef=0.5,\n",
    "        max_grad_norm=0.5,\n",
    "        verbose=1,\n",
    "        device=device,\n",
    "        policy_kwargs=dict(net_arch=[128, 128])\n",
    "    )\n",
    "\n",
    "    model.learn(total_timesteps=350000)\n",
    "\n",
    "    mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=20)\n",
    "    results.append((ent_coef, mean_reward, std_reward))\n",
    "\n",
    "highest = 0\n",
    "best_entropy_coef = 0.01\n",
    "\n",
    "print(\"\\n=== Final Results ===\")\n",
    "for ent_coef, mean_reward, std_reward in results:\n",
    "    print(f\"Entropy: {ent_coef} | Mean reward: {mean_reward:.2f}  {std_reward:.2f}\")\n",
    "\n",
    "    if mean_reward > highest:\n",
    "        highest = mean_reward\n",
    "        best_entropy_coef = ent_coef\n",
    "\n",
    "print(f\"The best entropy coefficient: {best_entropy_coef}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e50688e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Using cuda device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.3e+03  |\n",
      "|    ep_rew_mean     | -4.8e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 745      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 2304     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.3e+03     |\n",
      "|    ep_rew_mean          | -2e+03      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 728         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 4608        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009124953 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.77       |\n",
      "|    explained_variance   | -0.000646   |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 2.3e+03     |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    value_loss           | 4.48e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5000, episode_reward=4929.24 +/- 0.04\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.3e+03     |\n",
      "|    mean_reward          | 4.93e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 5000        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017874148 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.752      |\n",
      "|    explained_variance   | -3.1e-06    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 919         |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 1.92e+03    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.3e+03  |\n",
      "|    ep_rew_mean     | -27      |\n",
      "| time/              |          |\n",
      "|    fps             | 192      |\n",
      "|    iterations      | 3        |\n",
      "|    time_elapsed    | 35       |\n",
      "|    total_timesteps | 6912     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.26e+03    |\n",
      "|    ep_rew_mean          | 1.3e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 9216        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007874141 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.738      |\n",
      "|    explained_variance   | 0.00212     |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 740         |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00832    |\n",
      "|    value_loss           | 2e+03       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=6708.86 +/- 0.04\n",
      "Episode length: 1872.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.87e+03    |\n",
      "|    mean_reward          | 6.71e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 10000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006945251 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.716      |\n",
      "|    explained_variance   | 3.58e-06    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 795         |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    value_loss           | 2.21e+03    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.07e+03 |\n",
      "|    ep_rew_mean     | 1.85e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 180      |\n",
      "|    iterations      | 5        |\n",
      "|    time_elapsed    | 63       |\n",
      "|    total_timesteps | 11520    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.97e+03    |\n",
      "|    ep_rew_mean          | 2.96e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 206         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 67          |\n",
      "|    total_timesteps      | 13824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008916422 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.688      |\n",
      "|    explained_variance   | 4.71e-06    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.11e+03    |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    value_loss           | 2.76e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=15000, episode_reward=9818.28 +/- 0.01\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.3e+03     |\n",
      "|    mean_reward          | 9.82e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 15000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010309038 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.659      |\n",
      "|    explained_variance   | 1.42e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.01e+03    |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    value_loss           | 2.76e+03    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.92e+03 |\n",
      "|    ep_rew_mean     | 3.47e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 166      |\n",
      "|    iterations      | 7        |\n",
      "|    time_elapsed    | 96       |\n",
      "|    total_timesteps | 16128    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.81e+03   |\n",
      "|    ep_rew_mean          | 3.93e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 184        |\n",
      "|    iterations           | 8          |\n",
      "|    time_elapsed         | 100        |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00833192 |\n",
      "|    clip_fraction        | 0.131      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.631     |\n",
      "|    explained_variance   | 2.03e-05   |\n",
      "|    learning_rate        | 0.003      |\n",
      "|    loss                 | 1.22e+03   |\n",
      "|    n_updates            | 70         |\n",
      "|    policy_gradient_loss | -0.0124    |\n",
      "|    value_loss           | 3.08e+03   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=4777.47 +/- 0.02\n",
      "Episode length: 960.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 960        |\n",
      "|    mean_reward          | 4.78e+03   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 20000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01435045 |\n",
      "|    clip_fraction        | 0.131      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.576     |\n",
      "|    explained_variance   | 1.65e-05   |\n",
      "|    learning_rate        | 0.003      |\n",
      "|    loss                 | 1.25e+03   |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.011     |\n",
      "|    value_loss           | 3.44e+03   |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.67e+03 |\n",
      "|    ep_rew_mean     | 4.12e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 181      |\n",
      "|    iterations      | 9        |\n",
      "|    time_elapsed    | 114      |\n",
      "|    total_timesteps | 20736    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.52e+03    |\n",
      "|    ep_rew_mean          | 4.28e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 196         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 117         |\n",
      "|    total_timesteps      | 23040       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010845519 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.527      |\n",
      "|    explained_variance   | 1.74e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.38e+03    |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00823    |\n",
      "|    value_loss           | 3.84e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=25000, episode_reward=9614.74 +/- 0.00\n",
      "Episode length: 2136.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.14e+03    |\n",
      "|    mean_reward          | 9.61e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 25000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008792451 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.484      |\n",
      "|    explained_variance   | 2.49e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.37e+03    |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00389    |\n",
      "|    value_loss           | 3.76e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.41e+03 |\n",
      "|    ep_rew_mean     | 4.38e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 174      |\n",
      "|    iterations      | 11       |\n",
      "|    time_elapsed    | 145      |\n",
      "|    total_timesteps | 25344    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.31e+03    |\n",
      "|    ep_rew_mean          | 4.39e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 186         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 148         |\n",
      "|    total_timesteps      | 27648       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010768254 |\n",
      "|    clip_fraction        | 0.099       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.43       |\n",
      "|    explained_variance   | 1.91e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.61e+03    |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00917    |\n",
      "|    value_loss           | 4.53e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.23e+03   |\n",
      "|    ep_rew_mean          | 4.38e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 197        |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 151        |\n",
      "|    total_timesteps      | 29952      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00929865 |\n",
      "|    clip_fraction        | 0.0832     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.385     |\n",
      "|    explained_variance   | 2.12e-05   |\n",
      "|    learning_rate        | 0.003      |\n",
      "|    loss                 | 1.56e+03   |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.00449   |\n",
      "|    value_loss           | 4.42e+03   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=5803.94 +/- 0.00\n",
      "Episode length: 960.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 960          |\n",
      "|    mean_reward          | 5.8e+03      |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 30000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063251914 |\n",
      "|    clip_fraction        | 0.066        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.371       |\n",
      "|    explained_variance   | 1.63e-05     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.88e+03     |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00269     |\n",
      "|    value_loss           | 4.77e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.15e+03 |\n",
      "|    ep_rew_mean     | 4.39e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 194      |\n",
      "|    iterations      | 14       |\n",
      "|    time_elapsed    | 166      |\n",
      "|    total_timesteps | 32256    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 4.36e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 204         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 169         |\n",
      "|    total_timesteps      | 34560       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014907347 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.355      |\n",
      "|    explained_variance   | 1.35e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.92e+03    |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | 0.008       |\n",
      "|    value_loss           | 4.74e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=35000, episode_reward=5803.94 +/- 0.00\n",
      "Episode length: 960.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 960         |\n",
      "|    mean_reward          | 5.8e+03     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 35000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004442393 |\n",
      "|    clip_fraction        | 0.0357      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.336      |\n",
      "|    explained_variance   | 1.04e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.49e+03    |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.00376    |\n",
      "|    value_loss           | 3.96e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.02e+03 |\n",
      "|    ep_rew_mean     | 4.25e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 200      |\n",
      "|    iterations      | 16       |\n",
      "|    time_elapsed    | 183      |\n",
      "|    total_timesteps | 36864    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 979         |\n",
      "|    ep_rew_mean          | 4.2e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 209         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 186         |\n",
      "|    total_timesteps      | 39168       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004661751 |\n",
      "|    clip_fraction        | 0.0738      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.294      |\n",
      "|    explained_variance   | 5.78e-06    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.39e+03    |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00517    |\n",
      "|    value_loss           | 3.59e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=5803.94 +/- 0.00\n",
      "Episode length: 960.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 960          |\n",
      "|    mean_reward          | 5.8e+03      |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 40000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070619644 |\n",
      "|    clip_fraction        | 0.0484       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.271       |\n",
      "|    explained_variance   | 4.47e-06     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.77e+03     |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00406     |\n",
      "|    value_loss           | 4.14e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 961      |\n",
      "|    ep_rew_mean     | 4.26e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 206      |\n",
      "|    iterations      | 18       |\n",
      "|    time_elapsed    | 200      |\n",
      "|    total_timesteps | 41472    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 930          |\n",
      "|    ep_rew_mean          | 4.23e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 214          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 203          |\n",
      "|    total_timesteps      | 43776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055502737 |\n",
      "|    clip_fraction        | 0.0538       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.268       |\n",
      "|    explained_variance   | 6.62e-06     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.52e+03     |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00412     |\n",
      "|    value_loss           | 4.17e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=45000, episode_reward=6687.82 +/- 0.00\n",
      "Episode length: 960.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 960          |\n",
      "|    mean_reward          | 6.69e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 45000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033171226 |\n",
      "|    clip_fraction        | 0.0375       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.245       |\n",
      "|    explained_variance   | 3.81e-06     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.27e+03     |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.00404     |\n",
      "|    value_loss           | 3.54e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 902      |\n",
      "|    ep_rew_mean     | 4.23e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 211      |\n",
      "|    iterations      | 20       |\n",
      "|    time_elapsed    | 217      |\n",
      "|    total_timesteps | 46080    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 876          |\n",
      "|    ep_rew_mean          | 4.21e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 218          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 221          |\n",
      "|    total_timesteps      | 48384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028818003 |\n",
      "|    clip_fraction        | 0.03         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.235       |\n",
      "|    explained_variance   | 5.01e-06     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.34e+03     |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00153     |\n",
      "|    value_loss           | 3.68e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=6687.82 +/- 0.00\n",
      "Episode length: 960.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 960         |\n",
      "|    mean_reward          | 6.69e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 50000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003039403 |\n",
      "|    clip_fraction        | 0.0364      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.236      |\n",
      "|    explained_variance   | 4.53e-06    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.56e+03    |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00259    |\n",
      "|    value_loss           | 3.72e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 856      |\n",
      "|    ep_rew_mean     | 4.23e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 215      |\n",
      "|    iterations      | 22       |\n",
      "|    time_elapsed    | 235      |\n",
      "|    total_timesteps | 50688    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 841          |\n",
      "|    ep_rew_mean          | 4.25e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 222          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 238          |\n",
      "|    total_timesteps      | 52992        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029430434 |\n",
      "|    clip_fraction        | 0.0312       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.205       |\n",
      "|    explained_variance   | 3.16e-06     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.28e+03     |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00214     |\n",
      "|    value_loss           | 3.94e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=55000, episode_reward=6687.82 +/- 0.00\n",
      "Episode length: 960.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 960         |\n",
      "|    mean_reward          | 6.69e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 55000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002286148 |\n",
      "|    clip_fraction        | 0.03        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.186      |\n",
      "|    explained_variance   | 2.26e-06    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.21e+03    |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -9.96e-05   |\n",
      "|    value_loss           | 3.45e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 825      |\n",
      "|    ep_rew_mean     | 4.26e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 218      |\n",
      "|    iterations      | 24       |\n",
      "|    time_elapsed    | 252      |\n",
      "|    total_timesteps | 55296    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 809          |\n",
      "|    ep_rew_mean          | 4.25e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 225          |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 255          |\n",
      "|    total_timesteps      | 57600        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059176637 |\n",
      "|    clip_fraction        | 0.0453       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.218       |\n",
      "|    explained_variance   | 2.68e-06     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.58e+03     |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.00135     |\n",
      "|    value_loss           | 3.45e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 797        |\n",
      "|    ep_rew_mean          | 4.29e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 231        |\n",
      "|    iterations           | 26         |\n",
      "|    time_elapsed         | 258        |\n",
      "|    total_timesteps      | 59904      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00247883 |\n",
      "|    clip_fraction        | 0.0239     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.212     |\n",
      "|    explained_variance   | 1.97e-06   |\n",
      "|    learning_rate        | 0.003      |\n",
      "|    loss                 | 1.52e+03   |\n",
      "|    n_updates            | 250        |\n",
      "|    policy_gradient_loss | -0.00233   |\n",
      "|    value_loss           | 3.73e+03   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=6687.82 +/- 0.00\n",
      "Episode length: 960.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 960          |\n",
      "|    mean_reward          | 6.69e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 60000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050217127 |\n",
      "|    clip_fraction        | 0.0425       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.25        |\n",
      "|    explained_variance   | 2.03e-06     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.88e+03     |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.00237     |\n",
      "|    value_loss           | 4.05e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 786      |\n",
      "|    ep_rew_mean     | 4.3e+03  |\n",
      "| time/              |          |\n",
      "|    fps             | 227      |\n",
      "|    iterations      | 27       |\n",
      "|    time_elapsed    | 273      |\n",
      "|    total_timesteps | 62208    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 774         |\n",
      "|    ep_rew_mean          | 4.29e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 276         |\n",
      "|    total_timesteps      | 64512       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005167371 |\n",
      "|    clip_fraction        | 0.0479      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.245      |\n",
      "|    explained_variance   | 2.03e-06    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.35e+03    |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.00206    |\n",
      "|    value_loss           | 3.85e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=65000, episode_reward=6687.82 +/- 0.00\n",
      "Episode length: 960.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 960         |\n",
      "|    mean_reward          | 6.69e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 65000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008263221 |\n",
      "|    clip_fraction        | 0.0542      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.217      |\n",
      "|    explained_variance   | 1.31e-06    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 2.09e+03    |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.000514   |\n",
      "|    value_loss           | 3.99e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 765      |\n",
      "|    ep_rew_mean     | 4.29e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 229      |\n",
      "|    iterations      | 29       |\n",
      "|    time_elapsed    | 291      |\n",
      "|    total_timesteps | 66816    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 758          |\n",
      "|    ep_rew_mean          | 4.32e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 234          |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 294          |\n",
      "|    total_timesteps      | 69120        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066826656 |\n",
      "|    clip_fraction        | 0.0565       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.228       |\n",
      "|    explained_variance   | 1.43e-06     |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.64e+03     |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | 0.000985     |\n",
      "|    value_loss           | 3.24e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=4700.49 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 576         |\n",
      "|    mean_reward          | 4.7e+03     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 70000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015506235 |\n",
      "|    clip_fraction        | 0.0644      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.234      |\n",
      "|    explained_variance   | 1.43e-06    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.3e+03     |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.00252    |\n",
      "|    value_loss           | 3.56e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 755      |\n",
      "|    ep_rew_mean     | 4.36e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 234      |\n",
      "|    iterations      | 31       |\n",
      "|    time_elapsed    | 304      |\n",
      "|    total_timesteps | 71424    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 749         |\n",
      "|    ep_rew_mean          | 4.38e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 307         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023928156 |\n",
      "|    clip_fraction        | 0.0702      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.259      |\n",
      "|    explained_variance   | 2.21e-06    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.58e+03    |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.00348    |\n",
      "|    value_loss           | 3.17e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=75000, episode_reward=6687.82 +/- 0.00\n",
      "Episode length: 960.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 960         |\n",
      "|    mean_reward          | 6.69e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 75000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010103241 |\n",
      "|    clip_fraction        | 0.0673      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.222      |\n",
      "|    explained_variance   | 9.54e-07    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 2.12e+03    |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.00226    |\n",
      "|    value_loss           | 3.81e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 732      |\n",
      "|    ep_rew_mean     | 4.51e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 236      |\n",
      "|    iterations      | 33       |\n",
      "|    time_elapsed    | 321      |\n",
      "|    total_timesteps | 76032    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 657        |\n",
      "|    ep_rew_mean          | 4.49e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 240        |\n",
      "|    iterations           | 34         |\n",
      "|    time_elapsed         | 325        |\n",
      "|    total_timesteps      | 78336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12248138 |\n",
      "|    clip_fraction        | 0.0839     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.158     |\n",
      "|    explained_variance   | 1.37e-06   |\n",
      "|    learning_rate        | 0.003      |\n",
      "|    loss                 | 2.13e+03   |\n",
      "|    n_updates            | 330        |\n",
      "|    policy_gradient_loss | -0.000848  |\n",
      "|    value_loss           | 3.19e+03   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=-3885.29 +/- 0.08\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 2.3e+03   |\n",
      "|    mean_reward          | -3.89e+03 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 80000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 3.2969022 |\n",
      "|    clip_fraction        | 0.131     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.131    |\n",
      "|    explained_variance   | 6.56e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.99e+03  |\n",
      "|    n_updates            | 340       |\n",
      "|    policy_gradient_loss | 0.021     |\n",
      "|    value_loss           | 5.31e+03  |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 665      |\n",
      "|    ep_rew_mean     | 4.41e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 227      |\n",
      "|    iterations      | 35       |\n",
      "|    time_elapsed    | 354      |\n",
      "|    total_timesteps | 80640    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 672          |\n",
      "|    ep_rew_mean          | 4.3e+03      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 231          |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 358          |\n",
      "|    total_timesteps      | 82944        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016529795 |\n",
      "|    clip_fraction        | 0.00422      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0293      |\n",
      "|    explained_variance   | -0.278       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 69.2         |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | 0.00219      |\n",
      "|    value_loss           | 2.65e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=85000, episode_reward=-3885.32 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.3e+03     |\n",
      "|    mean_reward          | -3.89e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 85000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001148232 |\n",
      "|    clip_fraction        | 0.0073      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0205     |\n",
      "|    explained_variance   | -0.0151     |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 75.6        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.00162    |\n",
      "|    value_loss           | 2.92e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 682      |\n",
      "|    ep_rew_mean     | 4.2e+03  |\n",
      "| time/              |          |\n",
      "|    fps             | 219      |\n",
      "|    iterations      | 37       |\n",
      "|    time_elapsed    | 388      |\n",
      "|    total_timesteps | 85248    |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 692           |\n",
      "|    ep_rew_mean          | 4.1e+03       |\n",
      "| time/                   |               |\n",
      "|    fps                  | 223           |\n",
      "|    iterations           | 38            |\n",
      "|    time_elapsed         | 391           |\n",
      "|    total_timesteps      | 87552         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00031641763 |\n",
      "|    clip_fraction        | 0.00289       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0176       |\n",
      "|    explained_variance   | 0.0166        |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 55.9          |\n",
      "|    n_updates            | 370           |\n",
      "|    policy_gradient_loss | -0.000269     |\n",
      "|    value_loss           | 4.2e+03       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 704          |\n",
      "|    ep_rew_mean          | 4.01e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 227          |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 394          |\n",
      "|    total_timesteps      | 89856        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013707707 |\n",
      "|    clip_fraction        | 0.00133      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0114      |\n",
      "|    explained_variance   | 0.0382       |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 42.5         |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.000352    |\n",
      "|    value_loss           | 709          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=-3885.32 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 2.3e+03       |\n",
      "|    mean_reward          | -3.89e+03     |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 90000         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00025906455 |\n",
      "|    clip_fraction        | 0.000469      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00487      |\n",
      "|    explained_variance   | 0.00525       |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 35.8          |\n",
      "|    n_updates            | 390           |\n",
      "|    policy_gradient_loss | -0.000222     |\n",
      "|    value_loss           | 1.17e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 718      |\n",
      "|    ep_rew_mean     | 3.92e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 217      |\n",
      "|    iterations      | 40       |\n",
      "|    time_elapsed    | 424      |\n",
      "|    total_timesteps | 92160    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 731         |\n",
      "|    ep_rew_mean          | 3.88e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 220         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 427         |\n",
      "|    total_timesteps      | 94464       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015673686 |\n",
      "|    clip_fraction        | 0.0251      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0586     |\n",
      "|    explained_variance   | 0.0374      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 24.7        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.00324    |\n",
      "|    value_loss           | 1.28e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=95000, episode_reward=-3885.32 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.3e+03     |\n",
      "|    mean_reward          | -3.89e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 95000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.048990954 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.216      |\n",
      "|    explained_variance   | -7.07e-05   |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 87.1        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | 0.000729    |\n",
      "|    value_loss           | 173         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 746      |\n",
      "|    ep_rew_mean     | 3.85e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 211      |\n",
      "|    iterations      | 42       |\n",
      "|    time_elapsed    | 457      |\n",
      "|    total_timesteps | 96768    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 759         |\n",
      "|    ep_rew_mean          | 3.79e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 214         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 461         |\n",
      "|    total_timesteps      | 99072       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031780325 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.212      |\n",
      "|    explained_variance   | 0.0162      |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 85.4        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0047     |\n",
      "|    value_loss           | 176         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=-3885.32 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.3e+03     |\n",
      "|    mean_reward          | -3.89e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 100000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013451612 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.204      |\n",
      "|    explained_variance   | 0.00261     |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 61.1        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    value_loss           | 154         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 774      |\n",
      "|    ep_rew_mean     | 3.77e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 206      |\n",
      "|    iterations      | 44       |\n",
      "|    time_elapsed    | 490      |\n",
      "|    total_timesteps | 101376   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 789       |\n",
      "|    ep_rew_mean          | 3.69e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 209       |\n",
      "|    iterations           | 45        |\n",
      "|    time_elapsed         | 494       |\n",
      "|    total_timesteps      | 103680    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8327631 |\n",
      "|    clip_fraction        | 0.239     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.174    |\n",
      "|    explained_variance   | 0.00272   |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 202       |\n",
      "|    n_updates            | 440       |\n",
      "|    policy_gradient_loss | 0.0287    |\n",
      "|    value_loss           | 413       |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=105000, episode_reward=-3885.32 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 2.3e+03       |\n",
      "|    mean_reward          | -3.89e+03     |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 105000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.6586894e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00326      |\n",
      "|    explained_variance   | -0.174        |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 20.5          |\n",
      "|    n_updates            | 450           |\n",
      "|    policy_gradient_loss | -5.41e-05     |\n",
      "|    value_loss           | 359           |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 804      |\n",
      "|    ep_rew_mean     | 3.61e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 202      |\n",
      "|    iterations      | 46       |\n",
      "|    time_elapsed    | 524      |\n",
      "|    total_timesteps | 105984   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 820          |\n",
      "|    ep_rew_mean          | 3.54e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 205          |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 527          |\n",
      "|    total_timesteps      | 108288       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011147435 |\n",
      "|    clip_fraction        | 0.00043      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0266      |\n",
      "|    explained_variance   | 1.3e-05      |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 49.6         |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.0017      |\n",
      "|    value_loss           | 456          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=110000, episode_reward=-3885.32 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.3e+03     |\n",
      "|    mean_reward          | -3.89e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 110000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.057270736 |\n",
      "|    clip_fraction        | 0.0721      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.124      |\n",
      "|    explained_variance   | 3.87e-06    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 38.3        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    value_loss           | 138         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 835      |\n",
      "|    ep_rew_mean     | 3.51e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 198      |\n",
      "|    iterations      | 48       |\n",
      "|    time_elapsed    | 557      |\n",
      "|    total_timesteps | 110592   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 851         |\n",
      "|    ep_rew_mean          | 3.45e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 201         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 561         |\n",
      "|    total_timesteps      | 112896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042221326 |\n",
      "|    clip_fraction        | 0.0687      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0989     |\n",
      "|    explained_variance   | -2.74e-06   |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 100         |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | 0.0367      |\n",
      "|    value_loss           | 263         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=115000, episode_reward=-3885.32 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.3e+03     |\n",
      "|    mean_reward          | -3.89e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 115000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029945184 |\n",
      "|    clip_fraction        | 0.00602     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.00214    |\n",
      "|    explained_variance   | 1.97e-06    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 47.7        |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | 0.0107      |\n",
      "|    value_loss           | 142         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 867      |\n",
      "|    ep_rew_mean     | 3.36e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 194      |\n",
      "|    iterations      | 50       |\n",
      "|    time_elapsed    | 591      |\n",
      "|    total_timesteps | 115200   |\n",
      "---------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 884            |\n",
      "|    ep_rew_mean          | 3.28e+03       |\n",
      "| time/                   |                |\n",
      "|    fps                  | 197            |\n",
      "|    iterations           | 51             |\n",
      "|    time_elapsed         | 594            |\n",
      "|    total_timesteps      | 117504         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -5.3239545e-11 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000336      |\n",
      "|    explained_variance   | 1.15e-05       |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 25.6           |\n",
      "|    n_updates            | 500            |\n",
      "|    policy_gradient_loss | -2.29e-07      |\n",
      "|    value_loss           | 441            |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 900            |\n",
      "|    ep_rew_mean          | 3.2e+03        |\n",
      "| time/                   |                |\n",
      "|    fps                  | 200            |\n",
      "|    iterations           | 52             |\n",
      "|    time_elapsed         | 597            |\n",
      "|    total_timesteps      | 119808         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -6.0111915e-12 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000337      |\n",
      "|    explained_variance   | 0.00204        |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 20.5           |\n",
      "|    n_updates            | 510            |\n",
      "|    policy_gradient_loss | 1.39e-08       |\n",
      "|    value_loss           | 211            |\n",
      "--------------------------------------------\n",
      "Eval num_timesteps=120000, episode_reward=-3885.32 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "--------------------------------------------\n",
      "| eval/                   |                |\n",
      "|    mean_ep_length       | 2.3e+03        |\n",
      "|    mean_reward          | -3.89e+03      |\n",
      "| time/                   |                |\n",
      "|    total_timesteps      | 120000         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -4.1313796e-11 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000337      |\n",
      "|    explained_variance   | 0.0321         |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 18.4           |\n",
      "|    n_updates            | 520            |\n",
      "|    policy_gradient_loss | -6.73e-08      |\n",
      "|    value_loss           | 118            |\n",
      "--------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 917      |\n",
      "|    ep_rew_mean     | 3.12e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 194      |\n",
      "|    iterations      | 53       |\n",
      "|    time_elapsed    | 627      |\n",
      "|    total_timesteps | 122112   |\n",
      "---------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 933            |\n",
      "|    ep_rew_mean          | 3.04e+03       |\n",
      "| time/                   |                |\n",
      "|    fps                  | 197            |\n",
      "|    iterations           | 54             |\n",
      "|    time_elapsed         | 630            |\n",
      "|    total_timesteps      | 124416         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -4.3127103e-11 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000346      |\n",
      "|    explained_variance   | 0.0786         |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 19.7           |\n",
      "|    n_updates            | 530            |\n",
      "|    policy_gradient_loss | -1.2e-07       |\n",
      "|    value_loss           | 71             |\n",
      "--------------------------------------------\n",
      "Eval num_timesteps=125000, episode_reward=-3885.32 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "--------------------------------------------\n",
      "| eval/                   |                |\n",
      "|    mean_ep_length       | 2.3e+03        |\n",
      "|    mean_reward          | -3.89e+03      |\n",
      "| time/                   |                |\n",
      "|    total_timesteps      | 125000         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -4.7410253e-11 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.00035       |\n",
      "|    explained_variance   | 1.38e-05       |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 19.2           |\n",
      "|    n_updates            | 540            |\n",
      "|    policy_gradient_loss | -1.5e-07       |\n",
      "|    value_loss           | 89.7           |\n",
      "--------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 950      |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 191      |\n",
      "|    iterations      | 55       |\n",
      "|    time_elapsed    | 660      |\n",
      "|    total_timesteps | 126720   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 966           |\n",
      "|    ep_rew_mean          | 2.87e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 194           |\n",
      "|    iterations           | 56            |\n",
      "|    time_elapsed         | 663           |\n",
      "|    total_timesteps      | 129024        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -6.727987e-11 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.000356     |\n",
      "|    explained_variance   | 1.82e-05      |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 18.1          |\n",
      "|    n_updates            | 550           |\n",
      "|    policy_gradient_loss | -1.5e-07      |\n",
      "|    value_loss           | 72.7          |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=130000, episode_reward=-3885.32 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "--------------------------------------------\n",
      "| eval/                   |                |\n",
      "|    mean_ep_length       | 2.3e+03        |\n",
      "|    mean_reward          | -3.89e+03      |\n",
      "| time/                   |                |\n",
      "|    total_timesteps      | 130000         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -5.5337068e-11 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000366      |\n",
      "|    explained_variance   | 4.18e-05       |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 15             |\n",
      "|    n_updates            | 560            |\n",
      "|    policy_gradient_loss | -1.82e-07      |\n",
      "|    value_loss           | 56.6           |\n",
      "--------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 984      |\n",
      "|    ep_rew_mean     | 2.79e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 189      |\n",
      "|    iterations      | 57       |\n",
      "|    time_elapsed    | 693      |\n",
      "|    total_timesteps | 131328   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1e+03         |\n",
      "|    ep_rew_mean          | 2.71e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 191           |\n",
      "|    iterations           | 58            |\n",
      "|    time_elapsed         | 696           |\n",
      "|    total_timesteps      | 133632        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -5.581171e-11 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.000369     |\n",
      "|    explained_variance   | 0.139         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 17.8          |\n",
      "|    n_updates            | 570           |\n",
      "|    policy_gradient_loss | -1.18e-07     |\n",
      "|    value_loss           | 39.8          |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=135000, episode_reward=-3885.32 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "--------------------------------------------\n",
      "| eval/                   |                |\n",
      "|    mean_ep_length       | 2.3e+03        |\n",
      "|    mean_reward          | -3.89e+03      |\n",
      "| time/                   |                |\n",
      "|    total_timesteps      | 135000         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -2.3032669e-10 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.00038       |\n",
      "|    explained_variance   | 0.0657         |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 17.5           |\n",
      "|    n_updates            | 580            |\n",
      "|    policy_gradient_loss | -3.11e-07      |\n",
      "|    value_loss           | 38.8           |\n",
      "--------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.02e+03 |\n",
      "|    ep_rew_mean     | 2.63e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 187      |\n",
      "|    iterations      | 59       |\n",
      "|    time_elapsed    | 726      |\n",
      "|    total_timesteps | 135936   |\n",
      "---------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 1.03e+03       |\n",
      "|    ep_rew_mean          | 2.55e+03       |\n",
      "| time/                   |                |\n",
      "|    fps                  | 189            |\n",
      "|    iterations           | 60             |\n",
      "|    time_elapsed         | 729            |\n",
      "|    total_timesteps      | 138240         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -2.3830182e-10 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000413      |\n",
      "|    explained_variance   | 0.0183         |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 16.9           |\n",
      "|    n_updates            | 590            |\n",
      "|    policy_gradient_loss | -6.75e-07      |\n",
      "|    value_loss           | 35.2           |\n",
      "--------------------------------------------\n",
      "Eval num_timesteps=140000, episode_reward=-3885.32 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 2.3e+03       |\n",
      "|    mean_reward          | -3.89e+03     |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 140000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -3.334378e-10 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.000432     |\n",
      "|    explained_variance   | 0.0635        |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 17.3          |\n",
      "|    n_updates            | 600           |\n",
      "|    policy_gradient_loss | -4.85e-07     |\n",
      "|    value_loss           | 38.8          |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.05e+03 |\n",
      "|    ep_rew_mean     | 2.47e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 185      |\n",
      "|    iterations      | 61       |\n",
      "|    time_elapsed    | 759      |\n",
      "|    total_timesteps | 140544   |\n",
      "---------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 1.07e+03       |\n",
      "|    ep_rew_mean          | 2.4e+03        |\n",
      "| time/                   |                |\n",
      "|    fps                  | 187            |\n",
      "|    iterations           | 62             |\n",
      "|    time_elapsed         | 762            |\n",
      "|    total_timesteps      | 142848         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -1.8978881e-10 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000459      |\n",
      "|    explained_variance   | 0.0327         |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 18.6           |\n",
      "|    n_updates            | 610            |\n",
      "|    policy_gradient_loss | -4.33e-07      |\n",
      "|    value_loss           | 36.2           |\n",
      "--------------------------------------------\n",
      "Eval num_timesteps=145000, episode_reward=-3885.32 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "--------------------------------------------\n",
      "| eval/                   |                |\n",
      "|    mean_ep_length       | 2.3e+03        |\n",
      "|    mean_reward          | -3.89e+03      |\n",
      "| time/                   |                |\n",
      "|    total_timesteps      | 145000         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -4.6244963e-10 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.00048       |\n",
      "|    explained_variance   | 0.0677         |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 20.3           |\n",
      "|    n_updates            | 620            |\n",
      "|    policy_gradient_loss | -6.19e-07      |\n",
      "|    value_loss           | 38.8           |\n",
      "--------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.09e+03 |\n",
      "|    ep_rew_mean     | 2.33e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 183      |\n",
      "|    iterations      | 63       |\n",
      "|    time_elapsed    | 792      |\n",
      "|    total_timesteps | 145152   |\n",
      "---------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 1.1e+03        |\n",
      "|    ep_rew_mean          | 2.26e+03       |\n",
      "| time/                   |                |\n",
      "|    fps                  | 185            |\n",
      "|    iterations           | 64             |\n",
      "|    time_elapsed         | 795            |\n",
      "|    total_timesteps      | 147456         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -3.6533548e-10 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000513      |\n",
      "|    explained_variance   | 0.0742         |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 18.4           |\n",
      "|    n_updates            | 630            |\n",
      "|    policy_gradient_loss | -5.43e-07      |\n",
      "|    value_loss           | 34             |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.12e+03      |\n",
      "|    ep_rew_mean          | 2.17e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 187           |\n",
      "|    iterations           | 65            |\n",
      "|    time_elapsed         | 798           |\n",
      "|    total_timesteps      | 149760        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -3.792479e-10 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.000538     |\n",
      "|    explained_variance   | 0.0915        |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 14.4          |\n",
      "|    n_updates            | 640           |\n",
      "|    policy_gradient_loss | -5.2e-07      |\n",
      "|    value_loss           | 34.1          |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=150000, episode_reward=-3885.32 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "--------------------------------------------\n",
      "| eval/                   |                |\n",
      "|    mean_ep_length       | 2.3e+03        |\n",
      "|    mean_reward          | -3.89e+03      |\n",
      "| time/                   |                |\n",
      "|    total_timesteps      | 150000         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -5.4053545e-10 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.00057       |\n",
      "|    explained_variance   | 0.1            |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 17.2           |\n",
      "|    n_updates            | 650            |\n",
      "|    policy_gradient_loss | -8.55e-07      |\n",
      "|    value_loss           | 32.8           |\n",
      "--------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.14e+03 |\n",
      "|    ep_rew_mean     | 2.1e+03  |\n",
      "| time/              |          |\n",
      "|    fps             | 183      |\n",
      "|    iterations      | 66       |\n",
      "|    time_elapsed    | 828      |\n",
      "|    total_timesteps | 152064   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.15e+03      |\n",
      "|    ep_rew_mean          | 2.03e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 185           |\n",
      "|    iterations           | 67            |\n",
      "|    time_elapsed         | 831           |\n",
      "|    total_timesteps      | 154368        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -4.242736e-10 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.000598     |\n",
      "|    explained_variance   | 0.11          |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 12.7          |\n",
      "|    n_updates            | 660           |\n",
      "|    policy_gradient_loss | -5.19e-07     |\n",
      "|    value_loss           | 31.9          |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=155000, episode_reward=-3885.32 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "--------------------------------------------\n",
      "| eval/                   |                |\n",
      "|    mean_ep_length       | 2.3e+03        |\n",
      "|    mean_reward          | -3.89e+03      |\n",
      "| time/                   |                |\n",
      "|    total_timesteps      | 155000         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -3.1465106e-10 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000623      |\n",
      "|    explained_variance   | 0.134          |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 12.2           |\n",
      "|    n_updates            | 670            |\n",
      "|    policy_gradient_loss | -3.53e-07      |\n",
      "|    value_loss           | 27.9           |\n",
      "--------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.17e+03 |\n",
      "|    ep_rew_mean     | 1.95e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 181      |\n",
      "|    iterations      | 68       |\n",
      "|    time_elapsed    | 861      |\n",
      "|    total_timesteps | 156672   |\n",
      "---------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 1.19e+03       |\n",
      "|    ep_rew_mean          | 1.86e+03       |\n",
      "| time/                   |                |\n",
      "|    fps                  | 183            |\n",
      "|    iterations           | 69             |\n",
      "|    time_elapsed         | 864            |\n",
      "|    total_timesteps      | 158976         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -3.9445353e-10 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000638      |\n",
      "|    explained_variance   | 0.257          |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 13             |\n",
      "|    n_updates            | 680            |\n",
      "|    policy_gradient_loss | -5.12e-07      |\n",
      "|    value_loss           | 26             |\n",
      "--------------------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=-3885.32 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "--------------------------------------------\n",
      "| eval/                   |                |\n",
      "|    mean_ep_length       | 2.3e+03        |\n",
      "|    mean_reward          | -3.89e+03      |\n",
      "| time/                   |                |\n",
      "|    total_timesteps      | 160000         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -7.0153305e-10 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000671      |\n",
      "|    explained_variance   | 0.273          |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 12.5           |\n",
      "|    n_updates            | 690            |\n",
      "|    policy_gradient_loss | -9.58e-07      |\n",
      "|    value_loss           | 25.5           |\n",
      "--------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.2e+03  |\n",
      "|    ep_rew_mean     | 1.78e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 180      |\n",
      "|    iterations      | 70       |\n",
      "|    time_elapsed    | 894      |\n",
      "|    total_timesteps | 161280   |\n",
      "---------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 1.22e+03       |\n",
      "|    ep_rew_mean          | 1.68e+03       |\n",
      "| time/                   |                |\n",
      "|    fps                  | 182            |\n",
      "|    iterations           | 71             |\n",
      "|    time_elapsed         | 897            |\n",
      "|    total_timesteps      | 163584         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -1.0361532e-09 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000711      |\n",
      "|    explained_variance   | 0.308          |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 13             |\n",
      "|    n_updates            | 700            |\n",
      "|    policy_gradient_loss | -1.29e-06      |\n",
      "|    value_loss           | 24.9           |\n",
      "--------------------------------------------\n",
      "Eval num_timesteps=165000, episode_reward=-3885.32 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "--------------------------------------------\n",
      "| eval/                   |                |\n",
      "|    mean_ep_length       | 2.3e+03        |\n",
      "|    mean_reward          | -3.89e+03      |\n",
      "| time/                   |                |\n",
      "|    total_timesteps      | 165000         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -1.6745787e-09 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000774      |\n",
      "|    explained_variance   | 0.315          |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 11.5           |\n",
      "|    n_updates            | 710            |\n",
      "|    policy_gradient_loss | -1.76e-06      |\n",
      "|    value_loss           | 24.7           |\n",
      "--------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.24e+03 |\n",
      "|    ep_rew_mean     | 1.6e+03  |\n",
      "| time/              |          |\n",
      "|    fps             | 178      |\n",
      "|    iterations      | 72       |\n",
      "|    time_elapsed    | 927      |\n",
      "|    total_timesteps | 165888   |\n",
      "---------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 1.25e+03       |\n",
      "|    ep_rew_mean          | 1.52e+03       |\n",
      "| time/                   |                |\n",
      "|    fps                  | 180            |\n",
      "|    iterations           | 73             |\n",
      "|    time_elapsed         | 930            |\n",
      "|    total_timesteps      | 168192         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -2.2628455e-09 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000846      |\n",
      "|    explained_variance   | 0.323          |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 12.1           |\n",
      "|    n_updates            | 720            |\n",
      "|    policy_gradient_loss | -1.94e-06      |\n",
      "|    value_loss           | 24.2           |\n",
      "--------------------------------------------\n",
      "Eval num_timesteps=170000, episode_reward=-3885.32 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "--------------------------------------------\n",
      "| eval/                   |                |\n",
      "|    mean_ep_length       | 2.3e+03        |\n",
      "|    mean_reward          | -3.89e+03      |\n",
      "| time/                   |                |\n",
      "|    total_timesteps      | 170000         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -3.5847278e-09 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.000952      |\n",
      "|    explained_variance   | 0.336          |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 12.8           |\n",
      "|    n_updates            | 730            |\n",
      "|    policy_gradient_loss | -2.87e-06      |\n",
      "|    value_loss           | 23.9           |\n",
      "--------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.27e+03 |\n",
      "|    ep_rew_mean     | 1.45e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 177      |\n",
      "|    iterations      | 74       |\n",
      "|    time_elapsed    | 960      |\n",
      "|    total_timesteps | 170496   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.29e+03      |\n",
      "|    ep_rew_mean          | 1.37e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 179           |\n",
      "|    iterations           | 75            |\n",
      "|    time_elapsed         | 963           |\n",
      "|    total_timesteps      | 172800        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -5.629056e-09 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0011       |\n",
      "|    explained_variance   | 0.345         |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 12.6          |\n",
      "|    n_updates            | 740           |\n",
      "|    policy_gradient_loss | -3.97e-06     |\n",
      "|    value_loss           | 24.1          |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=175000, episode_reward=-3885.32 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "--------------------------------------------\n",
      "| eval/                   |                |\n",
      "|    mean_ep_length       | 2.3e+03        |\n",
      "|    mean_reward          | -3.89e+03      |\n",
      "| time/                   |                |\n",
      "|    total_timesteps      | 175000         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -7.7444495e-09 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.00125       |\n",
      "|    explained_variance   | 0.341          |\n",
      "|    learning_rate        | 0.003          |\n",
      "|    loss                 | 12.6           |\n",
      "|    n_updates            | 750            |\n",
      "|    policy_gradient_loss | -3.85e-06      |\n",
      "|    value_loss           | 23.9           |\n",
      "--------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.31e+03 |\n",
      "|    ep_rew_mean     | 1.29e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 176      |\n",
      "|    iterations      | 76       |\n",
      "|    time_elapsed    | 993      |\n",
      "|    total_timesteps | 175104   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.32e+03    |\n",
      "|    ep_rew_mean          | 1.22e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 177         |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 996         |\n",
      "|    total_timesteps      | 177408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 5.05712e-09 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.00151    |\n",
      "|    explained_variance   | 0.345       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 11.8        |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -6.5e-06    |\n",
      "|    value_loss           | 23.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.34e+03     |\n",
      "|    ep_rew_mean          | 1.14e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 179          |\n",
      "|    iterations           | 78           |\n",
      "|    time_elapsed         | 1000         |\n",
      "|    total_timesteps      | 179712       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007873907 |\n",
      "|    clip_fraction        | 0.000352     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.00328     |\n",
      "|    explained_variance   | 0.265        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 17.5         |\n",
      "|    n_updates            | 770          |\n",
      "|    policy_gradient_loss | -0.000416    |\n",
      "|    value_loss           | 31.8         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=180000, episode_reward=-3885.32 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.3e+03     |\n",
      "|    mean_reward          | -3.89e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 180000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002945581 |\n",
      "|    clip_fraction        | 0.00043     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.00539    |\n",
      "|    explained_variance   | 0.331       |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.000349   |\n",
      "|    value_loss           | 24.7        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.36e+03 |\n",
      "|    ep_rew_mean     | 1.05e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 176      |\n",
      "|    iterations      | 79       |\n",
      "|    time_elapsed    | 1029     |\n",
      "|    total_timesteps | 182016   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.37e+03     |\n",
      "|    ep_rew_mean          | 1.03e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 178          |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 1032         |\n",
      "|    total_timesteps      | 184320       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020314518 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0304      |\n",
      "|    explained_variance   | 0.345        |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 11.8         |\n",
      "|    n_updates            | 790          |\n",
      "|    policy_gradient_loss | -0.00227     |\n",
      "|    value_loss           | 23.9         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=185000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 185000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8412336 |\n",
      "|    clip_fraction        | 0.362     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.0814   |\n",
      "|    explained_variance   | -0.0728   |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 281       |\n",
      "|    n_updates            | 800       |\n",
      "|    policy_gradient_loss | 0.0932    |\n",
      "|    value_loss           | 1.43e+03  |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.38e+03 |\n",
      "|    ep_rew_mean     | 490      |\n",
      "| time/              |          |\n",
      "|    fps             | 179      |\n",
      "|    iterations      | 81       |\n",
      "|    time_elapsed    | 1042     |\n",
      "|    total_timesteps | 186624   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.38e+03     |\n",
      "|    ep_rew_mean          | -212         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 180          |\n",
      "|    iterations           | 82           |\n",
      "|    time_elapsed         | 1045         |\n",
      "|    total_timesteps      | 188928       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006093009 |\n",
      "|    clip_fraction        | 0.00672      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0583      |\n",
      "|    explained_variance   | -1.79e-06    |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 5.32e+04     |\n",
      "|    n_updates            | 810          |\n",
      "|    policy_gradient_loss | -0.00324     |\n",
      "|    value_loss           | 1.13e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=190000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 576          |\n",
      "|    mean_reward          | -1.41e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 190000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005559102 |\n",
      "|    clip_fraction        | 0.00445      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0687      |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 4.47e+04     |\n",
      "|    n_updates            | 820          |\n",
      "|    policy_gradient_loss | -0.00285     |\n",
      "|    value_loss           | 1.01e+05     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.38e+03 |\n",
      "|    ep_rew_mean     | -747     |\n",
      "| time/              |          |\n",
      "|    fps             | 181      |\n",
      "|    iterations      | 83       |\n",
      "|    time_elapsed    | 1054     |\n",
      "|    total_timesteps | 191232   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.39e+03      |\n",
      "|    ep_rew_mean          | -1.43e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 182           |\n",
      "|    iterations           | 84            |\n",
      "|    time_elapsed         | 1057          |\n",
      "|    total_timesteps      | 193536        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00044480263 |\n",
      "|    clip_fraction        | 0.00434       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0829       |\n",
      "|    explained_variance   | -1.14e-05     |\n",
      "|    learning_rate        | 0.003         |\n",
      "|    loss                 | 4.4e+04       |\n",
      "|    n_updates            | 830           |\n",
      "|    policy_gradient_loss | -0.00278      |\n",
      "|    value_loss           | 9.98e+04      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=195000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 576          |\n",
      "|    mean_reward          | -1.41e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 195000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009957553 |\n",
      "|    clip_fraction        | 0.01         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.098       |\n",
      "|    explained_variance   | -6.91e-06    |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 3.25e+04     |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.00369     |\n",
      "|    value_loss           | 7.24e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.39e+03  |\n",
      "|    ep_rew_mean     | -1.89e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 183       |\n",
      "|    iterations      | 85        |\n",
      "|    time_elapsed    | 1067      |\n",
      "|    total_timesteps | 195840    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.39e+03     |\n",
      "|    ep_rew_mean          | -2.33e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 185          |\n",
      "|    iterations           | 86           |\n",
      "|    time_elapsed         | 1070         |\n",
      "|    total_timesteps      | 198144       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028442838 |\n",
      "|    clip_fraction        | 0.02         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.12        |\n",
      "|    explained_variance   | -1.91e-06    |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 2.51e+04     |\n",
      "|    n_updates            | 850          |\n",
      "|    policy_gradient_loss | -0.00602     |\n",
      "|    value_loss           | 5.4e+04      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=200000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 576         |\n",
      "|    mean_reward          | -1.41e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 200000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004956889 |\n",
      "|    clip_fraction        | 0.0279      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.152      |\n",
      "|    explained_variance   | -2.26e-06   |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.88e+04    |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.00696    |\n",
      "|    value_loss           | 4.02e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.4e+03   |\n",
      "|    ep_rew_mean     | -2.69e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 185       |\n",
      "|    iterations      | 87        |\n",
      "|    time_elapsed    | 1080      |\n",
      "|    total_timesteps | 200448    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.41e+03   |\n",
      "|    ep_rew_mean          | -2.83e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 187        |\n",
      "|    iterations           | 88         |\n",
      "|    time_elapsed         | 1083       |\n",
      "|    total_timesteps      | 202752     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01725863 |\n",
      "|    clip_fraction        | 0.0998     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.208     |\n",
      "|    explained_variance   | -2.38e-06  |\n",
      "|    learning_rate        | 0.003      |\n",
      "|    loss                 | 7.98e+03   |\n",
      "|    n_updates            | 870        |\n",
      "|    policy_gradient_loss | -0.0135    |\n",
      "|    value_loss           | 1.64e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=205000, episode_reward=-11185.87 +/- 0.00\n",
      "Episode length: 648.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 648        |\n",
      "|    mean_reward          | -1.12e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 205000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01457184 |\n",
      "|    clip_fraction        | 0.139      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.246     |\n",
      "|    explained_variance   | -2.5e-06   |\n",
      "|    learning_rate        | 0.003      |\n",
      "|    loss                 | 2.34e+03   |\n",
      "|    n_updates            | 880        |\n",
      "|    policy_gradient_loss | -0.0148    |\n",
      "|    value_loss           | 6.24e+03   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.42e+03  |\n",
      "|    ep_rew_mean     | -2.88e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 187       |\n",
      "|    iterations      | 89        |\n",
      "|    time_elapsed    | 1094      |\n",
      "|    total_timesteps | 205056    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.44e+03    |\n",
      "|    ep_rew_mean          | -2.9e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 188         |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 1097        |\n",
      "|    total_timesteps      | 207360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005625252 |\n",
      "|    clip_fraction        | 0.09        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.255      |\n",
      "|    explained_variance   | -2.98e-06   |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 2.38e+03    |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | -0.00813    |\n",
      "|    value_loss           | 6.28e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.46e+03     |\n",
      "|    ep_rew_mean          | -2.91e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 190          |\n",
      "|    iterations           | 91           |\n",
      "|    time_elapsed         | 1100         |\n",
      "|    total_timesteps      | 209664       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066969683 |\n",
      "|    clip_fraction        | 0.0818       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.254       |\n",
      "|    explained_variance   | -5.36e-06    |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.89e+03     |\n",
      "|    n_updates            | 900          |\n",
      "|    policy_gradient_loss | -0.0071      |\n",
      "|    value_loss           | 5.27e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=210000, episode_reward=4841.29 +/- 0.10\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.3e+03     |\n",
      "|    mean_reward          | 4.84e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 210000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004112487 |\n",
      "|    clip_fraction        | 0.0268      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.254      |\n",
      "|    explained_variance   | -1.59e-05   |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.6e+03     |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.0024     |\n",
      "|    value_loss           | 4.71e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.48e+03 |\n",
      "|    ep_rew_mean     | -2.9e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 187      |\n",
      "|    iterations      | 92       |\n",
      "|    time_elapsed    | 1130     |\n",
      "|    total_timesteps | 211968   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.49e+03    |\n",
      "|    ep_rew_mean          | -2.89e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 189         |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 1133        |\n",
      "|    total_timesteps      | 214272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005404598 |\n",
      "|    clip_fraction        | 0.0651      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.249      |\n",
      "|    explained_variance   | -1.13e-05   |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 1.56e+03    |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.00671    |\n",
      "|    value_loss           | 4.49e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=215000, episode_reward=5270.97 +/- 0.02\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.3e+03    |\n",
      "|    mean_reward          | 5.27e+03   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 215000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00509861 |\n",
      "|    clip_fraction        | 0.0976     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.25      |\n",
      "|    explained_variance   | -2e-05     |\n",
      "|    learning_rate        | 0.003      |\n",
      "|    loss                 | 1.51e+03   |\n",
      "|    n_updates            | 930        |\n",
      "|    policy_gradient_loss | -0.00882   |\n",
      "|    value_loss           | 4.47e+03   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.51e+03  |\n",
      "|    ep_rew_mean     | -2.89e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 186       |\n",
      "|    iterations      | 94        |\n",
      "|    time_elapsed    | 1163      |\n",
      "|    total_timesteps | 216576    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.53e+03     |\n",
      "|    ep_rew_mean          | -2.9e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 187          |\n",
      "|    iterations           | 95           |\n",
      "|    time_elapsed         | 1166         |\n",
      "|    total_timesteps      | 218880       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035956223 |\n",
      "|    clip_fraction        | 0.0428       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.247       |\n",
      "|    explained_variance   | -1.53e-05    |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.34e+03     |\n",
      "|    n_updates            | 940          |\n",
      "|    policy_gradient_loss | -0.00496     |\n",
      "|    value_loss           | 3.76e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=220000, episode_reward=6103.03 +/- 0.03\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.3e+03      |\n",
      "|    mean_reward          | 6.1e+03      |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 220000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076590204 |\n",
      "|    clip_fraction        | 0.0875       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.244       |\n",
      "|    explained_variance   | -2.56e-05    |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.12e+03     |\n",
      "|    n_updates            | 950          |\n",
      "|    policy_gradient_loss | -0.00427     |\n",
      "|    value_loss           | 3.43e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.54e+03  |\n",
      "|    ep_rew_mean     | -2.89e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 184       |\n",
      "|    iterations      | 96        |\n",
      "|    time_elapsed    | 1196      |\n",
      "|    total_timesteps | 221184    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.56e+03     |\n",
      "|    ep_rew_mean          | -2.88e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 186          |\n",
      "|    iterations           | 97           |\n",
      "|    time_elapsed         | 1199         |\n",
      "|    total_timesteps      | 223488       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041244747 |\n",
      "|    clip_fraction        | 0.0352       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.235       |\n",
      "|    explained_variance   | -1.47e-05    |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 1.05e+03     |\n",
      "|    n_updates            | 960          |\n",
      "|    policy_gradient_loss | -0.00416     |\n",
      "|    value_loss           | 3.05e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=225000, episode_reward=6054.52 +/- 0.05\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.3e+03     |\n",
      "|    mean_reward          | 6.05e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 225000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005858732 |\n",
      "|    clip_fraction        | 0.0333      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.231      |\n",
      "|    explained_variance   | -3.24e-05   |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 967         |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | -0.00349    |\n",
      "|    value_loss           | 2.87e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.58e+03  |\n",
      "|    ep_rew_mean     | -2.87e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 183       |\n",
      "|    iterations      | 98        |\n",
      "|    time_elapsed    | 1229      |\n",
      "|    total_timesteps | 225792    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.6e+03    |\n",
      "|    ep_rew_mean          | -2.86e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 185        |\n",
      "|    iterations           | 99         |\n",
      "|    time_elapsed         | 1232       |\n",
      "|    total_timesteps      | 228096     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00448111 |\n",
      "|    clip_fraction        | 0.0521     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.223     |\n",
      "|    explained_variance   | -3.23e-05  |\n",
      "|    learning_rate        | 0.003      |\n",
      "|    loss                 | 823        |\n",
      "|    n_updates            | 980        |\n",
      "|    policy_gradient_loss | -0.00346   |\n",
      "|    value_loss           | 2.59e+03   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=230000, episode_reward=6051.81 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.3e+03     |\n",
      "|    mean_reward          | 6.05e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 230000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006156651 |\n",
      "|    clip_fraction        | 0.0294      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.219      |\n",
      "|    explained_variance   | -7.8e-05    |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 899         |\n",
      "|    n_updates            | 990         |\n",
      "|    policy_gradient_loss | -0.0031     |\n",
      "|    value_loss           | 2.75e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.61e+03  |\n",
      "|    ep_rew_mean     | -2.86e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 182       |\n",
      "|    iterations      | 100       |\n",
      "|    time_elapsed    | 1262      |\n",
      "|    total_timesteps | 230400    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.63e+03    |\n",
      "|    ep_rew_mean          | -2.85e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 183         |\n",
      "|    iterations           | 101         |\n",
      "|    time_elapsed         | 1265        |\n",
      "|    total_timesteps      | 232704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006719251 |\n",
      "|    clip_fraction        | 0.0894      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.218      |\n",
      "|    explained_variance   | -8.05e-05   |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 420         |\n",
      "|    n_updates            | 1000        |\n",
      "|    policy_gradient_loss | -0.00245    |\n",
      "|    value_loss           | 2.05e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=235000, episode_reward=7113.81 +/- 0.10\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.3e+03     |\n",
      "|    mean_reward          | 7.11e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 235000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004143297 |\n",
      "|    clip_fraction        | 0.0497      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.215      |\n",
      "|    explained_variance   | -8.82e-06   |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 530         |\n",
      "|    n_updates            | 1010        |\n",
      "|    policy_gradient_loss | -0.00365    |\n",
      "|    value_loss           | 1.79e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.65e+03  |\n",
      "|    ep_rew_mean     | -2.85e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 181       |\n",
      "|    iterations      | 102       |\n",
      "|    time_elapsed    | 1294      |\n",
      "|    total_timesteps | 235008    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.66e+03   |\n",
      "|    ep_rew_mean          | -2.84e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 182        |\n",
      "|    iterations           | 103        |\n",
      "|    time_elapsed         | 1298       |\n",
      "|    total_timesteps      | 237312     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01660526 |\n",
      "|    clip_fraction        | 0.0594     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.207     |\n",
      "|    explained_variance   | -1.92e-05  |\n",
      "|    learning_rate        | 0.003      |\n",
      "|    loss                 | 432        |\n",
      "|    n_updates            | 1020       |\n",
      "|    policy_gradient_loss | 0.00177    |\n",
      "|    value_loss           | 1.51e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.68e+03    |\n",
      "|    ep_rew_mean          | -2.84e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 184         |\n",
      "|    iterations           | 104         |\n",
      "|    time_elapsed         | 1301        |\n",
      "|    total_timesteps      | 239616      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008613292 |\n",
      "|    clip_fraction        | 0.04        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.194      |\n",
      "|    explained_variance   | -2.15e-05   |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 290         |\n",
      "|    n_updates            | 1030        |\n",
      "|    policy_gradient_loss | -0.000484   |\n",
      "|    value_loss           | 1.2e+03     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=240000, episode_reward=6904.26 +/- 0.01\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.3e+03     |\n",
      "|    mean_reward          | 6.9e+03     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 240000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008483902 |\n",
      "|    clip_fraction        | 0.0646      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.189      |\n",
      "|    explained_variance   | -2.48e-05   |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 281         |\n",
      "|    n_updates            | 1040        |\n",
      "|    policy_gradient_loss | 0.000331    |\n",
      "|    value_loss           | 1.15e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.7e+03   |\n",
      "|    ep_rew_mean     | -2.83e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 181       |\n",
      "|    iterations      | 105       |\n",
      "|    time_elapsed    | 1331      |\n",
      "|    total_timesteps | 241920    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.71e+03    |\n",
      "|    ep_rew_mean          | -2.82e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 183         |\n",
      "|    iterations           | 106         |\n",
      "|    time_elapsed         | 1334        |\n",
      "|    total_timesteps      | 244224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006431392 |\n",
      "|    clip_fraction        | 0.045       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.181      |\n",
      "|    explained_variance   | -2.57e-05   |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 218         |\n",
      "|    n_updates            | 1050        |\n",
      "|    policy_gradient_loss | -0.00174    |\n",
      "|    value_loss           | 961         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=245000, episode_reward=7419.06 +/- 0.04\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.3e+03      |\n",
      "|    mean_reward          | 7.42e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 245000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058396054 |\n",
      "|    clip_fraction        | 0.0387       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.17        |\n",
      "|    explained_variance   | -1.98e-05    |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 175          |\n",
      "|    n_updates            | 1060         |\n",
      "|    policy_gradient_loss | -0.00502     |\n",
      "|    value_loss           | 826          |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.73e+03  |\n",
      "|    ep_rew_mean     | -2.81e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 180       |\n",
      "|    iterations      | 107       |\n",
      "|    time_elapsed    | 1363      |\n",
      "|    total_timesteps | 246528    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.75e+03     |\n",
      "|    ep_rew_mean          | -2.79e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 182          |\n",
      "|    iterations           | 108          |\n",
      "|    time_elapsed         | 1367         |\n",
      "|    total_timesteps      | 248832       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049896436 |\n",
      "|    clip_fraction        | 0.0338       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.166       |\n",
      "|    explained_variance   | -2.62e-05    |\n",
      "|    learning_rate        | 0.003        |\n",
      "|    loss                 | 134          |\n",
      "|    n_updates            | 1070         |\n",
      "|    policy_gradient_loss | -0.0037      |\n",
      "|    value_loss           | 717          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=250000, episode_reward=4217.88 +/- 0.21\n",
      "Episode length: 1440.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.44e+03    |\n",
      "|    mean_reward          | 4.22e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 250000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004800797 |\n",
      "|    clip_fraction        | 0.022       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.157      |\n",
      "|    explained_variance   | -2.79e-05   |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 169         |\n",
      "|    n_updates            | 1080        |\n",
      "|    policy_gradient_loss | -0.00363    |\n",
      "|    value_loss           | 752         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.76e+03  |\n",
      "|    ep_rew_mean     | -2.77e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 181       |\n",
      "|    iterations      | 109       |\n",
      "|    time_elapsed    | 1386      |\n",
      "|    total_timesteps | 251136    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.78e+03    |\n",
      "|    ep_rew_mean          | -2.75e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 182         |\n",
      "|    iterations           | 110         |\n",
      "|    time_elapsed         | 1389        |\n",
      "|    total_timesteps      | 253440      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006143882 |\n",
      "|    clip_fraction        | 0.022       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.142      |\n",
      "|    explained_variance   | -3.33e-05   |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 111         |\n",
      "|    n_updates            | 1090        |\n",
      "|    policy_gradient_loss | -0.00251    |\n",
      "|    value_loss           | 583         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=255000, episode_reward=4217.95 +/- 0.00\n",
      "Episode length: 1440.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.44e+03    |\n",
      "|    mean_reward          | 4.22e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 255000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009226387 |\n",
      "|    clip_fraction        | 0.0327      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.134      |\n",
      "|    explained_variance   | -3.87e-05   |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 87.5        |\n",
      "|    n_updates            | 1100        |\n",
      "|    policy_gradient_loss | 0.000888    |\n",
      "|    value_loss           | 456         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.8e+03   |\n",
      "|    ep_rew_mean     | -2.74e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 181       |\n",
      "|    iterations      | 111       |\n",
      "|    time_elapsed    | 1409      |\n",
      "|    total_timesteps | 255744    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.81e+03    |\n",
      "|    ep_rew_mean          | -2.73e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 182         |\n",
      "|    iterations           | 112         |\n",
      "|    time_elapsed         | 1412        |\n",
      "|    total_timesteps      | 258048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011277524 |\n",
      "|    clip_fraction        | 0.0591      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.135      |\n",
      "|    explained_variance   | -3.06e-05   |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 145         |\n",
      "|    n_updates            | 1110        |\n",
      "|    policy_gradient_loss | 0.00623     |\n",
      "|    value_loss           | 392         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=260000, episode_reward=6947.61 +/- 0.09\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.3e+03     |\n",
      "|    mean_reward          | 6.95e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 260000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009707456 |\n",
      "|    clip_fraction        | 0.0864      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.118      |\n",
      "|    explained_variance   | -5.72e-05   |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 44.6        |\n",
      "|    n_updates            | 1120        |\n",
      "|    policy_gradient_loss | 0.0069      |\n",
      "|    value_loss           | 282         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.83e+03 |\n",
      "|    ep_rew_mean     | -2.7e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 180      |\n",
      "|    iterations      | 113      |\n",
      "|    time_elapsed    | 1442     |\n",
      "|    total_timesteps | 260352   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.85e+03    |\n",
      "|    ep_rew_mean          | -2.65e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 181         |\n",
      "|    iterations           | 114         |\n",
      "|    time_elapsed         | 1445        |\n",
      "|    total_timesteps      | 262656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007958131 |\n",
      "|    clip_fraction        | 0.049       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.116      |\n",
      "|    explained_variance   | -7.81e-05   |\n",
      "|    learning_rate        | 0.003       |\n",
      "|    loss                 | 46.2        |\n",
      "|    n_updates            | 1130        |\n",
      "|    policy_gradient_loss | -0.00175    |\n",
      "|    value_loss           | 246         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.87e+03   |\n",
      "|    ep_rew_mean          | -3.17e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 182        |\n",
      "|    iterations           | 115        |\n",
      "|    time_elapsed         | 1449       |\n",
      "|    total_timesteps      | 264960     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.79076105 |\n",
      "|    clip_fraction        | 0.157      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0197    |\n",
      "|    explained_variance   | -5.73e-05  |\n",
      "|    learning_rate        | 0.003      |\n",
      "|    loss                 | 41.7       |\n",
      "|    n_updates            | 1140       |\n",
      "|    policy_gradient_loss | 0.203      |\n",
      "|    value_loss           | 109        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=265000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 576        |\n",
      "|    mean_reward          | -1.41e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 265000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02325087 |\n",
      "|    clip_fraction        | 0.00262    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.000247  |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.003      |\n",
      "|    loss                 | 9.05e+04   |\n",
      "|    n_updates            | 1150       |\n",
      "|    policy_gradient_loss | 0.00701    |\n",
      "|    value_loss           | 1.9e+05    |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.8e+03  |\n",
      "|    ep_rew_mean     | -3.6e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 183      |\n",
      "|    iterations      | 116      |\n",
      "|    time_elapsed    | 1458     |\n",
      "|    total_timesteps | 267264   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.73e+03  |\n",
      "|    ep_rew_mean          | -4.1e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 184       |\n",
      "|    iterations           | 117       |\n",
      "|    time_elapsed         | 1462      |\n",
      "|    total_timesteps      | 269568    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.99e-07 |\n",
      "|    explained_variance   | 2.98e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 9.2e+04   |\n",
      "|    n_updates            | 1160      |\n",
      "|    policy_gradient_loss | 3.74e-08  |\n",
      "|    value_loss           | 1.93e+05  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=270000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 270000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.94e-07 |\n",
      "|    explained_variance   | 2.98e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 9.02e+04  |\n",
      "|    n_updates            | 1170      |\n",
      "|    policy_gradient_loss | 1.29e-08  |\n",
      "|    value_loss           | 1.9e+05   |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.66e+03  |\n",
      "|    ep_rew_mean     | -4.62e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 184       |\n",
      "|    iterations      | 118       |\n",
      "|    time_elapsed    | 1471      |\n",
      "|    total_timesteps | 271872    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.59e+03  |\n",
      "|    ep_rew_mean          | -5.13e+03 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 185       |\n",
      "|    iterations           | 119       |\n",
      "|    time_elapsed         | 1474      |\n",
      "|    total_timesteps      | 274176    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.97e-07 |\n",
      "|    explained_variance   | 5.96e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 8.57e+04  |\n",
      "|    n_updates            | 1180      |\n",
      "|    policy_gradient_loss | 1.78e-08  |\n",
      "|    value_loss           | 1.81e+05  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=275000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 275000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.98e-07 |\n",
      "|    explained_variance   | 1.79e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 8.24e+04  |\n",
      "|    n_updates            | 1190      |\n",
      "|    policy_gradient_loss | 3.76e-08  |\n",
      "|    value_loss           | 1.75e+05  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.52e+03  |\n",
      "|    ep_rew_mean     | -5.54e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 186       |\n",
      "|    iterations      | 120       |\n",
      "|    time_elapsed    | 1484      |\n",
      "|    total_timesteps | 276480    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.45e+03  |\n",
      "|    ep_rew_mean          | -5.94e+03 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 187       |\n",
      "|    iterations           | 121       |\n",
      "|    time_elapsed         | 1487      |\n",
      "|    total_timesteps      | 278784    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.96e-07 |\n",
      "|    explained_variance   | 4.77e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 8.07e+04  |\n",
      "|    n_updates            | 1200      |\n",
      "|    policy_gradient_loss | -5.69e-08 |\n",
      "|    value_loss           | 1.73e+05  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=280000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 280000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.95e-07 |\n",
      "|    explained_variance   | 5.96e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 7.87e+04  |\n",
      "|    n_updates            | 1210      |\n",
      "|    policy_gradient_loss | -2.58e-09 |\n",
      "|    value_loss           | 1.68e+05  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.38e+03  |\n",
      "|    ep_rew_mean     | -6.35e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 187       |\n",
      "|    iterations      | 122       |\n",
      "|    time_elapsed    | 1497      |\n",
      "|    total_timesteps | 281088    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.31e+03  |\n",
      "|    ep_rew_mean          | -6.76e+03 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 188       |\n",
      "|    iterations           | 123       |\n",
      "|    time_elapsed         | 1500      |\n",
      "|    total_timesteps      | 283392    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.97e-07 |\n",
      "|    explained_variance   | 6.56e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 7.33e+04  |\n",
      "|    n_updates            | 1220      |\n",
      "|    policy_gradient_loss | 3.69e-08  |\n",
      "|    value_loss           | 1.61e+05  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=285000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 285000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.95e-07 |\n",
      "|    explained_variance   | 5.96e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 7.68e+04  |\n",
      "|    n_updates            | 1230      |\n",
      "|    policy_gradient_loss | 2.71e-09  |\n",
      "|    value_loss           | 1.63e+05  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.24e+03  |\n",
      "|    ep_rew_mean     | -7.17e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 189       |\n",
      "|    iterations      | 124       |\n",
      "|    time_elapsed    | 1510      |\n",
      "|    total_timesteps | 285696    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.17e+03  |\n",
      "|    ep_rew_mean          | -7.58e+03 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 190       |\n",
      "|    iterations           | 125       |\n",
      "|    time_elapsed         | 1513      |\n",
      "|    total_timesteps      | 288000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.98e-07 |\n",
      "|    explained_variance   | 6.62e-06  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 7.3e+04   |\n",
      "|    n_updates            | 1240      |\n",
      "|    policy_gradient_loss | -3.33e-08 |\n",
      "|    value_loss           | 1.54e+05  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=290000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 290000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.97e-07 |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 6.39e+04  |\n",
      "|    n_updates            | 1250      |\n",
      "|    policy_gradient_loss | -3.69e-08 |\n",
      "|    value_loss           | 1.42e+05  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.11e+03  |\n",
      "|    ep_rew_mean     | -7.99e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 190       |\n",
      "|    iterations      | 126       |\n",
      "|    time_elapsed    | 1523      |\n",
      "|    total_timesteps | 290304    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.07e+03  |\n",
      "|    ep_rew_mean          | -8.26e+03 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 191       |\n",
      "|    iterations           | 127       |\n",
      "|    time_elapsed         | 1526      |\n",
      "|    total_timesteps      | 292608    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.95e-07 |\n",
      "|    explained_variance   | 1.79e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 7.04e+04  |\n",
      "|    n_updates            | 1260      |\n",
      "|    policy_gradient_loss | 9.25e-09  |\n",
      "|    value_loss           | 1.5e+05   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.06e+03  |\n",
      "|    ep_rew_mean          | -8.29e+03 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 192       |\n",
      "|    iterations           | 128       |\n",
      "|    time_elapsed         | 1529      |\n",
      "|    total_timesteps      | 294912    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.95e-07 |\n",
      "|    explained_variance   | 2.98e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 6.75e+04  |\n",
      "|    n_updates            | 1270      |\n",
      "|    policy_gradient_loss | -8.25e-09 |\n",
      "|    value_loss           | 1.43e+05  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=295000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 295000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.98e-07 |\n",
      "|    explained_variance   | 2.38e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 6.62e+04  |\n",
      "|    n_updates            | 1280      |\n",
      "|    policy_gradient_loss | 1.1e-08   |\n",
      "|    value_loss           | 1.41e+05  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.06e+03  |\n",
      "|    ep_rew_mean     | -8.33e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 193       |\n",
      "|    iterations      | 129       |\n",
      "|    time_elapsed    | 1539      |\n",
      "|    total_timesteps | 297216    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.06e+03  |\n",
      "|    ep_rew_mean          | -8.39e+03 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 194       |\n",
      "|    iterations           | 130       |\n",
      "|    time_elapsed         | 1542      |\n",
      "|    total_timesteps      | 299520    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.97e-07 |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 6.29e+04  |\n",
      "|    n_updates            | 1290      |\n",
      "|    policy_gradient_loss | -4.69e-08 |\n",
      "|    value_loss           | 1.39e+05  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=300000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 300000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.94e-07 |\n",
      "|    explained_variance   | 2.98e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 6.24e+04  |\n",
      "|    n_updates            | 1300      |\n",
      "|    policy_gradient_loss | -2.79e-08 |\n",
      "|    value_loss           | 1.35e+05  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.05e+03  |\n",
      "|    ep_rew_mean     | -8.51e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 194       |\n",
      "|    iterations      | 131       |\n",
      "|    time_elapsed    | 1552      |\n",
      "|    total_timesteps | 301824    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.05e+03  |\n",
      "|    ep_rew_mean          | -8.72e+03 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 195       |\n",
      "|    iterations           | 132       |\n",
      "|    time_elapsed         | 1555      |\n",
      "|    total_timesteps      | 304128    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.92e-07 |\n",
      "|    explained_variance   | 1.79e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 6.15e+04  |\n",
      "|    n_updates            | 1310      |\n",
      "|    policy_gradient_loss | 3.28e-08  |\n",
      "|    value_loss           | 1.3e+05   |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=305000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 305000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.95e-07 |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 5.8e+04   |\n",
      "|    n_updates            | 1320      |\n",
      "|    policy_gradient_loss | 2.39e-08  |\n",
      "|    value_loss           | 1.26e+05  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.02e+03  |\n",
      "|    ep_rew_mean     | -9.18e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 195       |\n",
      "|    iterations      | 133       |\n",
      "|    time_elapsed    | 1564      |\n",
      "|    total_timesteps | 306432    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 954       |\n",
      "|    ep_rew_mean          | -9.89e+03 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 196       |\n",
      "|    iterations           | 134       |\n",
      "|    time_elapsed         | 1568      |\n",
      "|    total_timesteps      | 308736    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.95e-07 |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 5.99e+04  |\n",
      "|    n_updates            | 1330      |\n",
      "|    policy_gradient_loss | 2.82e-08  |\n",
      "|    value_loss           | 1.27e+05  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=310000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 310000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.97e-07 |\n",
      "|    explained_variance   | 4.17e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 5.52e+04  |\n",
      "|    n_updates            | 1340      |\n",
      "|    policy_gradient_loss | 1.06e-08  |\n",
      "|    value_loss           | 1.24e+05  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 884       |\n",
      "|    ep_rew_mean     | -1.06e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 197       |\n",
      "|    iterations      | 135       |\n",
      "|    time_elapsed    | 1577      |\n",
      "|    total_timesteps | 311040    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 815       |\n",
      "|    ep_rew_mean          | -1.14e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 198       |\n",
      "|    iterations           | 136       |\n",
      "|    time_elapsed         | 1580      |\n",
      "|    total_timesteps      | 313344    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.95e-07 |\n",
      "|    explained_variance   | 1.49e-06  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 5.13e+04  |\n",
      "|    n_updates            | 1350      |\n",
      "|    policy_gradient_loss | -2.57e-08 |\n",
      "|    value_loss           | 1.14e+05  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=315000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 315000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.97e-07 |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 5.48e+04  |\n",
      "|    n_updates            | 1360      |\n",
      "|    policy_gradient_loss | 4.37e-09  |\n",
      "|    value_loss           | 1.15e+05  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 746       |\n",
      "|    ep_rew_mean     | -1.22e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 198       |\n",
      "|    iterations      | 137       |\n",
      "|    time_elapsed    | 1590      |\n",
      "|    total_timesteps | 315648    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 677       |\n",
      "|    ep_rew_mean          | -1.3e+04  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 199       |\n",
      "|    iterations           | 138       |\n",
      "|    time_elapsed         | 1593      |\n",
      "|    total_timesteps      | 317952    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.94e-07 |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 5.57e+04  |\n",
      "|    n_updates            | 1370      |\n",
      "|    policy_gradient_loss | 3.54e-08  |\n",
      "|    value_loss           | 1.15e+05  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=320000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 320000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.95e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 5.42e+04  |\n",
      "|    n_updates            | 1380      |\n",
      "|    policy_gradient_loss | 2.2e-09   |\n",
      "|    value_loss           | 1.12e+05  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 608       |\n",
      "|    ep_rew_mean     | -1.39e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 199       |\n",
      "|    iterations      | 139       |\n",
      "|    time_elapsed    | 1603      |\n",
      "|    total_timesteps | 320256    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 200       |\n",
      "|    iterations           | 140       |\n",
      "|    time_elapsed         | 1606      |\n",
      "|    total_timesteps      | 322560    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.98e-07 |\n",
      "|    explained_variance   | 1.79e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 5.18e+04  |\n",
      "|    n_updates            | 1390      |\n",
      "|    policy_gradient_loss | -1.72e-09 |\n",
      "|    value_loss           | 1.11e+05  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 201       |\n",
      "|    iterations           | 141       |\n",
      "|    time_elapsed         | 1609      |\n",
      "|    total_timesteps      | 324864    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.95e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 4.92e+04  |\n",
      "|    n_updates            | 1400      |\n",
      "|    policy_gradient_loss | 1.64e-09  |\n",
      "|    value_loss           | 1.06e+05  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=325000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 325000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.95e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 5.12e+04  |\n",
      "|    n_updates            | 1410      |\n",
      "|    policy_gradient_loss | 8.36e-09  |\n",
      "|    value_loss           | 1.06e+05  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 201       |\n",
      "|    iterations      | 142       |\n",
      "|    time_elapsed    | 1619      |\n",
      "|    total_timesteps | 327168    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 203       |\n",
      "|    iterations           | 143       |\n",
      "|    time_elapsed         | 1622      |\n",
      "|    total_timesteps      | 329472    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.94e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 4.8e+04   |\n",
      "|    n_updates            | 1420      |\n",
      "|    policy_gradient_loss | 1.04e-08  |\n",
      "|    value_loss           | 1.04e+05  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=330000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 330000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.93e-07 |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 4.88e+04  |\n",
      "|    n_updates            | 1430      |\n",
      "|    policy_gradient_loss | 2.08e-08  |\n",
      "|    value_loss           | 1.02e+05  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 203       |\n",
      "|    iterations      | 144       |\n",
      "|    time_elapsed    | 1632      |\n",
      "|    total_timesteps | 331776    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 204       |\n",
      "|    iterations           | 145       |\n",
      "|    time_elapsed         | 1635      |\n",
      "|    total_timesteps      | 334080    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.96e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 4.93e+04  |\n",
      "|    n_updates            | 1440      |\n",
      "|    policy_gradient_loss | 5.67e-09  |\n",
      "|    value_loss           | 1e+05     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=335000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 335000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.98e-07 |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 4.68e+04  |\n",
      "|    n_updates            | 1450      |\n",
      "|    policy_gradient_loss | -2.36e-09 |\n",
      "|    value_loss           | 9.88e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 204       |\n",
      "|    iterations      | 146       |\n",
      "|    time_elapsed    | 1645      |\n",
      "|    total_timesteps | 336384    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 205       |\n",
      "|    iterations           | 147       |\n",
      "|    time_elapsed         | 1648      |\n",
      "|    total_timesteps      | 338688    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.93e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 4.46e+04  |\n",
      "|    n_updates            | 1460      |\n",
      "|    policy_gradient_loss | -3.36e-08 |\n",
      "|    value_loss           | 9.7e+04   |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=340000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 340000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.97e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 4.42e+04  |\n",
      "|    n_updates            | 1470      |\n",
      "|    policy_gradient_loss | -1.77e-08 |\n",
      "|    value_loss           | 9.54e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 205       |\n",
      "|    iterations      | 148       |\n",
      "|    time_elapsed    | 1658      |\n",
      "|    total_timesteps | 340992    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 206       |\n",
      "|    iterations           | 149       |\n",
      "|    time_elapsed         | 1661      |\n",
      "|    total_timesteps      | 343296    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.98e-07 |\n",
      "|    explained_variance   | 2.38e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 4.54e+04  |\n",
      "|    n_updates            | 1480      |\n",
      "|    policy_gradient_loss | 2.45e-08  |\n",
      "|    value_loss           | 9.37e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=345000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 345000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.95e-07 |\n",
      "|    explained_variance   | 5.36e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 4.25e+04  |\n",
      "|    n_updates            | 1490      |\n",
      "|    policy_gradient_loss | 2.34e-08  |\n",
      "|    value_loss           | 9.1e+04   |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 206       |\n",
      "|    iterations      | 150       |\n",
      "|    time_elapsed    | 1671      |\n",
      "|    total_timesteps | 345600    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 207       |\n",
      "|    iterations           | 151       |\n",
      "|    time_elapsed         | 1674      |\n",
      "|    total_timesteps      | 347904    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.95e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 4.2e+04   |\n",
      "|    n_updates            | 1500      |\n",
      "|    policy_gradient_loss | -5.9e-09  |\n",
      "|    value_loss           | 9.01e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=350000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 350000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.96e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 4.28e+04  |\n",
      "|    n_updates            | 1510      |\n",
      "|    policy_gradient_loss | -9.61e-09 |\n",
      "|    value_loss           | 8.85e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 207       |\n",
      "|    iterations      | 152       |\n",
      "|    time_elapsed    | 1684      |\n",
      "|    total_timesteps | 350208    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 208       |\n",
      "|    iterations           | 153       |\n",
      "|    time_elapsed         | 1687      |\n",
      "|    total_timesteps      | 352512    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.96e-07 |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 4.2e+04   |\n",
      "|    n_updates            | 1520      |\n",
      "|    policy_gradient_loss | -3.39e-08 |\n",
      "|    value_loss           | 8.69e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 209       |\n",
      "|    iterations           | 154       |\n",
      "|    time_elapsed         | 1690      |\n",
      "|    total_timesteps      | 354816    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.96e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 4.12e+04  |\n",
      "|    n_updates            | 1530      |\n",
      "|    policy_gradient_loss | 3.22e-09  |\n",
      "|    value_loss           | 8.56e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=355000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 355000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.95e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.75e+04  |\n",
      "|    n_updates            | 1540      |\n",
      "|    policy_gradient_loss | 2.08e-08  |\n",
      "|    value_loss           | 8.41e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 210       |\n",
      "|    iterations      | 155       |\n",
      "|    time_elapsed    | 1699      |\n",
      "|    total_timesteps | 357120    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 211       |\n",
      "|    iterations           | 156       |\n",
      "|    time_elapsed         | 1703      |\n",
      "|    total_timesteps      | 359424    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.95e-07 |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.77e+04  |\n",
      "|    n_updates            | 1550      |\n",
      "|    policy_gradient_loss | -1.15e-09 |\n",
      "|    value_loss           | 8.28e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=360000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 360000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.92e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.95e+04  |\n",
      "|    n_updates            | 1560      |\n",
      "|    policy_gradient_loss | -1.35e-08 |\n",
      "|    value_loss           | 8.14e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 211       |\n",
      "|    iterations      | 157       |\n",
      "|    time_elapsed    | 1712      |\n",
      "|    total_timesteps | 361728    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 212       |\n",
      "|    iterations           | 158       |\n",
      "|    time_elapsed         | 1715      |\n",
      "|    total_timesteps      | 364032    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.96e-07 |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.57e+04  |\n",
      "|    n_updates            | 1570      |\n",
      "|    policy_gradient_loss | 4.98e-09  |\n",
      "|    value_loss           | 8e+04     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=365000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 365000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.94e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.5e+04   |\n",
      "|    n_updates            | 1580      |\n",
      "|    policy_gradient_loss | -1.07e-09 |\n",
      "|    value_loss           | 7.87e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 212       |\n",
      "|    iterations      | 159       |\n",
      "|    time_elapsed    | 1725      |\n",
      "|    total_timesteps | 366336    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 213       |\n",
      "|    iterations           | 160       |\n",
      "|    time_elapsed         | 1728      |\n",
      "|    total_timesteps      | 368640    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.96e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.46e+04  |\n",
      "|    n_updates            | 1590      |\n",
      "|    policy_gradient_loss | -7.27e-09 |\n",
      "|    value_loss           | 7.76e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=370000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 370000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.97e-07 |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.44e+04  |\n",
      "|    n_updates            | 1600      |\n",
      "|    policy_gradient_loss | 1.39e-08  |\n",
      "|    value_loss           | 7.61e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 213       |\n",
      "|    iterations      | 161       |\n",
      "|    time_elapsed    | 1738      |\n",
      "|    total_timesteps | 370944    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 214       |\n",
      "|    iterations           | 162       |\n",
      "|    time_elapsed         | 1741      |\n",
      "|    total_timesteps      | 373248    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.94e-07 |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.2e+04   |\n",
      "|    n_updates            | 1610      |\n",
      "|    policy_gradient_loss | -5e-09    |\n",
      "|    value_loss           | 7.5e+04   |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=375000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 375000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.95e-07 |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.85e+04  |\n",
      "|    n_updates            | 1620      |\n",
      "|    policy_gradient_loss | -8.07e-09 |\n",
      "|    value_loss           | 7.42e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 214       |\n",
      "|    iterations      | 163       |\n",
      "|    time_elapsed    | 1750      |\n",
      "|    total_timesteps | 375552    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 215       |\n",
      "|    iterations           | 164       |\n",
      "|    time_elapsed         | 1754      |\n",
      "|    total_timesteps      | 377856    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.94e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.4e+04   |\n",
      "|    n_updates            | 1630      |\n",
      "|    policy_gradient_loss | 4.87e-09  |\n",
      "|    value_loss           | 7.28e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=380000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 380000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.95e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.37e+04  |\n",
      "|    n_updates            | 1640      |\n",
      "|    policy_gradient_loss | 1.59e-08  |\n",
      "|    value_loss           | 7.22e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 215       |\n",
      "|    iterations      | 165       |\n",
      "|    time_elapsed    | 1763      |\n",
      "|    total_timesteps | 380160    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 216       |\n",
      "|    iterations           | 166       |\n",
      "|    time_elapsed         | 1766      |\n",
      "|    total_timesteps      | 382464    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.98e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.34e+04  |\n",
      "|    n_updates            | 1650      |\n",
      "|    policy_gradient_loss | 3.05e-09  |\n",
      "|    value_loss           | 7.11e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 217       |\n",
      "|    iterations           | 167       |\n",
      "|    time_elapsed         | 1769      |\n",
      "|    total_timesteps      | 384768    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.98e-07 |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.88e+04  |\n",
      "|    n_updates            | 1660      |\n",
      "|    policy_gradient_loss | -1.49e-08 |\n",
      "|    value_loss           | 6.96e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=385000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 385000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.97e-07 |\n",
      "|    explained_variance   | 1.79e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.43e+04  |\n",
      "|    n_updates            | 1670      |\n",
      "|    policy_gradient_loss | -1.18e-08 |\n",
      "|    value_loss           | 6.89e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 217       |\n",
      "|    iterations      | 168       |\n",
      "|    time_elapsed    | 1779      |\n",
      "|    total_timesteps | 387072    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 218       |\n",
      "|    iterations           | 169       |\n",
      "|    time_elapsed         | 1782      |\n",
      "|    total_timesteps      | 389376    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.98e-07 |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.64e+04  |\n",
      "|    n_updates            | 1680      |\n",
      "|    policy_gradient_loss | -4.09e-09 |\n",
      "|    value_loss           | 6.8e+04   |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=390000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 390000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.95e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.13e+04  |\n",
      "|    n_updates            | 1690      |\n",
      "|    policy_gradient_loss | 7.07e-09  |\n",
      "|    value_loss           | 6.75e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 218       |\n",
      "|    iterations      | 170       |\n",
      "|    time_elapsed    | 1792      |\n",
      "|    total_timesteps | 391680    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 219       |\n",
      "|    iterations           | 171       |\n",
      "|    time_elapsed         | 1795      |\n",
      "|    total_timesteps      | 393984    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.97e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.96e+04  |\n",
      "|    n_updates            | 1700      |\n",
      "|    policy_gradient_loss | 1.21e-08  |\n",
      "|    value_loss           | 6.64e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=395000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 395000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.94e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.25e+04  |\n",
      "|    n_updates            | 1710      |\n",
      "|    policy_gradient_loss | -5.62e-09 |\n",
      "|    value_loss           | 6.54e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 219       |\n",
      "|    iterations      | 172       |\n",
      "|    time_elapsed    | 1804      |\n",
      "|    total_timesteps | 396288    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 220       |\n",
      "|    iterations           | 173       |\n",
      "|    time_elapsed         | 1808      |\n",
      "|    total_timesteps      | 398592    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.96e-07 |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.36e+04  |\n",
      "|    n_updates            | 1720      |\n",
      "|    policy_gradient_loss | -3.81e-09 |\n",
      "|    value_loss           | 6.47e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=400000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 400000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.94e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.37e+04  |\n",
      "|    n_updates            | 1730      |\n",
      "|    policy_gradient_loss | -2.76e-09 |\n",
      "|    value_loss           | 6.4e+04   |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 220       |\n",
      "|    iterations      | 174       |\n",
      "|    time_elapsed    | 1817      |\n",
      "|    total_timesteps | 400896    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 221       |\n",
      "|    iterations           | 175       |\n",
      "|    time_elapsed         | 1820      |\n",
      "|    total_timesteps      | 403200    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.97e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.74e+04  |\n",
      "|    n_updates            | 1740      |\n",
      "|    policy_gradient_loss | -9.87e-10 |\n",
      "|    value_loss           | 6.33e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=405000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 405000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.93e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.04e+04  |\n",
      "|    n_updates            | 1750      |\n",
      "|    policy_gradient_loss | 1.03e-08  |\n",
      "|    value_loss           | 6.27e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 221       |\n",
      "|    iterations      | 176       |\n",
      "|    time_elapsed    | 1830      |\n",
      "|    total_timesteps | 405504    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 222       |\n",
      "|    iterations           | 177       |\n",
      "|    time_elapsed         | 1833      |\n",
      "|    total_timesteps      | 407808    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.95e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.4e+04   |\n",
      "|    n_updates            | 1760      |\n",
      "|    policy_gradient_loss | 9.37e-09  |\n",
      "|    value_loss           | 6.2e+04   |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=410000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 410000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.93e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.2e+04   |\n",
      "|    n_updates            | 1770      |\n",
      "|    policy_gradient_loss | -3.77e-10 |\n",
      "|    value_loss           | 6.09e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 222       |\n",
      "|    iterations      | 178       |\n",
      "|    time_elapsed    | 1842      |\n",
      "|    total_timesteps | 410112    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 223       |\n",
      "|    iterations           | 179       |\n",
      "|    time_elapsed         | 1845      |\n",
      "|    total_timesteps      | 412416    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.95e-07 |\n",
      "|    explained_variance   | 2.38e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.33e+04  |\n",
      "|    n_updates            | 1780      |\n",
      "|    policy_gradient_loss | -1.48e-08 |\n",
      "|    value_loss           | 6.06e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 224       |\n",
      "|    iterations           | 180       |\n",
      "|    time_elapsed         | 1848      |\n",
      "|    total_timesteps      | 414720    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.99e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.73e+04  |\n",
      "|    n_updates            | 1790      |\n",
      "|    policy_gradient_loss | 5.12e-11  |\n",
      "|    value_loss           | 6.02e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=415000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 415000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.97e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.74e+04  |\n",
      "|    n_updates            | 1800      |\n",
      "|    policy_gradient_loss | 6.71e-10  |\n",
      "|    value_loss           | 5.97e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 224       |\n",
      "|    iterations      | 181       |\n",
      "|    time_elapsed    | 1858      |\n",
      "|    total_timesteps | 417024    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 225       |\n",
      "|    iterations           | 182       |\n",
      "|    time_elapsed         | 1861      |\n",
      "|    total_timesteps      | 419328    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.99e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.99e+04  |\n",
      "|    n_updates            | 1810      |\n",
      "|    policy_gradient_loss | 2.78e-09  |\n",
      "|    value_loss           | 5.92e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=420000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 420000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.96e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.05e+04  |\n",
      "|    n_updates            | 1820      |\n",
      "|    policy_gradient_loss | -1.71e-09 |\n",
      "|    value_loss           | 5.8e+04   |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 225       |\n",
      "|    iterations      | 183       |\n",
      "|    time_elapsed    | 1871      |\n",
      "|    total_timesteps | 421632    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 226       |\n",
      "|    iterations           | 184       |\n",
      "|    time_elapsed         | 1874      |\n",
      "|    total_timesteps      | 423936    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.97e-07 |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.62e+04  |\n",
      "|    n_updates            | 1830      |\n",
      "|    policy_gradient_loss | 1.03e-09  |\n",
      "|    value_loss           | 5.81e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=425000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 425000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.97e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.52e+04  |\n",
      "|    n_updates            | 1840      |\n",
      "|    policy_gradient_loss | -9.97e-10 |\n",
      "|    value_loss           | 5.8e+04   |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 226       |\n",
      "|    iterations      | 185       |\n",
      "|    time_elapsed    | 1883      |\n",
      "|    total_timesteps | 426240    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 227       |\n",
      "|    iterations           | 186       |\n",
      "|    time_elapsed         | 1886      |\n",
      "|    total_timesteps      | 428544    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.95e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.99e+04  |\n",
      "|    n_updates            | 1850      |\n",
      "|    policy_gradient_loss | 5.96e-09  |\n",
      "|    value_loss           | 5.77e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=430000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 430000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.92e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.64e+04  |\n",
      "|    n_updates            | 1860      |\n",
      "|    policy_gradient_loss | -2e-09    |\n",
      "|    value_loss           | 5.76e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 227       |\n",
      "|    iterations      | 187       |\n",
      "|    time_elapsed    | 1896      |\n",
      "|    total_timesteps | 430848    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 228       |\n",
      "|    iterations           | 188       |\n",
      "|    time_elapsed         | 1899      |\n",
      "|    total_timesteps      | 433152    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.97e-07 |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.67e+04  |\n",
      "|    n_updates            | 1870      |\n",
      "|    policy_gradient_loss | 1.35e-09  |\n",
      "|    value_loss           | 5.71e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=435000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 435000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.96e-07 |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.14e+04  |\n",
      "|    n_updates            | 1880      |\n",
      "|    policy_gradient_loss | 1.63e-10  |\n",
      "|    value_loss           | 5.68e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 228       |\n",
      "|    iterations      | 189       |\n",
      "|    time_elapsed    | 1909      |\n",
      "|    total_timesteps | 435456    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 228       |\n",
      "|    iterations           | 190       |\n",
      "|    time_elapsed         | 1912      |\n",
      "|    total_timesteps      | 437760    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.96e-07 |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.89e+04  |\n",
      "|    n_updates            | 1890      |\n",
      "|    policy_gradient_loss | 3.18e-09  |\n",
      "|    value_loss           | 5.69e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=440000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 440000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.98e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.62e+04  |\n",
      "|    n_updates            | 1900      |\n",
      "|    policy_gradient_loss | -1.12e-08 |\n",
      "|    value_loss           | 5.65e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 228       |\n",
      "|    iterations      | 191       |\n",
      "|    time_elapsed    | 1921      |\n",
      "|    total_timesteps | 440064    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 229       |\n",
      "|    iterations           | 192       |\n",
      "|    time_elapsed         | 1924      |\n",
      "|    total_timesteps      | 442368    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.94e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.66e+04  |\n",
      "|    n_updates            | 1910      |\n",
      "|    policy_gradient_loss | 2.71e-09  |\n",
      "|    value_loss           | 5.66e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 230       |\n",
      "|    iterations           | 193       |\n",
      "|    time_elapsed         | 1927      |\n",
      "|    total_timesteps      | 444672    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.95e-07 |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.07e+04  |\n",
      "|    n_updates            | 1920      |\n",
      "|    policy_gradient_loss | -3.48e-09 |\n",
      "|    value_loss           | 5.7e+04   |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=445000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 445000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.95e-07 |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 4.22e+04  |\n",
      "|    n_updates            | 1930      |\n",
      "|    policy_gradient_loss | -7.5e-10  |\n",
      "|    value_loss           | 5.65e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 230       |\n",
      "|    iterations      | 194       |\n",
      "|    time_elapsed    | 1937      |\n",
      "|    total_timesteps | 446976    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 231       |\n",
      "|    iterations           | 195       |\n",
      "|    time_elapsed         | 1940      |\n",
      "|    total_timesteps      | 449280    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.97e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.48e+04  |\n",
      "|    n_updates            | 1940      |\n",
      "|    policy_gradient_loss | -1.18e-09 |\n",
      "|    value_loss           | 5.6e+04   |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=450000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 450000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.92e-07 |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 1.88e+04  |\n",
      "|    n_updates            | 1950      |\n",
      "|    policy_gradient_loss | -1.74e-09 |\n",
      "|    value_loss           | 5.6e+04   |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 231       |\n",
      "|    iterations      | 196       |\n",
      "|    time_elapsed    | 1950      |\n",
      "|    total_timesteps | 451584    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 232       |\n",
      "|    iterations           | 197       |\n",
      "|    time_elapsed         | 1953      |\n",
      "|    total_timesteps      | 453888    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.98e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.82e+04  |\n",
      "|    n_updates            | 1960      |\n",
      "|    policy_gradient_loss | -5.59e-11 |\n",
      "|    value_loss           | 5.65e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=455000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 455000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.95e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.86e+04  |\n",
      "|    n_updates            | 1970      |\n",
      "|    policy_gradient_loss | 9.31e-11  |\n",
      "|    value_loss           | 5.67e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 232       |\n",
      "|    iterations      | 198       |\n",
      "|    time_elapsed    | 1963      |\n",
      "|    total_timesteps | 456192    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 233       |\n",
      "|    iterations           | 199       |\n",
      "|    time_elapsed         | 1966      |\n",
      "|    total_timesteps      | 458496    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.96e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.37e+04  |\n",
      "|    n_updates            | 1980      |\n",
      "|    policy_gradient_loss | 5.59e-10  |\n",
      "|    value_loss           | 5.69e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=460000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 460000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.95e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.52e+04  |\n",
      "|    n_updates            | 1990      |\n",
      "|    policy_gradient_loss | 5.82e-10  |\n",
      "|    value_loss           | 5.67e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 233       |\n",
      "|    iterations      | 200       |\n",
      "|    time_elapsed    | 1976      |\n",
      "|    total_timesteps | 460800    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 233       |\n",
      "|    iterations           | 201       |\n",
      "|    time_elapsed         | 1979      |\n",
      "|    total_timesteps      | 463104    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.97e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.24e+04  |\n",
      "|    n_updates            | 2000      |\n",
      "|    policy_gradient_loss | -1.53e-09 |\n",
      "|    value_loss           | 5.74e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=465000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 465000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.95e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.95e+04  |\n",
      "|    n_updates            | 2010      |\n",
      "|    policy_gradient_loss | -1.32e-09 |\n",
      "|    value_loss           | 5.73e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 233       |\n",
      "|    iterations      | 202       |\n",
      "|    time_elapsed    | 1989      |\n",
      "|    total_timesteps | 465408    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 234       |\n",
      "|    iterations           | 203       |\n",
      "|    time_elapsed         | 1992      |\n",
      "|    total_timesteps      | 467712    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.98e-07 |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.88e+04  |\n",
      "|    n_updates            | 2020      |\n",
      "|    policy_gradient_loss | -9.41e-10 |\n",
      "|    value_loss           | 5.84e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=470000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 470000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.96e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.39e+04  |\n",
      "|    n_updates            | 2030      |\n",
      "|    policy_gradient_loss | 1.17e-09  |\n",
      "|    value_loss           | 5.72e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 234       |\n",
      "|    iterations      | 204       |\n",
      "|    time_elapsed    | 2002      |\n",
      "|    total_timesteps | 470016    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 235       |\n",
      "|    iterations           | 205       |\n",
      "|    time_elapsed         | 2005      |\n",
      "|    total_timesteps      | 472320    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.97e-07 |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.22e+04  |\n",
      "|    n_updates            | 2040      |\n",
      "|    policy_gradient_loss | 8.59e-10  |\n",
      "|    value_loss           | 5.81e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 236       |\n",
      "|    iterations           | 206       |\n",
      "|    time_elapsed         | 2008      |\n",
      "|    total_timesteps      | 474624    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.96e-07 |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.36e+04  |\n",
      "|    n_updates            | 2050      |\n",
      "|    policy_gradient_loss | 2.56e-09  |\n",
      "|    value_loss           | 5.88e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=475000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 475000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.95e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 1.38e+04  |\n",
      "|    n_updates            | 2060      |\n",
      "|    policy_gradient_loss | -2.51e-10 |\n",
      "|    value_loss           | 5.87e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 236       |\n",
      "|    iterations      | 207       |\n",
      "|    time_elapsed    | 2018      |\n",
      "|    total_timesteps | 476928    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 237       |\n",
      "|    iterations           | 208       |\n",
      "|    time_elapsed         | 2021      |\n",
      "|    total_timesteps      | 479232    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.95e-07 |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.13e+04  |\n",
      "|    n_updates            | 2070      |\n",
      "|    policy_gradient_loss | 1.68e-10  |\n",
      "|    value_loss           | 5.88e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=480000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 480000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.96e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 4.21e+04  |\n",
      "|    n_updates            | 2080      |\n",
      "|    policy_gradient_loss | -2.53e-09 |\n",
      "|    value_loss           | 5.99e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 237       |\n",
      "|    iterations      | 209       |\n",
      "|    time_elapsed    | 2030      |\n",
      "|    total_timesteps | 481536    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 237       |\n",
      "|    iterations           | 210       |\n",
      "|    time_elapsed         | 2034      |\n",
      "|    total_timesteps      | 483840    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.95e-07 |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.4e+04   |\n",
      "|    n_updates            | 2090      |\n",
      "|    policy_gradient_loss | -1.97e-09 |\n",
      "|    value_loss           | 5.98e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=485000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 485000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.94e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.04e+04  |\n",
      "|    n_updates            | 2100      |\n",
      "|    policy_gradient_loss | 6.61e-10  |\n",
      "|    value_loss           | 6.04e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 237       |\n",
      "|    iterations      | 211       |\n",
      "|    time_elapsed    | 2043      |\n",
      "|    total_timesteps | 486144    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 238       |\n",
      "|    iterations           | 212       |\n",
      "|    time_elapsed         | 2046      |\n",
      "|    total_timesteps      | 488448    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.94e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 1.66e+04  |\n",
      "|    n_updates            | 2110      |\n",
      "|    policy_gradient_loss | 4.47e-10  |\n",
      "|    value_loss           | 6.25e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=490000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 490000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.96e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.16e+04  |\n",
      "|    n_updates            | 2120      |\n",
      "|    policy_gradient_loss | 4.75e-10  |\n",
      "|    value_loss           | 6.16e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 238       |\n",
      "|    iterations      | 213       |\n",
      "|    time_elapsed    | 2056      |\n",
      "|    total_timesteps | 490752    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 239       |\n",
      "|    iterations           | 214       |\n",
      "|    time_elapsed         | 2059      |\n",
      "|    total_timesteps      | 493056    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.97e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 4.33e+04  |\n",
      "|    n_updates            | 2130      |\n",
      "|    policy_gradient_loss | -5.03e-10 |\n",
      "|    value_loss           | 6.22e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=495000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 495000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.98e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.21e+04  |\n",
      "|    n_updates            | 2140      |\n",
      "|    policy_gradient_loss | -6.52e-10 |\n",
      "|    value_loss           | 6.24e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 239       |\n",
      "|    iterations      | 215       |\n",
      "|    time_elapsed    | 2069      |\n",
      "|    total_timesteps | 495360    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 240       |\n",
      "|    iterations           | 216       |\n",
      "|    time_elapsed         | 2072      |\n",
      "|    total_timesteps      | 497664    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.94e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.09e+04  |\n",
      "|    n_updates            | 2150      |\n",
      "|    policy_gradient_loss | -5.59e-10 |\n",
      "|    value_loss           | 6.38e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 240       |\n",
      "|    iterations           | 217       |\n",
      "|    time_elapsed         | 2076      |\n",
      "|    total_timesteps      | 499968    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.93e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.73e+04  |\n",
      "|    n_updates            | 2160      |\n",
      "|    policy_gradient_loss | -7.08e-10 |\n",
      "|    value_loss           | 6.48e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=500000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 500000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.95e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.6e+04   |\n",
      "|    n_updates            | 2170      |\n",
      "|    policy_gradient_loss | 2.55e-09  |\n",
      "|    value_loss           | 6.45e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 240       |\n",
      "|    iterations      | 218       |\n",
      "|    time_elapsed    | 2085      |\n",
      "|    total_timesteps | 502272    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 241       |\n",
      "|    iterations           | 219       |\n",
      "|    time_elapsed         | 2088      |\n",
      "|    total_timesteps      | 504576    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.95e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.5e+04   |\n",
      "|    n_updates            | 2180      |\n",
      "|    policy_gradient_loss | -6.52e-10 |\n",
      "|    value_loss           | 6.66e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=505000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 505000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.96e-07 |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.18e+04  |\n",
      "|    n_updates            | 2190      |\n",
      "|    policy_gradient_loss | -3.54e-10 |\n",
      "|    value_loss           | 6.68e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 241       |\n",
      "|    iterations      | 220       |\n",
      "|    time_elapsed    | 2098      |\n",
      "|    total_timesteps | 506880    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 242       |\n",
      "|    iterations           | 221       |\n",
      "|    time_elapsed         | 2101      |\n",
      "|    total_timesteps      | 509184    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.93e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.32e+04  |\n",
      "|    n_updates            | 2200      |\n",
      "|    policy_gradient_loss | 4.56e-10  |\n",
      "|    value_loss           | 6.82e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=510000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 510000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.95e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.12e+04  |\n",
      "|    n_updates            | 2210      |\n",
      "|    policy_gradient_loss | 8.2e-10   |\n",
      "|    value_loss           | 6.77e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 242       |\n",
      "|    iterations      | 222       |\n",
      "|    time_elapsed    | 2111      |\n",
      "|    total_timesteps | 511488    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 242       |\n",
      "|    iterations           | 223       |\n",
      "|    time_elapsed         | 2114      |\n",
      "|    total_timesteps      | 513792    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.94e-07 |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 5.2e+04   |\n",
      "|    n_updates            | 2220      |\n",
      "|    policy_gradient_loss | 3.21e-10  |\n",
      "|    value_loss           | 6.9e+04   |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=515000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 515000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.97e-07 |\n",
      "|    explained_variance   | 2.38e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.78e+04  |\n",
      "|    n_updates            | 2230      |\n",
      "|    policy_gradient_loss | -3.49e-10 |\n",
      "|    value_loss           | 6.95e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 242       |\n",
      "|    iterations      | 224       |\n",
      "|    time_elapsed    | 2124      |\n",
      "|    total_timesteps | 516096    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 243       |\n",
      "|    iterations           | 225       |\n",
      "|    time_elapsed         | 2127      |\n",
      "|    total_timesteps      | 518400    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.96e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.22e+04  |\n",
      "|    n_updates            | 2240      |\n",
      "|    policy_gradient_loss | -1.18e-09 |\n",
      "|    value_loss           | 6.94e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=520000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 520000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.92e-07 |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.75e+04  |\n",
      "|    n_updates            | 2250      |\n",
      "|    policy_gradient_loss | -4.75e-10 |\n",
      "|    value_loss           | 6.98e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 243       |\n",
      "|    iterations      | 226       |\n",
      "|    time_elapsed    | 2137      |\n",
      "|    total_timesteps | 520704    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 244       |\n",
      "|    iterations           | 227       |\n",
      "|    time_elapsed         | 2140      |\n",
      "|    total_timesteps      | 523008    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.95e-07 |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.02e+04  |\n",
      "|    n_updates            | 2260      |\n",
      "|    policy_gradient_loss | -1.49e-09 |\n",
      "|    value_loss           | 7.12e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=525000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 525000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.96e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.7e+04   |\n",
      "|    n_updates            | 2270      |\n",
      "|    policy_gradient_loss | 2.42e-10  |\n",
      "|    value_loss           | 7.28e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 244       |\n",
      "|    iterations      | 228       |\n",
      "|    time_elapsed    | 2150      |\n",
      "|    total_timesteps | 525312    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 244       |\n",
      "|    iterations           | 229       |\n",
      "|    time_elapsed         | 2153      |\n",
      "|    total_timesteps      | 527616    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.96e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 5.94e+04  |\n",
      "|    n_updates            | 2280      |\n",
      "|    policy_gradient_loss | 5.96e-10  |\n",
      "|    value_loss           | 7.26e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 245       |\n",
      "|    iterations           | 230       |\n",
      "|    time_elapsed         | 2156      |\n",
      "|    total_timesteps      | 529920    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.98e-07 |\n",
      "|    explained_variance   | 2.38e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.18e+04  |\n",
      "|    n_updates            | 2290      |\n",
      "|    policy_gradient_loss | -3.82e-10 |\n",
      "|    value_loss           | 7.23e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=530000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 530000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.94e-07 |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 5.59e+04  |\n",
      "|    n_updates            | 2300      |\n",
      "|    policy_gradient_loss | -2.61e-10 |\n",
      "|    value_loss           | 7.23e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 245       |\n",
      "|    iterations      | 231       |\n",
      "|    time_elapsed    | 2166      |\n",
      "|    total_timesteps | 532224    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 246       |\n",
      "|    iterations           | 232       |\n",
      "|    time_elapsed         | 2169      |\n",
      "|    total_timesteps      | 534528    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.97e-07 |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.24e+04  |\n",
      "|    n_updates            | 2310      |\n",
      "|    policy_gradient_loss | 1.68e-09  |\n",
      "|    value_loss           | 7.16e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=535000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 535000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.96e-07 |\n",
      "|    explained_variance   | 2.38e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 4.08e+04  |\n",
      "|    n_updates            | 2320      |\n",
      "|    policy_gradient_loss | 1.7e-09   |\n",
      "|    value_loss           | 7.29e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 246       |\n",
      "|    iterations      | 233       |\n",
      "|    time_elapsed    | 2179      |\n",
      "|    total_timesteps | 536832    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 246       |\n",
      "|    iterations           | 234       |\n",
      "|    time_elapsed         | 2182      |\n",
      "|    total_timesteps      | 539136    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.96e-07 |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.98e+04  |\n",
      "|    n_updates            | 2330      |\n",
      "|    policy_gradient_loss | -3.86e-10 |\n",
      "|    value_loss           | 7.37e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=540000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 540000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.95e-07 |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 4.02e+04  |\n",
      "|    n_updates            | 2340      |\n",
      "|    policy_gradient_loss | 1.23e-09  |\n",
      "|    value_loss           | 7.33e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 246       |\n",
      "|    iterations      | 235       |\n",
      "|    time_elapsed    | 2192      |\n",
      "|    total_timesteps | 541440    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 247       |\n",
      "|    iterations           | 236       |\n",
      "|    time_elapsed         | 2195      |\n",
      "|    total_timesteps      | 543744    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.91e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 1.72e+04  |\n",
      "|    n_updates            | 2350      |\n",
      "|    policy_gradient_loss | 1.63e-10  |\n",
      "|    value_loss           | 7.32e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=545000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 545000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.95e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.3e+04   |\n",
      "|    n_updates            | 2360      |\n",
      "|    policy_gradient_loss | 5.49e-10  |\n",
      "|    value_loss           | 7.32e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 247       |\n",
      "|    iterations      | 237       |\n",
      "|    time_elapsed    | 2205      |\n",
      "|    total_timesteps | 546048    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 248       |\n",
      "|    iterations           | 238       |\n",
      "|    time_elapsed         | 2208      |\n",
      "|    total_timesteps      | 548352    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.97e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 1.78e+04  |\n",
      "|    n_updates            | 2370      |\n",
      "|    policy_gradient_loss | 5.54e-10  |\n",
      "|    value_loss           | 7.33e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=550000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 550000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.95e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.55e+04  |\n",
      "|    n_updates            | 2380      |\n",
      "|    policy_gradient_loss | 1.08e-09  |\n",
      "|    value_loss           | 7.48e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 248       |\n",
      "|    iterations      | 239       |\n",
      "|    time_elapsed    | 2217      |\n",
      "|    total_timesteps | 550656    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 249       |\n",
      "|    iterations           | 240       |\n",
      "|    time_elapsed         | 2220      |\n",
      "|    total_timesteps      | 552960    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.98e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.59e+04  |\n",
      "|    n_updates            | 2390      |\n",
      "|    policy_gradient_loss | -8.29e-10 |\n",
      "|    value_loss           | 7.22e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=555000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 555000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.96e-07 |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 1.99e+04  |\n",
      "|    n_updates            | 2400      |\n",
      "|    policy_gradient_loss | 3.49e-10  |\n",
      "|    value_loss           | 7.32e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 248       |\n",
      "|    iterations      | 241       |\n",
      "|    time_elapsed    | 2230      |\n",
      "|    total_timesteps | 555264    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 249       |\n",
      "|    iterations           | 242       |\n",
      "|    time_elapsed         | 2233      |\n",
      "|    total_timesteps      | 557568    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.95e-07 |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 4.54e+04  |\n",
      "|    n_updates            | 2410      |\n",
      "|    policy_gradient_loss | 4.84e-10  |\n",
      "|    value_loss           | 7.37e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 250       |\n",
      "|    iterations           | 243       |\n",
      "|    time_elapsed         | 2236      |\n",
      "|    total_timesteps      | 559872    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.98e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.24e+04  |\n",
      "|    n_updates            | 2420      |\n",
      "|    policy_gradient_loss | 6.61e-10  |\n",
      "|    value_loss           | 7.29e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=560000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 560000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.95e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 5.09e+04  |\n",
      "|    n_updates            | 2430      |\n",
      "|    policy_gradient_loss | -8.29e-10 |\n",
      "|    value_loss           | 7.4e+04   |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 250       |\n",
      "|    iterations      | 244       |\n",
      "|    time_elapsed    | 2245      |\n",
      "|    total_timesteps | 562176    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 251       |\n",
      "|    iterations           | 245       |\n",
      "|    time_elapsed         | 2248      |\n",
      "|    total_timesteps      | 564480    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.94e-07 |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.99e+04  |\n",
      "|    n_updates            | 2440      |\n",
      "|    policy_gradient_loss | -1.37e-09 |\n",
      "|    value_loss           | 7.44e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=565000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 565000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.91e-07 |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 4.02e+04  |\n",
      "|    n_updates            | 2450      |\n",
      "|    policy_gradient_loss | 1.49e-10  |\n",
      "|    value_loss           | 7.4e+04   |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 250       |\n",
      "|    iterations      | 246       |\n",
      "|    time_elapsed    | 2258      |\n",
      "|    total_timesteps | 566784    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 251       |\n",
      "|    iterations           | 247       |\n",
      "|    time_elapsed         | 2261      |\n",
      "|    total_timesteps      | 569088    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.98e-07 |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 5.46e+04  |\n",
      "|    n_updates            | 2460      |\n",
      "|    policy_gradient_loss | 1.5e-09   |\n",
      "|    value_loss           | 7.39e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=570000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 570000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.95e-07 |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.55e+04  |\n",
      "|    n_updates            | 2470      |\n",
      "|    policy_gradient_loss | -2.41e-09 |\n",
      "|    value_loss           | 7.46e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 251       |\n",
      "|    iterations      | 248       |\n",
      "|    time_elapsed    | 2270      |\n",
      "|    total_timesteps | 571392    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 252       |\n",
      "|    iterations           | 249       |\n",
      "|    time_elapsed         | 2273      |\n",
      "|    total_timesteps      | 573696    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.96e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.88e+04  |\n",
      "|    n_updates            | 2480      |\n",
      "|    policy_gradient_loss | 2.05e-09  |\n",
      "|    value_loss           | 7.47e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=575000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 575000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.96e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 4.94e+04  |\n",
      "|    n_updates            | 2490      |\n",
      "|    policy_gradient_loss | -5.68e-10 |\n",
      "|    value_loss           | 7.39e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 252       |\n",
      "|    iterations      | 250       |\n",
      "|    time_elapsed    | 2283      |\n",
      "|    total_timesteps | 576000    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 252       |\n",
      "|    iterations           | 251       |\n",
      "|    time_elapsed         | 2286      |\n",
      "|    total_timesteps      | 578304    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.92e-07 |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.14e+04  |\n",
      "|    n_updates            | 2500      |\n",
      "|    policy_gradient_loss | 6.89e-10  |\n",
      "|    value_loss           | 7.32e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=580000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 580000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.93e-07 |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.54e+04  |\n",
      "|    n_updates            | 2510      |\n",
      "|    policy_gradient_loss | -2.42e-10 |\n",
      "|    value_loss           | 7.33e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 252       |\n",
      "|    iterations      | 252       |\n",
      "|    time_elapsed    | 2296      |\n",
      "|    total_timesteps | 580608    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 253       |\n",
      "|    iterations           | 253       |\n",
      "|    time_elapsed         | 2299      |\n",
      "|    total_timesteps      | 582912    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.92e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.33e+04  |\n",
      "|    n_updates            | 2520      |\n",
      "|    policy_gradient_loss | 7.73e-10  |\n",
      "|    value_loss           | 7.27e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=585000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 585000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.97e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 1.85e+04  |\n",
      "|    n_updates            | 2530      |\n",
      "|    policy_gradient_loss | 1.23e-09  |\n",
      "|    value_loss           | 7.36e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 253       |\n",
      "|    iterations      | 254       |\n",
      "|    time_elapsed    | 2308      |\n",
      "|    total_timesteps | 585216    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 254       |\n",
      "|    iterations           | 255       |\n",
      "|    time_elapsed         | 2311      |\n",
      "|    total_timesteps      | 587520    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.95e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 4.21e+04  |\n",
      "|    n_updates            | 2540      |\n",
      "|    policy_gradient_loss | -1.28e-09 |\n",
      "|    value_loss           | 7.54e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 254       |\n",
      "|    iterations           | 256       |\n",
      "|    time_elapsed         | 2314      |\n",
      "|    total_timesteps      | 589824    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.92e-07 |\n",
      "|    explained_variance   | 2.38e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.3e+04   |\n",
      "|    n_updates            | 2550      |\n",
      "|    policy_gradient_loss | -1.73e-09 |\n",
      "|    value_loss           | 7.33e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=590000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 590000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.91e-07 |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 4.02e+04  |\n",
      "|    n_updates            | 2560      |\n",
      "|    policy_gradient_loss | 7.64e-10  |\n",
      "|    value_loss           | 7.38e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 254       |\n",
      "|    iterations      | 257       |\n",
      "|    time_elapsed    | 2324      |\n",
      "|    total_timesteps | 592128    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 255       |\n",
      "|    iterations           | 258       |\n",
      "|    time_elapsed         | 2327      |\n",
      "|    total_timesteps      | 594432    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.97e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.09e+04  |\n",
      "|    n_updates            | 2570      |\n",
      "|    policy_gradient_loss | 1.02e-09  |\n",
      "|    value_loss           | 7.5e+04   |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=595000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 595000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.95e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.59e+04  |\n",
      "|    n_updates            | 2580      |\n",
      "|    policy_gradient_loss | 1.03e-09  |\n",
      "|    value_loss           | 7.24e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 255       |\n",
      "|    iterations      | 259       |\n",
      "|    time_elapsed    | 2336      |\n",
      "|    total_timesteps | 596736    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 256       |\n",
      "|    iterations           | 260       |\n",
      "|    time_elapsed         | 2339      |\n",
      "|    total_timesteps      | 599040    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.93e-07 |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.26e+04  |\n",
      "|    n_updates            | 2590      |\n",
      "|    policy_gradient_loss | 8.06e-10  |\n",
      "|    value_loss           | 7.36e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=600000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 600000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.98e-07 |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.94e+04  |\n",
      "|    n_updates            | 2600      |\n",
      "|    policy_gradient_loss | -5.59e-10 |\n",
      "|    value_loss           | 7.32e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 255       |\n",
      "|    iterations      | 261       |\n",
      "|    time_elapsed    | 2349      |\n",
      "|    total_timesteps | 601344    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 256       |\n",
      "|    iterations           | 262       |\n",
      "|    time_elapsed         | 2352      |\n",
      "|    total_timesteps      | 603648    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.92e-07 |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.09e+04  |\n",
      "|    n_updates            | 2610      |\n",
      "|    policy_gradient_loss | -1.48e-09 |\n",
      "|    value_loss           | 7.37e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=605000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 605000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.96e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 5.53e+04  |\n",
      "|    n_updates            | 2620      |\n",
      "|    policy_gradient_loss | 1.01e-09  |\n",
      "|    value_loss           | 7.54e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 256       |\n",
      "|    iterations      | 263       |\n",
      "|    time_elapsed    | 2361      |\n",
      "|    total_timesteps | 605952    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 257       |\n",
      "|    iterations           | 264       |\n",
      "|    time_elapsed         | 2364      |\n",
      "|    total_timesteps      | 608256    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.94e-07 |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.82e+04  |\n",
      "|    n_updates            | 2630      |\n",
      "|    policy_gradient_loss | 1.38e-09  |\n",
      "|    value_loss           | 7.41e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=610000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 610000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.94e-07 |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.54e+04  |\n",
      "|    n_updates            | 2640      |\n",
      "|    policy_gradient_loss | -5.03e-10 |\n",
      "|    value_loss           | 7.47e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 257       |\n",
      "|    iterations      | 265       |\n",
      "|    time_elapsed    | 2374      |\n",
      "|    total_timesteps | 610560    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 257       |\n",
      "|    iterations           | 266       |\n",
      "|    time_elapsed         | 2377      |\n",
      "|    total_timesteps      | 612864    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.92e-07 |\n",
      "|    explained_variance   | 2.38e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 4.3e+04   |\n",
      "|    n_updates            | 2650      |\n",
      "|    policy_gradient_loss | -2.7e-10  |\n",
      "|    value_loss           | 7.32e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=615000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 615000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.94e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.66e+04  |\n",
      "|    n_updates            | 2660      |\n",
      "|    policy_gradient_loss | 3.26e-10  |\n",
      "|    value_loss           | 7.4e+04   |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 257       |\n",
      "|    iterations      | 267       |\n",
      "|    time_elapsed    | 2386      |\n",
      "|    total_timesteps | 615168    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 258       |\n",
      "|    iterations           | 268       |\n",
      "|    time_elapsed         | 2389      |\n",
      "|    total_timesteps      | 617472    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.94e-07 |\n",
      "|    explained_variance   | 2.38e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.75e+04  |\n",
      "|    n_updates            | 2670      |\n",
      "|    policy_gradient_loss | -1.04e-09 |\n",
      "|    value_loss           | 7.49e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 258       |\n",
      "|    iterations           | 269       |\n",
      "|    time_elapsed         | 2392      |\n",
      "|    total_timesteps      | 619776    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.93e-07 |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 5.8e+04   |\n",
      "|    n_updates            | 2680      |\n",
      "|    policy_gradient_loss | -3.17e-10 |\n",
      "|    value_loss           | 7.42e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=620000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 620000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.93e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.32e+04  |\n",
      "|    n_updates            | 2690      |\n",
      "|    policy_gradient_loss | 8.89e-10  |\n",
      "|    value_loss           | 7.25e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 258       |\n",
      "|    iterations      | 270       |\n",
      "|    time_elapsed    | 2402      |\n",
      "|    total_timesteps | 622080    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 259       |\n",
      "|    iterations           | 271       |\n",
      "|    time_elapsed         | 2405      |\n",
      "|    total_timesteps      | 624384    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.93e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.49e+04  |\n",
      "|    n_updates            | 2700      |\n",
      "|    policy_gradient_loss | 1.85e-09  |\n",
      "|    value_loss           | 7.28e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=625000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 625000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.92e-07 |\n",
      "|    explained_variance   | 2.38e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 1.76e+04  |\n",
      "|    n_updates            | 2710      |\n",
      "|    policy_gradient_loss | 6.47e-10  |\n",
      "|    value_loss           | 7.46e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 259       |\n",
      "|    iterations      | 272       |\n",
      "|    time_elapsed    | 2415      |\n",
      "|    total_timesteps | 626688    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 260       |\n",
      "|    iterations           | 273       |\n",
      "|    time_elapsed         | 2418      |\n",
      "|    total_timesteps      | 628992    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.92e-07 |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.27e+04  |\n",
      "|    n_updates            | 2720      |\n",
      "|    policy_gradient_loss | -6.33e-10 |\n",
      "|    value_loss           | 7.33e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=630000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 630000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.93e-07 |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 1.83e+04  |\n",
      "|    n_updates            | 2730      |\n",
      "|    policy_gradient_loss | -4e-10    |\n",
      "|    value_loss           | 7.4e+04   |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 260       |\n",
      "|    iterations      | 274       |\n",
      "|    time_elapsed    | 2427      |\n",
      "|    total_timesteps | 631296    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 260       |\n",
      "|    iterations           | 275       |\n",
      "|    time_elapsed         | 2430      |\n",
      "|    total_timesteps      | 633600    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.95e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.28e+04  |\n",
      "|    n_updates            | 2740      |\n",
      "|    policy_gradient_loss | -6.71e-10 |\n",
      "|    value_loss           | 7.37e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=635000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 635000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.95e-07 |\n",
      "|    explained_variance   | 2.38e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 4.21e+04  |\n",
      "|    n_updates            | 2750      |\n",
      "|    policy_gradient_loss | 5.77e-10  |\n",
      "|    value_loss           | 7.32e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 260       |\n",
      "|    iterations      | 276       |\n",
      "|    time_elapsed    | 2440      |\n",
      "|    total_timesteps | 635904    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 261       |\n",
      "|    iterations           | 277       |\n",
      "|    time_elapsed         | 2443      |\n",
      "|    total_timesteps      | 638208    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.94e-07 |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.67e+04  |\n",
      "|    n_updates            | 2760      |\n",
      "|    policy_gradient_loss | 1.18e-09  |\n",
      "|    value_loss           | 7.53e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=640000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 640000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.95e-07 |\n",
      "|    explained_variance   | 2.38e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 4.33e+04  |\n",
      "|    n_updates            | 2770      |\n",
      "|    policy_gradient_loss | -3.07e-10 |\n",
      "|    value_loss           | 7.35e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 261       |\n",
      "|    iterations      | 278       |\n",
      "|    time_elapsed    | 2452      |\n",
      "|    total_timesteps | 640512    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 261       |\n",
      "|    iterations           | 279       |\n",
      "|    time_elapsed         | 2455      |\n",
      "|    total_timesteps      | 642816    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.95e-07 |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 4.53e+04  |\n",
      "|    n_updates            | 2780      |\n",
      "|    policy_gradient_loss | 5.4e-10   |\n",
      "|    value_loss           | 7.44e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=645000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 645000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.92e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 4.35e+04  |\n",
      "|    n_updates            | 2790      |\n",
      "|    policy_gradient_loss | -9.87e-10 |\n",
      "|    value_loss           | 7.37e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 261       |\n",
      "|    iterations      | 280       |\n",
      "|    time_elapsed    | 2465      |\n",
      "|    total_timesteps | 645120    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 262       |\n",
      "|    iterations           | 281       |\n",
      "|    time_elapsed         | 2468      |\n",
      "|    total_timesteps      | 647424    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.93e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 4.59e+04  |\n",
      "|    n_updates            | 2800      |\n",
      "|    policy_gradient_loss | -2.24e-10 |\n",
      "|    value_loss           | 7.43e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 262       |\n",
      "|    iterations           | 282       |\n",
      "|    time_elapsed         | 2471      |\n",
      "|    total_timesteps      | 649728    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.95e-07 |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.98e+04  |\n",
      "|    n_updates            | 2810      |\n",
      "|    policy_gradient_loss | 8.57e-10  |\n",
      "|    value_loss           | 7.42e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=650000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 650000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.94e-07 |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 5.11e+04  |\n",
      "|    n_updates            | 2820      |\n",
      "|    policy_gradient_loss | -1.3e-09  |\n",
      "|    value_loss           | 7.37e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 262       |\n",
      "|    iterations      | 283       |\n",
      "|    time_elapsed    | 2480      |\n",
      "|    total_timesteps | 652032    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 263       |\n",
      "|    iterations           | 284       |\n",
      "|    time_elapsed         | 2483      |\n",
      "|    total_timesteps      | 654336    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.93e-07 |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 4e+04     |\n",
      "|    n_updates            | 2830      |\n",
      "|    policy_gradient_loss | 1.07e-09  |\n",
      "|    value_loss           | 7.31e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=655000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 655000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -7e-07    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.67e+04  |\n",
      "|    n_updates            | 2840      |\n",
      "|    policy_gradient_loss | -1.02e-10 |\n",
      "|    value_loss           | 7.32e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 263       |\n",
      "|    iterations      | 285       |\n",
      "|    time_elapsed    | 2493      |\n",
      "|    total_timesteps | 656640    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 263       |\n",
      "|    iterations           | 286       |\n",
      "|    time_elapsed         | 2496      |\n",
      "|    total_timesteps      | 658944    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.92e-07 |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.83e+04  |\n",
      "|    n_updates            | 2850      |\n",
      "|    policy_gradient_loss | -4.84e-10 |\n",
      "|    value_loss           | 7.28e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=660000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 660000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.93e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 4.19e+04  |\n",
      "|    n_updates            | 2860      |\n",
      "|    policy_gradient_loss | 6.38e-10  |\n",
      "|    value_loss           | 7.41e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 263       |\n",
      "|    iterations      | 287       |\n",
      "|    time_elapsed    | 2505      |\n",
      "|    total_timesteps | 661248    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 264       |\n",
      "|    iterations           | 288       |\n",
      "|    time_elapsed         | 2509      |\n",
      "|    total_timesteps      | 663552    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.94e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 4.89e+04  |\n",
      "|    n_updates            | 2870      |\n",
      "|    policy_gradient_loss | -1.51e-09 |\n",
      "|    value_loss           | 7.41e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=665000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 665000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.94e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 5.16e+04  |\n",
      "|    n_updates            | 2880      |\n",
      "|    policy_gradient_loss | -5.59e-11 |\n",
      "|    value_loss           | 7.31e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 264       |\n",
      "|    iterations      | 289       |\n",
      "|    time_elapsed    | 2518      |\n",
      "|    total_timesteps | 665856    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 264       |\n",
      "|    iterations           | 290       |\n",
      "|    time_elapsed         | 2521      |\n",
      "|    total_timesteps      | 668160    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.93e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.74e+04  |\n",
      "|    n_updates            | 2890      |\n",
      "|    policy_gradient_loss | 5.59e-11  |\n",
      "|    value_loss           | 7.3e+04   |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=670000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 670000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.93e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.51e+04  |\n",
      "|    n_updates            | 2900      |\n",
      "|    policy_gradient_loss | 3.63e-10  |\n",
      "|    value_loss           | 7.5e+04   |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 264       |\n",
      "|    iterations      | 291       |\n",
      "|    time_elapsed    | 2531      |\n",
      "|    total_timesteps | 670464    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 265       |\n",
      "|    iterations           | 292       |\n",
      "|    time_elapsed         | 2534      |\n",
      "|    total_timesteps      | 672768    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.93e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 5.29e+04  |\n",
      "|    n_updates            | 2910      |\n",
      "|    policy_gradient_loss | -1.68e-09 |\n",
      "|    value_loss           | 7.46e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=675000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 675000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.94e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 9.44e+03  |\n",
      "|    n_updates            | 2920      |\n",
      "|    policy_gradient_loss | -1.85e-09 |\n",
      "|    value_loss           | 7.19e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 265       |\n",
      "|    iterations      | 293       |\n",
      "|    time_elapsed    | 2543      |\n",
      "|    total_timesteps | 675072    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 265       |\n",
      "|    iterations           | 294       |\n",
      "|    time_elapsed         | 2546      |\n",
      "|    total_timesteps      | 677376    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.92e-07 |\n",
      "|    explained_variance   | 2.38e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.02e+04  |\n",
      "|    n_updates            | 2930      |\n",
      "|    policy_gradient_loss | -2.98e-10 |\n",
      "|    value_loss           | 7.44e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 266       |\n",
      "|    iterations           | 295       |\n",
      "|    time_elapsed         | 2549      |\n",
      "|    total_timesteps      | 679680    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.92e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.1e+04   |\n",
      "|    n_updates            | 2940      |\n",
      "|    policy_gradient_loss | -4.94e-10 |\n",
      "|    value_loss           | 7.58e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=680000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 680000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.93e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 4.41e+04  |\n",
      "|    n_updates            | 2950      |\n",
      "|    policy_gradient_loss | -1.3e-10  |\n",
      "|    value_loss           | 7.4e+04   |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 266       |\n",
      "|    iterations      | 296       |\n",
      "|    time_elapsed    | 2559      |\n",
      "|    total_timesteps | 681984    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 267       |\n",
      "|    iterations           | 297       |\n",
      "|    time_elapsed         | 2562      |\n",
      "|    total_timesteps      | 684288    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.96e-07 |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 5.78e+04  |\n",
      "|    n_updates            | 2960      |\n",
      "|    policy_gradient_loss | 1.02e-10  |\n",
      "|    value_loss           | 7.47e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=685000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 685000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.93e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 4.32e+04  |\n",
      "|    n_updates            | 2970      |\n",
      "|    policy_gradient_loss | 1.49e-10  |\n",
      "|    value_loss           | 7.31e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 266       |\n",
      "|    iterations      | 298       |\n",
      "|    time_elapsed    | 2571      |\n",
      "|    total_timesteps | 686592    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 267       |\n",
      "|    iterations           | 299       |\n",
      "|    time_elapsed         | 2574      |\n",
      "|    total_timesteps      | 688896    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.94e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.73e+04  |\n",
      "|    n_updates            | 2980      |\n",
      "|    policy_gradient_loss | -4.84e-10 |\n",
      "|    value_loss           | 7.49e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=690000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 690000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.94e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.37e+04  |\n",
      "|    n_updates            | 2990      |\n",
      "|    policy_gradient_loss | -8.48e-10 |\n",
      "|    value_loss           | 7.38e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 267       |\n",
      "|    iterations      | 300       |\n",
      "|    time_elapsed    | 2584      |\n",
      "|    total_timesteps | 691200    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 268       |\n",
      "|    iterations           | 301       |\n",
      "|    time_elapsed         | 2587      |\n",
      "|    total_timesteps      | 693504    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.92e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 1.7e+04   |\n",
      "|    n_updates            | 3000      |\n",
      "|    policy_gradient_loss | 3.91e-10  |\n",
      "|    value_loss           | 7.41e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=695000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 695000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.94e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 1.84e+04  |\n",
      "|    n_updates            | 3010      |\n",
      "|    policy_gradient_loss | 1.02e-09  |\n",
      "|    value_loss           | 7.27e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 267       |\n",
      "|    iterations      | 302       |\n",
      "|    time_elapsed    | 2596      |\n",
      "|    total_timesteps | 695808    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 268       |\n",
      "|    iterations           | 303       |\n",
      "|    time_elapsed         | 2599      |\n",
      "|    total_timesteps      | 698112    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.9e-07  |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.52e+04  |\n",
      "|    n_updates            | 3020      |\n",
      "|    policy_gradient_loss | 4.89e-10  |\n",
      "|    value_loss           | 7.37e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=700000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 700000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.93e-07 |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.95e+04  |\n",
      "|    n_updates            | 3030      |\n",
      "|    policy_gradient_loss | -2e-10    |\n",
      "|    value_loss           | 7.44e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 268       |\n",
      "|    iterations      | 304       |\n",
      "|    time_elapsed    | 2609      |\n",
      "|    total_timesteps | 700416    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 268       |\n",
      "|    iterations           | 305       |\n",
      "|    time_elapsed         | 2612      |\n",
      "|    total_timesteps      | 702720    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.91e-07 |\n",
      "|    explained_variance   | 2.38e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 4.21e+04  |\n",
      "|    n_updates            | 3040      |\n",
      "|    policy_gradient_loss | 1.03e-09  |\n",
      "|    value_loss           | 7.57e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=705000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 705000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.92e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 5.24e+04  |\n",
      "|    n_updates            | 3050      |\n",
      "|    policy_gradient_loss | -5.77e-10 |\n",
      "|    value_loss           | 7.27e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 268       |\n",
      "|    iterations      | 306       |\n",
      "|    time_elapsed    | 2622      |\n",
      "|    total_timesteps | 705024    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 269       |\n",
      "|    iterations           | 307       |\n",
      "|    time_elapsed         | 2625      |\n",
      "|    total_timesteps      | 707328    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.91e-07 |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 1.87e+04  |\n",
      "|    n_updates            | 3060      |\n",
      "|    policy_gradient_loss | -2.61e-09 |\n",
      "|    value_loss           | 7.35e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 269       |\n",
      "|    iterations           | 308       |\n",
      "|    time_elapsed         | 2628      |\n",
      "|    total_timesteps      | 709632    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.95e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.02e+04  |\n",
      "|    n_updates            | 3070      |\n",
      "|    policy_gradient_loss | 2.8e-09   |\n",
      "|    value_loss           | 7.31e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=710000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 710000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.9e-07  |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.73e+04  |\n",
      "|    n_updates            | 3080      |\n",
      "|    policy_gradient_loss | -6.24e-10 |\n",
      "|    value_loss           | 7.5e+04   |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 269       |\n",
      "|    iterations      | 309       |\n",
      "|    time_elapsed    | 2638      |\n",
      "|    total_timesteps | 711936    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 270       |\n",
      "|    iterations           | 310       |\n",
      "|    time_elapsed         | 2641      |\n",
      "|    total_timesteps      | 714240    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.9e-07  |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 4.78e+04  |\n",
      "|    n_updates            | 3090      |\n",
      "|    policy_gradient_loss | -2.79e-10 |\n",
      "|    value_loss           | 7.21e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=715000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 715000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.92e-07 |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.6e+04   |\n",
      "|    n_updates            | 3100      |\n",
      "|    policy_gradient_loss | -2.98e-10 |\n",
      "|    value_loss           | 7.28e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 270       |\n",
      "|    iterations      | 311       |\n",
      "|    time_elapsed    | 2651      |\n",
      "|    total_timesteps | 716544    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 270       |\n",
      "|    iterations           | 312       |\n",
      "|    time_elapsed         | 2654      |\n",
      "|    total_timesteps      | 718848    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.92e-07 |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.82e+04  |\n",
      "|    n_updates            | 3110      |\n",
      "|    policy_gradient_loss | 5.22e-10  |\n",
      "|    value_loss           | 7.34e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=720000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 720000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.92e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 4.75e+04  |\n",
      "|    n_updates            | 3120      |\n",
      "|    policy_gradient_loss | 9.69e-10  |\n",
      "|    value_loss           | 7.38e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 270       |\n",
      "|    iterations      | 313       |\n",
      "|    time_elapsed    | 2664      |\n",
      "|    total_timesteps | 721152    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 271       |\n",
      "|    iterations           | 314       |\n",
      "|    time_elapsed         | 2667      |\n",
      "|    total_timesteps      | 723456    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.94e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.48e+04  |\n",
      "|    n_updates            | 3130      |\n",
      "|    policy_gradient_loss | -3.45e-10 |\n",
      "|    value_loss           | 7.35e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=725000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 725000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.93e-07 |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 4.26e+04  |\n",
      "|    n_updates            | 3140      |\n",
      "|    policy_gradient_loss | 1.68e-10  |\n",
      "|    value_loss           | 7.49e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 271       |\n",
      "|    iterations      | 315       |\n",
      "|    time_elapsed    | 2677      |\n",
      "|    total_timesteps | 725760    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 271       |\n",
      "|    iterations           | 316       |\n",
      "|    time_elapsed         | 2680      |\n",
      "|    total_timesteps      | 728064    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.89e-07 |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.87e+04  |\n",
      "|    n_updates            | 3150      |\n",
      "|    policy_gradient_loss | -6.98e-11 |\n",
      "|    value_loss           | 7.4e+04   |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=730000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 730000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.97e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 5.14e+04  |\n",
      "|    n_updates            | 3160      |\n",
      "|    policy_gradient_loss | 2.98e-10  |\n",
      "|    value_loss           | 7.33e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 271       |\n",
      "|    iterations      | 317       |\n",
      "|    time_elapsed    | 2690      |\n",
      "|    total_timesteps | 730368    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 272       |\n",
      "|    iterations           | 318       |\n",
      "|    time_elapsed         | 2693      |\n",
      "|    total_timesteps      | 732672    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.93e-07 |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.36e+04  |\n",
      "|    n_updates            | 3170      |\n",
      "|    policy_gradient_loss | 1.15e-09  |\n",
      "|    value_loss           | 7.47e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 272       |\n",
      "|    iterations           | 319       |\n",
      "|    time_elapsed         | 2696      |\n",
      "|    total_timesteps      | 734976    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.97e-07 |\n",
      "|    explained_variance   | 2.38e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.27e+04  |\n",
      "|    n_updates            | 3180      |\n",
      "|    policy_gradient_loss | 4.84e-10  |\n",
      "|    value_loss           | 7.5e+04   |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=735000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 735000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.93e-07 |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 1.07e+04  |\n",
      "|    n_updates            | 3190      |\n",
      "|    policy_gradient_loss | -2.14e-10 |\n",
      "|    value_loss           | 7.33e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 272       |\n",
      "|    iterations      | 320       |\n",
      "|    time_elapsed    | 2706      |\n",
      "|    total_timesteps | 737280    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 272       |\n",
      "|    iterations           | 321       |\n",
      "|    time_elapsed         | 2709      |\n",
      "|    total_timesteps      | 739584    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.93e-07 |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.39e+04  |\n",
      "|    n_updates            | 3200      |\n",
      "|    policy_gradient_loss | 6.98e-10  |\n",
      "|    value_loss           | 7.4e+04   |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=740000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 740000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.92e-07 |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.95e+04  |\n",
      "|    n_updates            | 3210      |\n",
      "|    policy_gradient_loss | 6.43e-10  |\n",
      "|    value_loss           | 7.44e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 272       |\n",
      "|    iterations      | 322       |\n",
      "|    time_elapsed    | 2719      |\n",
      "|    total_timesteps | 741888    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 273       |\n",
      "|    iterations           | 323       |\n",
      "|    time_elapsed         | 2722      |\n",
      "|    total_timesteps      | 744192    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.9e-07  |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 4.44e+04  |\n",
      "|    n_updates            | 3220      |\n",
      "|    policy_gradient_loss | 2.42e-10  |\n",
      "|    value_loss           | 7.41e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=745000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 745000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.9e-07  |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 5.15e+04  |\n",
      "|    n_updates            | 3230      |\n",
      "|    policy_gradient_loss | -2.84e-10 |\n",
      "|    value_loss           | 7.35e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 273       |\n",
      "|    iterations      | 324       |\n",
      "|    time_elapsed    | 2732      |\n",
      "|    total_timesteps | 746496    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 273       |\n",
      "|    iterations           | 325       |\n",
      "|    time_elapsed         | 2735      |\n",
      "|    total_timesteps      | 748800    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.93e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 4.41e+04  |\n",
      "|    n_updates            | 3240      |\n",
      "|    policy_gradient_loss | 3.96e-10  |\n",
      "|    value_loss           | 7.45e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=750000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 750000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.94e-07 |\n",
      "|    explained_variance   | 2.38e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 7.32e+04  |\n",
      "|    n_updates            | 3250      |\n",
      "|    policy_gradient_loss | 7.82e-10  |\n",
      "|    value_loss           | 7.48e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 273       |\n",
      "|    iterations      | 326       |\n",
      "|    time_elapsed    | 2744      |\n",
      "|    total_timesteps | 751104    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 274       |\n",
      "|    iterations           | 327       |\n",
      "|    time_elapsed         | 2748      |\n",
      "|    total_timesteps      | 753408    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.93e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.68e+04  |\n",
      "|    n_updates            | 3260      |\n",
      "|    policy_gradient_loss | 6.52e-11  |\n",
      "|    value_loss           | 7.51e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=755000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 755000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.93e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 1.86e+04  |\n",
      "|    n_updates            | 3270      |\n",
      "|    policy_gradient_loss | 9.78e-11  |\n",
      "|    value_loss           | 7.37e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 274       |\n",
      "|    iterations      | 328       |\n",
      "|    time_elapsed    | 2757      |\n",
      "|    total_timesteps | 755712    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 274       |\n",
      "|    iterations           | 329       |\n",
      "|    time_elapsed         | 2760      |\n",
      "|    total_timesteps      | 758016    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.93e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 4.13e+04  |\n",
      "|    n_updates            | 3280      |\n",
      "|    policy_gradient_loss | -5.54e-10 |\n",
      "|    value_loss           | 7.41e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=760000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 760000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.93e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 6.28e+04  |\n",
      "|    n_updates            | 3290      |\n",
      "|    policy_gradient_loss | -3.45e-10 |\n",
      "|    value_loss           | 7.4e+04   |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 274       |\n",
      "|    iterations      | 330       |\n",
      "|    time_elapsed    | 2770      |\n",
      "|    total_timesteps | 760320    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 274       |\n",
      "|    iterations           | 331       |\n",
      "|    time_elapsed         | 2773      |\n",
      "|    total_timesteps      | 762624    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.93e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.11e+04  |\n",
      "|    n_updates            | 3300      |\n",
      "|    policy_gradient_loss | 8.01e-10  |\n",
      "|    value_loss           | 7.34e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 275       |\n",
      "|    iterations           | 332       |\n",
      "|    time_elapsed         | 2776      |\n",
      "|    total_timesteps      | 764928    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.94e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.45e+04  |\n",
      "|    n_updates            | 3310      |\n",
      "|    policy_gradient_loss | -8.75e-10 |\n",
      "|    value_loss           | 7.35e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=765000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 765000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.93e-07 |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.36e+04  |\n",
      "|    n_updates            | 3320      |\n",
      "|    policy_gradient_loss | 8.29e-10  |\n",
      "|    value_loss           | 7.5e+04   |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 275       |\n",
      "|    iterations      | 333       |\n",
      "|    time_elapsed    | 2786      |\n",
      "|    total_timesteps | 767232    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 275       |\n",
      "|    iterations           | 334       |\n",
      "|    time_elapsed         | 2789      |\n",
      "|    total_timesteps      | 769536    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.93e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.93e+04  |\n",
      "|    n_updates            | 3330      |\n",
      "|    policy_gradient_loss | -1.71e-09 |\n",
      "|    value_loss           | 7.32e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=770000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 770000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.93e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.03e+04  |\n",
      "|    n_updates            | 3340      |\n",
      "|    policy_gradient_loss | -1.65e-09 |\n",
      "|    value_loss           | 7.43e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 275       |\n",
      "|    iterations      | 335       |\n",
      "|    time_elapsed    | 2799      |\n",
      "|    total_timesteps | 771840    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 276       |\n",
      "|    iterations           | 336       |\n",
      "|    time_elapsed         | 2802      |\n",
      "|    total_timesteps      | 774144    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.91e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 6.93e+04  |\n",
      "|    n_updates            | 3350      |\n",
      "|    policy_gradient_loss | 1.62e-09  |\n",
      "|    value_loss           | 7.52e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=775000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 775000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.92e-07 |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 5.68e+04  |\n",
      "|    n_updates            | 3360      |\n",
      "|    policy_gradient_loss | -2.05e-10 |\n",
      "|    value_loss           | 7.43e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 276       |\n",
      "|    iterations      | 337       |\n",
      "|    time_elapsed    | 2812      |\n",
      "|    total_timesteps | 776448    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 276       |\n",
      "|    iterations           | 338       |\n",
      "|    time_elapsed         | 2815      |\n",
      "|    total_timesteps      | 778752    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.96e-07 |\n",
      "|    explained_variance   | 2.38e-07  |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.92e+04  |\n",
      "|    n_updates            | 3370      |\n",
      "|    policy_gradient_loss | 1.56e-09  |\n",
      "|    value_loss           | 7.37e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=780000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 780000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.93e-07 |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.29e+04  |\n",
      "|    n_updates            | 3380      |\n",
      "|    policy_gradient_loss | -1.51e-09 |\n",
      "|    value_loss           | 7.33e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 276       |\n",
      "|    iterations      | 339       |\n",
      "|    time_elapsed    | 2825      |\n",
      "|    total_timesteps | 781056    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 276       |\n",
      "|    iterations           | 340       |\n",
      "|    time_elapsed         | 2828      |\n",
      "|    total_timesteps      | 783360    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.93e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 4.61e+04  |\n",
      "|    n_updates            | 3390      |\n",
      "|    policy_gradient_loss | -3.63e-10 |\n",
      "|    value_loss           | 7.31e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=785000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 785000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.9e-07  |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 4.08e+04  |\n",
      "|    n_updates            | 3400      |\n",
      "|    policy_gradient_loss | -8.85e-10 |\n",
      "|    value_loss           | 7.45e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 276       |\n",
      "|    iterations      | 341       |\n",
      "|    time_elapsed    | 2837      |\n",
      "|    total_timesteps | 785664    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 277       |\n",
      "|    iterations           | 342       |\n",
      "|    time_elapsed         | 2841      |\n",
      "|    total_timesteps      | 787968    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.95e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.49e+04  |\n",
      "|    n_updates            | 3410      |\n",
      "|    policy_gradient_loss | -3.73e-10 |\n",
      "|    value_loss           | 7.38e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=790000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 790000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.94e-07 |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.45e+04  |\n",
      "|    n_updates            | 3420      |\n",
      "|    policy_gradient_loss | -1.11e-09 |\n",
      "|    value_loss           | 7.31e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 277       |\n",
      "|    iterations      | 343       |\n",
      "|    time_elapsed    | 2850      |\n",
      "|    total_timesteps | 790272    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 277       |\n",
      "|    iterations           | 344       |\n",
      "|    time_elapsed         | 2853      |\n",
      "|    total_timesteps      | 792576    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.92e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3e+04     |\n",
      "|    n_updates            | 3430      |\n",
      "|    policy_gradient_loss | -1.96e-10 |\n",
      "|    value_loss           | 7.3e+04   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 278       |\n",
      "|    iterations           | 345       |\n",
      "|    time_elapsed         | 2857      |\n",
      "|    total_timesteps      | 794880    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.92e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 4.3e+04   |\n",
      "|    n_updates            | 3440      |\n",
      "|    policy_gradient_loss | 7.45e-10  |\n",
      "|    value_loss           | 7.33e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=795000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 795000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.91e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 2.73e+04  |\n",
      "|    n_updates            | 3450      |\n",
      "|    policy_gradient_loss | -8.29e-10 |\n",
      "|    value_loss           | 7.4e+04   |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 278       |\n",
      "|    iterations      | 346       |\n",
      "|    time_elapsed    | 2866      |\n",
      "|    total_timesteps | 797184    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 576       |\n",
      "|    ep_rew_mean          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 278       |\n",
      "|    iterations           | 347       |\n",
      "|    time_elapsed         | 2869      |\n",
      "|    total_timesteps      | 799488    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.93e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 3.33e+04  |\n",
      "|    n_updates            | 3460      |\n",
      "|    policy_gradient_loss | 1.4e-10   |\n",
      "|    value_loss           | 7.43e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=800000, episode_reward=-14118.03 +/- 0.00\n",
      "Episode length: 576.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 576       |\n",
      "|    mean_reward          | -1.41e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 800000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.89e-07 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.003     |\n",
      "|    loss                 | 4.1e+04   |\n",
      "|    n_updates            | 3470      |\n",
      "|    policy_gradient_loss | -1.15e-09 |\n",
      "|    value_loss           | 7.32e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 278       |\n",
      "|    iterations      | 348       |\n",
      "|    time_elapsed    | 2879      |\n",
      "|    total_timesteps | 801792    |\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sb3_contrib import MaskablePPO\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "import numpy as np\n",
    "import torch\n",
    "from environment3 import LifeStyleEnv\n",
    "import gymnasium as gym\n",
    "from sb3_contrib.common.wrappers import ActionMasker\n",
    "\n",
    "# best_entropy_coef = 0.001\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def mask_fn(env: gym.Env) -> np.ndarray:\n",
    "    unwrapped_env = env\n",
    "    while hasattr(unwrapped_env, \"env\"):\n",
    "        unwrapped_env = unwrapped_env.env\n",
    "    return unwrapped_env.action_masks()\n",
    "\n",
    "def make_env(is_eval: bool = False):\n",
    "    env = LifeStyleEnv()\n",
    "    env = Monitor(env)\n",
    "    if not is_eval:\n",
    "        check_env(env, warn=True) \n",
    "    return env\n",
    "\n",
    "env = make_env()\n",
    "env = ActionMasker(env, mask_fn)\n",
    "\n",
    "eval_env = make_env(is_eval=True)\n",
    "eval_env = ActionMasker(eval_env, mask_fn)\n",
    "\n",
    "eval_callback = EvalCallback(\n",
    "    eval_env,\n",
    "    best_model_save_path=\"./logs/best_model\",\n",
    "    log_path=\"./logs/results\",\n",
    "    eval_freq=5000,\n",
    "    n_eval_episodes=10,\n",
    "    deterministic=True,\n",
    "    render=False\n",
    ")\n",
    "\n",
    "model = MaskablePPO(\n",
    "    \"MultiInputPolicy\",  \n",
    "    env,\n",
    "    learning_rate=0.003,\n",
    "    n_steps=2304,\n",
    "    batch_size=512,\n",
    "    n_epochs=10,\n",
    "    gamma=0.99,\n",
    "    gae_lambda=0.95,\n",
    "    clip_range=0.2,\n",
    "    ent_coef=best_entropy_coef,  \n",
    "    vf_coef=0.5,\n",
    "    max_grad_norm=0.5,\n",
    "    verbose=1,\n",
    "    device=device,\n",
    "    policy_kwargs=dict(net_arch=[128, 128])\n",
    ")\n",
    "\n",
    "model.learn(\n",
    "    total_timesteps=800000, \n",
    "    callback=eval_callback\n",
    ")\n",
    "\n",
    "model.save(\"../agent/ppo_lifestylecoach_best_entropy2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29392ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Final Evaluation...\n",
      "-------------------------------------------------------------------------------------------------------------------------------------\n",
      "| Day | Timeslot   | Action     | Event      | BMI      | Stress   | Energy   | Hunger   | Cal. Intake  | Cal. Burned  | Reward   |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------\n",
      "| 0   | 1          | 8          | sleep      | 24.22    | 46.00    | 54.00    | 48.00    | 0.00         | 66.15        | 0.42     |\n",
      "| 0   | 2          | 8          | sleep      | 24.22    | 42.00    | 58.00    | 46.00    | 0.00         | 132.30       | 1.04     |\n",
      "| 0   | 3          | 8          | sleep      | 24.22    | 38.00    | 62.00    | 44.00    | 0.00         | 198.45       | 1.63     |\n",
      "| 0   | 4          | 8          | sleep      | 24.22    | 34.00    | 66.00    | 42.00    | 0.00         | 264.60       | 2.20     |\n",
      "| 0   | 5          | 8          | sleep      | 24.22    | 30.00    | 70.00    | 40.00    | 0.00         | 330.75       | 2.75     |\n",
      "| 0   | 6          | 8          | sleep      | 24.22    | 26.00    | 74.00    | 38.00    | 0.00         | 396.90       | 3.27     |\n",
      "| 0   | 7          | 5          | action     | 24.22    | 26.00    | 59.00    | 53.00    | 0.00         | 1058.40      | 3.15     |\n",
      "| 0   | 8          | 0          | action     | 24.22    | 26.00    | 79.00    | 33.00    | 350.00       | 1058.40      | 5.17     |\n",
      "| 0   | 9          | 5          | action     | 24.22    | 26.00    | 64.00    | 48.00    | 350.00       | 1719.90      | 7.51     |\n",
      "| 0   | 10         | 5          | action     | 24.22    | 26.00    | 49.00    | 63.00    | 350.00       | 2381.40      | 8.48     |\n",
      "| 0   | 11         | 8          | work       | 24.22    | 31.00    | 44.00    | 68.00    | 350.00       | 2528.40      | 8.02     |\n",
      "| 0   | 12         | 8          | work       | 24.22    | 36.00    | 39.00    | 73.00    | 350.00       | 2675.40      | 7.42     |\n",
      "| 0   | 13         | 0          | action     | 24.22    | 36.00    | 59.00    | 53.00    | 700.00       | 2675.40      | 9.88     |\n",
      "| 0   | 14         | 8          | work       | 24.22    | 41.00    | 54.00    | 58.00    | 700.00       | 2822.40      | 9.74     |\n",
      "| 0   | 15         | 8          | work       | 24.22    | 46.00    | 49.00    | 63.00    | 700.00       | 2969.40      | 9.44     |\n",
      "| 0   | 16         | 8          | work       | 24.22    | 51.00    | 44.00    | 68.00    | 700.00       | 3116.40      | 8.98     |\n",
      "| 0   | 17         | 8          | work       | 24.22    | 56.00    | 39.00    | 73.00    | 700.00       | 3263.40      | 8.38     |\n",
      "| 0   | 18         | 8          | work       | 24.22    | 61.00    | 34.00    | 78.00    | 700.00       | 3410.40      | 7.62     |\n",
      "| 0   | 19         | 0          | action     | 24.22    | 61.00    | 54.00    | 58.00    | 1050.00      | 3410.40      | 10.70    |\n",
      "| 0   | 20         | 0          | action     | 24.22    | 61.00    | 74.00    | 38.00    | 1400.00      | 3410.40      | 11.32    |\n",
      "| 0   | 21         | 0          | action     | 24.22    | 61.00    | 94.00    | 18.00    | 1750.00      | 3410.40      | 9.94     |\n",
      "| 0   | 22         | 0          | action     | 24.22    | 61.00    | 100.00   | 0.00     | 2100.00      | 3410.40      | 8.29     |\n",
      "| 0   | 23         | 8          | sleep      | 24.22    | 57.00    | 100.00   | 0.00     | 2100.00      | 3476.55      | 8.70     |\n",
      "| 1   | 0          | 8          | sleep      | 24.16    | 53.00    | 100.00   | 0.00     | 0.00         | 0.00         | 18.89    |\n",
      "| 1   | 1          | 8          | sleep      | 24.16    | 49.00    | 100.00   | 0.00     | 0.00         | 65.97        | 1.35     |\n",
      "| 1   | 2          | 8          | sleep      | 24.16    | 45.00    | 100.00   | 0.00     | 0.00         | 131.95       | 1.76     |\n",
      "| 1   | 3          | 8          | sleep      | 24.16    | 41.00    | 100.00   | 0.00     | 0.00         | 197.92       | 2.17     |\n",
      "| 1   | 4          | 8          | sleep      | 24.16    | 37.00    | 100.00   | 0.00     | 0.00         | 263.89       | 0.58     |\n",
      "| 1   | 5          | 8          | sleep      | 24.16    | 33.00    | 100.00   | 0.00     | 0.00         | 329.86       | -1.01    |\n",
      "| 1   | 6          | 8          | sleep      | 24.16    | 29.00    | 100.00   | 0.00     | 0.00         | 395.84       | -2.60    |\n",
      "| 1   | 7          | 5          | action     | 24.16    | 29.00    | 85.00    | 15.00    | 0.00         | 1055.57      | -1.30    |\n",
      "| 1   | 8          | 0          | action     | 24.16    | 29.00    | 100.00   | 0.00     | 350.00       | 1055.57      | 5.12     |\n",
      "| 1   | 9          | 5          | action     | 24.16    | 29.00    | 85.00    | 15.00    | 350.00       | 1715.30      | 8.42     |\n",
      "| 1   | 10         | 5          | action     | 24.16    | 29.00    | 70.00    | 30.00    | 350.00       | 2375.03      | 11.72    |\n",
      "| 1   | 11         | 8          | work       | 24.16    | 34.00    | 65.00    | 35.00    | 350.00       | 2521.63      | 12.27    |\n",
      "| 1   | 12         | 8          | work       | 24.16    | 39.00    | 60.00    | 40.00    | 350.00       | 2668.24      | 12.68    |\n",
      "| 1   | 13         | 0          | action     | 24.16    | 39.00    | 80.00    | 20.00    | 700.00       | 2668.24      | 11.41    |\n",
      "| 1   | 14         | 8          | work       | 24.16    | 44.00    | 75.00    | 25.00    | 700.00       | 2814.85      | 12.04    |\n",
      "| 1   | 15         | 8          | work       | 24.16    | 49.00    | 70.00    | 30.00    | 700.00       | 2961.45      | 12.67    |\n",
      "| 1   | 16         | 8          | work       | 24.16    | 54.00    | 65.00    | 35.00    | 700.00       | 3108.06      | 13.23    |\n",
      "| 1   | 17         | 8          | work       | 24.16    | 59.00    | 60.00    | 40.00    | 700.00       | 3254.67      | 13.63    |\n",
      "| 1   | 18         | 8          | work       | 24.16    | 64.00    | 55.00    | 45.00    | 700.00       | 3401.27      | 13.88    |\n",
      "| 1   | 19         | 0          | action     | 24.16    | 64.00    | 75.00    | 25.00    | 1050.00      | 3401.27      | 12.99    |\n",
      "| 1   | 20         | 0          | action     | 24.16    | 64.00    | 95.00    | 5.00     | 1400.00      | 3401.27      | 11.41    |\n",
      "| 1   | 21         | 0          | action     | 24.16    | 64.00    | 100.00   | 0.00     | 1750.00      | 3401.27      | 9.84     |\n",
      "| 1   | 22         | 0          | action     | 24.16    | 64.00    | 100.00   | 0.00     | 2100.00      | 3401.27      | 8.18     |\n",
      "| 1   | 23         | 8          | sleep      | 24.16    | 60.00    | 100.00   | 0.00     | 2100.00      | 3467.24      | 8.59     |\n",
      "| 2   | 0          | 8          | sleep      | 24.09    | 56.00    | 100.00   | 0.00     | 0.00         | 0.00         | 18.78    |\n",
      "| 2   | 1          | 8          | sleep      | 24.09    | 52.00    | 100.00   | 0.00     | 0.00         | 65.80        | 1.29     |\n",
      "| 2   | 2          | 8          | sleep      | 24.09    | 48.00    | 100.00   | 0.00     | 0.00         | 131.59       | 1.70     |\n",
      "| 2   | 3          | 8          | sleep      | 24.09    | 44.00    | 100.00   | 0.00     | 0.00         | 197.39       | 2.11     |\n",
      "| 2   | 4          | 8          | sleep      | 24.09    | 40.00    | 100.00   | 0.00     | 0.00         | 263.19       | 0.52     |\n",
      "| 2   | 5          | 8          | sleep      | 24.09    | 36.00    | 100.00   | 0.00     | 0.00         | 328.99       | -1.08    |\n",
      "| 2   | 6          | 8          | sleep      | 24.09    | 32.00    | 100.00   | 0.00     | 0.00         | 394.78       | -2.67    |\n",
      "| 2   | 7          | 5          | action     | 24.09    | 32.00    | 85.00    | 15.00    | 0.00         | 1052.75      | -1.38    |\n",
      "| 2   | 8          | 0          | action     | 24.09    | 32.00    | 100.00   | 0.00     | 350.00       | 1052.75      | 5.05     |\n",
      "| 2   | 9          | 5          | action     | 24.09    | 32.00    | 85.00    | 15.00    | 350.00       | 1710.72      | 8.34     |\n",
      "| 2   | 10         | 5          | action     | 24.09    | 32.00    | 70.00    | 30.00    | 350.00       | 2368.69      | 11.63    |\n",
      "| 2   | 11         | 8          | work       | 24.09    | 37.00    | 65.00    | 35.00    | 350.00       | 2514.91      | 12.18    |\n",
      "| 2   | 12         | 8          | work       | 24.09    | 42.00    | 60.00    | 40.00    | 350.00       | 2661.12      | 12.58    |\n",
      "| 2   | 13         | 0          | action     | 24.09    | 42.00    | 80.00    | 20.00    | 700.00       | 2661.12      | 11.31    |\n",
      "| 2   | 14         | 8          | work       | 24.09    | 47.00    | 75.00    | 25.00    | 700.00       | 2807.34      | 11.94    |\n",
      "| 2   | 15         | 8          | work       | 24.09    | 52.00    | 70.00    | 30.00    | 700.00       | 2953.56      | 12.57    |\n",
      "| 2   | 16         | 8          | work       | 24.09    | 57.00    | 65.00    | 35.00    | 700.00       | 3099.77      | 13.13    |\n",
      "| 2   | 17         | 8          | work       | 24.09    | 62.00    | 60.00    | 40.00    | 700.00       | 3245.99      | 13.53    |\n",
      "| 2   | 18         | 8          | work       | 24.09    | 67.00    | 55.00    | 45.00    | 700.00       | 3392.20      | 13.78    |\n",
      "| 2   | 19         | 0          | action     | 24.09    | 67.00    | 75.00    | 25.00    | 1050.00      | 3392.20      | 12.89    |\n",
      "| 2   | 20         | 0          | action     | 24.09    | 67.00    | 95.00    | 5.00     | 1400.00      | 3392.20      | 11.31    |\n",
      "| 2   | 21         | 0          | action     | 24.09    | 67.00    | 100.00   | 0.00     | 1750.00      | 3392.20      | 9.73     |\n",
      "| 2   | 22         | 0          | action     | 24.09    | 67.00    | 100.00   | 0.00     | 2100.00      | 3392.20      | 8.07     |\n",
      "| 2   | 23         | 8          | sleep      | 24.09    | 63.00    | 100.00   | 0.00     | 2100.00      | 3458.00      | 8.48     |\n",
      "| 3   | 0          | 8          | sleep      | 24.03    | 59.00    | 100.00   | 0.00     | 0.00         | 0.00         | 18.68    |\n",
      "| 3   | 1          | 8          | sleep      | 24.03    | 55.00    | 100.00   | 0.00     | 0.00         | 65.62        | 1.23     |\n",
      "| 3   | 2          | 8          | sleep      | 24.03    | 51.00    | 100.00   | 0.00     | 0.00         | 131.24       | 1.64     |\n",
      "| 3   | 3          | 8          | sleep      | 24.03    | 47.00    | 100.00   | 0.00     | 0.00         | 196.87       | 2.04     |\n",
      "| 3   | 4          | 8          | sleep      | 24.03    | 43.00    | 100.00   | 0.00     | 0.00         | 262.49       | 0.45     |\n",
      "| 3   | 5          | 8          | sleep      | 24.03    | 39.00    | 100.00   | 0.00     | 0.00         | 328.11       | -1.14    |\n",
      "| 3   | 6          | 8          | sleep      | 24.03    | 35.00    | 100.00   | 0.00     | 0.00         | 393.73       | -2.73    |\n",
      "| 3   | 7          | 5          | action     | 24.03    | 35.00    | 85.00    | 15.00    | 0.00         | 1049.96      | -1.45    |\n",
      "| 3   | 8          | 0          | action     | 24.03    | 35.00    | 100.00   | 0.00     | 350.00       | 1049.96      | 4.97     |\n",
      "| 3   | 9          | 5          | action     | 24.03    | 35.00    | 85.00    | 15.00    | 350.00       | 1706.18      | 8.25     |\n",
      "| 3   | 10         | 5          | action     | 24.03    | 35.00    | 70.00    | 30.00    | 350.00       | 2362.40      | 11.53    |\n",
      "| 3   | 11         | 8          | work       | 24.03    | 40.00    | 65.00    | 35.00    | 350.00       | 2508.23      | 12.09    |\n",
      "| 3   | 12         | 8          | work       | 24.03    | 45.00    | 60.00    | 40.00    | 350.00       | 2654.06      | 12.49    |\n",
      "| 3   | 13         | 0          | action     | 24.03    | 45.00    | 80.00    | 20.00    | 700.00       | 2654.06      | 11.22    |\n",
      "| 3   | 14         | 8          | work       | 24.03    | 50.00    | 75.00    | 25.00    | 700.00       | 2799.89      | 11.85    |\n",
      "| 3   | 15         | 8          | work       | 24.03    | 55.00    | 70.00    | 30.00    | 700.00       | 2945.71      | 12.47    |\n",
      "| 3   | 16         | 8          | work       | 24.03    | 60.00    | 65.00    | 35.00    | 700.00       | 3091.54      | 13.03    |\n",
      "| 3   | 17         | 8          | work       | 24.03    | 65.00    | 60.00    | 40.00    | 700.00       | 3237.37      | 13.43    |\n",
      "| 3   | 18         | 8          | work       | 24.03    | 70.00    | 55.00    | 45.00    | 700.00       | 3383.19      | 13.67    |\n",
      "| 3   | 19         | 0          | action     | 24.03    | 70.00    | 75.00    | 25.00    | 1050.00      | 3383.19      | 12.78    |\n",
      "| 3   | 20         | 0          | action     | 24.03    | 70.00    | 95.00    | 5.00     | 1400.00      | 3383.19      | 11.21    |\n",
      "| 3   | 21         | 0          | action     | 24.03    | 70.00    | 100.00   | 0.00     | 1750.00      | 3383.19      | 9.63     |\n",
      "| 3   | 22         | 0          | action     | 24.03    | 70.00    | 100.00   | 0.00     | 2100.00      | 3383.19      | 7.97     |\n",
      "| 3   | 23         | 8          | sleep      | 24.03    | 66.00    | 100.00   | 0.00     | 2100.00      | 3448.82      | 8.37     |\n",
      "| 4   | 0          | 8          | sleep      | 23.96    | 62.00    | 100.00   | 0.00     | 0.00         | 0.00         | 18.58    |\n",
      "| 4   | 1          | 8          | sleep      | 23.96    | 58.00    | 100.00   | 0.00     | 0.00         | 65.45        | 1.17     |\n",
      "| 4   | 2          | 8          | sleep      | 23.96    | 54.00    | 100.00   | 0.00     | 0.00         | 130.90       | 1.57     |\n",
      "| 4   | 3          | 8          | sleep      | 23.96    | 50.00    | 100.00   | 0.00     | 0.00         | 196.35       | 1.98     |\n",
      "| 4   | 4          | 8          | sleep      | 23.96    | 46.00    | 100.00   | 0.00     | 0.00         | 261.79       | 0.39     |\n",
      "| 4   | 5          | 8          | sleep      | 23.96    | 42.00    | 100.00   | 0.00     | 0.00         | 327.24       | -1.20    |\n",
      "| 4   | 6          | 8          | sleep      | 23.96    | 38.00    | 100.00   | 0.00     | 0.00         | 392.69       | -2.80    |\n",
      "| 4   | 7          | 5          | action     | 23.96    | 38.00    | 85.00    | 15.00    | 0.00         | 1047.18      | -1.52    |\n",
      "| 4   | 8          | 0          | action     | 23.96    | 38.00    | 100.00   | 0.00     | 350.00       | 1047.18      | 4.90     |\n",
      "| 4   | 9          | 5          | action     | 23.96    | 38.00    | 85.00    | 15.00    | 350.00       | 1701.67      | 8.17     |\n",
      "| 4   | 10         | 5          | action     | 23.96    | 38.00    | 70.00    | 30.00    | 350.00       | 2356.15      | 11.44    |\n",
      "| 4   | 11         | 8          | work       | 23.96    | 43.00    | 65.00    | 35.00    | 350.00       | 2501.60      | 11.99    |\n",
      "| 4   | 12         | 8          | work       | 23.96    | 48.00    | 60.00    | 40.00    | 350.00       | 2647.04      | 12.39    |\n",
      "| 4   | 13         | 0          | action     | 23.96    | 48.00    | 80.00    | 20.00    | 700.00       | 2647.04      | 11.12    |\n",
      "| 4   | 14         | 8          | work       | 23.96    | 53.00    | 75.00    | 25.00    | 700.00       | 2792.48      | 11.75    |\n",
      "| 4   | 15         | 8          | work       | 23.96    | 58.00    | 70.00    | 30.00    | 700.00       | 2937.92      | 12.38    |\n",
      "| 4   | 16         | 8          | work       | 23.96    | 63.00    | 65.00    | 35.00    | 700.00       | 3083.36      | 12.93    |\n",
      "| 4   | 17         | 8          | work       | 23.96    | 68.00    | 60.00    | 40.00    | 700.00       | 3228.80      | 13.32    |\n",
      "| 4   | 18         | 8          | work       | 23.96    | 73.00    | 55.00    | 45.00    | 700.00       | 3374.24      | 13.57    |\n",
      "| 4   | 19         | 0          | action     | 23.96    | 73.00    | 75.00    | 25.00    | 1050.00      | 3374.24      | 12.68    |\n",
      "| 4   | 20         | 0          | action     | 23.96    | 73.00    | 95.00    | 5.00     | 1400.00      | 3374.24      | 11.10    |\n",
      "| 4   | 21         | 0          | action     | 23.96    | 73.00    | 100.00   | 0.00     | 1750.00      | 3374.24      | 9.53     |\n",
      "| 4   | 22         | 0          | action     | 23.96    | 73.00    | 100.00   | 0.00     | 2100.00      | 3374.24      | 7.86     |\n",
      "| 4   | 23         | 8          | sleep      | 23.96    | 69.00    | 100.00   | 0.00     | 2100.00      | 3439.69      | 8.27     |\n",
      "| 5   | 0          | 8          | sleep      | 23.90    | 65.00    | 100.00   | 0.00     | 0.00         | 0.00         | 18.48    |\n",
      "| 5   | 1          | 8          | sleep      | 23.90    | 61.00    | 100.00   | 0.00     | 0.00         | 65.28        | 1.11     |\n",
      "| 5   | 2          | 8          | sleep      | 23.90    | 57.00    | 100.00   | 0.00     | 0.00         | 130.55       | 1.51     |\n",
      "| 5   | 3          | 8          | sleep      | 23.90    | 53.00    | 100.00   | 0.00     | 0.00         | 195.83       | 1.92     |\n",
      "| 5   | 4          | 8          | sleep      | 23.90    | 49.00    | 100.00   | 0.00     | 0.00         | 261.11       | 0.33     |\n",
      "| 5   | 5          | 8          | sleep      | 23.90    | 45.00    | 100.00   | 0.00     | 0.00         | 326.38       | -1.27    |\n",
      "| 5   | 6          | 8          | sleep      | 23.90    | 41.00    | 100.00   | 0.00     | 0.00         | 391.66       | -2.86    |\n",
      "| 5   | 7          | 5          | action     | 23.90    | 41.00    | 85.00    | 15.00    | 0.00         | 1044.42      | -1.60    |\n",
      "| 5   | 8          | 0          | action     | 23.90    | 41.00    | 100.00   | 0.00     | 350.00       | 1044.42      | 4.83     |\n",
      "| 5   | 9          | 5          | action     | 23.90    | 41.00    | 85.00    | 15.00    | 350.00       | 1697.18      | 8.09     |\n",
      "| 5   | 10         | 5          | action     | 23.90    | 41.00    | 70.00    | 30.00    | 350.00       | 2349.95      | 11.35    |\n",
      "| 5   | 11         | 8          | work       | 23.90    | 46.00    | 65.00    | 35.00    | 350.00       | 2495.00      | 11.90    |\n",
      "| 5   | 12         | 8          | work       | 23.90    | 51.00    | 60.00    | 40.00    | 350.00       | 2640.06      | 12.30    |\n",
      "| 5   | 13         | 0          | action     | 23.90    | 51.00    | 80.00    | 20.00    | 700.00       | 2640.06      | 11.03    |\n",
      "| 5   | 14         | 8          | work       | 23.90    | 56.00    | 75.00    | 25.00    | 700.00       | 2785.12      | 11.65    |\n",
      "| 5   | 15         | 8          | work       | 23.90    | 61.00    | 70.00    | 30.00    | 700.00       | 2930.18      | 12.28    |\n",
      "| 5   | 16         | 8          | work       | 23.90    | 66.00    | 65.00    | 35.00    | 700.00       | 3075.24      | 12.83    |\n",
      "| 5   | 17         | 8          | work       | 23.90    | 71.00    | 60.00    | 40.00    | 700.00       | 3220.30      | 13.22    |\n",
      "| 5   | 18         | 8          | work       | 23.90    | 76.00    | 55.00    | 45.00    | 700.00       | 3365.35      | 13.47    |\n",
      "| 5   | 19         | 0          | action     | 23.90    | 76.00    | 75.00    | 25.00    | 1050.00      | 3365.35      | 12.58    |\n",
      "| 5   | 20         | 0          | action     | 23.90    | 76.00    | 95.00    | 5.00     | 1400.00      | 3365.35      | 11.00    |\n",
      "| 5   | 21         | 0          | action     | 23.90    | 76.00    | 100.00   | 0.00     | 1750.00      | 3365.35      | 9.42     |\n",
      "| 5   | 22         | 0          | action     | 23.90    | 76.00    | 100.00   | 0.00     | 2100.00      | 3365.35      | 7.76     |\n",
      "| 5   | 23         | 8          | sleep      | 23.90    | 72.00    | 100.00   | 0.00     | 2100.00      | 3430.63      | 8.16     |\n",
      "| 6   | 0          | 8          | sleep      | 23.84    | 68.00    | 100.00   | 0.00     | 0.00         | 0.00         | 18.38    |\n",
      "| 6   | 1          | 8          | sleep      | 23.84    | 64.00    | 100.00   | 0.00     | 0.00         | 65.10        | 1.05     |\n",
      "| 6   | 2          | 8          | sleep      | 23.84    | 60.00    | 100.00   | 0.00     | 0.00         | 130.21       | 1.45     |\n",
      "| 6   | 3          | 8          | sleep      | 23.84    | 56.00    | 100.00   | 0.00     | 0.00         | 195.31       | 1.86     |\n",
      "| 6   | 4          | 8          | sleep      | 23.84    | 52.00    | 100.00   | 0.00     | 0.00         | 260.42       | 0.26     |\n",
      "| 6   | 5          | 8          | sleep      | 23.84    | 48.00    | 100.00   | 0.00     | 0.00         | 325.52       | -1.33    |\n",
      "| 6   | 6          | 8          | sleep      | 23.84    | 44.00    | 100.00   | 0.00     | 0.00         | 390.63       | -2.93    |\n",
      "| 6   | 7          | 5          | action     | 23.84    | 44.00    | 85.00    | 15.00    | 0.00         | 1041.68      | -1.67    |\n",
      "| 6   | 8          | 0          | action     | 23.84    | 44.00    | 100.00   | 0.00     | 350.00       | 1041.68      | 4.75     |\n",
      "| 6   | 9          | 5          | action     | 23.84    | 44.00    | 85.00    | 15.00    | 350.00       | 1692.73      | 8.01     |\n",
      "| 6   | 10         | 5          | action     | 23.84    | 44.00    | 70.00    | 30.00    | 350.00       | 2343.78      | 11.26    |\n",
      "| 6   | 11         | 8          | work       | 23.84    | 49.00    | 65.00    | 35.00    | 350.00       | 2488.46      | 11.81    |\n",
      "| 6   | 12         | 8          | work       | 23.84    | 54.00    | 60.00    | 40.00    | 350.00       | 2633.13      | 12.20    |\n",
      "| 6   | 13         | 0          | action     | 23.84    | 54.00    | 80.00    | 20.00    | 700.00       | 2633.13      | 10.93    |\n",
      "| 6   | 14         | 8          | work       | 23.84    | 59.00    | 75.00    | 25.00    | 700.00       | 2777.81      | 11.56    |\n",
      "| 6   | 15         | 8          | work       | 23.84    | 64.00    | 70.00    | 30.00    | 700.00       | 2922.49      | 12.18    |\n",
      "| 6   | 16         | 8          | work       | 23.84    | 69.00    | 65.00    | 35.00    | 700.00       | 3067.17      | 12.73    |\n",
      "| 6   | 17         | 8          | work       | 23.84    | 74.00    | 60.00    | 40.00    | 700.00       | 3211.84      | 13.12    |\n",
      "| 6   | 18         | 8          | work       | 23.84    | 79.00    | 55.00    | 45.00    | 700.00       | 3356.52      | 13.36    |\n",
      "| 6   | 19         | 0          | action     | 23.84    | 79.00    | 75.00    | 25.00    | 1050.00      | 3356.52      | 12.47    |\n",
      "| 6   | 20         | 0          | action     | 23.84    | 79.00    | 95.00    | 5.00     | 1400.00      | 3356.52      | 10.90    |\n",
      "| 6   | 21         | 0          | action     | 23.84    | 79.00    | 100.00   | 0.00     | 1750.00      | 3356.52      | 9.32     |\n",
      "| 6   | 22         | 0          | action     | 23.84    | 79.00    | 100.00   | 0.00     | 2100.00      | 3356.52      | 7.65     |\n",
      "| 6   | 23         | 8          | sleep      | 23.84    | 75.00    | 100.00   | 0.00     | 2100.00      | 3421.63      | 8.06     |\n",
      "| 7   | 0          | 8          | sleep      | 23.78    | 71.00    | 100.00   | 0.00     | 0.00         | 0.00         | 18.27    |\n",
      "| 7   | 1          | 8          | sleep      | 23.78    | 67.00    | 100.00   | 0.00     | 0.00         | 64.93        | 0.98     |\n",
      "| 7   | 2          | 8          | sleep      | 23.78    | 63.00    | 100.00   | 0.00     | 0.00         | 129.87       | 1.39     |\n",
      "| 7   | 3          | 8          | sleep      | 23.78    | 59.00    | 100.00   | 0.00     | 0.00         | 194.80       | 1.79     |\n",
      "| 7   | 4          | 8          | sleep      | 23.78    | 55.00    | 100.00   | 0.00     | 0.00         | 259.74       | 0.20     |\n",
      "| 7   | 5          | 8          | sleep      | 23.78    | 51.00    | 100.00   | 0.00     | 0.00         | 324.67       | -1.40    |\n",
      "| 7   | 6          | 8          | sleep      | 23.78    | 47.00    | 100.00   | 0.00     | 0.00         | 389.61       | -2.99    |\n",
      "| 7   | 7          | 5          | action     | 23.78    | 47.00    | 85.00    | 15.00    | 0.00         | 1038.96      | -1.75    |\n",
      "| 7   | 8          | 0          | action     | 23.78    | 47.00    | 100.00   | 0.00     | 350.00       | 1038.96      | 4.68     |\n",
      "| 7   | 9          | 5          | action     | 23.78    | 47.00    | 85.00    | 15.00    | 350.00       | 1688.30      | 7.93     |\n",
      "| 7   | 10         | 5          | action     | 23.78    | 47.00    | 70.00    | 30.00    | 350.00       | 2337.65      | 11.17    |\n",
      "| 7   | 11         | 8          | work       | 23.78    | 52.00    | 65.00    | 35.00    | 350.00       | 2481.95      | 11.72    |\n",
      "| 7   | 12         | 8          | work       | 23.78    | 57.00    | 60.00    | 40.00    | 350.00       | 2626.25      | 12.11    |\n",
      "| 7   | 13         | 0          | action     | 23.78    | 57.00    | 80.00    | 20.00    | 700.00       | 2626.25      | 10.84    |\n",
      "| 7   | 14         | 8          | work       | 23.78    | 62.00    | 75.00    | 25.00    | 700.00       | 2770.55      | 11.46    |\n",
      "| 7   | 15         | 8          | work       | 23.78    | 67.00    | 70.00    | 30.00    | 700.00       | 2914.85      | 12.08    |\n",
      "| 7   | 16         | 8          | work       | 23.78    | 72.00    | 65.00    | 35.00    | 700.00       | 3059.15      | 12.63    |\n",
      "| 7   | 17         | 8          | work       | 23.78    | 77.00    | 60.00    | 40.00    | 700.00       | 3203.45      | 13.02    |\n",
      "| 7   | 18         | 8          | work       | 23.78    | 82.00    | 55.00    | 45.00    | 700.00       | 3347.75      | 13.26    |\n",
      "| 7   | 19         | 0          | action     | 23.78    | 82.00    | 75.00    | 25.00    | 1050.00      | 3347.75      | 12.37    |\n",
      "| 7   | 20         | 0          | action     | 23.78    | 82.00    | 95.00    | 5.00     | 1400.00      | 3347.75      | 10.80    |\n",
      "| 7   | 21         | 0          | action     | 23.78    | 82.00    | 100.00   | 0.00     | 1750.00      | 3347.75      | 9.22     |\n",
      "| 7   | 22         | 0          | action     | 23.78    | 82.00    | 100.00   | 0.00     | 2100.00      | 3347.75      | 7.54     |\n",
      "| 7   | 23         | 8          | sleep      | 23.78    | 78.00    | 100.00   | 0.00     | 2100.00      | 3412.68      | 7.95     |\n",
      "| 8   | 0          | 8          | sleep      | 23.71    | 74.00    | 100.00   | 0.00     | 0.00         | 0.00         | 18.17    |\n",
      "| 8   | 1          | 8          | sleep      | 23.71    | 70.00    | 100.00   | 0.00     | 0.00         | 64.77        | 0.92     |\n",
      "| 8   | 2          | 8          | sleep      | 23.71    | 66.00    | 100.00   | 0.00     | 0.00         | 129.53       | 1.33     |\n",
      "| 8   | 3          | 8          | sleep      | 23.71    | 62.00    | 100.00   | 0.00     | 0.00         | 194.30       | 1.73     |\n",
      "| 8   | 4          | 8          | sleep      | 23.71    | 58.00    | 100.00   | 0.00     | 0.00         | 259.06       | 0.14     |\n",
      "| 8   | 5          | 8          | sleep      | 23.71    | 54.00    | 100.00   | 0.00     | 0.00         | 323.83       | -1.46    |\n",
      "| 8   | 6          | 8          | sleep      | 23.71    | 50.00    | 100.00   | 0.00     | 0.00         | 388.59       | -3.06    |\n",
      "| 8   | 7          | 5          | action     | 23.71    | 50.00    | 85.00    | 15.00    | 0.00         | 1036.25      | -1.82    |\n",
      "| 8   | 8          | 0          | action     | 23.71    | 50.00    | 100.00   | 0.00     | 350.00       | 1036.25      | 4.61     |\n",
      "| 8   | 9          | 5          | action     | 23.71    | 50.00    | 85.00    | 15.00    | 350.00       | 1683.91      | 7.84     |\n",
      "| 8   | 10         | 5          | action     | 23.71    | 50.00    | 70.00    | 30.00    | 350.00       | 2331.56      | 11.08    |\n",
      "| 8   | 11         | 8          | work       | 23.71    | 55.00    | 65.00    | 35.00    | 350.00       | 2475.49      | 11.63    |\n",
      "| 8   | 12         | 8          | work       | 23.71    | 60.00    | 60.00    | 40.00    | 350.00       | 2619.41      | 12.02    |\n",
      "| 8   | 13         | 0          | action     | 23.71    | 60.00    | 80.00    | 20.00    | 700.00       | 2619.41      | 10.75    |\n",
      "| 8   | 14         | 8          | work       | 23.71    | 65.00    | 75.00    | 25.00    | 700.00       | 2763.34      | 11.37    |\n",
      "| 8   | 15         | 8          | work       | 23.71    | 70.00    | 70.00    | 30.00    | 700.00       | 2907.26      | 11.99    |\n",
      "| 8   | 16         | 8          | work       | 23.71    | 75.00    | 65.00    | 35.00    | 700.00       | 3051.18      | 12.53    |\n",
      "| 8   | 17         | 8          | work       | 23.71    | 80.00    | 60.00    | 40.00    | 700.00       | 3195.11      | 12.92    |\n",
      "| 8   | 18         | 8          | work       | 23.71    | 85.00    | 55.00    | 45.00    | 700.00       | 3339.03      | 13.16    |\n",
      "| 8   | 19         | 0          | action     | 23.71    | 85.00    | 75.00    | 25.00    | 1050.00      | 3339.03      | 12.27    |\n",
      "| 8   | 20         | 0          | action     | 23.71    | 85.00    | 95.00    | 5.00     | 1400.00      | 3339.03      | 10.69    |\n",
      "| 8   | 21         | 0          | action     | 23.71    | 85.00    | 100.00   | 0.00     | 1750.00      | 3339.03      | 9.12     |\n",
      "| 8   | 22         | 0          | action     | 23.71    | 85.00    | 100.00   | 0.00     | 2100.00      | 3339.03      | 7.44     |\n",
      "| 8   | 23         | 8          | sleep      | 23.71    | 81.00    | 100.00   | 0.00     | 2100.00      | 3403.80      | 7.84     |\n",
      "| 9   | 0          | 8          | sleep      | 23.65    | 77.00    | 100.00   | 0.00     | 0.00         | 0.00         | 18.07    |\n",
      "| 9   | 1          | 8          | sleep      | 23.65    | 73.00    | 100.00   | 0.00     | 0.00         | 64.60        | 0.86     |\n",
      "| 9   | 2          | 8          | sleep      | 23.65    | 69.00    | 100.00   | 0.00     | 0.00         | 129.20       | 1.27     |\n",
      "| 9   | 3          | 8          | sleep      | 23.65    | 65.00    | 100.00   | 0.00     | 0.00         | 193.79       | 1.67     |\n",
      "| 9   | 4          | 8          | sleep      | 23.65    | 61.00    | 100.00   | 0.00     | 0.00         | 258.39       | 0.07     |\n",
      "| 9   | 5          | 8          | sleep      | 23.65    | 57.00    | 100.00   | 0.00     | 0.00         | 322.99       | -1.53    |\n",
      "| 9   | 6          | 8          | sleep      | 23.65    | 53.00    | 100.00   | 0.00     | 0.00         | 387.59       | -3.12    |\n",
      "| 9   | 7          | 5          | action     | 23.65    | 53.00    | 85.00    | 15.00    | 0.00         | 1033.56      | -1.89    |\n",
      "| 9   | 8          | 0          | action     | 23.65    | 53.00    | 100.00   | 0.00     | 350.00       | 1033.56      | 4.53     |\n",
      "| 9   | 9          | 5          | action     | 23.65    | 53.00    | 85.00    | 15.00    | 350.00       | 1679.54      | 7.76     |\n",
      "| 9   | 10         | 5          | action     | 23.65    | 53.00    | 70.00    | 30.00    | 350.00       | 2325.52      | 10.99    |\n",
      "| 9   | 11         | 8          | work       | 23.65    | 58.00    | 65.00    | 35.00    | 350.00       | 2469.07      | 11.53    |\n",
      "| 9   | 12         | 8          | work       | 23.65    | 63.00    | 60.00    | 40.00    | 350.00       | 2612.62      | 11.92    |\n",
      "| 9   | 13         | 0          | action     | 23.65    | 63.00    | 80.00    | 20.00    | 700.00       | 2612.62      | 10.65    |\n",
      "| 9   | 14         | 8          | work       | 23.65    | 68.00    | 75.00    | 25.00    | 700.00       | 2756.17      | 11.27    |\n",
      "| 9   | 15         | 8          | work       | 23.65    | 73.00    | 70.00    | 30.00    | 700.00       | 2899.72      | 11.89    |\n",
      "| 9   | 16         | 8          | work       | 23.65    | 78.00    | 65.00    | 35.00    | 700.00       | 3043.27      | 12.43    |\n",
      "| 9   | 17         | 8          | work       | 23.65    | 83.00    | 60.00    | 40.00    | 700.00       | 3186.82      | 12.82    |\n",
      "| 9   | 18         | 8          | work       | 23.65    | 88.00    | 55.00    | 45.00    | 700.00       | 3330.37      | 13.05    |\n",
      "| 9   | 19         | 0          | action     | 23.65    | 88.00    | 75.00    | 25.00    | 1050.00      | 3330.37      | 12.17    |\n",
      "| 9   | 20         | 0          | action     | 23.65    | 88.00    | 95.00    | 5.00     | 1400.00      | 3330.37      | 10.59    |\n",
      "| 9   | 21         | 0          | action     | 23.65    | 88.00    | 100.00   | 0.00     | 1750.00      | 3330.37      | 9.02     |\n",
      "| 9   | 22         | 0          | action     | 23.65    | 88.00    | 100.00   | 0.00     | 2100.00      | 3330.37      | 7.34     |\n",
      "| 9   | 23         | 8          | sleep      | 23.65    | 84.00    | 100.00   | 0.00     | 2100.00      | 3394.97      | 7.74     |\n",
      "| 10  | 0          | 8          | sleep      | 23.59    | 80.00    | 100.00   | 0.00     | 0.00         | 0.00         | 17.97    |\n",
      "| 10  | 1          | 8          | sleep      | 23.59    | 76.00    | 100.00   | 0.00     | 0.00         | 64.43        | 0.80     |\n",
      "| 10  | 2          | 8          | sleep      | 23.59    | 72.00    | 100.00   | 0.00     | 0.00         | 128.86       | 1.20     |\n",
      "| 10  | 3          | 8          | sleep      | 23.59    | 68.00    | 100.00   | 0.00     | 0.00         | 193.29       | 1.61     |\n",
      "| 10  | 4          | 8          | sleep      | 23.59    | 64.00    | 100.00   | 0.00     | 0.00         | 257.72       | 0.01     |\n",
      "| 10  | 5          | 8          | sleep      | 23.59    | 60.00    | 100.00   | 0.00     | 0.00         | 322.15       | -1.59    |\n",
      "| 10  | 6          | 8          | sleep      | 23.59    | 56.00    | 100.00   | 0.00     | 0.00         | 386.59       | -3.19    |\n",
      "| 10  | 7          | 5          | action     | 23.59    | 56.00    | 85.00    | 15.00    | 0.00         | 1030.89      | -1.97    |\n",
      "| 10  | 8          | 0          | action     | 23.59    | 56.00    | 100.00   | 0.00     | 350.00       | 1030.89      | 4.46     |\n",
      "| 10  | 9          | 5          | action     | 23.59    | 56.00    | 85.00    | 15.00    | 350.00       | 1675.20      | 7.68     |\n",
      "| 10  | 10         | 5          | action     | 23.59    | 56.00    | 70.00    | 30.00    | 350.00       | 2319.51      | 10.90    |\n",
      "| 10  | 11         | 8          | work       | 23.59    | 61.00    | 65.00    | 35.00    | 350.00       | 2462.69      | 11.44    |\n",
      "| 10  | 12         | 8          | work       | 23.59    | 66.00    | 60.00    | 40.00    | 350.00       | 2605.87      | 11.83    |\n",
      "| 10  | 13         | 0          | action     | 23.59    | 66.00    | 80.00    | 20.00    | 700.00       | 2605.87      | 10.56    |\n",
      "| 10  | 14         | 8          | work       | 23.59    | 71.00    | 75.00    | 25.00    | 700.00       | 2749.05      | 11.18    |\n",
      "| 10  | 15         | 8          | work       | 23.59    | 76.00    | 70.00    | 30.00    | 700.00       | 2892.23      | 11.79    |\n",
      "| 10  | 16         | 8          | work       | 23.59    | 81.00    | 65.00    | 35.00    | 700.00       | 3035.41      | 12.33    |\n",
      "| 10  | 17         | 8          | work       | 23.59    | 86.00    | 60.00    | 40.00    | 700.00       | 3178.59      | 12.72    |\n",
      "| 10  | 18         | 8          | work       | 23.59    | 91.00    | 55.00    | 45.00    | 700.00       | 3321.77      | 12.95    |\n",
      "| 10  | 19         | 0          | action     | 23.59    | 91.00    | 75.00    | 25.00    | 1050.00      | 3321.77      | 12.07    |\n",
      "| 10  | 20         | 0          | action     | 23.59    | 91.00    | 95.00    | 5.00     | 1400.00      | 3321.77      | 10.49    |\n",
      "| 10  | 21         | 0          | action     | 23.59    | 91.00    | 100.00   | 0.00     | 1750.00      | 3321.77      | 8.92     |\n",
      "| 10  | 22         | 0          | action     | 23.59    | 91.00    | 100.00   | 0.00     | 2100.00      | 3321.77      | 7.23     |\n",
      "| 10  | 23         | 8          | sleep      | 23.59    | 87.00    | 100.00   | 0.00     | 2100.00      | 3386.20      | 7.63     |\n",
      "| 11  | 0          | 8          | sleep      | 23.53    | 83.00    | 100.00   | 0.00     | 0.00         | 0.00         | 17.87    |\n",
      "| 11  | 1          | 8          | sleep      | 23.53    | 79.00    | 100.00   | 0.00     | 0.00         | 64.27        | 0.74     |\n",
      "| 11  | 2          | 8          | sleep      | 23.53    | 75.00    | 100.00   | 0.00     | 0.00         | 128.53       | 1.14     |\n",
      "| 11  | 3          | 8          | sleep      | 23.53    | 71.00    | 100.00   | 0.00     | 0.00         | 192.80       | 1.54     |\n",
      "| 11  | 4          | 8          | sleep      | 23.53    | 67.00    | 100.00   | 0.00     | 0.00         | 257.06       | -0.05    |\n",
      "| 11  | 5          | 8          | sleep      | 23.53    | 63.00    | 100.00   | 0.00     | 0.00         | 321.33       | -1.65    |\n",
      "| 11  | 6          | 8          | sleep      | 23.53    | 59.00    | 100.00   | 0.00     | 0.00         | 385.59       | -3.25    |\n",
      "| 11  | 7          | 5          | action     | 23.53    | 59.00    | 85.00    | 15.00    | 0.00         | 1028.24      | -2.04    |\n",
      "| 11  | 8          | 0          | action     | 23.53    | 59.00    | 100.00   | 0.00     | 350.00       | 1028.24      | 4.39     |\n",
      "| 11  | 9          | 5          | action     | 23.53    | 59.00    | 85.00    | 15.00    | 350.00       | 1670.89      | 7.60     |\n",
      "| 11  | 10         | 5          | action     | 23.53    | 59.00    | 70.00    | 30.00    | 350.00       | 2313.54      | 10.81    |\n",
      "| 11  | 11         | 8          | work       | 23.53    | 64.00    | 65.00    | 35.00    | 350.00       | 2456.36      | 11.35    |\n",
      "| 11  | 12         | 8          | work       | 23.53    | 69.00    | 60.00    | 40.00    | 350.00       | 2599.17      | 11.74    |\n",
      "| 11  | 13         | 0          | action     | 23.53    | 69.00    | 80.00    | 20.00    | 700.00       | 2599.17      | 10.47    |\n",
      "| 11  | 14         | 8          | work       | 23.53    | 74.00    | 75.00    | 25.00    | 700.00       | 2741.98      | 11.08    |\n",
      "| 11  | 15         | 8          | work       | 23.53    | 79.00    | 70.00    | 30.00    | 700.00       | 2884.79      | 11.70    |\n",
      "| 11  | 16         | 8          | work       | 23.53    | 84.00    | 65.00    | 35.00    | 700.00       | 3027.60      | 12.23    |\n",
      "| 11  | 17         | 8          | work       | 23.53    | 89.00    | 60.00    | 40.00    | 700.00       | 3170.41      | 12.62    |\n",
      "| 11  | 18         | 8          | work       | 23.53    | 94.00    | 55.00    | 45.00    | 700.00       | 3313.22      | 12.85    |\n",
      "| 11  | 19         | 0          | action     | 23.53    | 94.00    | 75.00    | 25.00    | 1050.00      | 3313.22      | 11.96    |\n",
      "| 11  | 20         | 0          | action     | 23.53    | 94.00    | 95.00    | 5.00     | 1400.00      | 3313.22      | 10.39    |\n",
      "| 11  | 21         | 0          | action     | 23.53    | 94.00    | 100.00   | 0.00     | 1750.00      | 3313.22      | 8.81     |\n",
      "| 11  | 22         | 0          | action     | 23.53    | 94.00    | 100.00   | 0.00     | 2100.00      | 3313.22      | 7.13     |\n",
      "| 11  | 23         | 8          | sleep      | 23.53    | 90.00    | 100.00   | 0.00     | 2100.00      | 3377.49      | 7.53     |\n",
      "| 12  | 0          | 8          | sleep      | 23.47    | 86.00    | 100.00   | 0.00     | 0.00         | 0.00         | 17.77    |\n",
      "| 12  | 1          | 8          | sleep      | 23.47    | 82.00    | 100.00   | 0.00     | 0.00         | 64.10        | 0.68     |\n",
      "| 12  | 2          | 8          | sleep      | 23.47    | 78.00    | 100.00   | 0.00     | 0.00         | 128.20       | 1.08     |\n",
      "| 12  | 3          | 8          | sleep      | 23.47    | 74.00    | 100.00   | 0.00     | 0.00         | 192.30       | 1.48     |\n",
      "| 12  | 4          | 8          | sleep      | 23.47    | 70.00    | 100.00   | 0.00     | 0.00         | 256.40       | -0.12    |\n",
      "| 12  | 5          | 8          | sleep      | 23.47    | 66.00    | 100.00   | 0.00     | 0.00         | 320.50       | -1.72    |\n",
      "| 12  | 6          | 8          | sleep      | 23.47    | 62.00    | 100.00   | 0.00     | 0.00         | 384.60       | -3.32    |\n",
      "| 12  | 7          | 5          | action     | 23.47    | 62.00    | 85.00    | 15.00    | 0.00         | 1025.61      | -2.11    |\n",
      "| 12  | 8          | 0          | action     | 23.47    | 62.00    | 100.00   | 0.00     | 350.00       | 1025.61      | 4.31     |\n",
      "| 12  | 9          | 5          | action     | 23.47    | 62.00    | 85.00    | 15.00    | 350.00       | 1666.61      | 7.52     |\n",
      "| 12  | 10         | 5          | action     | 23.47    | 62.00    | 70.00    | 30.00    | 350.00       | 2307.62      | 10.72    |\n",
      "| 12  | 11         | 8          | work       | 23.47    | 67.00    | 65.00    | 35.00    | 350.00       | 2450.06      | 11.26    |\n",
      "| 12  | 12         | 8          | work       | 23.47    | 72.00    | 60.00    | 40.00    | 350.00       | 2592.51      | 11.64    |\n",
      "| 12  | 13         | 0          | action     | 23.47    | 72.00    | 80.00    | 20.00    | 700.00       | 2592.51      | 10.37    |\n",
      "| 12  | 14         | 8          | work       | 23.47    | 77.00    | 75.00    | 25.00    | 700.00       | 2734.95      | 10.99    |\n",
      "| 12  | 15         | 8          | work       | 23.47    | 82.00    | 70.00    | 30.00    | 700.00       | 2877.40      | 11.60    |\n",
      "| 12  | 16         | 8          | work       | 23.47    | 87.00    | 65.00    | 35.00    | 700.00       | 3019.84      | 12.13    |\n",
      "| 12  | 17         | 8          | work       | 23.47    | 92.00    | 60.00    | 40.00    | 700.00       | 3162.29      | 12.52    |\n",
      "| 12  | 18         | 8          | work       | 23.47    | 97.00    | 55.00    | 45.00    | 700.00       | 3304.73      | 12.75    |\n",
      "| 12  | 19         | 0          | action     | 23.47    | 97.00    | 75.00    | 25.00    | 1050.00      | 3304.73      | 11.86    |\n",
      "| 12  | 20         | 0          | action     | 23.47    | 97.00    | 95.00    | 5.00     | 1400.00      | 3304.73      | 10.29    |\n",
      "| 12  | 21         | 0          | action     | 23.47    | 97.00    | 100.00   | 0.00     | 1750.00      | 3304.73      | 8.71     |\n",
      "| 12  | 22         | 0          | action     | 23.47    | 97.00    | 100.00   | 0.00     | 2100.00      | 3304.73      | 7.02     |\n",
      "| 12  | 23         | 8          | sleep      | 23.47    | 93.00    | 100.00   | 0.00     | 2100.00      | 3368.83      | 7.42     |\n",
      "| 13  | 0          | 8          | sleep      | 23.41    | 89.00    | 100.00   | 0.00     | 0.00         | 0.00         | 17.67    |\n",
      "| 13  | 1          | 8          | sleep      | 23.41    | 85.00    | 100.00   | 0.00     | 0.00         | 63.94        | 0.62     |\n",
      "| 13  | 2          | 8          | sleep      | 23.41    | 81.00    | 100.00   | 0.00     | 0.00         | 127.87       | 1.02     |\n",
      "| 13  | 3          | 8          | sleep      | 23.41    | 77.00    | 100.00   | 0.00     | 0.00         | 191.81       | 1.42     |\n",
      "| 13  | 4          | 8          | sleep      | 23.41    | 73.00    | 100.00   | 0.00     | 0.00         | 255.75       | -0.18    |\n",
      "| 13  | 5          | 8          | sleep      | 23.41    | 69.00    | 100.00   | 0.00     | 0.00         | 319.68       | -1.78    |\n",
      "| 13  | 6          | 8          | sleep      | 23.41    | 65.00    | 100.00   | 0.00     | 0.00         | 383.62       | -3.38    |\n",
      "| 13  | 7          | 5          | action     | 23.41    | 65.00    | 85.00    | 15.00    | 0.00         | 1022.99      | -2.19    |\n",
      "| 13  | 8          | 0          | action     | 23.41    | 65.00    | 100.00   | 0.00     | 350.00       | 1022.99      | 4.24     |\n",
      "| 13  | 9          | 5          | action     | 23.41    | 65.00    | 85.00    | 15.00    | 350.00       | 1662.36      | 7.44     |\n",
      "| 13  | 10         | 5          | action     | 23.41    | 65.00    | 70.00    | 30.00    | 350.00       | 2301.73      | 10.64    |\n",
      "| 13  | 11         | 8          | work       | 23.41    | 70.00    | 65.00    | 35.00    | 350.00       | 2443.81      | 11.17    |\n",
      "| 13  | 12         | 8          | work       | 23.41    | 75.00    | 60.00    | 40.00    | 350.00       | 2585.89      | 11.55    |\n",
      "| 13  | 13         | 0          | action     | 23.41    | 75.00    | 80.00    | 20.00    | 700.00       | 2585.89      | 10.28    |\n",
      "| 13  | 14         | 8          | work       | 23.41    | 80.00    | 75.00    | 25.00    | 700.00       | 2727.97      | 10.89    |\n",
      "| 13  | 15         | 8          | work       | 23.41    | 85.00    | 70.00    | 30.00    | 700.00       | 2870.05      | 11.50    |\n",
      "| 13  | 16         | 8          | work       | 23.41    | 90.00    | 65.00    | 35.00    | 700.00       | 3012.14      | 12.04    |\n",
      "| 13  | 17         | 8          | work       | 23.41    | 95.00    | 60.00    | 40.00    | 700.00       | 3154.22      | 12.42    |\n",
      "| 13  | 18         | 8          | work       | 23.41    | 100.00   | 55.00    | 45.00    | 700.00       | 3296.30      | 12.65    |\n",
      "| 13  | 19         | 0          | action     | 23.41    | 100.00   | 75.00    | 25.00    | 1050.00      | 3296.30      | 11.76    |\n",
      "| 13  | 20         | 0          | action     | 23.41    | 100.00   | 95.00    | 5.00     | 1400.00      | 3296.30      | 10.19    |\n",
      "| 13  | 21         | 0          | action     | 23.41    | 100.00   | 100.00   | 0.00     | 1750.00      | 3296.30      | 8.61     |\n",
      "| 13  | 22         | 0          | action     | 23.41    | 100.00   | 100.00   | 0.00     | 2100.00      | 3296.30      | 6.92     |\n",
      "| 13  | 23         | 8          | sleep      | 23.41    | 96.00    | 100.00   | 0.00     | 2100.00      | 3360.24      | 7.32     |\n",
      "| 14  | 0          | 8          | sleep      | 23.35    | 92.00    | 100.00   | 0.00     | 0.00         | 0.00         | 17.57    |\n",
      "| 14  | 1          | 8          | sleep      | 23.35    | 88.00    | 100.00   | 0.00     | 0.00         | 63.77        | 0.56     |\n",
      "| 14  | 2          | 8          | sleep      | 23.35    | 84.00    | 100.00   | 0.00     | 0.00         | 127.55       | 0.96     |\n",
      "| 14  | 3          | 8          | sleep      | 23.35    | 80.00    | 100.00   | 0.00     | 0.00         | 191.32       | 1.36     |\n",
      "| 14  | 4          | 8          | sleep      | 23.35    | 76.00    | 100.00   | 0.00     | 0.00         | 255.10       | -0.24    |\n",
      "| 14  | 5          | 8          | sleep      | 23.35    | 72.00    | 100.00   | 0.00     | 0.00         | 318.87       | -1.85    |\n",
      "| 14  | 6          | 8          | sleep      | 23.35    | 68.00    | 100.00   | 0.00     | 0.00         | 382.65       | -3.45    |\n",
      "| 14  | 7          | 5          | action     | 23.35    | 68.00    | 85.00    | 15.00    | 0.00         | 1020.39      | -2.26    |\n",
      "| 14  | 8          | 0          | action     | 23.35    | 68.00    | 100.00   | 0.00     | 350.00       | 1020.39      | 4.17     |\n",
      "| 14  | 9          | 5          | action     | 23.35    | 68.00    | 85.00    | 15.00    | 350.00       | 1658.13      | 7.36     |\n",
      "| 14  | 10         | 5          | action     | 23.35    | 68.00    | 70.00    | 30.00    | 350.00       | 2295.88      | 10.55    |\n",
      "| 14  | 11         | 8          | work       | 23.35    | 73.00    | 65.00    | 35.00    | 350.00       | 2437.60      | 11.08    |\n",
      "| 14  | 12         | 8          | work       | 23.35    | 78.00    | 60.00    | 40.00    | 350.00       | 2579.32      | 11.46    |\n",
      "| 14  | 13         | 0          | action     | 23.35    | 78.00    | 80.00    | 20.00    | 700.00       | 2579.32      | 10.19    |\n",
      "| 14  | 14         | 8          | work       | 23.35    | 83.00    | 75.00    | 25.00    | 700.00       | 2721.04      | 10.80    |\n",
      "| 14  | 15         | 8          | work       | 23.35    | 88.00    | 70.00    | 30.00    | 700.00       | 2862.76      | 11.41    |\n",
      "| 14  | 16         | 8          | work       | 23.35    | 93.00    | 65.00    | 35.00    | 700.00       | 3004.48      | 11.94    |\n",
      "| 14  | 17         | 8          | work       | 23.35    | 98.00    | 60.00    | 40.00    | 700.00       | 3146.20      | 12.32    |\n",
      "| 14  | 18         | 8          | work       | 23.35    | 100.00   | 55.00    | 45.00    | 700.00       | 3287.92      | 12.60    |\n",
      "| 14  | 19         | 0          | action     | 23.35    | 100.00   | 75.00    | 25.00    | 1050.00      | 3287.92      | 11.72    |\n",
      "| 14  | 20         | 0          | action     | 23.35    | 100.00   | 95.00    | 5.00     | 1400.00      | 3287.92      | 10.15    |\n",
      "| 14  | 21         | 0          | action     | 23.35    | 100.00   | 100.00   | 0.00     | 1750.00      | 3287.92      | 8.57     |\n",
      "| 14  | 22         | 0          | action     | 23.35    | 100.00   | 100.00   | 0.00     | 2100.00      | 3287.92      | 6.88     |\n",
      "| 14  | 23         | 8          | sleep      | 23.35    | 96.00    | 100.00   | 0.00     | 2100.00      | 3351.70      | 7.28     |\n",
      "| 15  | 0          | 8          | sleep      | 23.29    | 92.00    | 100.00   | 0.00     | 0.00         | 0.00         | 17.53    |\n",
      "| 15  | 1          | 8          | sleep      | 23.29    | 88.00    | 100.00   | 0.00     | 0.00         | 63.61        | 0.56     |\n",
      "| 15  | 2          | 8          | sleep      | 23.29    | 84.00    | 100.00   | 0.00     | 0.00         | 127.23       | 0.96     |\n",
      "| 15  | 3          | 8          | sleep      | 23.29    | 80.00    | 100.00   | 0.00     | 0.00         | 190.84       | 1.35     |\n",
      "| 15  | 4          | 8          | sleep      | 23.29    | 76.00    | 100.00   | 0.00     | 0.00         | 254.45       | -0.25    |\n",
      "| 15  | 5          | 8          | sleep      | 23.29    | 72.00    | 100.00   | 0.00     | 0.00         | 318.06       | -1.85    |\n",
      "| 15  | 6          | 8          | sleep      | 23.29    | 68.00    | 100.00   | 0.00     | 0.00         | 381.68       | -3.45    |\n",
      "| 15  | 7          | 5          | action     | 23.29    | 68.00    | 85.00    | 15.00    | 0.00         | 1017.81      | -2.27    |\n",
      "| 15  | 8          | 0          | action     | 23.29    | 68.00    | 100.00   | 0.00     | 350.00       | 1017.81      | 4.16     |\n",
      "| 15  | 9          | 5          | action     | 23.29    | 68.00    | 85.00    | 15.00    | 350.00       | 1653.94      | 7.34     |\n",
      "| 15  | 10         | 5          | action     | 23.29    | 68.00    | 70.00    | 30.00    | 350.00       | 2290.06      | 10.52    |\n",
      "| 15  | 11         | 8          | work       | 23.29    | 73.00    | 65.00    | 35.00    | 350.00       | 2431.43      | 11.05    |\n",
      "| 15  | 12         | 8          | work       | 23.29    | 78.00    | 60.00    | 40.00    | 350.00       | 2572.79      | 11.43    |\n",
      "| 15  | 13         | 0          | action     | 23.29    | 78.00    | 80.00    | 20.00    | 700.00       | 2572.79      | 10.16    |\n",
      "| 15  | 14         | 8          | work       | 23.29    | 83.00    | 75.00    | 25.00    | 700.00       | 2714.15      | 10.77    |\n",
      "| 15  | 15         | 8          | work       | 23.29    | 88.00    | 70.00    | 30.00    | 700.00       | 2855.51      | 11.37    |\n",
      "| 15  | 16         | 8          | work       | 23.29    | 93.00    | 65.00    | 35.00    | 700.00       | 2996.87      | 11.90    |\n",
      "| 15  | 17         | 8          | work       | 23.29    | 98.00    | 60.00    | 40.00    | 700.00       | 3138.24      | 12.28    |\n",
      "| 15  | 18         | 8          | work       | 23.29    | 100.00   | 55.00    | 45.00    | 700.00       | 3279.60      | 12.56    |\n",
      "| 15  | 19         | 0          | action     | 23.29    | 100.00   | 75.00    | 25.00    | 1050.00      | 3279.60      | 11.68    |\n",
      "| 15  | 20         | 0          | action     | 23.29    | 100.00   | 95.00    | 5.00     | 1400.00      | 3279.60      | 10.11    |\n",
      "| 15  | 21         | 0          | action     | 23.29    | 100.00   | 100.00   | 0.00     | 1750.00      | 3279.60      | 8.53     |\n",
      "| 15  | 22         | 0          | action     | 23.29    | 100.00   | 100.00   | 0.00     | 2100.00      | 3279.60      | 6.83     |\n",
      "| 15  | 23         | 8          | sleep      | 23.29    | 96.00    | 100.00   | 0.00     | 2100.00      | 3343.21      | 7.23     |\n",
      "| 16  | 0          | 8          | sleep      | 23.23    | 92.00    | 100.00   | 0.00     | 0.00         | 0.00         | 17.49    |\n",
      "| 16  | 1          | 8          | sleep      | 23.23    | 88.00    | 100.00   | 0.00     | 0.00         | 63.45        | 0.56     |\n",
      "| 16  | 2          | 8          | sleep      | 23.23    | 84.00    | 100.00   | 0.00     | 0.00         | 126.91       | 0.95     |\n",
      "| 16  | 3          | 8          | sleep      | 23.23    | 80.00    | 100.00   | 0.00     | 0.00         | 190.36       | 1.35     |\n",
      "| 16  | 4          | 8          | sleep      | 23.23    | 76.00    | 100.00   | 0.00     | 0.00         | 253.81       | -0.25    |\n",
      "| 16  | 5          | 8          | sleep      | 23.23    | 72.00    | 100.00   | 0.00     | 0.00         | 317.26       | -1.85    |\n",
      "| 16  | 6          | 8          | sleep      | 23.23    | 68.00    | 100.00   | 0.00     | 0.00         | 380.72       | -3.46    |\n",
      "| 16  | 7          | 5          | action     | 23.23    | 68.00    | 85.00    | 15.00    | 0.00         | 1015.24      | -2.28    |\n",
      "| 16  | 8          | 0          | action     | 23.23    | 68.00    | 100.00   | 0.00     | 350.00       | 1015.24      | 4.14     |\n",
      "| 16  | 9          | 5          | action     | 23.23    | 68.00    | 85.00    | 15.00    | 350.00       | 1649.77      | 7.32     |\n",
      "| 16  | 10         | 5          | action     | 23.23    | 68.00    | 70.00    | 30.00    | 350.00       | 2284.29      | 10.49    |\n",
      "| 16  | 11         | 8          | work       | 23.23    | 73.00    | 65.00    | 35.00    | 350.00       | 2425.30      | 11.02    |\n",
      "| 16  | 12         | 8          | work       | 23.23    | 78.00    | 60.00    | 40.00    | 350.00       | 2566.30      | 11.39    |\n",
      "| 16  | 13         | 0          | action     | 23.23    | 78.00    | 80.00    | 20.00    | 700.00       | 2566.30      | 10.13    |\n",
      "| 16  | 14         | 8          | work       | 23.23    | 83.00    | 75.00    | 25.00    | 700.00       | 2707.31      | 10.73    |\n",
      "| 16  | 15         | 8          | work       | 23.23    | 88.00    | 70.00    | 30.00    | 700.00       | 2848.31      | 11.34    |\n",
      "| 16  | 16         | 8          | work       | 23.23    | 93.00    | 65.00    | 35.00    | 700.00       | 2989.32      | 11.87    |\n",
      "| 16  | 17         | 8          | work       | 23.23    | 98.00    | 60.00    | 40.00    | 700.00       | 3130.32      | 12.24    |\n",
      "| 16  | 18         | 8          | work       | 23.23    | 100.00   | 55.00    | 45.00    | 700.00       | 3271.33      | 12.52    |\n",
      "| 16  | 19         | 0          | action     | 23.23    | 100.00   | 75.00    | 25.00    | 1050.00      | 3271.33      | 11.64    |\n",
      "| 16  | 20         | 0          | action     | 23.23    | 100.00   | 95.00    | 5.00     | 1400.00      | 3271.33      | 10.07    |\n",
      "| 16  | 21         | 0          | action     | 23.23    | 100.00   | 100.00   | 0.00     | 1750.00      | 3271.33      | 8.49     |\n",
      "| 16  | 22         | 0          | action     | 23.23    | 100.00   | 100.00   | 0.00     | 2100.00      | 3271.33      | 6.79     |\n",
      "| 16  | 23         | 8          | sleep      | 23.23    | 96.00    | 100.00   | 0.00     | 2100.00      | 3334.78      | 7.19     |\n",
      "| 17  | 0          | 8          | sleep      | 23.18    | 92.00    | 100.00   | 0.00     | 0.00         | 0.00         | 17.45    |\n",
      "| 17  | 1          | 8          | sleep      | 23.18    | 88.00    | 100.00   | 0.00     | 0.00         | 63.29        | 0.56     |\n",
      "| 17  | 2          | 8          | sleep      | 23.18    | 84.00    | 100.00   | 0.00     | 0.00         | 126.59       | 0.95     |\n",
      "| 17  | 3          | 8          | sleep      | 23.18    | 80.00    | 100.00   | 0.00     | 0.00         | 189.88       | 1.35     |\n",
      "| 17  | 4          | 8          | sleep      | 23.18    | 76.00    | 100.00   | 0.00     | 0.00         | 253.17       | -0.25    |\n",
      "| 17  | 5          | 8          | sleep      | 23.18    | 72.00    | 100.00   | 0.00     | 0.00         | 316.47       | -1.86    |\n",
      "| 17  | 6          | 8          | sleep      | 23.18    | 68.00    | 100.00   | 0.00     | 0.00         | 379.76       | -3.46    |\n",
      "| 17  | 7          | 5          | action     | 23.18    | 68.00    | 85.00    | 15.00    | 0.00         | 1012.69      | -2.30    |\n",
      "| 17  | 8          | 0          | action     | 23.18    | 68.00    | 100.00   | 0.00     | 350.00       | 1012.69      | 4.13     |\n",
      "| 17  | 9          | 5          | action     | 23.18    | 68.00    | 85.00    | 15.00    | 350.00       | 1645.62      | 7.30     |\n",
      "| 17  | 10         | 5          | action     | 23.18    | 68.00    | 70.00    | 30.00    | 350.00       | 2278.55      | 10.46    |\n",
      "| 17  | 11         | 8          | work       | 23.18    | 73.00    | 65.00    | 35.00    | 350.00       | 2419.21      | 10.99    |\n",
      "| 17  | 12         | 8          | work       | 23.18    | 78.00    | 60.00    | 40.00    | 350.00       | 2559.86      | 11.36    |\n",
      "| 17  | 13         | 0          | action     | 23.18    | 78.00    | 80.00    | 20.00    | 700.00       | 2559.86      | 10.10    |\n",
      "| 17  | 14         | 8          | work       | 23.18    | 83.00    | 75.00    | 25.00    | 700.00       | 2700.51      | 10.70    |\n",
      "| 17  | 15         | 8          | work       | 23.18    | 88.00    | 70.00    | 30.00    | 700.00       | 2841.16      | 11.30    |\n",
      "| 17  | 16         | 8          | work       | 23.18    | 93.00    | 65.00    | 35.00    | 700.00       | 2981.81      | 11.83    |\n",
      "| 17  | 17         | 8          | work       | 23.18    | 98.00    | 60.00    | 40.00    | 700.00       | 3122.46      | 12.20    |\n",
      "| 17  | 18         | 8          | work       | 23.18    | 100.00   | 55.00    | 45.00    | 700.00       | 3263.12      | 12.48    |\n",
      "| 17  | 19         | 0          | action     | 23.18    | 100.00   | 75.00    | 25.00    | 1050.00      | 3263.12      | 11.60    |\n",
      "| 17  | 20         | 0          | action     | 23.18    | 100.00   | 95.00    | 5.00     | 1400.00      | 3263.12      | 10.03    |\n",
      "| 17  | 21         | 0          | action     | 23.18    | 100.00   | 100.00   | 0.00     | 1750.00      | 3263.12      | 8.46     |\n",
      "| 17  | 22         | 0          | action     | 23.18    | 100.00   | 100.00   | 0.00     | 2100.00      | 3263.12      | 6.75     |\n",
      "| 17  | 23         | 8          | sleep      | 23.18    | 96.00    | 100.00   | 0.00     | 2100.00      | 3326.41      | 7.14     |\n",
      "| 18  | 0          | 8          | sleep      | 23.12    | 92.00    | 100.00   | 0.00     | 0.00         | 0.00         | 17.42    |\n",
      "| 18  | 1          | 8          | sleep      | 23.12    | 88.00    | 100.00   | 0.00     | 0.00         | 63.13        | 0.56     |\n",
      "| 18  | 2          | 8          | sleep      | 23.12    | 84.00    | 100.00   | 0.00     | 0.00         | 126.27       | 0.95     |\n",
      "| 18  | 3          | 8          | sleep      | 23.12    | 80.00    | 100.00   | 0.00     | 0.00         | 189.40       | 1.35     |\n",
      "| 18  | 4          | 8          | sleep      | 23.12    | 76.00    | 100.00   | 0.00     | 0.00         | 252.54       | -0.26    |\n",
      "| 18  | 5          | 8          | sleep      | 23.12    | 72.00    | 100.00   | 0.00     | 0.00         | 315.67       | -1.86    |\n",
      "| 18  | 6          | 8          | sleep      | 23.12    | 68.00    | 100.00   | 0.00     | 0.00         | 378.81       | -3.47    |\n",
      "| 18  | 7          | 5          | action     | 23.12    | 68.00    | 85.00    | 15.00    | 0.00         | 1010.16      | -2.31    |\n",
      "| 18  | 8          | 0          | action     | 23.12    | 68.00    | 100.00   | 0.00     | 350.00       | 1010.16      | 4.12     |\n",
      "| 18  | 9          | 5          | action     | 23.12    | 68.00    | 85.00    | 15.00    | 350.00       | 1641.51      | 7.28     |\n",
      "| 18  | 10         | 5          | action     | 23.12    | 68.00    | 70.00    | 30.00    | 350.00       | 2272.86      | 10.43    |\n",
      "| 18  | 11         | 8          | work       | 23.12    | 73.00    | 65.00    | 35.00    | 350.00       | 2413.16      | 10.96    |\n",
      "| 18  | 12         | 8          | work       | 23.12    | 78.00    | 60.00    | 40.00    | 350.00       | 2553.46      | 11.33    |\n",
      "| 18  | 13         | 0          | action     | 23.12    | 78.00    | 80.00    | 20.00    | 700.00       | 2553.46      | 10.06    |\n",
      "| 18  | 14         | 8          | work       | 23.12    | 83.00    | 75.00    | 25.00    | 700.00       | 2693.76      | 10.67    |\n",
      "| 18  | 15         | 8          | work       | 23.12    | 88.00    | 70.00    | 30.00    | 700.00       | 2834.06      | 11.27    |\n",
      "| 18  | 16         | 8          | work       | 23.12    | 93.00    | 65.00    | 35.00    | 700.00       | 2974.36      | 11.79    |\n",
      "| 18  | 17         | 8          | work       | 23.12    | 98.00    | 60.00    | 40.00    | 700.00       | 3114.66      | 12.16    |\n",
      "| 18  | 18         | 8          | work       | 23.12    | 100.00   | 55.00    | 45.00    | 700.00       | 3254.96      | 12.44    |\n",
      "| 18  | 19         | 0          | action     | 23.12    | 100.00   | 75.00    | 25.00    | 1050.00      | 3254.96      | 11.56    |\n",
      "| 18  | 20         | 0          | action     | 23.12    | 100.00   | 95.00    | 5.00     | 1400.00      | 3254.96      | 9.99     |\n",
      "| 18  | 21         | 0          | action     | 23.12    | 100.00   | 100.00   | 0.00     | 1750.00      | 3254.96      | 8.42     |\n",
      "| 18  | 22         | 0          | action     | 23.12    | 100.00   | 100.00   | 0.00     | 2100.00      | 3254.96      | 6.70     |\n",
      "| 18  | 23         | 8          | sleep      | 23.12    | 96.00    | 100.00   | 0.00     | 2100.00      | 3318.09      | 7.10     |\n",
      "| 19  | 0          | 8          | sleep      | 23.06    | 92.00    | 100.00   | 0.00     | 0.00         | 0.00         | 17.38    |\n",
      "| 19  | 1          | 8          | sleep      | 23.06    | 88.00    | 100.00   | 0.00     | 0.00         | 62.98        | 0.55     |\n",
      "| 19  | 2          | 8          | sleep      | 23.06    | 84.00    | 100.00   | 0.00     | 0.00         | 125.96       | 0.95     |\n",
      "| 19  | 3          | 8          | sleep      | 23.06    | 80.00    | 100.00   | 0.00     | 0.00         | 188.93       | 1.34     |\n",
      "| 19  | 4          | 8          | sleep      | 23.06    | 76.00    | 100.00   | 0.00     | 0.00         | 251.91       | -0.26    |\n",
      "| 19  | 5          | 8          | sleep      | 23.06    | 72.00    | 100.00   | 0.00     | 0.00         | 314.89       | -1.87    |\n",
      "| 19  | 6          | 8          | sleep      | 23.06    | 68.00    | 100.00   | 0.00     | 0.00         | 377.87       | -3.47    |\n",
      "| 19  | 7          | 5          | action     | 23.06    | 68.00    | 85.00    | 15.00    | 0.00         | 1007.64      | -2.32    |\n",
      "| 19  | 8          | 0          | action     | 23.06    | 68.00    | 100.00   | 0.00     | 350.00       | 1007.64      | 4.11     |\n",
      "| 19  | 9          | 5          | action     | 23.06    | 68.00    | 85.00    | 15.00    | 350.00       | 1637.42      | 7.26     |\n",
      "| 19  | 10         | 5          | action     | 23.06    | 68.00    | 70.00    | 30.00    | 350.00       | 2267.20      | 10.40    |\n",
      "| 19  | 11         | 8          | work       | 23.06    | 73.00    | 65.00    | 35.00    | 350.00       | 2407.15      | 10.93    |\n",
      "| 19  | 12         | 8          | work       | 23.06    | 78.00    | 60.00    | 40.00    | 350.00       | 2547.10      | 11.30    |\n",
      "| 19  | 13         | 0          | action     | 23.06    | 78.00    | 80.00    | 20.00    | 700.00       | 2547.10      | 10.03    |\n",
      "| 19  | 14         | 8          | work       | 23.06    | 83.00    | 75.00    | 25.00    | 700.00       | 2687.05      | 10.63    |\n",
      "| 19  | 15         | 8          | work       | 23.06    | 88.00    | 70.00    | 30.00    | 700.00       | 2827.00      | 11.23    |\n",
      "| 19  | 16         | 8          | work       | 23.06    | 93.00    | 65.00    | 35.00    | 700.00       | 2966.95      | 11.76    |\n",
      "| 19  | 17         | 8          | work       | 23.06    | 98.00    | 60.00    | 40.00    | 700.00       | 3106.90      | 12.13    |\n",
      "| 19  | 18         | 8          | work       | 23.06    | 100.00   | 55.00    | 45.00    | 700.00       | 3246.85      | 12.40    |\n",
      "| 19  | 19         | 0          | action     | 23.06    | 100.00   | 75.00    | 25.00    | 1050.00      | 3246.85      | 11.52    |\n",
      "| 19  | 20         | 0          | action     | 23.06    | 100.00   | 95.00    | 5.00     | 1400.00      | 3246.85      | 9.95     |\n",
      "| 19  | 21         | 0          | action     | 23.06    | 100.00   | 100.00   | 0.00     | 1750.00      | 3246.85      | 8.38     |\n",
      "| 19  | 22         | 0          | action     | 23.06    | 100.00   | 100.00   | 0.00     | 2100.00      | 3246.85      | 6.66     |\n",
      "| 19  | 23         | 8          | sleep      | 23.06    | 96.00    | 100.00   | 0.00     | 2100.00      | 3309.83      | 7.06     |\n",
      "| 20  | 0          | 8          | sleep      | 23.00    | 92.00    | 100.00   | 0.00     | 0.00         | 0.00         | 17.34    |\n",
      "| 20  | 1          | 8          | sleep      | 23.00    | 88.00    | 100.00   | 0.00     | 0.00         | 62.82        | 0.55     |\n",
      "| 20  | 2          | 8          | sleep      | 23.00    | 84.00    | 100.00   | 0.00     | 0.00         | 125.64       | 0.95     |\n",
      "| 20  | 3          | 8          | sleep      | 23.00    | 80.00    | 100.00   | 0.00     | 0.00         | 188.46       | 1.34     |\n",
      "| 20  | 4          | 8          | sleep      | 23.00    | 76.00    | 100.00   | 0.00     | 0.00         | 251.29       | -0.26    |\n",
      "| 20  | 5          | 8          | sleep      | 23.00    | 72.00    | 100.00   | 0.00     | 0.00         | 314.11       | -1.87    |\n",
      "| 20  | 6          | 8          | sleep      | 23.00    | 68.00    | 100.00   | 0.00     | 0.00         | 376.93       | -3.48    |\n",
      "| 20  | 7          | 5          | action     | 23.00    | 68.00    | 85.00    | 15.00    | 0.00         | 1005.14      | -2.33    |\n",
      "| 20  | 8          | 0          | action     | 23.00    | 68.00    | 100.00   | 0.00     | 350.00       | 1005.14      | 4.09     |\n",
      "| 20  | 9          | 5          | action     | 23.00    | 68.00    | 85.00    | 15.00    | 350.00       | 1633.36      | 7.24     |\n",
      "| 20  | 10         | 5          | action     | 23.00    | 68.00    | 70.00    | 30.00    | 350.00       | 2261.57      | 10.38    |\n",
      "| 20  | 11         | 8          | work       | 23.00    | 73.00    | 65.00    | 35.00    | 350.00       | 2401.18      | 10.90    |\n",
      "| 20  | 12         | 8          | work       | 23.00    | 78.00    | 60.00    | 40.00    | 350.00       | 2540.78      | 11.27    |\n",
      "| 20  | 13         | 0          | action     | 23.00    | 78.00    | 80.00    | 20.00    | 700.00       | 2540.78      | 10.00    |\n",
      "| 20  | 14         | 8          | work       | 23.00    | 83.00    | 75.00    | 25.00    | 700.00       | 2680.38      | 10.60    |\n",
      "| 20  | 15         | 8          | work       | 23.00    | 88.00    | 70.00    | 30.00    | 700.00       | 2819.99      | 11.20    |\n",
      "| 20  | 16         | 8          | work       | 23.00    | 93.00    | 65.00    | 35.00    | 700.00       | 2959.59      | 11.72    |\n",
      "| 20  | 17         | 8          | work       | 23.00    | 98.00    | 60.00    | 40.00    | 700.00       | 3099.19      | 12.09    |\n",
      "| 20  | 18         | 8          | work       | 23.00    | 100.00   | 55.00    | 45.00    | 700.00       | 3238.80      | 12.36    |\n",
      "| 20  | 19         | 0          | action     | 23.00    | 100.00   | 75.00    | 25.00    | 1050.00      | 3238.80      | 11.48    |\n",
      "| 20  | 20         | 0          | action     | 23.00    | 100.00   | 95.00    | 5.00     | 1400.00      | 3238.80      | 9.91     |\n",
      "| 20  | 21         | 0          | action     | 23.00    | 100.00   | 100.00   | 0.00     | 1750.00      | 3238.80      | 8.34     |\n",
      "| 20  | 22         | 0          | action     | 23.00    | 100.00   | 100.00   | 0.00     | 2100.00      | 3238.80      | 6.62     |\n",
      "| 20  | 23         | 8          | sleep      | 23.00    | 96.00    | 100.00   | 0.00     | 2100.00      | 3301.62      | 7.01     |\n",
      "| 21  | 0          | 8          | sleep      | 22.95    | 92.00    | 100.00   | 0.00     | 0.00         | 0.00         | 17.30    |\n",
      "| 21  | 1          | 8          | sleep      | 22.95    | 88.00    | 100.00   | 0.00     | 0.00         | 62.67        | 0.55     |\n",
      "| 21  | 2          | 8          | sleep      | 22.95    | 84.00    | 100.00   | 0.00     | 0.00         | 125.33       | 0.95     |\n",
      "| 21  | 3          | 8          | sleep      | 22.95    | 80.00    | 100.00   | 0.00     | 0.00         | 188.00       | 1.34     |\n",
      "| 21  | 4          | 8          | sleep      | 22.95    | 76.00    | 100.00   | 0.00     | 0.00         | 250.67       | -0.27    |\n",
      "| 21  | 5          | 8          | sleep      | 22.95    | 72.00    | 100.00   | 0.00     | 0.00         | 313.33       | -1.87    |\n",
      "| 21  | 6          | 8          | sleep      | 22.95    | 68.00    | 100.00   | 0.00     | 0.00         | 376.00       | -3.48    |\n",
      "| 21  | 7          | 5          | action     | 22.95    | 68.00    | 85.00    | 15.00    | 0.00         | 1002.66      | -2.35    |\n",
      "| 21  | 8          | 0          | action     | 22.95    | 68.00    | 100.00   | 0.00     | 350.00       | 1002.66      | 4.08     |\n",
      "| 21  | 9          | 5          | action     | 22.95    | 68.00    | 85.00    | 15.00    | 350.00       | 1629.32      | 7.22     |\n",
      "| 21  | 10         | 5          | action     | 22.95    | 68.00    | 70.00    | 30.00    | 350.00       | 2255.99      | 10.35    |\n",
      "| 21  | 11         | 8          | work       | 22.95    | 73.00    | 65.00    | 35.00    | 350.00       | 2395.24      | 10.87    |\n",
      "| 21  | 12         | 8          | work       | 22.95    | 78.00    | 60.00    | 40.00    | 350.00       | 2534.50      | 11.24    |\n",
      "| 21  | 13         | 0          | action     | 22.95    | 78.00    | 80.00    | 20.00    | 700.00       | 2534.50      | 9.97     |\n",
      "| 21  | 14         | 8          | work       | 22.95    | 83.00    | 75.00    | 25.00    | 700.00       | 2673.76      | 10.57    |\n",
      "| 21  | 15         | 8          | work       | 22.95    | 88.00    | 70.00    | 30.00    | 700.00       | 2813.02      | 11.16    |\n",
      "| 21  | 16         | 8          | work       | 22.95    | 93.00    | 65.00    | 35.00    | 700.00       | 2952.28      | 11.68    |\n",
      "| 21  | 17         | 8          | work       | 22.95    | 98.00    | 60.00    | 40.00    | 700.00       | 3091.54      | 12.05    |\n",
      "| 21  | 18         | 8          | work       | 22.95    | 100.00   | 55.00    | 45.00    | 700.00       | 3230.79      | 12.32    |\n",
      "| 21  | 19         | 0          | action     | 22.95    | 100.00   | 75.00    | 25.00    | 1050.00      | 3230.79      | 11.44    |\n",
      "| 21  | 20         | 0          | action     | 22.95    | 100.00   | 95.00    | 5.00     | 1400.00      | 3230.79      | 9.87     |\n",
      "| 21  | 21         | 0          | action     | 22.95    | 100.00   | 100.00   | 0.00     | 1750.00      | 3230.79      | 8.30     |\n",
      "| 21  | 22         | 0          | action     | 22.95    | 100.00   | 100.00   | 0.00     | 2100.00      | 3230.79      | 6.58     |\n",
      "| 21  | 23         | 8          | sleep      | 22.95    | 96.00    | 100.00   | 0.00     | 2100.00      | 3293.46      | 6.97     |\n",
      "| 22  | 0          | 8          | sleep      | 22.89    | 92.00    | 100.00   | 0.00     | 0.00         | 0.00         | 17.26    |\n",
      "| 22  | 1          | 8          | sleep      | 22.89    | 88.00    | 100.00   | 0.00     | 0.00         | 62.51        | 0.55     |\n",
      "| 22  | 2          | 8          | sleep      | 22.89    | 84.00    | 100.00   | 0.00     | 0.00         | 125.02       | 0.95     |\n",
      "| 22  | 3          | 8          | sleep      | 22.89    | 80.00    | 100.00   | 0.00     | 0.00         | 187.54       | 1.34     |\n",
      "| 22  | 4          | 8          | sleep      | 22.89    | 76.00    | 100.00   | 0.00     | 0.00         | 250.05       | -0.27    |\n",
      "| 22  | 5          | 8          | sleep      | 22.89    | 72.00    | 100.00   | 0.00     | 0.00         | 312.56       | -1.88    |\n",
      "| 22  | 6          | 8          | sleep      | 22.89    | 68.00    | 100.00   | 0.00     | 0.00         | 375.07       | -3.48    |\n",
      "| 22  | 7          | 5          | action     | 22.89    | 68.00    | 85.00    | 15.00    | 0.00         | 1000.19      | -2.36    |\n",
      "| 22  | 8          | 0          | action     | 22.89    | 68.00    | 100.00   | 0.00     | 350.00       | 1000.19      | 4.07     |\n",
      "| 22  | 9          | 5          | action     | 22.89    | 68.00    | 85.00    | 15.00    | 350.00       | 1625.32      | 7.20     |\n",
      "| 22  | 10         | 5          | action     | 22.89    | 68.00    | 70.00    | 30.00    | 350.00       | 2250.44      | 10.32    |\n",
      "| 22  | 11         | 8          | work       | 22.89    | 73.00    | 65.00    | 35.00    | 350.00       | 2389.35      | 10.84    |\n",
      "| 22  | 12         | 8          | work       | 22.89    | 78.00    | 60.00    | 40.00    | 350.00       | 2528.27      | 11.20    |\n",
      "| 22  | 13         | 0          | action     | 22.89    | 78.00    | 80.00    | 20.00    | 700.00       | 2528.27      | 9.94     |\n",
      "| 22  | 14         | 8          | work       | 22.89    | 83.00    | 75.00    | 25.00    | 700.00       | 2667.18      | 10.54    |\n",
      "| 22  | 15         | 8          | work       | 22.89    | 88.00    | 70.00    | 30.00    | 700.00       | 2806.10      | 11.13    |\n",
      "| 22  | 16         | 8          | work       | 22.89    | 93.00    | 65.00    | 35.00    | 700.00       | 2945.02      | 11.65    |\n",
      "| 22  | 17         | 8          | work       | 22.89    | 98.00    | 60.00    | 40.00    | 700.00       | 3083.93      | 12.01    |\n",
      "| 22  | 18         | 8          | work       | 22.89    | 100.00   | 55.00    | 45.00    | 700.00       | 3222.85      | 12.28    |\n",
      "| 22  | 19         | 0          | action     | 22.89    | 100.00   | 75.00    | 25.00    | 1050.00      | 3222.85      | 11.40    |\n",
      "| 22  | 20         | 0          | action     | 22.89    | 100.00   | 95.00    | 5.00     | 1400.00      | 3222.85      | 9.83     |\n",
      "| 22  | 21         | 0          | action     | 22.89    | 100.00   | 100.00   | 0.00     | 1750.00      | 3222.85      | 8.26     |\n",
      "| 22  | 22         | 0          | action     | 22.89    | 100.00   | 100.00   | 0.00     | 2100.00      | 3222.85      | 6.54     |\n",
      "| 22  | 23         | 8          | sleep      | 22.89    | 96.00    | 100.00   | 0.00     | 2100.00      | 3285.36      | 6.93     |\n",
      "| 23  | 0          | 8          | sleep      | 22.83    | 92.00    | 100.00   | 0.00     | 0.00         | 0.00         | 17.22    |\n",
      "| 23  | 1          | 8          | sleep      | 22.83    | 88.00    | 100.00   | 0.00     | 0.00         | 62.36        | 0.55     |\n",
      "| 23  | 2          | 8          | sleep      | 22.83    | 84.00    | 100.00   | 0.00     | 0.00         | 124.72       | 0.94     |\n",
      "| 23  | 3          | 8          | sleep      | 22.83    | 80.00    | 100.00   | 0.00     | 0.00         | 187.08       | 1.34     |\n",
      "| 23  | 4          | 8          | sleep      | 22.83    | 76.00    | 100.00   | 0.00     | 0.00         | 249.44       | -0.27    |\n",
      "| 23  | 5          | 8          | sleep      | 22.83    | 72.00    | 100.00   | 0.00     | 0.00         | 311.79       | -1.88    |\n",
      "| 23  | 6          | 8          | sleep      | 22.83    | 68.00    | 100.00   | 0.00     | 0.00         | 374.15       | -3.49    |\n",
      "| 23  | 7          | 5          | action     | 22.83    | 68.00    | 85.00    | 15.00    | 0.00         | 997.74       | -2.37    |\n",
      "| 23  | 8          | 0          | action     | 22.83    | 68.00    | 100.00   | 0.00     | 350.00       | 997.74       | 4.06     |\n",
      "| 23  | 9          | 5          | action     | 22.83    | 68.00    | 85.00    | 15.00    | 350.00       | 1621.33      | 7.18     |\n",
      "| 23  | 10         | 5          | action     | 22.83    | 68.00    | 70.00    | 30.00    | 350.00       | 2244.92      | 10.29    |\n",
      "| 23  | 11         | 8          | work       | 22.83    | 73.00    | 65.00    | 35.00    | 350.00       | 2383.50      | 10.81    |\n",
      "| 23  | 12         | 8          | work       | 22.83    | 78.00    | 60.00    | 40.00    | 350.00       | 2522.07      | 11.17    |\n",
      "| 23  | 13         | 0          | action     | 22.83    | 78.00    | 80.00    | 20.00    | 700.00       | 2522.07      | 9.91     |\n",
      "| 23  | 14         | 8          | work       | 22.83    | 83.00    | 75.00    | 25.00    | 700.00       | 2660.65      | 10.50    |\n",
      "| 23  | 15         | 8          | work       | 22.83    | 88.00    | 70.00    | 30.00    | 700.00       | 2799.22      | 11.10    |\n",
      "| 23  | 16         | 8          | work       | 22.83    | 93.00    | 65.00    | 35.00    | 700.00       | 2937.80      | 11.61    |\n",
      "| 23  | 17         | 8          | work       | 22.83    | 98.00    | 60.00    | 40.00    | 700.00       | 3076.38      | 11.98    |\n",
      "| 23  | 18         | 8          | work       | 22.83    | 100.00   | 55.00    | 45.00    | 700.00       | 3214.95      | 12.25    |\n",
      "| 23  | 19         | 0          | action     | 22.83    | 100.00   | 75.00    | 25.00    | 1050.00      | 3214.95      | 11.37    |\n",
      "| 23  | 20         | 0          | action     | 22.83    | 100.00   | 95.00    | 5.00     | 1400.00      | 3214.95      | 9.80     |\n",
      "| 23  | 21         | 0          | action     | 22.83    | 100.00   | 100.00   | 0.00     | 1750.00      | 3214.95      | 8.23     |\n",
      "| 23  | 22         | 0          | action     | 22.83    | 100.00   | 100.00   | 0.00     | 2100.00      | 3214.95      | 6.49     |\n",
      "| 23  | 23         | 8          | sleep      | 22.83    | 96.00    | 100.00   | 0.00     | 2100.00      | 3277.31      | 6.89     |\n",
      "| 24  | 0          | 8          | sleep      | 22.78    | 92.00    | 100.00   | 0.00     | 0.00         | 0.00         | 17.18    |\n",
      "| 24  | 1          | 8          | sleep      | 22.78    | 88.00    | 100.00   | 0.00     | 0.00         | 62.21        | 0.55     |\n",
      "| 24  | 2          | 8          | sleep      | 22.78    | 84.00    | 100.00   | 0.00     | 0.00         | 124.41       | 0.94     |\n",
      "| 24  | 3          | 8          | sleep      | 22.78    | 80.00    | 100.00   | 0.00     | 0.00         | 186.62       | 1.33     |\n",
      "| 24  | 4          | 8          | sleep      | 22.78    | 76.00    | 100.00   | 0.00     | 0.00         | 248.83       | -0.28    |\n",
      "| 24  | 5          | 8          | sleep      | 22.78    | 72.00    | 100.00   | 0.00     | 0.00         | 311.03       | -1.88    |\n",
      "| 24  | 6          | 8          | sleep      | 22.78    | 68.00    | 100.00   | 0.00     | 0.00         | 373.24       | -3.49    |\n",
      "| 24  | 7          | 5          | action     | 22.78    | 68.00    | 85.00    | 15.00    | 0.00         | 995.31       | -2.38    |\n",
      "| 24  | 8          | 0          | action     | 22.78    | 68.00    | 100.00   | 0.00     | 350.00       | 995.31       | 4.05     |\n",
      "| 24  | 9          | 5          | action     | 22.78    | 68.00    | 85.00    | 15.00    | 350.00       | 1617.38      | 7.16     |\n",
      "| 24  | 10         | 5          | action     | 22.78    | 68.00    | 70.00    | 30.00    | 350.00       | 2239.45      | 10.27    |\n",
      "| 24  | 11         | 8          | work       | 22.78    | 73.00    | 65.00    | 35.00    | 350.00       | 2377.68      | 10.78    |\n",
      "| 24  | 12         | 8          | work       | 22.78    | 78.00    | 60.00    | 40.00    | 350.00       | 2515.92      | 11.14    |\n",
      "| 24  | 13         | 0          | action     | 22.78    | 78.00    | 80.00    | 20.00    | 700.00       | 2515.92      | 9.88     |\n",
      "| 24  | 14         | 8          | work       | 22.78    | 83.00    | 75.00    | 25.00    | 700.00       | 2654.16      | 10.47    |\n",
      "| 24  | 15         | 8          | work       | 22.78    | 88.00    | 70.00    | 30.00    | 700.00       | 2792.40      | 11.06    |\n",
      "| 24  | 16         | 8          | work       | 22.78    | 93.00    | 65.00    | 35.00    | 700.00       | 2930.63      | 11.58    |\n",
      "| 24  | 17         | 8          | work       | 22.78    | 98.00    | 60.00    | 40.00    | 700.00       | 3068.87      | 11.94    |\n",
      "| 24  | 18         | 8          | work       | 22.78    | 100.00   | 55.00    | 45.00    | 700.00       | 3207.11      | 12.21    |\n",
      "| 24  | 19         | 0          | action     | 22.78    | 100.00   | 75.00    | 25.00    | 1050.00      | 3207.11      | 11.33    |\n",
      "| 24  | 20         | 0          | action     | 22.78    | 100.00   | 95.00    | 5.00     | 1400.00      | 3207.11      | 9.76     |\n",
      "| 24  | 21         | 0          | action     | 22.78    | 100.00   | 100.00   | 0.00     | 1750.00      | 3207.11      | 8.19     |\n",
      "| 24  | 22         | 0          | action     | 22.78    | 100.00   | 100.00   | 0.00     | 2100.00      | 3207.11      | 6.45     |\n",
      "| 24  | 23         | 8          | sleep      | 22.78    | 96.00    | 100.00   | 0.00     | 2100.00      | 3269.31      | 6.84     |\n",
      "| 25  | 0          | 8          | sleep      | 22.72    | 92.00    | 100.00   | 0.00     | 0.00         | 0.00         | 17.15    |\n",
      "| 25  | 1          | 8          | sleep      | 22.72    | 88.00    | 100.00   | 0.00     | 0.00         | 62.06        | 0.55     |\n",
      "| 25  | 2          | 8          | sleep      | 22.72    | 84.00    | 100.00   | 0.00     | 0.00         | 124.11       | 0.94     |\n",
      "| 25  | 3          | 8          | sleep      | 22.72    | 80.00    | 100.00   | 0.00     | 0.00         | 186.17       | 1.33     |\n",
      "| 25  | 4          | 8          | sleep      | 22.72    | 76.00    | 100.00   | 0.00     | 0.00         | 248.22       | -0.28    |\n",
      "| 25  | 5          | 8          | sleep      | 22.72    | 72.00    | 100.00   | 0.00     | 0.00         | 310.28       | -1.89    |\n",
      "| 25  | 6          | 8          | sleep      | 22.72    | 68.00    | 100.00   | 0.00     | 0.00         | 372.33       | -3.50    |\n",
      "| 25  | 7          | 5          | action     | 22.72    | 68.00    | 85.00    | 15.00    | 0.00         | 992.89       | -2.40    |\n",
      "| 25  | 8          | 0          | action     | 22.72    | 68.00    | 100.00   | 0.00     | 350.00       | 992.89       | 4.04     |\n",
      "| 25  | 9          | 5          | action     | 22.72    | 68.00    | 85.00    | 15.00    | 350.00       | 1613.45      | 7.14     |\n",
      "| 25  | 10         | 5          | action     | 22.72    | 68.00    | 70.00    | 30.00    | 350.00       | 2234.00      | 10.24    |\n",
      "| 25  | 11         | 8          | work       | 22.72    | 73.00    | 65.00    | 35.00    | 350.00       | 2371.91      | 10.75    |\n",
      "| 25  | 12         | 8          | work       | 22.72    | 78.00    | 60.00    | 40.00    | 350.00       | 2509.81      | 11.11    |\n",
      "| 25  | 13         | 0          | action     | 22.72    | 78.00    | 80.00    | 20.00    | 700.00       | 2509.81      | 9.85     |\n",
      "| 25  | 14         | 8          | work       | 22.72    | 83.00    | 75.00    | 25.00    | 700.00       | 2647.71      | 10.44    |\n",
      "| 25  | 15         | 8          | work       | 22.72    | 88.00    | 70.00    | 30.00    | 700.00       | 2785.61      | 11.03    |\n",
      "| 25  | 16         | 8          | work       | 22.72    | 93.00    | 65.00    | 35.00    | 700.00       | 2923.51      | 11.54    |\n",
      "| 25  | 17         | 8          | work       | 22.72    | 98.00    | 60.00    | 40.00    | 700.00       | 3061.41      | 11.90    |\n",
      "| 25  | 18         | 8          | work       | 22.72    | 100.00   | 55.00    | 45.00    | 700.00       | 3199.32      | 12.17    |\n",
      "| 25  | 19         | 0          | action     | 22.72    | 100.00   | 75.00    | 25.00    | 1050.00      | 3199.32      | 11.29    |\n",
      "| 25  | 20         | 0          | action     | 22.72    | 100.00   | 95.00    | 5.00     | 1400.00      | 3199.32      | 9.72     |\n",
      "| 25  | 21         | 0          | action     | 22.72    | 100.00   | 100.00   | 0.00     | 1750.00      | 3199.32      | 8.15     |\n",
      "| 25  | 22         | 0          | action     | 22.72    | 100.00   | 100.00   | 0.00     | 2100.00      | 3199.32      | 6.41     |\n",
      "| 25  | 23         | 8          | sleep      | 22.72    | 96.00    | 100.00   | 0.00     | 2100.00      | 3261.37      | 6.80     |\n",
      "| 26  | 0          | 8          | sleep      | 22.67    | 92.00    | 100.00   | 0.00     | 0.00         | 0.00         | 17.11    |\n",
      "| 26  | 1          | 8          | sleep      | 22.67    | 88.00    | 100.00   | 0.00     | 0.00         | 61.91        | 0.55     |\n",
      "| 26  | 2          | 8          | sleep      | 22.67    | 84.00    | 100.00   | 0.00     | 0.00         | 123.81       | 0.94     |\n",
      "| 26  | 3          | 8          | sleep      | 22.67    | 80.00    | 100.00   | 0.00     | 0.00         | 185.72       | 1.33     |\n",
      "| 26  | 4          | 8          | sleep      | 22.67    | 76.00    | 100.00   | 0.00     | 0.00         | 247.62       | -0.28    |\n",
      "| 26  | 5          | 8          | sleep      | 22.67    | 72.00    | 100.00   | 0.00     | 0.00         | 309.53       | -1.89    |\n",
      "| 26  | 6          | 8          | sleep      | 22.67    | 68.00    | 100.00   | 0.00     | 0.00         | 371.43       | -3.50    |\n",
      "| 26  | 7          | 5          | action     | 22.67    | 68.00    | 85.00    | 15.00    | 0.00         | 990.49       | -2.41    |\n",
      "| 26  | 8          | 0          | action     | 22.67    | 68.00    | 100.00   | 0.00     | 350.00       | 990.49       | 4.02     |\n",
      "| 26  | 9          | 5          | action     | 22.67    | 68.00    | 85.00    | 15.00    | 350.00       | 1609.54      | 7.12     |\n",
      "| 26  | 10         | 5          | action     | 22.67    | 68.00    | 70.00    | 30.00    | 350.00       | 2228.60      | 10.21    |\n",
      "| 26  | 11         | 8          | work       | 22.67    | 73.00    | 65.00    | 35.00    | 350.00       | 2366.17      | 10.73    |\n",
      "| 26  | 12         | 8          | work       | 22.67    | 78.00    | 60.00    | 40.00    | 350.00       | 2503.74      | 11.08    |\n",
      "| 26  | 13         | 0          | action     | 22.67    | 78.00    | 80.00    | 20.00    | 700.00       | 2503.74      | 9.82     |\n",
      "| 26  | 14         | 8          | work       | 22.67    | 83.00    | 75.00    | 25.00    | 700.00       | 2641.30      | 10.41    |\n",
      "| 26  | 15         | 8          | work       | 22.67    | 88.00    | 70.00    | 30.00    | 700.00       | 2778.87      | 11.00    |\n",
      "| 26  | 16         | 8          | work       | 22.67    | 93.00    | 65.00    | 35.00    | 700.00       | 2916.44      | 11.51    |\n",
      "| 26  | 17         | 8          | work       | 22.67    | 98.00    | 60.00    | 40.00    | 700.00       | 3054.01      | 11.87    |\n",
      "| 26  | 18         | 8          | work       | 22.67    | 100.00   | 55.00    | 45.00    | 700.00       | 3191.57      | 12.13    |\n",
      "| 26  | 19         | 0          | action     | 22.67    | 100.00   | 75.00    | 25.00    | 1050.00      | 3191.57      | 11.25    |\n",
      "| 26  | 20         | 0          | action     | 22.67    | 100.00   | 95.00    | 5.00     | 1400.00      | 3191.57      | 9.68     |\n",
      "| 26  | 21         | 0          | action     | 22.67    | 100.00   | 100.00   | 0.00     | 1750.00      | 3191.57      | 8.11     |\n",
      "| 26  | 22         | 0          | action     | 22.67    | 100.00   | 100.00   | 0.00     | 2100.00      | 3191.57      | 6.37     |\n",
      "| 26  | 23         | 8          | sleep      | 22.67    | 96.00    | 100.00   | 0.00     | 2100.00      | 3253.48      | 6.76     |\n",
      "| 27  | 0          | 8          | sleep      | 22.61    | 92.00    | 100.00   | 0.00     | 0.00         | 0.00         | 17.07    |\n",
      "| 27  | 1          | 8          | sleep      | 22.61    | 88.00    | 100.00   | 0.00     | 0.00         | 61.76        | 0.55     |\n",
      "| 27  | 2          | 8          | sleep      | 22.61    | 84.00    | 100.00   | 0.00     | 0.00         | 123.51       | 0.94     |\n",
      "| 27  | 3          | 8          | sleep      | 22.61    | 80.00    | 100.00   | 0.00     | 0.00         | 185.27       | 1.33     |\n",
      "| 27  | 4          | 8          | sleep      | 22.61    | 76.00    | 100.00   | 0.00     | 0.00         | 247.03       | -0.28    |\n",
      "| 27  | 5          | 8          | sleep      | 22.61    | 72.00    | 100.00   | 0.00     | 0.00         | 308.78       | -1.90    |\n",
      "| 27  | 6          | 8          | sleep      | 22.61    | 68.00    | 100.00   | 0.00     | 0.00         | 370.54       | -3.51    |\n",
      "| 27  | 7          | 5          | action     | 22.61    | 68.00    | 85.00    | 15.00    | 0.00         | 988.10       | -2.42    |\n",
      "| 27  | 8          | 0          | action     | 22.61    | 68.00    | 100.00   | 0.00     | 350.00       | 988.10       | 4.01     |\n",
      "| 27  | 9          | 5          | action     | 22.61    | 68.00    | 85.00    | 15.00    | 350.00       | 1605.67      | 7.10     |\n",
      "| 27  | 10         | 5          | action     | 22.61    | 68.00    | 70.00    | 30.00    | 350.00       | 2223.23      | 10.19    |\n",
      "| 27  | 11         | 8          | work       | 22.61    | 73.00    | 65.00    | 35.00    | 350.00       | 2360.47      | 10.70    |\n",
      "| 27  | 12         | 8          | work       | 22.61    | 78.00    | 60.00    | 40.00    | 350.00       | 2497.70      | 11.05    |\n",
      "| 27  | 13         | 0          | action     | 22.61    | 78.00    | 80.00    | 20.00    | 700.00       | 2497.70      | 9.79     |\n",
      "| 27  | 14         | 8          | work       | 22.61    | 83.00    | 75.00    | 25.00    | 700.00       | 2634.94      | 10.38    |\n",
      "| 27  | 15         | 8          | work       | 22.61    | 88.00    | 70.00    | 30.00    | 700.00       | 2772.18      | 10.96    |\n",
      "| 27  | 16         | 8          | work       | 22.61    | 93.00    | 65.00    | 35.00    | 700.00       | 2909.41      | 11.47    |\n",
      "| 27  | 17         | 8          | work       | 22.61    | 98.00    | 60.00    | 40.00    | 700.00       | 3046.65      | 11.83    |\n",
      "| 27  | 18         | 8          | work       | 22.61    | 100.00   | 55.00    | 45.00    | 700.00       | 3183.88      | 12.09    |\n",
      "| 27  | 19         | 0          | action     | 22.61    | 100.00   | 75.00    | 25.00    | 1050.00      | 3183.88      | 11.21    |\n",
      "| 27  | 20         | 0          | action     | 22.61    | 100.00   | 95.00    | 5.00     | 1400.00      | 3183.88      | 9.65     |\n",
      "| 27  | 21         | 0          | action     | 22.61    | 100.00   | 100.00   | 0.00     | 1750.00      | 3183.88      | 8.08     |\n",
      "| 27  | 22         | 0          | action     | 22.61    | 100.00   | 100.00   | 0.00     | 2100.00      | 3183.88      | 6.33     |\n",
      "| 27  | 23         | 8          | sleep      | 22.61    | 96.00    | 100.00   | 0.00     | 2100.00      | 3245.64      | 6.72     |\n",
      "| 28  | 0          | 8          | sleep      | 22.56    | 92.00    | 100.00   | 0.00     | 0.00         | 0.00         | 17.03    |\n",
      "| 28  | 1          | 8          | sleep      | 22.56    | 88.00    | 100.00   | 0.00     | 0.00         | 61.61        | 0.55     |\n",
      "| 28  | 2          | 8          | sleep      | 22.56    | 84.00    | 100.00   | 0.00     | 0.00         | 123.22       | 0.94     |\n",
      "| 28  | 3          | 8          | sleep      | 22.56    | 80.00    | 100.00   | 0.00     | 0.00         | 184.82       | 1.32     |\n",
      "| 28  | 4          | 8          | sleep      | 22.56    | 76.00    | 100.00   | 0.00     | 0.00         | 246.43       | -0.29    |\n",
      "| 28  | 5          | 8          | sleep      | 22.56    | 72.00    | 100.00   | 0.00     | 0.00         | 308.04       | -1.90    |\n",
      "| 28  | 6          | 8          | sleep      | 22.56    | 68.00    | 100.00   | 0.00     | 0.00         | 369.65       | -3.51    |\n",
      "| 28  | 7          | 5          | action     | 22.56    | 68.00    | 85.00    | 15.00    | 0.00         | 985.73       | -2.43    |\n",
      "| 28  | 8          | 0          | action     | 22.56    | 68.00    | 100.00   | 0.00     | 350.00       | 985.73       | 4.00     |\n",
      "| 28  | 9          | 5          | action     | 22.56    | 68.00    | 85.00    | 15.00    | 350.00       | 1601.81      | 7.08     |\n",
      "| 28  | 10         | 5          | action     | 22.56    | 68.00    | 70.00    | 30.00    | 350.00       | 2217.90      | 10.16    |\n",
      "| 28  | 11         | 8          | work       | 22.56    | 73.00    | 65.00    | 35.00    | 350.00       | 2354.80      | 10.67    |\n",
      "| 28  | 12         | 8          | work       | 22.56    | 78.00    | 60.00    | 40.00    | 350.00       | 2491.71      | 11.02    |\n",
      "| 28  | 13         | 0          | action     | 22.56    | 78.00    | 80.00    | 20.00    | 700.00       | 2491.71      | 9.76     |\n",
      "| 28  | 14         | 8          | work       | 22.56    | 83.00    | 75.00    | 25.00    | 700.00       | 2628.62      | 10.35    |\n",
      "| 28  | 15         | 8          | work       | 22.56    | 88.00    | 70.00    | 30.00    | 700.00       | 2765.52      | 10.93    |\n",
      "| 28  | 16         | 8          | work       | 22.56    | 93.00    | 65.00    | 35.00    | 700.00       | 2902.43      | 11.44    |\n",
      "| 28  | 17         | 8          | work       | 22.56    | 98.00    | 60.00    | 40.00    | 700.00       | 3039.34      | 11.79    |\n",
      "| 28  | 18         | 8          | work       | 22.56    | 100.00   | 55.00    | 45.00    | 700.00       | 3176.24      | 12.06    |\n",
      "| 28  | 19         | 0          | action     | 22.56    | 100.00   | 75.00    | 25.00    | 1050.00      | 3176.24      | 11.18    |\n",
      "| 28  | 20         | 0          | action     | 22.56    | 100.00   | 95.00    | 5.00     | 1400.00      | 3176.24      | 9.61     |\n",
      "| 28  | 21         | 0          | action     | 22.56    | 100.00   | 100.00   | 0.00     | 1750.00      | 3176.24      | 8.04     |\n",
      "| 28  | 22         | 0          | action     | 22.56    | 100.00   | 100.00   | 0.00     | 2100.00      | 3176.24      | 6.29     |\n",
      "| 28  | 23         | 8          | sleep      | 22.56    | 96.00    | 100.00   | 0.00     | 2100.00      | 3237.85      | 6.68     |\n",
      "| 29  | 0          | 8          | sleep      | 22.50    | 92.00    | 100.00   | 0.00     | 0.00         | 0.00         | 17.00    |\n",
      "| 29  | 1          | 8          | sleep      | 22.50    | 88.00    | 100.00   | 0.00     | 0.00         | 61.46        | 0.55     |\n",
      "| 29  | 2          | 8          | sleep      | 22.50    | 84.00    | 100.00   | 0.00     | 0.00         | 122.92       | 0.93     |\n",
      "| 29  | 3          | 8          | sleep      | 22.50    | 80.00    | 100.00   | 0.00     | 0.00         | 184.38       | 1.32     |\n",
      "| 29  | 4          | 8          | sleep      | 22.50    | 76.00    | 100.00   | 0.00     | 0.00         | 245.84       | -0.29    |\n",
      "| 29  | 5          | 8          | sleep      | 22.50    | 72.00    | 100.00   | 0.00     | 0.00         | 307.30       | -1.90    |\n",
      "| 29  | 6          | 8          | sleep      | 22.50    | 68.00    | 100.00   | 0.00     | 0.00         | 368.77       | -3.52    |\n",
      "| 29  | 7          | 5          | action     | 22.50    | 68.00    | 85.00    | 15.00    | 0.00         | 983.38       | -2.44    |\n",
      "| 29  | 8          | 0          | action     | 22.50    | 68.00    | 100.00   | 0.00     | 350.00       | 983.38       | 3.99     |\n",
      "| 29  | 9          | 5          | action     | 22.50    | 68.00    | 85.00    | 15.00    | 350.00       | 1597.99      | 7.06     |\n",
      "| 29  | 10         | 5          | action     | 22.50    | 68.00    | 70.00    | 30.00    | 350.00       | 2212.60      | 10.14    |\n",
      "| 29  | 11         | 8          | work       | 22.50    | 73.00    | 65.00    | 35.00    | 350.00       | 2349.18      | 10.64    |\n",
      "| 29  | 12         | 8          | work       | 22.50    | 78.00    | 60.00    | 40.00    | 350.00       | 2485.76      | 10.99    |\n",
      "| 29  | 13         | 0          | action     | 22.50    | 78.00    | 80.00    | 20.00    | 700.00       | 2485.76      | 9.73     |\n",
      "| 29  | 14         | 8          | work       | 22.50    | 83.00    | 75.00    | 25.00    | 700.00       | 2622.34      | 10.32    |\n",
      "| 29  | 15         | 8          | work       | 22.50    | 88.00    | 70.00    | 30.00    | 700.00       | 2758.92      | 10.90    |\n",
      "| 29  | 16         | 8          | work       | 22.50    | 93.00    | 65.00    | 35.00    | 700.00       | 2895.50      | 11.41    |\n",
      "| 29  | 17         | 8          | work       | 22.50    | 98.00    | 60.00    | 40.00    | 700.00       | 3032.08      | 11.76    |\n",
      "| 29  | 18         | 8          | work       | 22.50    | 100.00   | 55.00    | 45.00    | 700.00       | 3168.66      | 12.02    |\n",
      "| 29  | 19         | 0          | action     | 22.50    | 100.00   | 75.00    | 25.00    | 1050.00      | 3168.66      | 11.14    |\n",
      "| 29  | 20         | 0          | action     | 22.50    | 100.00   | 95.00    | 5.00     | 1400.00      | 3168.66      | 9.57     |\n",
      "| 29  | 21         | 0          | action     | 22.50    | 100.00   | 100.00   | 0.00     | 1750.00      | 3168.66      | 8.00     |\n",
      "| 29  | 22         | 0          | action     | 22.50    | 100.00   | 100.00   | 0.00     | 2100.00      | 3168.66      | 6.25     |\n",
      "| 29  | 23         | 8          | sleep      | 22.50    | 96.00    | 100.00   | 0.00     | 2100.00      | 3230.12      | 6.64     |\n",
      "| 30  | 0          | 8          | sleep      | 22.45    | 92.00    | 100.00   | 0.00     | 0.00         | 0.00         | 16.96    |\n",
      "| 30  | 1          | 8          | sleep      | 22.45    | 88.00    | 100.00   | 0.00     | 0.00         | 61.31        | 0.55     |\n",
      "| 30  | 2          | 8          | sleep      | 22.45    | 84.00    | 100.00   | 0.00     | 0.00         | 122.63       | 0.93     |\n",
      "| 30  | 3          | 8          | sleep      | 22.45    | 80.00    | 100.00   | 0.00     | 0.00         | 183.94       | 1.32     |\n",
      "| 30  | 4          | 8          | sleep      | 22.45    | 76.00    | 100.00   | 0.00     | 0.00         | 245.26       | -0.29    |\n",
      "| 30  | 5          | 8          | sleep      | 22.45    | 72.00    | 100.00   | 0.00     | 0.00         | 306.57       | -1.91    |\n",
      "| 30  | 6          | 8          | sleep      | 22.45    | 68.00    | 100.00   | 0.00     | 0.00         | 367.89       | -3.52    |\n",
      "| 30  | 7          | 5          | action     | 22.45    | 68.00    | 85.00    | 15.00    | 0.00         | 981.04       | -2.45    |\n",
      "| 30  | 8          | 0          | action     | 22.45    | 68.00    | 100.00   | 0.00     | 350.00       | 981.04       | 3.98     |\n",
      "| 30  | 9          | 5          | action     | 22.45    | 68.00    | 85.00    | 15.00    | 350.00       | 1594.18      | 7.04     |\n",
      "| 30  | 10         | 5          | action     | 22.45    | 68.00    | 70.00    | 30.00    | 350.00       | 2207.33      | 10.11    |\n",
      "| 30  | 11         | 8          | work       | 22.45    | 73.00    | 65.00    | 35.00    | 350.00       | 2343.59      | 10.61    |\n",
      "| 30  | 12         | 8          | work       | 22.45    | 78.00    | 60.00    | 40.00    | 350.00       | 2479.84      | 10.97    |\n",
      "| 30  | 13         | 0          | action     | 22.45    | 78.00    | 80.00    | 20.00    | 700.00       | 2479.84      | 9.70     |\n",
      "| 30  | 14         | 8          | work       | 22.45    | 83.00    | 75.00    | 25.00    | 700.00       | 2616.10      | 10.29    |\n",
      "| 30  | 15         | 8          | work       | 22.45    | 88.00    | 70.00    | 30.00    | 700.00       | 2752.35      | 10.87    |\n",
      "| 30  | 16         | 8          | work       | 22.45    | 93.00    | 65.00    | 35.00    | 700.00       | 2888.61      | 11.37    |\n",
      "| 30  | 17         | 8          | work       | 22.45    | 98.00    | 60.00    | 40.00    | 700.00       | 3024.86      | 11.72    |\n",
      "| 30  | 18         | 8          | work       | 22.45    | 100.00   | 55.00    | 45.00    | 700.00       | 3161.12      | 11.98    |\n",
      "| 30  | 19         | 0          | action     | 22.45    | 100.00   | 75.00    | 25.00    | 1050.00      | 3161.12      | 11.10    |\n",
      "| 30  | 20         | 0          | action     | 22.45    | 100.00   | 95.00    | 5.00     | 1400.00      | 3161.12      | 9.54     |\n",
      "| 30  | 21         | 0          | action     | 22.45    | 100.00   | 100.00   | 0.00     | 1750.00      | 3161.12      | 7.97     |\n",
      "| 30  | 22         | 0          | action     | 22.45    | 100.00   | 100.00   | 0.00     | 2100.00      | 3161.12      | 6.21     |\n",
      "| 30  | 23         | 8          | sleep      | 22.45    | 96.00    | 100.00   | 0.00     | 2100.00      | 3222.43      | 6.60     |\n",
      "| 31  | 0          | 8          | sleep      | 22.40    | 92.00    | 100.00   | 0.00     | 0.00         | 0.00         | 16.92    |\n",
      "| 31  | 1          | 8          | sleep      | 22.40    | 88.00    | 100.00   | 0.00     | 0.00         | 61.17        | 0.55     |\n",
      "| 31  | 2          | 8          | sleep      | 22.40    | 84.00    | 100.00   | 0.00     | 0.00         | 122.34       | 0.93     |\n",
      "| 31  | 3          | 8          | sleep      | 22.40    | 80.00    | 100.00   | 0.00     | 0.00         | 183.51       | 1.32     |\n",
      "| 31  | 4          | 8          | sleep      | 22.40    | 76.00    | 100.00   | 0.00     | 0.00         | 244.68       | -0.30    |\n",
      "| 31  | 5          | 8          | sleep      | 22.40    | 72.00    | 100.00   | 0.00     | 0.00         | 305.85       | -1.91    |\n",
      "| 31  | 6          | 8          | sleep      | 22.40    | 68.00    | 100.00   | 0.00     | 0.00         | 367.02       | -3.52    |\n",
      "| 31  | 7          | 5          | action     | 22.40    | 68.00    | 85.00    | 15.00    | 0.00         | 978.71       | -2.47    |\n",
      "| 31  | 8          | 0          | action     | 22.40    | 68.00    | 100.00   | 0.00     | 350.00       | 978.71       | 3.97     |\n",
      "| 31  | 9          | 5          | action     | 22.40    | 68.00    | 85.00    | 15.00    | 350.00       | 1590.41      | 7.03     |\n",
      "| 31  | 10         | 5          | action     | 22.40    | 68.00    | 70.00    | 30.00    | 350.00       | 2202.10      | 10.08    |\n",
      "| 31  | 11         | 8          | work       | 22.40    | 73.00    | 65.00    | 35.00    | 350.00       | 2338.03      | 10.59    |\n",
      "| 31  | 12         | 8          | work       | 22.40    | 78.00    | 60.00    | 40.00    | 350.00       | 2473.97      | 10.94    |\n",
      "| 31  | 13         | 0          | action     | 22.40    | 78.00    | 80.00    | 20.00    | 700.00       | 2473.97      | 9.68     |\n",
      "| 31  | 14         | 8          | work       | 22.40    | 83.00    | 75.00    | 25.00    | 700.00       | 2609.90      | 10.26    |\n",
      "| 31  | 15         | 8          | work       | 22.40    | 88.00    | 70.00    | 30.00    | 700.00       | 2745.83      | 10.84    |\n",
      "| 31  | 16         | 8          | work       | 22.40    | 93.00    | 65.00    | 35.00    | 700.00       | 2881.76      | 11.34    |\n",
      "| 31  | 17         | 8          | work       | 22.40    | 98.00    | 60.00    | 40.00    | 700.00       | 3017.69      | 11.69    |\n",
      "| 31  | 18         | 8          | work       | 22.40    | 100.00   | 55.00    | 45.00    | 700.00       | 3153.63      | 11.95    |\n",
      "| 31  | 19         | 0          | action     | 22.40    | 100.00   | 75.00    | 25.00    | 1050.00      | 3153.63      | 11.07    |\n",
      "| 31  | 20         | 0          | action     | 22.40    | 100.00   | 95.00    | 5.00     | 1400.00      | 3153.63      | 9.50     |\n",
      "| 31  | 21         | 0          | action     | 22.40    | 100.00   | 100.00   | 0.00     | 1750.00      | 3153.63      | 7.93     |\n",
      "| 31  | 22         | 0          | action     | 22.40    | 100.00   | 100.00   | 0.00     | 2100.00      | 3153.63      | 6.17     |\n",
      "| 31  | 23         | 8          | sleep      | 22.40    | 96.00    | 100.00   | 0.00     | 2100.00      | 3214.80      | 6.56     |\n",
      "| 32  | 0          | 8          | sleep      | 22.34    | 92.00    | 100.00   | 0.00     | 0.00         | 0.00         | 16.89    |\n",
      "| 32  | 1          | 8          | sleep      | 22.34    | 88.00    | 100.00   | 0.00     | 0.00         | 61.03        | 0.55     |\n",
      "| 32  | 2          | 8          | sleep      | 22.34    | 84.00    | 100.00   | 0.00     | 0.00         | 122.05       | 0.93     |\n",
      "| 32  | 3          | 8          | sleep      | 22.34    | 80.00    | 100.00   | 0.00     | 0.00         | 183.08       | 1.32     |\n",
      "| 32  | 4          | 8          | sleep      | 22.34    | 76.00    | 100.00   | 0.00     | 0.00         | 244.10       | -0.30    |\n",
      "| 32  | 5          | 8          | sleep      | 22.34    | 72.00    | 100.00   | 0.00     | 0.00         | 305.13       | -1.91    |\n",
      "| 32  | 6          | 8          | sleep      | 22.34    | 68.00    | 100.00   | 0.00     | 0.00         | 366.15       | -3.53    |\n",
      "| 32  | 7          | 5          | action     | 22.34    | 68.00    | 85.00    | 15.00    | 0.00         | 976.40       | -2.48    |\n",
      "| 32  | 8          | 0          | action     | 22.34    | 68.00    | 100.00   | 0.00     | 350.00       | 976.40       | 3.96     |\n",
      "| 32  | 9          | 5          | action     | 22.34    | 68.00    | 85.00    | 15.00    | 350.00       | 1586.65      | 7.01     |\n",
      "| 32  | 10         | 5          | action     | 22.34    | 68.00    | 70.00    | 30.00    | 350.00       | 2196.91      | 10.06    |\n",
      "| 32  | 11         | 8          | work       | 22.34    | 73.00    | 65.00    | 35.00    | 350.00       | 2332.52      | 10.56    |\n",
      "| 32  | 12         | 8          | work       | 22.34    | 78.00    | 60.00    | 40.00    | 350.00       | 2468.13      | 10.91    |\n",
      "| 32  | 13         | 0          | action     | 22.34    | 78.00    | 80.00    | 20.00    | 700.00       | 2468.13      | 9.65     |\n",
      "| 32  | 14         | 8          | work       | 22.34    | 83.00    | 75.00    | 25.00    | 700.00       | 2603.74      | 10.23    |\n",
      "| 32  | 15         | 8          | work       | 22.34    | 88.00    | 70.00    | 30.00    | 700.00       | 2739.35      | 10.80    |\n",
      "| 32  | 16         | 8          | work       | 22.34    | 93.00    | 65.00    | 35.00    | 700.00       | 2874.96      | 11.30    |\n",
      "| 32  | 17         | 8          | work       | 22.34    | 98.00    | 60.00    | 40.00    | 700.00       | 3010.57      | 11.65    |\n",
      "| 32  | 18         | 8          | work       | 22.34    | 100.00   | 55.00    | 45.00    | 700.00       | 3146.19      | 11.91    |\n",
      "| 32  | 19         | 0          | action     | 22.34    | 100.00   | 75.00    | 25.00    | 1050.00      | 3146.19      | 11.03    |\n",
      "| 32  | 20         | 0          | action     | 22.34    | 100.00   | 95.00    | 5.00     | 1400.00      | 3146.19      | 9.46     |\n",
      "| 32  | 21         | 0          | action     | 22.34    | 100.00   | 100.00   | 0.00     | 1750.00      | 3146.19      | 7.90     |\n",
      "| 32  | 22         | 0          | action     | 22.34    | 100.00   | 100.00   | 0.00     | 2100.00      | 3146.19      | 6.13     |\n",
      "| 32  | 23         | 8          | sleep      | 22.34    | 96.00    | 100.00   | 0.00     | 2100.00      | 3207.21      | 6.52     |\n",
      "| 33  | 0          | 8          | sleep      | 22.29    | 92.00    | 100.00   | 0.00     | 0.00         | 0.00         | 16.85    |\n",
      "| 33  | 1          | 8          | sleep      | 22.29    | 88.00    | 100.00   | 0.00     | 0.00         | 60.88        | 0.54     |\n",
      "| 33  | 2          | 8          | sleep      | 22.29    | 84.00    | 100.00   | 0.00     | 0.00         | 121.76       | 0.93     |\n",
      "| 33  | 3          | 8          | sleep      | 22.29    | 80.00    | 100.00   | 0.00     | 0.00         | 182.65       | 1.31     |\n",
      "| 33  | 4          | 8          | sleep      | 22.29    | 76.00    | 100.00   | 0.00     | 0.00         | 243.53       | -0.30    |\n",
      "| 33  | 5          | 8          | sleep      | 22.29    | 72.00    | 100.00   | 0.00     | 0.00         | 304.41       | -1.92    |\n",
      "| 33  | 6          | 8          | sleep      | 22.29    | 68.00    | 100.00   | 0.00     | 0.00         | 365.29       | -3.53    |\n",
      "| 33  | 7          | 5          | action     | 22.29    | 68.00    | 85.00    | 15.00    | 0.00         | 974.11       | -2.49    |\n",
      "| 33  | 8          | 0          | action     | 22.29    | 68.00    | 100.00   | 0.00     | 350.00       | 974.11       | 3.94     |\n",
      "| 33  | 9          | 5          | action     | 22.29    | 68.00    | 85.00    | 15.00    | 350.00       | 1582.93      | 6.99     |\n",
      "| 33  | 10         | 5          | action     | 22.29    | 68.00    | 70.00    | 30.00    | 350.00       | 2191.74      | 10.03    |\n",
      "| 33  | 11         | 8          | work       | 22.29    | 73.00    | 65.00    | 35.00    | 350.00       | 2327.04      | 10.53    |\n",
      "| 33  | 12         | 8          | work       | 22.29    | 78.00    | 60.00    | 40.00    | 350.00       | 2462.33      | 10.88    |\n",
      "| 33  | 13         | 0          | action     | 22.29    | 78.00    | 80.00    | 20.00    | 700.00       | 2462.33      | 9.62     |\n",
      "| 33  | 14         | 8          | work       | 22.29    | 83.00    | 75.00    | 25.00    | 700.00       | 2597.62      | 10.20    |\n",
      "| 33  | 15         | 8          | work       | 22.29    | 88.00    | 70.00    | 30.00    | 700.00       | 2732.92      | 10.77    |\n",
      "| 33  | 16         | 8          | work       | 22.29    | 93.00    | 65.00    | 35.00    | 700.00       | 2868.21      | 11.27    |\n",
      "| 33  | 17         | 8          | work       | 22.29    | 98.00    | 60.00    | 40.00    | 700.00       | 3003.50      | 11.62    |\n",
      "| 33  | 18         | 8          | work       | 22.29    | 100.00   | 55.00    | 45.00    | 700.00       | 3138.79      | 11.87    |\n",
      "| 33  | 19         | 0          | action     | 22.29    | 100.00   | 75.00    | 25.00    | 1050.00      | 3138.79      | 10.99    |\n",
      "| 33  | 20         | 0          | action     | 22.29    | 100.00   | 95.00    | 5.00     | 1400.00      | 3138.79      | 9.43     |\n",
      "| 33  | 21         | 0          | action     | 22.29    | 100.00   | 100.00   | 0.00     | 1750.00      | 3138.79      | 7.86     |\n",
      "| 33  | 22         | 0          | action     | 22.29    | 100.00   | 100.00   | 0.00     | 2100.00      | 3138.79      | 6.09     |\n",
      "| 33  | 23         | 8          | sleep      | 22.29    | 96.00    | 100.00   | 0.00     | 2100.00      | 3199.68      | 6.48     |\n",
      "| 34  | 0          | 8          | sleep      | 22.24    | 92.00    | 100.00   | 0.00     | 0.00         | 0.00         | 16.82    |\n",
      "| 34  | 1          | 8          | sleep      | 22.24    | 88.00    | 100.00   | 0.00     | 0.00         | 60.74        | 0.54     |\n",
      "| 34  | 2          | 8          | sleep      | 22.24    | 84.00    | 100.00   | 0.00     | 0.00         | 121.48       | 0.93     |\n",
      "| 34  | 3          | 8          | sleep      | 22.24    | 80.00    | 100.00   | 0.00     | 0.00         | 182.22       | 1.31     |\n",
      "| 34  | 4          | 8          | sleep      | 22.24    | 76.00    | 100.00   | 0.00     | 0.00         | 242.96       | -0.31    |\n",
      "| 34  | 5          | 8          | sleep      | 22.24    | 72.00    | 100.00   | 0.00     | 0.00         | 303.70       | -1.92    |\n",
      "| 34  | 6          | 8          | sleep      | 22.24    | 68.00    | 100.00   | 0.00     | 0.00         | 364.44       | -3.54    |\n",
      "| 34  | 7          | 5          | action     | 22.24    | 68.00    | 85.00    | 15.00    | 0.00         | 971.83       | -2.50    |\n",
      "| 34  | 8          | 0          | action     | 22.24    | 68.00    | 100.00   | 0.00     | 350.00       | 971.83       | 3.93     |\n",
      "| 34  | 9          | 5          | action     | 22.24    | 68.00    | 85.00    | 15.00    | 350.00       | 1579.22      | 6.97     |\n",
      "| 34  | 10         | 5          | action     | 22.24    | 68.00    | 70.00    | 30.00    | 350.00       | 2186.62      | 10.01    |\n",
      "| 34  | 11         | 8          | work       | 22.24    | 73.00    | 65.00    | 35.00    | 350.00       | 2321.59      | 10.51    |\n",
      "| 34  | 12         | 8          | work       | 22.24    | 78.00    | 60.00    | 40.00    | 350.00       | 2456.57      | 10.85    |\n",
      "| 34  | 13         | 0          | action     | 22.24    | 78.00    | 80.00    | 20.00    | 700.00       | 2456.57      | 9.59     |\n",
      "| 34  | 14         | 8          | work       | 22.24    | 83.00    | 75.00    | 25.00    | 700.00       | 2591.55      | 10.17    |\n",
      "| 34  | 15         | 8          | work       | 22.24    | 88.00    | 70.00    | 30.00    | 700.00       | 2726.52      | 10.74    |\n",
      "| 34  | 16         | 8          | work       | 22.24    | 93.00    | 65.00    | 35.00    | 700.00       | 2861.50      | 11.24    |\n",
      "| 34  | 17         | 8          | work       | 22.24    | 98.00    | 60.00    | 40.00    | 700.00       | 2996.47      | 11.58    |\n",
      "| 34  | 18         | 8          | work       | 22.24    | 100.00   | 55.00    | 45.00    | 700.00       | 3131.45      | 11.84    |\n",
      "| 34  | 19         | 0          | action     | 22.24    | 100.00   | 75.00    | 25.00    | 1050.00      | 3131.45      | 10.96    |\n",
      "| 34  | 20         | 0          | action     | 22.24    | 100.00   | 95.00    | 5.00     | 1400.00      | 3131.45      | 9.39     |\n",
      "| 34  | 21         | 0          | action     | 22.24    | 100.00   | 100.00   | 0.00     | 1750.00      | 3131.45      | 7.82     |\n",
      "| 34  | 22         | 0          | action     | 22.24    | 100.00   | 100.00   | 0.00     | 2100.00      | 3131.45      | 6.05     |\n",
      "| 34  | 23         | 8          | sleep      | 22.24    | 96.00    | 100.00   | 0.00     | 2100.00      | 3192.19      | 6.44     |\n",
      "| 35  | 0          | 8          | sleep      | 22.19    | 92.00    | 100.00   | 0.00     | 0.00         | 0.00         | 16.78    |\n",
      "| 35  | 1          | 8          | sleep      | 22.19    | 88.00    | 100.00   | 0.00     | 0.00         | 60.60        | 0.54     |\n",
      "| 35  | 2          | 8          | sleep      | 22.19    | 84.00    | 100.00   | 0.00     | 0.00         | 121.20       | 0.93     |\n",
      "| 35  | 3          | 8          | sleep      | 22.19    | 80.00    | 100.00   | 0.00     | 0.00         | 181.79       | 1.31     |\n",
      "| 35  | 4          | 8          | sleep      | 22.19    | 76.00    | 100.00   | 0.00     | 0.00         | 242.39       | -0.31    |\n",
      "| 35  | 5          | 8          | sleep      | 22.19    | 72.00    | 100.00   | 0.00     | 0.00         | 302.99       | -1.93    |\n",
      "| 35  | 6          | 8          | sleep      | 22.19    | 68.00    | 100.00   | 0.00     | 0.00         | 363.59       | -3.54    |\n",
      "| 35  | 7          | 5          | action     | 22.19    | 68.00    | 85.00    | 15.00    | 0.00         | 969.57       | -2.51    |\n",
      "| 35  | 8          | 0          | action     | 22.19    | 68.00    | 100.00   | 0.00     | 350.00       | 969.57       | 3.92     |\n",
      "| 35  | 9          | 5          | action     | 22.19    | 68.00    | 85.00    | 15.00    | 350.00       | 1575.54      | 6.95     |\n",
      "| 35  | 10         | 5          | action     | 22.19    | 68.00    | 70.00    | 30.00    | 350.00       | 2181.52      | 9.98     |\n",
      "| 35  | 11         | 8          | work       | 22.19    | 73.00    | 65.00    | 35.00    | 350.00       | 2316.18      | 10.48    |\n",
      "| 35  | 12         | 8          | work       | 22.19    | 78.00    | 60.00    | 40.00    | 350.00       | 2450.85      | 10.82    |\n",
      "| 35  | 13         | 0          | action     | 22.19    | 78.00    | 80.00    | 20.00    | 700.00       | 2450.85      | 9.56     |\n",
      "| 35  | 14         | 8          | work       | 22.19    | 83.00    | 75.00    | 25.00    | 700.00       | 2585.51      | 10.14    |\n",
      "| 35  | 15         | 8          | work       | 22.19    | 88.00    | 70.00    | 30.00    | 700.00       | 2720.17      | 10.71    |\n",
      "| 35  | 16         | 8          | work       | 22.19    | 93.00    | 65.00    | 35.00    | 700.00       | 2854.83      | 11.21    |\n",
      "| 35  | 17         | 8          | work       | 22.19    | 98.00    | 60.00    | 40.00    | 700.00       | 2989.49      | 11.55    |\n",
      "| 35  | 18         | 8          | work       | 22.19    | 100.00   | 55.00    | 45.00    | 700.00       | 3124.16      | 11.80    |\n",
      "| 35  | 19         | 0          | action     | 22.19    | 100.00   | 75.00    | 25.00    | 1050.00      | 3124.16      | 10.92    |\n",
      "| 35  | 20         | 0          | action     | 22.19    | 100.00   | 95.00    | 5.00     | 1400.00      | 3124.16      | 9.36     |\n",
      "| 35  | 21         | 0          | action     | 22.19    | 100.00   | 100.00   | 0.00     | 1750.00      | 3124.16      | 7.79     |\n",
      "| 35  | 22         | 0          | action     | 22.19    | 100.00   | 100.00   | 0.00     | 2100.00      | 3124.16      | 6.01     |\n",
      "| 35  | 23         | 8          | sleep      | 22.19    | 96.00    | 100.00   | 0.00     | 2100.00      | 3184.75      | 6.40     |\n",
      "| 36  | 0          | 8          | sleep      | 22.14    | 92.00    | 100.00   | 0.00     | 0.00         | 0.00         | 16.74    |\n",
      "| 36  | 1          | 8          | sleep      | 22.14    | 88.00    | 100.00   | 0.00     | 0.00         | 60.46        | 0.54     |\n",
      "| 36  | 2          | 8          | sleep      | 22.14    | 84.00    | 100.00   | 0.00     | 0.00         | 120.91       | 0.92     |\n",
      "| 36  | 3          | 8          | sleep      | 22.14    | 80.00    | 100.00   | 0.00     | 0.00         | 181.37       | 1.31     |\n",
      "| 36  | 4          | 8          | sleep      | 22.14    | 76.00    | 100.00   | 0.00     | 0.00         | 241.83       | -0.31    |\n",
      "| 36  | 5          | 8          | sleep      | 22.14    | 72.00    | 100.00   | 0.00     | 0.00         | 302.29       | -1.93    |\n",
      "| 36  | 6          | 8          | sleep      | 22.14    | 68.00    | 100.00   | 0.00     | 0.00         | 362.74       | -3.55    |\n",
      "| 36  | 7          | 5          | action     | 22.14    | 68.00    | 85.00    | 15.00    | 0.00         | 967.32       | -2.52    |\n",
      "| 36  | 8          | 0          | action     | 22.14    | 68.00    | 100.00   | 0.00     | 350.00       | 967.32       | 3.91     |\n",
      "| 36  | 9          | 5          | action     | 22.14    | 68.00    | 85.00    | 15.00    | 350.00       | 1571.89      | 6.93     |\n",
      "| 36  | 10         | 5          | action     | 22.14    | 68.00    | 70.00    | 30.00    | 350.00       | 2176.46      | 9.96     |\n",
      "| 36  | 11         | 8          | work       | 22.14    | 73.00    | 65.00    | 35.00    | 350.00       | 2310.81      | 10.45    |\n",
      "| 36  | 12         | 8          | work       | 22.14    | 78.00    | 60.00    | 40.00    | 350.00       | 2445.16      | 10.79    |\n",
      "| 36  | 13         | 0          | action     | 22.14    | 78.00    | 80.00    | 20.00    | 700.00       | 2445.16      | 9.54     |\n",
      "| 36  | 14         | 8          | work       | 22.14    | 83.00    | 75.00    | 25.00    | 700.00       | 2579.51      | 10.11    |\n",
      "| 36  | 15         | 8          | work       | 22.14    | 88.00    | 70.00    | 30.00    | 700.00       | 2713.86      | 10.68    |\n",
      "| 36  | 16         | 8          | work       | 22.14    | 93.00    | 65.00    | 35.00    | 700.00       | 2848.21      | 11.17    |\n",
      "| 36  | 17         | 8          | work       | 22.14    | 98.00    | 60.00    | 40.00    | 700.00       | 2982.56      | 11.52    |\n",
      "| 36  | 18         | 8          | work       | 22.14    | 100.00   | 55.00    | 45.00    | 700.00       | 3116.91      | 11.77    |\n",
      "| 36  | 19         | 0          | action     | 22.14    | 100.00   | 75.00    | 25.00    | 1050.00      | 3116.91      | 10.89    |\n",
      "| 36  | 20         | 0          | action     | 22.14    | 100.00   | 95.00    | 5.00     | 1400.00      | 3116.91      | 9.32     |\n",
      "| 36  | 21         | 0          | action     | 22.14    | 100.00   | 100.00   | 0.00     | 1750.00      | 3116.91      | 7.75     |\n",
      "| 36  | 22         | 0          | action     | 22.14    | 100.00   | 100.00   | 0.00     | 2100.00      | 3116.91      | 5.98     |\n",
      "| 36  | 23         | 8          | sleep      | 22.14    | 96.00    | 100.00   | 0.00     | 2100.00      | 3177.37      | 6.36     |\n",
      "| 37  | 0          | 8          | sleep      | 22.09    | 92.00    | 100.00   | 0.00     | 0.00         | 0.00         | 16.71    |\n",
      "| 37  | 1          | 8          | sleep      | 22.09    | 88.00    | 100.00   | 0.00     | 0.00         | 60.32        | 0.54     |\n",
      "| 37  | 2          | 8          | sleep      | 22.09    | 84.00    | 100.00   | 0.00     | 0.00         | 120.64       | 0.92     |\n",
      "| 37  | 3          | 8          | sleep      | 22.09    | 80.00    | 100.00   | 0.00     | 0.00         | 180.95       | 1.30     |\n",
      "| 37  | 4          | 8          | sleep      | 22.09    | 76.00    | 100.00   | 0.00     | 0.00         | 241.27       | -0.31    |\n",
      "| 37  | 5          | 8          | sleep      | 22.09    | 72.00    | 100.00   | 0.00     | 0.00         | 301.59       | -1.93    |\n",
      "| 37  | 6          | 8          | sleep      | 22.09    | 68.00    | 100.00   | 0.00     | 0.00         | 361.91       | -3.55    |\n",
      "| 37  | 7          | 5          | action     | 22.09    | 68.00    | 85.00    | 15.00    | 0.00         | 965.08       | -2.53    |\n",
      "| 37  | 8          | 0          | action     | 22.09    | 68.00    | 100.00   | 0.00     | 350.00       | 965.08       | 3.90     |\n",
      "| 37  | 9          | 5          | action     | 22.09    | 68.00    | 85.00    | 15.00    | 350.00       | 1568.26      | 6.92     |\n",
      "| 37  | 10         | 5          | action     | 22.09    | 68.00    | 70.00    | 30.00    | 350.00       | 2171.44      | 9.93     |\n",
      "| 37  | 11         | 8          | work       | 22.09    | 73.00    | 65.00    | 35.00    | 350.00       | 2305.47      | 10.43    |\n",
      "| 37  | 12         | 8          | work       | 22.09    | 78.00    | 60.00    | 40.00    | 350.00       | 2439.51      | 10.77    |\n",
      "| 37  | 13         | 0          | action     | 22.09    | 78.00    | 80.00    | 20.00    | 700.00       | 2439.51      | 9.51     |\n",
      "| 37  | 14         | 8          | work       | 22.09    | 83.00    | 75.00    | 25.00    | 700.00       | 2573.55      | 10.08    |\n",
      "| 37  | 15         | 8          | work       | 22.09    | 88.00    | 70.00    | 30.00    | 700.00       | 2707.59      | 10.65    |\n",
      "| 37  | 16         | 8          | work       | 22.09    | 93.00    | 65.00    | 35.00    | 700.00       | 2841.63      | 11.14    |\n",
      "| 37  | 17         | 8          | work       | 22.09    | 98.00    | 60.00    | 40.00    | 700.00       | 2975.67      | 11.48    |\n",
      "| 37  | 18         | 8          | work       | 22.09    | 100.00   | 55.00    | 45.00    | 700.00       | 3109.71      | 11.73    |\n",
      "| 37  | 19         | 0          | action     | 22.09    | 100.00   | 75.00    | 25.00    | 1050.00      | 3109.71      | 10.85    |\n",
      "| 37  | 20         | 0          | action     | 22.09    | 100.00   | 95.00    | 5.00     | 1400.00      | 3109.71      | 9.29     |\n",
      "| 37  | 21         | 0          | action     | 22.09    | 100.00   | 100.00   | 0.00     | 1750.00      | 3109.71      | 7.72     |\n",
      "| 37  | 22         | 0          | action     | 22.09    | 100.00   | 100.00   | 0.00     | 2100.00      | 3109.71      | 5.94     |\n",
      "| 37  | 23         | 8          | sleep      | 22.09    | 96.00    | 100.00   | 0.00     | 2100.00      | 3170.03      | 6.32     |\n",
      "| 38  | 0          | 8          | sleep      | 22.04    | 92.00    | 100.00   | 0.00     | 0.00         | 0.00         | 16.68    |\n",
      "| 38  | 1          | 8          | sleep      | 22.04    | 88.00    | 100.00   | 0.00     | 0.00         | 60.18        | 0.54     |\n",
      "| 38  | 2          | 8          | sleep      | 22.04    | 84.00    | 100.00   | 0.00     | 0.00         | 120.36       | 0.92     |\n",
      "| 38  | 3          | 8          | sleep      | 22.04    | 80.00    | 100.00   | 0.00     | 0.00         | 180.54       | 1.30     |\n",
      "| 38  | 4          | 8          | sleep      | 22.04    | 76.00    | 100.00   | 0.00     | 0.00         | 240.72       | -0.32    |\n",
      "| 38  | 5          | 8          | sleep      | 22.04    | 72.00    | 100.00   | 0.00     | 0.00         | 300.89       | -1.94    |\n",
      "| 38  | 6          | 8          | sleep      | 22.04    | 68.00    | 100.00   | 0.00     | 0.00         | 361.07       | -3.55    |\n",
      "| 38  | 7          | 5          | action     | 22.04    | 68.00    | 85.00    | 15.00    | 0.00         | 962.86       | -2.55    |\n",
      "| 38  | 8          | 0          | action     | 22.04    | 68.00    | 100.00   | 0.00     | 350.00       | 962.86       | 3.89     |\n",
      "| 38  | 9          | 5          | action     | 22.04    | 68.00    | 85.00    | 15.00    | 350.00       | 1564.65      | 6.90     |\n",
      "| 38  | 10         | 5          | action     | 22.04    | 68.00    | 70.00    | 30.00    | 350.00       | 2166.44      | 9.91     |\n",
      "| 38  | 11         | 8          | work       | 22.04    | 73.00    | 65.00    | 35.00    | 350.00       | 2300.17      | 10.40    |\n",
      "| 38  | 12         | 8          | work       | 22.04    | 78.00    | 60.00    | 40.00    | 350.00       | 2433.90      | 10.74    |\n",
      "| 38  | 13         | 0          | action     | 22.04    | 78.00    | 80.00    | 20.00    | 700.00       | 2433.90      | 9.48     |\n",
      "| 38  | 14         | 8          | work       | 22.04    | 83.00    | 75.00    | 25.00    | 700.00       | 2567.63      | 10.05    |\n",
      "| 38  | 15         | 8          | work       | 22.04    | 88.00    | 70.00    | 30.00    | 700.00       | 2701.36      | 10.62    |\n",
      "| 38  | 16         | 8          | work       | 22.04    | 93.00    | 65.00    | 35.00    | 700.00       | 2835.10      | 11.11    |\n",
      "| 38  | 17         | 8          | work       | 22.04    | 98.00    | 60.00    | 40.00    | 700.00       | 2968.83      | 11.45    |\n",
      "| 38  | 18         | 8          | work       | 22.04    | 100.00   | 55.00    | 45.00    | 700.00       | 3102.56      | 11.69    |\n",
      "| 38  | 19         | 0          | action     | 22.04    | 100.00   | 75.00    | 25.00    | 1050.00      | 3102.56      | 10.82    |\n",
      "| 38  | 20         | 0          | action     | 22.04    | 100.00   | 95.00    | 5.00     | 1400.00      | 3102.56      | 9.25     |\n",
      "| 38  | 21         | 0          | action     | 22.04    | 100.00   | 100.00   | 0.00     | 1750.00      | 3102.56      | 7.68     |\n",
      "| 38  | 22         | 0          | action     | 22.04    | 100.00   | 100.00   | 0.00     | 2100.00      | 3102.56      | 5.90     |\n",
      "| 38  | 23         | 8          | sleep      | 22.04    | 96.00    | 100.00   | 0.00     | 2100.00      | 3162.74      | 6.28     |\n",
      "| 39  | 0          | 8          | sleep      | 21.98    | 92.00    | 100.00   | 0.00     | 0.00         | 0.00         | 16.64    |\n",
      "| 39  | 1          | 8          | sleep      | 21.98    | 88.00    | 100.00   | 0.00     | 0.00         | 60.04        | 0.54     |\n",
      "| 39  | 2          | 8          | sleep      | 21.98    | 84.00    | 100.00   | 0.00     | 0.00         | 120.08       | 0.92     |\n",
      "| 39  | 3          | 8          | sleep      | 21.98    | 80.00    | 100.00   | 0.00     | 0.00         | 180.12       | 1.30     |\n",
      "| 39  | 4          | 8          | sleep      | 21.98    | 76.00    | 100.00   | 0.00     | 0.00         | 240.16       | -0.32    |\n",
      "| 39  | 5          | 8          | sleep      | 21.98    | 72.00    | 100.00   | 0.00     | 0.00         | 300.21       | -1.94    |\n",
      "| 39  | 6          | 8          | sleep      | 21.98    | 68.00    | 100.00   | 0.00     | 0.00         | 360.25       | -3.56    |\n",
      "| 39  | 7          | 5          | action     | 21.98    | 68.00    | 85.00    | 15.00    | 0.00         | 960.66       | -2.56    |\n",
      "| 39  | 8          | 0          | action     | 21.98    | 68.00    | 100.00   | 0.00     | 350.00       | 960.66       | 3.88     |\n",
      "| 39  | 9          | 5          | action     | 21.98    | 68.00    | 85.00    | 15.00    | 350.00       | 1561.07      | 6.88     |\n",
      "| 39  | 10         | 5          | action     | 21.98    | 68.00    | 70.00    | 30.00    | 350.00       | 2161.48      | 9.88     |\n",
      "| 39  | 11         | 8          | work       | 21.98    | 73.00    | 65.00    | 35.00    | 350.00       | 2294.90      | 10.37    |\n",
      "| 39  | 12         | 8          | work       | 21.98    | 78.00    | 60.00    | 40.00    | 350.00       | 2428.33      | 10.71    |\n",
      "| 39  | 13         | 0          | action     | 21.98    | 78.00    | 80.00    | 20.00    | 700.00       | 2428.33      | 9.45     |\n",
      "| 39  | 14         | 8          | work       | 21.98    | 83.00    | 75.00    | 25.00    | 700.00       | 2561.75      | 10.02    |\n",
      "| 39  | 15         | 8          | work       | 21.98    | 88.00    | 70.00    | 30.00    | 700.00       | 2695.18      | 10.59    |\n",
      "| 39  | 16         | 8          | work       | 21.98    | 93.00    | 65.00    | 35.00    | 700.00       | 2828.60      | 11.08    |\n",
      "| 39  | 17         | 8          | work       | 21.98    | 98.00    | 60.00    | 40.00    | 700.00       | 2962.03      | 11.42    |\n",
      "| 39  | 18         | 8          | work       | 21.98    | 100.00   | 55.00    | 45.00    | 700.00       | 3095.45      | 11.66    |\n",
      "| 39  | 19         | 0          | action     | 21.98    | 100.00   | 75.00    | 25.00    | 1050.00      | 3095.45      | 10.78    |\n",
      "| 39  | 20         | 0          | action     | 21.98    | 100.00   | 95.00    | 5.00     | 1400.00      | 3095.45      | 9.22     |\n",
      "| 39  | 21         | 0          | action     | 21.98    | 100.00   | 100.00   | 0.00     | 1750.00      | 3095.45      | 7.65     |\n",
      "| 39  | 22         | 0          | action     | 21.98    | 100.00   | 100.00   | 0.00     | 2100.00      | 3095.45      | 5.86     |\n",
      "| 39  | 23         | 8          | sleep      | 21.98    | 96.00    | 100.00   | 0.00     | 2100.00      | 3155.49      | 6.24     |\n",
      "| 40  | 0          | 8          | sleep      | 21.93    | 92.00    | 100.00   | 0.00     | 0.00         | 0.00         | 116.61   |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------\n",
      "Mean evaluation reward: 7.2258824950863865\n",
      "Std deviation: 6.58237308364425\n"
     ]
    }
   ],
   "source": [
    "from environment3 import LifeStyleEnv\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from sb3_contrib.common.maskable.utils import get_action_masks\n",
    "import numpy as np\n",
    "from sb3_contrib import MaskablePPO\n",
    "\n",
    "def make_env(is_eval: bool = False):\n",
    "    env = LifeStyleEnv()\n",
    "    env = Monitor(env)\n",
    "    if not is_eval:\n",
    "        check_env(env, warn=True)\n",
    "    return env\n",
    "\n",
    "eval_env = make_env(is_eval=True)\n",
    "\n",
    "\n",
    "model = MaskablePPO.load(\"../agent/ppo_lifestylecoach_best_entropy.zip\")\n",
    "\n",
    "print(\"Starting Final Evaluation...\")\n",
    "print(\"-------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "print(f\"| {'Day':<3} | {'Timeslot':<10} | {'Action':<10} | {'Event':<10} | {'BMI':<8} | {'Stress':<8} | {'Energy':<8} | {'Hunger':<8} | {'Cal. Intake':<12} | {'Cal. Burned':<12} | {'Reward':<8} |\")\n",
    "print(\"-------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "episode_rewards = []\n",
    "for episode in range(1):  \n",
    "    obs, info = eval_env.reset()\n",
    "    unwrapped_env = eval_env.unwrapped\n",
    "    \n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        action_masks = get_action_masks(unwrapped_env)\n",
    "        action, _ = model.predict(obs, deterministic=True, action_masks=action_masks)\n",
    "        obs, reward, terminated, truncated, info = eval_env.step(action)\n",
    "        done = terminated or truncated\n",
    "        total_reward += reward\n",
    "        \n",
    "        timeslot_applied = unwrapped_env.state['current_timeslot'] - 1\n",
    "        timeslot_applied = max(timeslot_applied, 0)  \n",
    "        event_applied = unwrapped_env.daily_schedule[timeslot_applied]\n",
    "\n",
    "        print(\n",
    "            f\"| {unwrapped_env.state['day_of_episode']:<3} | \"\n",
    "            f\"{unwrapped_env.state['current_timeslot']:<10} | \"\n",
    "            f\"{action:<10} | \"\n",
    "            f\"{event_applied:<10} | \"\n",
    "            f\"{unwrapped_env.state['current_bmi']:<8.2f} | \"\n",
    "            f\"{unwrapped_env.state['current_stress_level']:<8.2f} | \"\n",
    "            f\"{unwrapped_env.state['current_energy_level']:<8.2f} | \"\n",
    "            f\"{unwrapped_env.state['current_hunger_level']:<8.2f} | \"\n",
    "            f\"{unwrapped_env.state['daily_calories_intake']:<12.2f} | \"\n",
    "            f\"{unwrapped_env.state['daily_calories_burned']:<12.2f} | \"\n",
    "            f\"{reward:<8.2f} |\"\n",
    "        )\n",
    "        \n",
    "        episode_rewards.append(reward)\n",
    "\n",
    "print(\"-------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "print(\"Mean evaluation reward:\", np.mean(episode_rewards))\n",
    "print(\"Std deviation:\", np.std(episode_rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27015967",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.15)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
