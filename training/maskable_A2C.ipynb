{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d664137b",
   "metadata": {},
   "source": [
    "## Test for best learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2741c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-06 10:43:03.883380: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-06 10:43:04.383494: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-06 10:43:05.655506: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Using cpu device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./logs/a2c/a2c_tensorboard_test1/A2C_2\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1687     |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.31    |\n",
      "|    explained_variance | 0.000747 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 51.1     |\n",
      "|    value_loss         | 2.24e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1.63e+03 |\n",
      "|    ep_rew_mean        | 1.24e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 1729     |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.951   |\n",
      "|    explained_variance | 0.000167 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 16.7     |\n",
      "|    value_loss         | 852      |\n",
      "------------------------------------\n",
      "Eval num_timesteps=5000, episode_reward=-11738.46 +/- 0.07\n",
      "Episode length: 504.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 504       |\n",
      "|    mean_reward        | -1.17e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.03     |\n",
      "|    explained_variance | 1.15e-05  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 249       |\n",
      "|    policy_loss        | 65.4      |\n",
      "|    value_loss         | 4.5e+03   |\n",
      "-------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1.38e+03 |\n",
      "|    ep_rew_mean        | 1.13e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 1117     |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.09    |\n",
      "|    explained_variance | 0.000224 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 57       |\n",
      "|    value_loss         | 3.14e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.21e+03  |\n",
      "|    ep_rew_mean        | 1.01e+04  |\n",
      "| time/                 |           |\n",
      "|    fps                | 1224      |\n",
      "|    iterations         | 400       |\n",
      "|    time_elapsed       | 6         |\n",
      "|    total_timesteps    | 8000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.816    |\n",
      "|    explained_variance | -1.43e-06 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 399       |\n",
      "|    policy_loss        | 18.5      |\n",
      "|    value_loss         | 671       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=-9718.91 +/- 0.00\n",
      "Episode length: 408.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 408       |\n",
      "|    mean_reward        | -9.72e+03 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 10000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.605    |\n",
      "|    explained_variance | 0.000467  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | -137      |\n",
      "|    value_loss         | 421       |\n",
      "-------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.07e+03 |\n",
      "|    ep_rew_mean     | 8.65e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 1108     |\n",
      "|    iterations      | 500      |\n",
      "|    time_elapsed    | 9        |\n",
      "|    total_timesteps | 10000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 912      |\n",
      "|    ep_rew_mean        | 7.17e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 1167     |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.687   |\n",
      "|    explained_variance | 0.00232  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 47.5     |\n",
      "|    value_loss         | 3.66e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 943      |\n",
      "|    ep_rew_mean        | 7.59e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 1208     |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.796   |\n",
      "|    explained_variance | 0.000106 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 26.5     |\n",
      "|    value_loss         | 1.46e+03 |\n",
      "------------------------------------\n",
      "Eval num_timesteps=15000, episode_reward=-19497.29 +/- 0.01\n",
      "Episode length: 1248.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1.25e+03  |\n",
      "|    mean_reward        | -1.95e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 15000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.787    |\n",
      "|    explained_variance | 8.85e-05  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 749       |\n",
      "|    policy_loss        | 14.8      |\n",
      "|    value_loss         | 1.01e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 984       |\n",
      "|    ep_rew_mean        | 8.29e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 895       |\n",
      "|    iterations         | 800       |\n",
      "|    time_elapsed       | 17        |\n",
      "|    total_timesteps    | 16000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.593    |\n",
      "|    explained_variance | -2.91e-05 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 799       |\n",
      "|    policy_loss        | 34.3      |\n",
      "|    value_loss         | 3.71e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 947      |\n",
      "|    ep_rew_mean        | 8.39e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 946      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.815   |\n",
      "|    explained_variance | 0.000242 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 21.9     |\n",
      "|    value_loss         | 803      |\n",
      "------------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=-15690.48 +/- 0.00\n",
      "Episode length: 1128.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1.13e+03  |\n",
      "|    mean_reward        | -1.57e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 20000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.653    |\n",
      "|    explained_variance | 0.000202  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | 12.2      |\n",
      "|    value_loss         | 574       |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 964      |\n",
      "|    ep_rew_mean     | 8.63e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 816      |\n",
      "|    iterations      | 1000     |\n",
      "|    time_elapsed    | 24       |\n",
      "|    total_timesteps | 20000    |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 999       |\n",
      "|    ep_rew_mean        | 9.02e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 857       |\n",
      "|    iterations         | 1100      |\n",
      "|    time_elapsed       | 25        |\n",
      "|    total_timesteps    | 22000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.505    |\n",
      "|    explained_variance | -0.000195 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1099      |\n",
      "|    policy_loss        | 0.536     |\n",
      "|    value_loss         | 80.7      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1.06e+03 |\n",
      "|    ep_rew_mean        | 9.58e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 894      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.528   |\n",
      "|    explained_variance | 0.000349 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 10       |\n",
      "|    value_loss         | 146      |\n",
      "------------------------------------\n",
      "Eval num_timesteps=25000, episode_reward=-15120.48 +/- 0.00\n",
      "Episode length: 1128.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1.13e+03  |\n",
      "|    mean_reward        | -1.51e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 25000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.443    |\n",
      "|    explained_variance | 0.00225   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1249      |\n",
      "|    policy_loss        | 3.6       |\n",
      "|    value_loss         | 495       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1.07e+03 |\n",
      "|    ep_rew_mean        | 9.77e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 803      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.519   |\n",
      "|    explained_variance | 0.0177   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -10.8    |\n",
      "|    value_loss         | 1.21e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1.1e+03  |\n",
      "|    ep_rew_mean        | 1.02e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 835      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 33       |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.522   |\n",
      "|    explained_variance | 0.0658   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 4.91     |\n",
      "|    value_loss         | 84.5     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=8617.39 +/- 0.00\n",
      "Episode length: 1056.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1.06e+03 |\n",
      "|    mean_reward        | 8.62e+03 |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.642   |\n",
      "|    explained_variance | 0.00811  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -28.1    |\n",
      "|    value_loss         | 1.91e+03 |\n",
      "------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.11e+03 |\n",
      "|    ep_rew_mean     | 1.04e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 775      |\n",
      "|    iterations      | 1500     |\n",
      "|    time_elapsed    | 38       |\n",
      "|    total_timesteps | 30000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1.1e+03  |\n",
      "|    ep_rew_mean        | 1.04e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 802      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 39       |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.247   |\n",
      "|    explained_variance | -0.291   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | -13.6    |\n",
      "|    value_loss         | 99.9     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.1e+03   |\n",
      "|    ep_rew_mean        | 1.04e+04  |\n",
      "| time/                 |           |\n",
      "|    fps                | 829       |\n",
      "|    iterations         | 1700      |\n",
      "|    time_elapsed       | 40        |\n",
      "|    total_timesteps    | 34000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.13e-11 |\n",
      "|    explained_variance | 0.129     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1699      |\n",
      "|    policy_loss        | -1.66e+03 |\n",
      "|    value_loss         | 1.72e+03  |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=35000, episode_reward=-37781.71 +/- 0.16\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -3.78e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 35000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.03e-13 |\n",
      "|    explained_variance | 0.0141    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1749      |\n",
      "|    policy_loss        | -516      |\n",
      "|    value_loss         | 421       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.14e+03  |\n",
      "|    ep_rew_mean        | 9.67e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 706       |\n",
      "|    iterations         | 1800      |\n",
      "|    time_elapsed       | 50        |\n",
      "|    total_timesteps    | 36000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.88e-16 |\n",
      "|    explained_variance | 0.439     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1799      |\n",
      "|    policy_loss        | -229      |\n",
      "|    value_loss         | 105       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.18e+03  |\n",
      "|    ep_rew_mean        | 8.83e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 728       |\n",
      "|    iterations         | 1900      |\n",
      "|    time_elapsed       | 52        |\n",
      "|    total_timesteps    | 38000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.03e-09 |\n",
      "|    explained_variance | 0.71      |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1899      |\n",
      "|    policy_loss        | 59.1      |\n",
      "|    value_loss         | 30        |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=-37781.77 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -3.78e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 40000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.41e-09 |\n",
      "|    explained_variance | 0.846     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1999      |\n",
      "|    policy_loss        | -161      |\n",
      "|    value_loss         | 18.1      |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.21e+03 |\n",
      "|    ep_rew_mean     | 8.05e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 642      |\n",
      "|    iterations      | 2000     |\n",
      "|    time_elapsed    | 62       |\n",
      "|    total_timesteps | 40000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1.25e+03 |\n",
      "|    ep_rew_mean        | 7.32e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 661      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0305  |\n",
      "|    explained_variance | 0.818    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -199     |\n",
      "|    value_loss         | 32       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1.28e+03 |\n",
      "|    ep_rew_mean        | 6.63e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 680      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 64       |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.779   |\n",
      "|    explained_variance | 0.57     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -20.6    |\n",
      "|    value_loss         | 40.2     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=45000, episode_reward=-37781.77 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -3.78e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 45000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0209   |\n",
      "|    explained_variance | 0.205     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2249      |\n",
      "|    policy_loss        | -963      |\n",
      "|    value_loss         | 932       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.31e+03  |\n",
      "|    ep_rew_mean        | 6.45e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 617       |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 74        |\n",
      "|    total_timesteps    | 46000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.95e-16 |\n",
      "|    explained_variance | 0.474     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | 182       |\n",
      "|    value_loss         | 50.5      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1.31e+03 |\n",
      "|    ep_rew_mean        | 6.45e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 634      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 75       |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00427 |\n",
      "|    explained_variance | 0.98     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | 17.2     |\n",
      "|    value_loss         | 2.15     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=-20652.24 +/- 0.26\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -2.07e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 50000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.168    |\n",
      "|    explained_variance | 0.843     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2499      |\n",
      "|    policy_loss        | -29.3     |\n",
      "|    value_loss         | 9.29      |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.33e+03 |\n",
      "|    ep_rew_mean     | 5.82e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 581      |\n",
      "|    iterations      | 2500     |\n",
      "|    time_elapsed    | 85       |\n",
      "|    total_timesteps | 50000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1.36e+03 |\n",
      "|    ep_rew_mean        | 5.8e+03  |\n",
      "| time/                 |          |\n",
      "|    fps                | 596      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 52000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.114   |\n",
      "|    explained_variance | 0.894    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -143     |\n",
      "|    value_loss         | 16.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1.39e+03 |\n",
      "|    ep_rew_mean        | 5.95e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 611      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 88       |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.386   |\n",
      "|    explained_variance | -2.68    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 21       |\n",
      "|    value_loss         | 1.44e+03 |\n",
      "------------------------------------\n",
      "Eval num_timesteps=55000, episode_reward=-11558.21 +/- 0.01\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.16e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 55000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.08e-07 |\n",
      "|    explained_variance | 0.0531    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2749      |\n",
      "|    policy_loss        | -901      |\n",
      "|    value_loss         | 388       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1.41e+03 |\n",
      "|    ep_rew_mean        | 5.88e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 568      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 98       |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.136   |\n",
      "|    explained_variance | 0.742    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 64.3     |\n",
      "|    value_loss         | 30.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1.43e+03 |\n",
      "|    ep_rew_mean        | 6.09e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 582      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 99       |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.11    |\n",
      "|    explained_variance | 0.672    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -87.7    |\n",
      "|    value_loss         | 8.53     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=-38835.04 +/- 0.12\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -3.88e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 60000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0787   |\n",
      "|    explained_variance | -0.178    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2999      |\n",
      "|    policy_loss        | 133       |\n",
      "|    value_loss         | 283       |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 6.26e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 547      |\n",
      "|    iterations      | 3000     |\n",
      "|    time_elapsed    | 109      |\n",
      "|    total_timesteps | 60000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1.47e+03 |\n",
      "|    ep_rew_mean        | 6.47e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 110      |\n",
      "|    total_timesteps    | 62000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.143   |\n",
      "|    explained_variance | 0.8      |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -246     |\n",
      "|    value_loss         | 20.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1.47e+03 |\n",
      "|    ep_rew_mean        | 6.47e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 571      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 111      |\n",
      "|    total_timesteps    | 64000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0096  |\n",
      "|    explained_variance | 0.935    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -228     |\n",
      "|    value_loss         | 12.8     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=65000, episode_reward=-18482.52 +/- 0.04\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.85e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 65000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.136    |\n",
      "|    explained_variance | 0.911     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3249      |\n",
      "|    policy_loss        | -95.7     |\n",
      "|    value_loss         | 7.03      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1.49e+03 |\n",
      "|    ep_rew_mean        | 6.66e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 540      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 122      |\n",
      "|    total_timesteps    | 66000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.195   |\n",
      "|    explained_variance | 0.972    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 199      |\n",
      "|    value_loss         | 23.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1.51e+03 |\n",
      "|    ep_rew_mean        | 6.85e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 551      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 123      |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.117   |\n",
      "|    explained_variance | 0.953    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 33       |\n",
      "|    value_loss         | 6.37     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=-15319.20 +/- 0.01\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.53e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 70000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.184    |\n",
      "|    explained_variance | 0.737     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3499      |\n",
      "|    policy_loss        | -343      |\n",
      "|    value_loss         | 19        |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.53e+03 |\n",
      "|    ep_rew_mean     | 7.03e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 524      |\n",
      "|    iterations      | 3500     |\n",
      "|    time_elapsed    | 133      |\n",
      "|    total_timesteps | 70000    |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.54e+03  |\n",
      "|    ep_rew_mean        | 7.21e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 535       |\n",
      "|    iterations         | 3600      |\n",
      "|    time_elapsed       | 134       |\n",
      "|    total_timesteps    | 72000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.38e-13 |\n",
      "|    explained_variance | 0.801     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3599      |\n",
      "|    policy_loss        | -178      |\n",
      "|    value_loss         | 27.8      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1.56e+03 |\n",
      "|    ep_rew_mean        | 6.71e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 545      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 135      |\n",
      "|    total_timesteps    | 74000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.151   |\n",
      "|    explained_variance | 0.428    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 369      |\n",
      "|    value_loss         | 1.92e+03 |\n",
      "------------------------------------\n",
      "Eval num_timesteps=75000, episode_reward=-20828.49 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -2.08e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 75000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.138    |\n",
      "|    explained_variance | 0.905     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3749      |\n",
      "|    policy_loss        | 89.7      |\n",
      "|    value_loss         | 11.2      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1.58e+03 |\n",
      "|    ep_rew_mean        | 6.89e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 521      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 145      |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.3e-05 |\n",
      "|    explained_variance | 0.0403   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | -91      |\n",
      "|    value_loss         | 36.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1.59e+03 |\n",
      "|    ep_rew_mean        | 7.08e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 530      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 147      |\n",
      "|    total_timesteps    | 78000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.024   |\n",
      "|    explained_variance | 0.237    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | -516     |\n",
      "|    value_loss         | 269      |\n",
      "------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=-36582.44 +/- 0.11\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -3.66e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 80000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0266   |\n",
      "|    explained_variance | 0.896     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3999      |\n",
      "|    policy_loss        | 58.5      |\n",
      "|    value_loss         | 9.39      |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.59e+03 |\n",
      "|    ep_rew_mean     | 7.08e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 507      |\n",
      "|    iterations      | 4000     |\n",
      "|    time_elapsed    | 157      |\n",
      "|    total_timesteps | 80000    |\n",
      "---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<MaskableA2C.MaskableA2C at 0x7323698b73a0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from environment3 import LifeStyleEnv\n",
    "from sb3_contrib.common.wrappers import ActionMasker\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "from MaskableA2C import MaskableA2C\n",
    "from stable_baselines3.common.torch_layers import CombinedExtractor\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def mask_fn(env: gym.Env) -> np.ndarray:\n",
    "    unwrapped_env = env\n",
    "    while hasattr(unwrapped_env, \"env\"):\n",
    "        unwrapped_env = unwrapped_env.env\n",
    "    return unwrapped_env.action_masks()\n",
    "\n",
    "def make_env():\n",
    "    env = LifeStyleEnv()\n",
    "    env = Monitor(env)\n",
    "    check_env(env, warn=True) \n",
    "    return env \n",
    "\n",
    "env = make_env()\n",
    "env = ActionMasker(env, mask_fn)\n",
    "\n",
    "eval_env = make_env()\n",
    "eval_env = ActionMasker(eval_env, mask_fn)\n",
    "\n",
    "eval_callback = EvalCallback(\n",
    "    eval_env,\n",
    "    best_model_save_path=\"./logs/a2c/a2c_best_model_test1\",\n",
    "    log_path=\"./logs/a2c/a2c_results_test1\",\n",
    "    eval_freq=5000,\n",
    "    n_eval_episodes=10,\n",
    "    deterministic=True,\n",
    "    render=False\n",
    ")\n",
    "\n",
    "model = MaskableA2C(\n",
    "    \"MultiInputPolicy\",  \n",
    "    env,\n",
    "    learning_rate=0.0005,\n",
    "    n_steps=20,           \n",
    "    gamma=0.95,\n",
    "    gae_lambda=0.95,\n",
    "    vf_coef=0.5,\n",
    "    max_grad_norm=0.5,\n",
    "    verbose=1,\n",
    "    device=device,\n",
    "    policy_kwargs=dict(\n",
    "        features_extractor_class=CombinedExtractor,  \n",
    "        features_extractor_kwargs={},                \n",
    "        net_arch=[256, 256]\n",
    "    ),\n",
    "    tensorboard_log=\"./logs/a2c/a2c_tensorboard_test1/\"\n",
    ")\n",
    "\n",
    "model.learn(total_timesteps=80000, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf35d31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Using cpu device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./logs/a2c/a2c_tensorboard_test2/A2C_2\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1709      |\n",
      "|    iterations         | 100       |\n",
      "|    time_elapsed       | 1         |\n",
      "|    total_timesteps    | 2000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.905    |\n",
      "|    explained_variance | -0.000297 |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 99        |\n",
      "|    policy_loss        | 28.7      |\n",
      "|    value_loss         | 2e+03     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.32e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 1711     |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.917   |\n",
      "|    explained_variance | 0.000269 |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 13.5     |\n",
      "|    value_loss         | 1.13e+03 |\n",
      "------------------------------------\n",
      "Eval num_timesteps=5000, episode_reward=-37781.72 +/- 0.15\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -3.78e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00335  |\n",
      "|    explained_variance | 6.59e-05  |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 249       |\n",
      "|    policy_loss        | -1.01e+03 |\n",
      "|    value_loss         | 4.82e+03  |\n",
      "-------------------------------------\n",
      "New best mean reward!\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.55e+03  |\n",
      "|    ep_rew_mean        | 1e+04     |\n",
      "| time/                 |           |\n",
      "|    fps                | 479       |\n",
      "|    iterations         | 300       |\n",
      "|    time_elapsed       | 12        |\n",
      "|    total_timesteps    | 6000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.03e-12 |\n",
      "|    explained_variance | 0.0249    |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 299       |\n",
      "|    policy_loss        | -1.94e+03 |\n",
      "|    value_loss         | 2.7e+03   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.74e+03  |\n",
      "|    ep_rew_mean        | 3.52e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 584       |\n",
      "|    iterations         | 400       |\n",
      "|    time_elapsed       | 13        |\n",
      "|    total_timesteps    | 8000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.77e-25 |\n",
      "|    explained_variance | 0.000748  |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 399       |\n",
      "|    policy_loss        | -1.01e+03 |\n",
      "|    value_loss         | 453       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=-37781.77 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -3.78e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 10000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.04e-35 |\n",
      "|    explained_variance | 0.00635   |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | -1.64e+03 |\n",
      "|    value_loss         | 242       |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.85e+03 |\n",
      "|    ep_rew_mean     | -416     |\n",
      "| time/              |          |\n",
      "|    fps             | 423      |\n",
      "|    iterations      | 500      |\n",
      "|    time_elapsed    | 23       |\n",
      "|    total_timesteps | 10000    |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.93e+03  |\n",
      "|    ep_rew_mean        | -3.04e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 483       |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 24        |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.34e-40 |\n",
      "|    explained_variance | 0.318     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | -1.56e+03 |\n",
      "|    value_loss         | 311       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.98e+03  |\n",
      "|    ep_rew_mean        | -4.92e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 538       |\n",
      "|    iterations         | 700       |\n",
      "|    time_elapsed       | 26        |\n",
      "|    total_timesteps    | 14000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.27e-09 |\n",
      "|    explained_variance | -0.0898   |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 699       |\n",
      "|    policy_loss        | 675       |\n",
      "|    value_loss         | 432       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=15000, episode_reward=-37781.77 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -3.78e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 15000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.97e-10 |\n",
      "|    explained_variance | 0.764     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 749       |\n",
      "|    policy_loss        | -836      |\n",
      "|    value_loss         | 57.6      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.98e+03  |\n",
      "|    ep_rew_mean        | -4.92e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 440       |\n",
      "|    iterations         | 800       |\n",
      "|    time_elapsed       | 36        |\n",
      "|    total_timesteps    | 16000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.15e-30 |\n",
      "|    explained_variance | 0.941     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 799       |\n",
      "|    policy_loss        | -332      |\n",
      "|    value_loss         | 8.48      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.02e+03  |\n",
      "|    ep_rew_mean        | -6.33e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 480       |\n",
      "|    iterations         | 900       |\n",
      "|    time_elapsed       | 37        |\n",
      "|    total_timesteps    | 18000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0939   |\n",
      "|    explained_variance | 0.959     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 899       |\n",
      "|    policy_loss        | 44.5      |\n",
      "|    value_loss         | 7.03      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=-36479.93 +/- 0.02\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -3.65e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 20000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0184   |\n",
      "|    explained_variance | 0.912     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | -22.4     |\n",
      "|    value_loss         | 8.09      |\n",
      "-------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.05e+03  |\n",
      "|    ep_rew_mean     | -7.42e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 416       |\n",
      "|    iterations      | 1000      |\n",
      "|    time_elapsed    | 48        |\n",
      "|    total_timesteps | 20000     |\n",
      "----------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.08e+03  |\n",
      "|    ep_rew_mean        | -8.3e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 451       |\n",
      "|    iterations         | 1100      |\n",
      "|    time_elapsed       | 48        |\n",
      "|    total_timesteps    | 22000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.67e-24 |\n",
      "|    explained_variance | 0.948     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 1099      |\n",
      "|    policy_loss        | -543      |\n",
      "|    value_loss         | 14.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.1e+03   |\n",
      "|    ep_rew_mean        | -9.01e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 480       |\n",
      "|    iterations         | 1200      |\n",
      "|    time_elapsed       | 49        |\n",
      "|    total_timesteps    | 24000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.04e-42 |\n",
      "|    explained_variance | 0.935     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 1199      |\n",
      "|    policy_loss        | -577      |\n",
      "|    value_loss         | 15.2      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=25000, episode_reward=-37781.76 +/- 0.02\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -3.78e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 25000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.54e-20 |\n",
      "|    explained_variance | 0.992     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 1249      |\n",
      "|    policy_loss        | 15.9      |\n",
      "|    value_loss         | 0.76      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.12e+03  |\n",
      "|    ep_rew_mean        | -9.43e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 430       |\n",
      "|    iterations         | 1300      |\n",
      "|    time_elapsed       | 60        |\n",
      "|    total_timesteps    | 26000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.15e-11 |\n",
      "|    explained_variance | 0.833     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 1299      |\n",
      "|    policy_loss        | -594      |\n",
      "|    value_loss         | 39.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.13e+03  |\n",
      "|    ep_rew_mean        | -9.97e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 454       |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 61        |\n",
      "|    total_timesteps    | 28000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.99e-17 |\n",
      "|    explained_variance | 0.898     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | -422      |\n",
      "|    value_loss         | 26.4      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=-35621.77 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -3.56e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 30000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000235 |\n",
      "|    explained_variance | 0.958     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | -31.5     |\n",
      "|    value_loss         | 4.92      |\n",
      "-------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.14e+03  |\n",
      "|    ep_rew_mean     | -1.04e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 417       |\n",
      "|    iterations      | 1500      |\n",
      "|    time_elapsed    | 71        |\n",
      "|    total_timesteps | 30000     |\n",
      "----------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.14e+03  |\n",
      "|    ep_rew_mean        | -1.04e+04 |\n",
      "| time/                 |           |\n",
      "|    fps                | 437       |\n",
      "|    iterations         | 1600      |\n",
      "|    time_elapsed       | 73        |\n",
      "|    total_timesteps    | 32000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00989  |\n",
      "|    explained_variance | 0.939     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 1599      |\n",
      "|    policy_loss        | -8.49     |\n",
      "|    value_loss         | 5.39      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.15e+03  |\n",
      "|    ep_rew_mean        | -1.08e+04 |\n",
      "| time/                 |           |\n",
      "|    fps                | 457       |\n",
      "|    iterations         | 1700      |\n",
      "|    time_elapsed       | 74        |\n",
      "|    total_timesteps    | 34000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.83e-28 |\n",
      "|    explained_variance | 0.975     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 1699      |\n",
      "|    policy_loss        | 263       |\n",
      "|    value_loss         | 4.63      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=35000, episode_reward=-37781.77 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -3.78e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 35000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0149   |\n",
      "|    explained_variance | 0.772     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 1749      |\n",
      "|    policy_loss        | -746      |\n",
      "|    value_loss         | 44.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.16e+03  |\n",
      "|    ep_rew_mean        | -1.11e+04 |\n",
      "| time/                 |           |\n",
      "|    fps                | 429       |\n",
      "|    iterations         | 1800      |\n",
      "|    time_elapsed       | 83        |\n",
      "|    total_timesteps    | 36000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00237  |\n",
      "|    explained_variance | 0.96      |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 1799      |\n",
      "|    policy_loss        | 121       |\n",
      "|    value_loss         | 8.49      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.17e+03  |\n",
      "|    ep_rew_mean        | -1.14e+04 |\n",
      "| time/                 |           |\n",
      "|    fps                | 446       |\n",
      "|    iterations         | 1900      |\n",
      "|    time_elapsed       | 85        |\n",
      "|    total_timesteps    | 38000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00953  |\n",
      "|    explained_variance | 0.896     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 1899      |\n",
      "|    policy_loss        | -187      |\n",
      "|    value_loss         | 10.5      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=-35756.77 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -3.58e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 40000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.01e-16 |\n",
      "|    explained_variance | 0.954     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 1999      |\n",
      "|    policy_loss        | -318      |\n",
      "|    value_loss         | 6.26      |\n",
      "-------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.18e+03  |\n",
      "|    ep_rew_mean     | -1.17e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 419       |\n",
      "|    iterations      | 2000      |\n",
      "|    time_elapsed    | 95        |\n",
      "|    total_timesteps | 40000     |\n",
      "----------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.19e+03  |\n",
      "|    ep_rew_mean        | -1.19e+04 |\n",
      "| time/                 |           |\n",
      "|    fps                | 435       |\n",
      "|    iterations         | 2100      |\n",
      "|    time_elapsed       | 96        |\n",
      "|    total_timesteps    | 42000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.73e-12 |\n",
      "|    explained_variance | 0.801     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 2099      |\n",
      "|    policy_loss        | -1.25e+03 |\n",
      "|    value_loss         | 53.3      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.19e+03  |\n",
      "|    ep_rew_mean        | -1.21e+04 |\n",
      "| time/                 |           |\n",
      "|    fps                | 450       |\n",
      "|    iterations         | 2200      |\n",
      "|    time_elapsed       | 97        |\n",
      "|    total_timesteps    | 44000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000172 |\n",
      "|    explained_variance | 0.368     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 2199      |\n",
      "|    policy_loss        | -561      |\n",
      "|    value_loss         | 86.3      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=45000, episode_reward=-35156.77 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -3.52e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 45000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000127 |\n",
      "|    explained_variance | 0.902     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 2249      |\n",
      "|    policy_loss        | -408      |\n",
      "|    value_loss         | 11.9      |\n",
      "-------------------------------------\n",
      "New best mean reward!\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.19e+03  |\n",
      "|    ep_rew_mean        | -1.21e+04 |\n",
      "| time/                 |           |\n",
      "|    fps                | 425       |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 108       |\n",
      "|    total_timesteps    | 46000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.72e-17 |\n",
      "|    explained_variance | 0.987     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | 26        |\n",
      "|    value_loss         | 1.81      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.2e+03   |\n",
      "|    ep_rew_mean        | -1.23e+04 |\n",
      "| time/                 |           |\n",
      "|    fps                | 439       |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 109       |\n",
      "|    total_timesteps    | 48000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.99e-06 |\n",
      "|    explained_variance | 0.961     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | -53.7     |\n",
      "|    value_loss         | 5.28      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=-34901.77 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -3.49e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 50000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.22e-05 |\n",
      "|    explained_variance | 0.968     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 2499      |\n",
      "|    policy_loss        | 202       |\n",
      "|    value_loss         | 4.89      |\n",
      "-------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.2e+03   |\n",
      "|    ep_rew_mean     | -1.25e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 420       |\n",
      "|    iterations      | 2500      |\n",
      "|    time_elapsed    | 118       |\n",
      "|    total_timesteps | 50000     |\n",
      "----------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.21e+03  |\n",
      "|    ep_rew_mean        | -1.27e+04 |\n",
      "| time/                 |           |\n",
      "|    fps                | 433       |\n",
      "|    iterations         | 2600      |\n",
      "|    time_elapsed       | 120       |\n",
      "|    total_timesteps    | 52000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.14e-17 |\n",
      "|    explained_variance | 0.982     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 2599      |\n",
      "|    policy_loss        | -681      |\n",
      "|    value_loss         | 5.48      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.21e+03  |\n",
      "|    ep_rew_mean        | -1.28e+04 |\n",
      "| time/                 |           |\n",
      "|    fps                | 445       |\n",
      "|    iterations         | 2700      |\n",
      "|    time_elapsed       | 121       |\n",
      "|    total_timesteps    | 54000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000135 |\n",
      "|    explained_variance | 0.91      |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 2699      |\n",
      "|    policy_loss        | 85.2      |\n",
      "|    value_loss         | 15.9      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=55000, episode_reward=-33581.77 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -3.36e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 55000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.188    |\n",
      "|    explained_variance | 0.963     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 2749      |\n",
      "|    policy_loss        | 498       |\n",
      "|    value_loss         | 4.71      |\n",
      "-------------------------------------\n",
      "New best mean reward!\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.21e+03  |\n",
      "|    ep_rew_mean        | -1.29e+04 |\n",
      "| time/                 |           |\n",
      "|    fps                | 425       |\n",
      "|    iterations         | 2800      |\n",
      "|    time_elapsed       | 131       |\n",
      "|    total_timesteps    | 56000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.28e-05 |\n",
      "|    explained_variance | 0.944     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 2799      |\n",
      "|    policy_loss        | 132       |\n",
      "|    value_loss         | 7.66      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.22e+03  |\n",
      "|    ep_rew_mean        | -1.31e+04 |\n",
      "| time/                 |           |\n",
      "|    fps                | 436       |\n",
      "|    iterations         | 2900      |\n",
      "|    time_elapsed       | 132       |\n",
      "|    total_timesteps    | 58000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.48e-37 |\n",
      "|    explained_variance | 0.437     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 2899      |\n",
      "|    policy_loss        | -1.56e+03 |\n",
      "|    value_loss         | 43.5      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=-34901.77 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -3.49e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 60000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.6e-08  |\n",
      "|    explained_variance | -2.46     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 2999      |\n",
      "|    policy_loss        | 1.01e+04  |\n",
      "|    value_loss         | 1.8e+03   |\n",
      "-------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.22e+03  |\n",
      "|    ep_rew_mean     | -1.32e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 419       |\n",
      "|    iterations      | 3000      |\n",
      "|    time_elapsed    | 143       |\n",
      "|    total_timesteps | 60000     |\n",
      "----------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.22e+03  |\n",
      "|    ep_rew_mean        | -1.32e+04 |\n",
      "| time/                 |           |\n",
      "|    fps                | 429       |\n",
      "|    iterations         | 3100      |\n",
      "|    time_elapsed       | 144       |\n",
      "|    total_timesteps    | 62000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000642 |\n",
      "|    explained_variance | 0.914     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 3099      |\n",
      "|    policy_loss        | -26.9     |\n",
      "|    value_loss         | 7.83      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.22e+03  |\n",
      "|    ep_rew_mean        | -1.33e+04 |\n",
      "| time/                 |           |\n",
      "|    fps                | 442       |\n",
      "|    iterations         | 3200      |\n",
      "|    time_elapsed       | 144       |\n",
      "|    total_timesteps    | 64000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.184    |\n",
      "|    explained_variance | 0.984     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 3199      |\n",
      "|    policy_loss        | 715       |\n",
      "|    value_loss         | 9.74      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=65000, episode_reward=-30186.15 +/- 0.04\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -3.02e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 65000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000319 |\n",
      "|    explained_variance | 0.761     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 3249      |\n",
      "|    policy_loss        | -556      |\n",
      "|    value_loss         | 26.4      |\n",
      "-------------------------------------\n",
      "New best mean reward!\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.23e+03  |\n",
      "|    ep_rew_mean        | -1.34e+04 |\n",
      "| time/                 |           |\n",
      "|    fps                | 425       |\n",
      "|    iterations         | 3300      |\n",
      "|    time_elapsed       | 155       |\n",
      "|    total_timesteps    | 66000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.53e-07 |\n",
      "|    explained_variance | 0.922     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 3299      |\n",
      "|    policy_loss        | -235      |\n",
      "|    value_loss         | 10.5      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.23e+03  |\n",
      "|    ep_rew_mean        | -1.34e+04 |\n",
      "| time/                 |           |\n",
      "|    fps                | 435       |\n",
      "|    iterations         | 3400      |\n",
      "|    time_elapsed       | 156       |\n",
      "|    total_timesteps    | 68000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0247   |\n",
      "|    explained_variance | 0.872     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 3399      |\n",
      "|    policy_loss        | 316       |\n",
      "|    value_loss         | 12.5      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=-36731.75 +/- 0.04\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -3.67e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 70000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.27e-34 |\n",
      "|    explained_variance | 0.981     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 3499      |\n",
      "|    policy_loss        | -1.13e+03 |\n",
      "|    value_loss         | 10.9      |\n",
      "-------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.23e+03  |\n",
      "|    ep_rew_mean     | -1.35e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 420       |\n",
      "|    iterations      | 3500      |\n",
      "|    time_elapsed    | 166       |\n",
      "|    total_timesteps | 70000     |\n",
      "----------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.23e+03  |\n",
      "|    ep_rew_mean        | -1.36e+04 |\n",
      "| time/                 |           |\n",
      "|    fps                | 429       |\n",
      "|    iterations         | 3600      |\n",
      "|    time_elapsed       | 167       |\n",
      "|    total_timesteps    | 72000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.03e-05 |\n",
      "|    explained_variance | 0.876     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 3599      |\n",
      "|    policy_loss        | -1.17e+03 |\n",
      "|    value_loss         | 28.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.24e+03  |\n",
      "|    ep_rew_mean        | -1.37e+04 |\n",
      "| time/                 |           |\n",
      "|    fps                | 438       |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 168       |\n",
      "|    total_timesteps    | 74000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.47e-05 |\n",
      "|    explained_variance | 0.783     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | -515      |\n",
      "|    value_loss         | 28.3      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=75000, episode_reward=-35411.77 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -3.54e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 75000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.7e-05  |\n",
      "|    explained_variance | 0.956     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 3749      |\n",
      "|    policy_loss        | 80.5      |\n",
      "|    value_loss         | 7.16      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.24e+03  |\n",
      "|    ep_rew_mean        | -1.37e+04 |\n",
      "| time/                 |           |\n",
      "|    fps                | 424       |\n",
      "|    iterations         | 3800      |\n",
      "|    time_elapsed       | 179       |\n",
      "|    total_timesteps    | 76000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.7e-11  |\n",
      "|    explained_variance | 0.98      |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 3799      |\n",
      "|    policy_loss        | -314      |\n",
      "|    value_loss         | 1.85      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.24e+03  |\n",
      "|    ep_rew_mean        | -1.37e+04 |\n",
      "| time/                 |           |\n",
      "|    fps                | 432       |\n",
      "|    iterations         | 3900      |\n",
      "|    time_elapsed       | 180       |\n",
      "|    total_timesteps    | 78000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0463   |\n",
      "|    explained_variance | 0.97      |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 3899      |\n",
      "|    policy_loss        | -655      |\n",
      "|    value_loss         | 5.16      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=-36746.77 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -3.67e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 80000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.017    |\n",
      "|    explained_variance | 0.972     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 3999      |\n",
      "|    policy_loss        | 227       |\n",
      "|    value_loss         | 3.7       |\n",
      "-------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.24e+03  |\n",
      "|    ep_rew_mean     | -1.38e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 420       |\n",
      "|    iterations      | 4000      |\n",
      "|    time_elapsed    | 190       |\n",
      "|    total_timesteps | 80000     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<MaskableA2C.MaskableA2C at 0x732360568460>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from environment3 import LifeStyleEnv\n",
    "from sb3_contrib.common.wrappers import ActionMasker\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "from MaskableA2C import MaskableA2C\n",
    "from stable_baselines3.common.torch_layers import CombinedExtractor\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def mask_fn(env: gym.Env) -> np.ndarray:\n",
    "    unwrapped_env = env\n",
    "    while hasattr(unwrapped_env, \"env\"):\n",
    "        unwrapped_env = unwrapped_env.env\n",
    "    return unwrapped_env.action_masks()\n",
    "\n",
    "def make_env():\n",
    "    env = LifeStyleEnv()\n",
    "    env = Monitor(env)\n",
    "    check_env(env, warn=True) \n",
    "    return env \n",
    "\n",
    "env = make_env()\n",
    "env = ActionMasker(env, mask_fn)\n",
    "\n",
    "eval_env = make_env()\n",
    "eval_env = ActionMasker(eval_env, mask_fn)\n",
    "\n",
    "eval_callback = EvalCallback(\n",
    "    eval_env,\n",
    "    best_model_save_path=\"./logs/a2c/a2c_best_model_test2\",\n",
    "    log_path=\"./logs/a2c/a2c_results_test2\",\n",
    "    eval_freq=5000,\n",
    "    n_eval_episodes=10,\n",
    "    deterministic=True,\n",
    "    render=False\n",
    ")\n",
    "\n",
    "model = MaskableA2C(\n",
    "    \"MultiInputPolicy\",  \n",
    "    env,\n",
    "    learning_rate=0.001,\n",
    "    n_steps=20,           \n",
    "    gamma=0.95,\n",
    "    gae_lambda=0.95,\n",
    "    vf_coef=0.5,\n",
    "    max_grad_norm=0.5,\n",
    "    verbose=1,\n",
    "    device=device,\n",
    "    policy_kwargs=dict(\n",
    "        features_extractor_class=CombinedExtractor,  \n",
    "        features_extractor_kwargs={},                \n",
    "        net_arch=[256, 256]\n",
    "    ),\n",
    "    tensorboard_log=\"./logs/a2c/a2c_tensorboard_test2/\"\n",
    ")\n",
    "\n",
    "model.learn(total_timesteps=80000, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60a1e76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of logs/a2c/a2c_results_test1/evaluations.npz: ['timesteps', 'results', 'ep_lengths']\n",
      "Mean reward for LR = 0.0005: -21171.98\n",
      "Contents of logs/a2c/a2c_results_test2/evaluations.npz: ['timesteps', 'results', 'ep_lengths']\n",
      "Mean reward for LR = 0.001: -35899.11\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Two file paths for comparison\n",
    "file_paths = [\n",
    "    'logs/a2c/a2c_results_test1/evaluations.npz',\n",
    "    'logs/a2c/a2c_results_test2/evaluations.npz'\n",
    "]\n",
    "\n",
    "labels = ['LR = 0.0005', 'LR = 0.001']  # Labels for the legend\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for file_path, label in zip(file_paths, labels):\n",
    "    try:\n",
    "        data = np.load(file_path)\n",
    "        print(f\"Contents of {file_path}: {data.files}\")\n",
    "        \n",
    "        timesteps = data['timesteps']\n",
    "        results = data['results']\n",
    "\n",
    "        mean_reward = np.mean(results)\n",
    "        print(f\"Mean reward for {label}: {mean_reward:.2f}\")\n",
    "        \n",
    "        # results might be a 2D array (num_eval, num_envs), take mean if needed\n",
    "        if results.ndim > 1:\n",
    "            results = results.mean(axis=1)\n",
    "\n",
    "        plt.plot(timesteps, results, label=label)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{file_path}' was not found.\")\n",
    "    except KeyError as e:\n",
    "        print(f\"Error: The key {e} was not found in the NPZ file. Check the contents using data.files.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred with {file_path}: {e}\")\n",
    "\n",
    "plt.title('A2C Performance Comparison')\n",
    "plt.xlabel('Total Timesteps')\n",
    "plt.ylabel('Mean Reward')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f541d7",
   "metadata": {},
   "source": [
    "## Test With Different Value Function Coeffecient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "029c7396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Using cpu device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./logs/a2c/a2c_tensorboard_test3/A2C_1\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 936      |\n",
      "|    ep_rew_mean        | 6.03e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 1558     |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.03    |\n",
      "|    explained_variance | 0.000311 |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 5.05     |\n",
      "|    value_loss         | 96.6     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 531       |\n",
      "|    ep_rew_mean        | 926       |\n",
      "| time/                 |           |\n",
      "|    fps                | 1579      |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 2         |\n",
      "|    total_timesteps    | 4000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.67e-12 |\n",
      "|    explained_variance | 0.0297    |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 199       |\n",
      "|    policy_loss        | -2.94e+03 |\n",
      "|    value_loss         | 3.41e+03  |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=5000, episode_reward=-4179.59 +/- 0.00\n",
      "Episode length: 168.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 168       |\n",
      "|    mean_reward        | -4.18e+03 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.27e-11 |\n",
      "|    explained_variance | 0.0627    |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 249       |\n",
      "|    policy_loss        | -2.46e+03 |\n",
      "|    value_loss         | 1.78e+03  |\n",
      "-------------------------------------\n",
      "New best mean reward!\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 452       |\n",
      "|    ep_rew_mean        | -449      |\n",
      "| time/                 |           |\n",
      "|    fps                | 1327      |\n",
      "|    iterations         | 300       |\n",
      "|    time_elapsed       | 4         |\n",
      "|    total_timesteps    | 6000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.79e-09 |\n",
      "|    explained_variance | 0.176     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 299       |\n",
      "|    policy_loss        | -508      |\n",
      "|    value_loss         | 320       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 427       |\n",
      "|    ep_rew_mean        | -895      |\n",
      "| time/                 |           |\n",
      "|    fps                | 1370      |\n",
      "|    iterations         | 400       |\n",
      "|    time_elapsed       | 5         |\n",
      "|    total_timesteps    | 8000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.81e-14 |\n",
      "|    explained_variance | 0.105     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 399       |\n",
      "|    policy_loss        | -5.15e+03 |\n",
      "|    value_loss         | 3e+03     |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=-4179.59 +/- 0.00\n",
      "Episode length: 168.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 168       |\n",
      "|    mean_reward        | -4.18e+03 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 10000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.36e-10 |\n",
      "|    explained_variance | 0.464     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | -2.67e+03 |\n",
      "|    value_loss         | 540       |\n",
      "-------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 410       |\n",
      "|    ep_rew_mean     | -1.18e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 1277      |\n",
      "|    iterations      | 500       |\n",
      "|    time_elapsed    | 7         |\n",
      "|    total_timesteps | 10000     |\n",
      "----------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 400       |\n",
      "|    ep_rew_mean        | -1.36e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 1316      |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 9         |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.4e-24  |\n",
      "|    explained_variance | -0.205    |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | -6.82e+03 |\n",
      "|    value_loss         | 2.34e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 394       |\n",
      "|    ep_rew_mean        | -1.46e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 1349      |\n",
      "|    iterations         | 700       |\n",
      "|    time_elapsed       | 10        |\n",
      "|    total_timesteps    | 14000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.25e-24 |\n",
      "|    explained_variance | 0.431     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 699       |\n",
      "|    policy_loss        | -3.61e+03 |\n",
      "|    value_loss         | 682       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=15000, episode_reward=-4179.59 +/- 0.00\n",
      "Episode length: 168.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 168       |\n",
      "|    mean_reward        | -4.18e+03 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 15000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.79e-05 |\n",
      "|    explained_variance | 0.478     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 749       |\n",
      "|    policy_loss        | 45.9      |\n",
      "|    value_loss         | 357       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 389       |\n",
      "|    ep_rew_mean        | -1.54e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 1302      |\n",
      "|    iterations         | 800       |\n",
      "|    time_elapsed       | 12        |\n",
      "|    total_timesteps    | 16000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.59e-05 |\n",
      "|    explained_variance | -1.11     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 799       |\n",
      "|    policy_loss        | 1.04e+04  |\n",
      "|    value_loss         | 3.96e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 386       |\n",
      "|    ep_rew_mean        | -1.6e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 1332      |\n",
      "|    iterations         | 900       |\n",
      "|    time_elapsed       | 13        |\n",
      "|    total_timesteps    | 18000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.58e-28 |\n",
      "|    explained_variance | 0.648     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 899       |\n",
      "|    policy_loss        | -4.89e+03 |\n",
      "|    value_loss         | 630       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=-4179.59 +/- 0.00\n",
      "Episode length: 168.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 168       |\n",
      "|    mean_reward        | -4.18e+03 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 20000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.33e-05 |\n",
      "|    explained_variance | 0.186     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | 6.62e+03  |\n",
      "|    value_loss         | 1.96e+03  |\n",
      "-------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 383       |\n",
      "|    ep_rew_mean     | -1.65e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 1298      |\n",
      "|    iterations      | 1000      |\n",
      "|    time_elapsed    | 15        |\n",
      "|    total_timesteps | 20000     |\n",
      "----------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 381       |\n",
      "|    ep_rew_mean        | -1.69e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 1321      |\n",
      "|    iterations         | 1100      |\n",
      "|    time_elapsed       | 16        |\n",
      "|    total_timesteps    | 22000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.28e-29 |\n",
      "|    explained_variance | 0.581     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 1099      |\n",
      "|    policy_loss        | -6.3e+03  |\n",
      "|    value_loss         | 812       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 379       |\n",
      "|    ep_rew_mean        | -1.72e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 1339      |\n",
      "|    iterations         | 1200      |\n",
      "|    time_elapsed       | 17        |\n",
      "|    total_timesteps    | 24000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00182  |\n",
      "|    explained_variance | 0.581     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 1199      |\n",
      "|    policy_loss        | 849       |\n",
      "|    value_loss         | 416       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=25000, episode_reward=-4179.59 +/- 0.00\n",
      "Episode length: 168.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 168       |\n",
      "|    mean_reward        | -4.18e+03 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 25000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00684  |\n",
      "|    explained_variance | -1.53     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 1249      |\n",
      "|    policy_loss        | 1.61e+04  |\n",
      "|    value_loss         | 5.1e+03   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 378       |\n",
      "|    ep_rew_mean        | -1.75e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 1313      |\n",
      "|    iterations         | 1300      |\n",
      "|    time_elapsed       | 19        |\n",
      "|    total_timesteps    | 26000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.49e-28 |\n",
      "|    explained_variance | 0.418     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 1299      |\n",
      "|    policy_loss        | -7.31e+03 |\n",
      "|    value_loss         | 1.18e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 376       |\n",
      "|    ep_rew_mean        | -1.77e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 1333      |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 20        |\n",
      "|    total_timesteps    | 28000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.89e-24 |\n",
      "|    explained_variance | 0.735     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | -1e+03    |\n",
      "|    value_loss         | 115       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=-4179.59 +/- 0.00\n",
      "Episode length: 168.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 168       |\n",
      "|    mean_reward        | -4.18e+03 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 30000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.51e-24 |\n",
      "|    explained_variance | 0.275     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | -1.03e+04 |\n",
      "|    value_loss         | 1.62e+03  |\n",
      "-------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 375       |\n",
      "|    ep_rew_mean     | -1.79e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 1311      |\n",
      "|    iterations      | 1500      |\n",
      "|    time_elapsed    | 22        |\n",
      "|    total_timesteps | 30000     |\n",
      "----------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 374       |\n",
      "|    ep_rew_mean        | -1.81e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 1328      |\n",
      "|    iterations         | 1600      |\n",
      "|    time_elapsed       | 24        |\n",
      "|    total_timesteps    | 32000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.61e-19 |\n",
      "|    explained_variance | 0.741     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 1599      |\n",
      "|    policy_loss        | -2.1e+03  |\n",
      "|    value_loss         | 158       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 373       |\n",
      "|    ep_rew_mean        | -1.83e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 1344      |\n",
      "|    iterations         | 1700      |\n",
      "|    time_elapsed       | 25        |\n",
      "|    total_timesteps    | 34000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0347   |\n",
      "|    explained_variance | -0.534    |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 1699      |\n",
      "|    policy_loss        | 2.23e+04  |\n",
      "|    value_loss         | 7.4e+03   |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=35000, episode_reward=-4761.74 +/- 0.01\n",
      "Episode length: 240.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 240       |\n",
      "|    mean_reward        | -4.76e+03 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 35000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.68e-19 |\n",
      "|    explained_variance | 0.518     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 1749      |\n",
      "|    policy_loss        | -7.06e+03 |\n",
      "|    value_loss         | 828       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 372       |\n",
      "|    ep_rew_mean        | -1.84e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 1402      |\n",
      "|    iterations         | 1800      |\n",
      "|    time_elapsed       | 25        |\n",
      "|    total_timesteps    | 36000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.07e-17 |\n",
      "|    explained_variance | 0.822     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 1799      |\n",
      "|    policy_loss        | -5.35e+03 |\n",
      "|    value_loss         | 352       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 360       |\n",
      "|    ep_rew_mean        | -2.01e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 1411      |\n",
      "|    iterations         | 1900      |\n",
      "|    time_elapsed       | 26        |\n",
      "|    total_timesteps    | 38000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0188   |\n",
      "|    explained_variance | 0.0356    |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 1899      |\n",
      "|    policy_loss        | 9.13e+03  |\n",
      "|    value_loss         | 1.53e+03  |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=-4761.73 +/- 0.00\n",
      "Episode length: 240.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 240       |\n",
      "|    mean_reward        | -4.76e+03 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 40000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.64e-15 |\n",
      "|    explained_variance | 0.783     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 1999      |\n",
      "|    policy_loss        | -5.77e+03 |\n",
      "|    value_loss         | 402       |\n",
      "-------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 360       |\n",
      "|    ep_rew_mean     | -2.06e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 1375      |\n",
      "|    iterations      | 2000      |\n",
      "|    time_elapsed    | 29        |\n",
      "|    total_timesteps | 40000     |\n",
      "----------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 360       |\n",
      "|    ep_rew_mean        | -2.06e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 1386      |\n",
      "|    iterations         | 2100      |\n",
      "|    time_elapsed       | 30        |\n",
      "|    total_timesteps    | 42000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000557 |\n",
      "|    explained_variance | 0.688     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 2099      |\n",
      "|    policy_loss        | 5.73e+03  |\n",
      "|    value_loss         | 707       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 360       |\n",
      "|    ep_rew_mean        | -2.06e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 1396      |\n",
      "|    iterations         | 2200      |\n",
      "|    time_elapsed       | 31        |\n",
      "|    total_timesteps    | 44000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.24e-13 |\n",
      "|    explained_variance | 0.612     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 2199      |\n",
      "|    policy_loss        | -6.11e+03 |\n",
      "|    value_loss         | 568       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=45000, episode_reward=-4761.73 +/- 0.00\n",
      "Episode length: 240.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 240       |\n",
      "|    mean_reward        | -4.76e+03 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 45000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.71e-12 |\n",
      "|    explained_variance | 0.835     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 2249      |\n",
      "|    policy_loss        | -4.1e+03  |\n",
      "|    value_loss         | 192       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 360       |\n",
      "|    ep_rew_mean        | -2.06e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 1366      |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 33        |\n",
      "|    total_timesteps    | 46000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.5e-12  |\n",
      "|    explained_variance | 0.907     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | 783       |\n",
      "|    value_loss         | 51.7      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 360       |\n",
      "|    ep_rew_mean        | -2.07e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 1376      |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 34        |\n",
      "|    total_timesteps    | 48000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.34e-11 |\n",
      "|    explained_variance | 0.558     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | -1.12e+04 |\n",
      "|    value_loss         | 1.3e+03   |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=-4761.73 +/- 0.00\n",
      "Episode length: 240.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 240       |\n",
      "|    mean_reward        | -4.76e+03 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 50000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.12e-10 |\n",
      "|    explained_variance | 0.845     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 2499      |\n",
      "|    policy_loss        | -429      |\n",
      "|    value_loss         | 74.4      |\n",
      "-------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 360       |\n",
      "|    ep_rew_mean     | -2.07e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 1350      |\n",
      "|    iterations      | 2500      |\n",
      "|    time_elapsed    | 37        |\n",
      "|    total_timesteps | 50000     |\n",
      "----------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 360       |\n",
      "|    ep_rew_mean        | -2.07e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 1360      |\n",
      "|    iterations         | 2600      |\n",
      "|    time_elapsed       | 38        |\n",
      "|    total_timesteps    | 52000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000178 |\n",
      "|    explained_variance | -0.379    |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 2599      |\n",
      "|    policy_loss        | 2.86e+04  |\n",
      "|    value_loss         | 7.79e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 360       |\n",
      "|    ep_rew_mean        | -2.07e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 1371      |\n",
      "|    iterations         | 2700      |\n",
      "|    time_elapsed       | 39        |\n",
      "|    total_timesteps    | 54000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.02e-06 |\n",
      "|    explained_variance | 0.874     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 2699      |\n",
      "|    policy_loss        | -3.71e+03 |\n",
      "|    value_loss         | 131       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=55000, episode_reward=-4761.73 +/- 0.00\n",
      "Episode length: 240.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 240       |\n",
      "|    mean_reward        | -4.76e+03 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 55000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.89e-06 |\n",
      "|    explained_variance | 0.89      |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 2749      |\n",
      "|    policy_loss        | 971       |\n",
      "|    value_loss         | 58.7      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 360       |\n",
      "|    ep_rew_mean        | -2.07e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 1347      |\n",
      "|    iterations         | 2800      |\n",
      "|    time_elapsed       | 41        |\n",
      "|    total_timesteps    | 56000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.09e-05 |\n",
      "|    explained_variance | -0.562    |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 2799      |\n",
      "|    policy_loss        | 1.18e+04  |\n",
      "|    value_loss         | 1.97e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 360       |\n",
      "|    ep_rew_mean        | -2.07e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 1356      |\n",
      "|    iterations         | 2900      |\n",
      "|    time_elapsed       | 42        |\n",
      "|    total_timesteps    | 58000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000727 |\n",
      "|    explained_variance | 0.842     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 2899      |\n",
      "|    policy_loss        | -4.93e+03 |\n",
      "|    value_loss         | 224       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=-4761.73 +/- 0.00\n",
      "Episode length: 240.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 240       |\n",
      "|    mean_reward        | -4.76e+03 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 60000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00852  |\n",
      "|    explained_variance | 0.73      |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 2999      |\n",
      "|    policy_loss        | 7.95e+03  |\n",
      "|    value_loss         | 851       |\n",
      "-------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 360       |\n",
      "|    ep_rew_mean     | -2.08e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 1334      |\n",
      "|    iterations      | 3000      |\n",
      "|    time_elapsed    | 44        |\n",
      "|    total_timesteps | 60000     |\n",
      "----------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 360       |\n",
      "|    ep_rew_mean        | -2.07e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 1342      |\n",
      "|    iterations         | 3100      |\n",
      "|    time_elapsed       | 46        |\n",
      "|    total_timesteps    | 62000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00318  |\n",
      "|    explained_variance | 0.632     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 3099      |\n",
      "|    policy_loss        | -4.97e+03 |\n",
      "|    value_loss         | 451       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 360       |\n",
      "|    ep_rew_mean        | -2.07e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 1350      |\n",
      "|    iterations         | 3200      |\n",
      "|    time_elapsed       | 47        |\n",
      "|    total_timesteps    | 64000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00205  |\n",
      "|    explained_variance | 0.891     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 3199      |\n",
      "|    policy_loss        | 1.84e+03  |\n",
      "|    value_loss         | 80.3      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=65000, episode_reward=-4761.73 +/- 0.00\n",
      "Episode length: 240.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 240       |\n",
      "|    mean_reward        | -4.76e+03 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 65000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000875 |\n",
      "|    explained_variance | -0.731    |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 3249      |\n",
      "|    policy_loss        | 1.15e+04  |\n",
      "|    value_loss         | 2.16e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 360       |\n",
      "|    ep_rew_mean        | -2.07e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 1330      |\n",
      "|    iterations         | 3300      |\n",
      "|    time_elapsed       | 49        |\n",
      "|    total_timesteps    | 66000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.492    |\n",
      "|    explained_variance | -2.42     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 3299      |\n",
      "|    policy_loss        | -4.52e+03 |\n",
      "|    value_loss         | 718       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 368       |\n",
      "|    ep_rew_mean        | -2.05e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 1336      |\n",
      "|    iterations         | 3400      |\n",
      "|    time_elapsed       | 50        |\n",
      "|    total_timesteps    | 68000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.255    |\n",
      "|    explained_variance | 0.52      |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 3399      |\n",
      "|    policy_loss        | -9.11e+03 |\n",
      "|    value_loss         | 1.91e+03  |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=-4761.73 +/- 0.00\n",
      "Episode length: 240.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 240       |\n",
      "|    mean_reward        | -4.76e+03 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 70000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.362    |\n",
      "|    explained_variance | 0.174     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 3499      |\n",
      "|    policy_loss        | -2.86e+03 |\n",
      "|    value_loss         | 284       |\n",
      "-------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 374       |\n",
      "|    ep_rew_mean     | -1.99e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 1318      |\n",
      "|    iterations      | 3500      |\n",
      "|    time_elapsed    | 53        |\n",
      "|    total_timesteps | 70000     |\n",
      "----------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 378       |\n",
      "|    ep_rew_mean        | -1.97e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 1323      |\n",
      "|    iterations         | 3600      |\n",
      "|    time_elapsed       | 54        |\n",
      "|    total_timesteps    | 72000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.54e-11 |\n",
      "|    explained_variance | 0.689     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 3599      |\n",
      "|    policy_loss        | -2.27e+03 |\n",
      "|    value_loss         | 131       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 378       |\n",
      "|    ep_rew_mean        | -1.97e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 1330      |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 55        |\n",
      "|    total_timesteps    | 74000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0933   |\n",
      "|    explained_variance | -0.702    |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | 3.74e+04  |\n",
      "|    value_loss         | 1.6e+04   |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=75000, episode_reward=-4487.65 +/- 0.00\n",
      "Episode length: 240.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 240       |\n",
      "|    mean_reward        | -4.49e+03 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 75000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.18e-13 |\n",
      "|    explained_variance | 0.57      |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 3749      |\n",
      "|    policy_loss        | -1.14e+04 |\n",
      "|    value_loss         | 1.02e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 378       |\n",
      "|    ep_rew_mean        | -1.97e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 1360      |\n",
      "|    iterations         | 3800      |\n",
      "|    time_elapsed       | 55        |\n",
      "|    total_timesteps    | 76000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.09e-13 |\n",
      "|    explained_variance | 0.889     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 3799      |\n",
      "|    policy_loss        | -2.83e+03 |\n",
      "|    value_loss         | 97.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 378       |\n",
      "|    ep_rew_mean        | -1.97e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 1366      |\n",
      "|    iterations         | 3900      |\n",
      "|    time_elapsed       | 57        |\n",
      "|    total_timesteps    | 78000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0133   |\n",
      "|    explained_variance | -0.0494   |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 3899      |\n",
      "|    policy_loss        | 2.27e+04  |\n",
      "|    value_loss         | 4.79e+03  |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=-4487.65 +/- 0.00\n",
      "Episode length: 240.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 240       |\n",
      "|    mean_reward        | -4.49e+03 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 80000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.21e-17 |\n",
      "|    explained_variance | 0.696     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 3999      |\n",
      "|    policy_loss        | -2.21e+03 |\n",
      "|    value_loss         | 200       |\n",
      "-------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 378       |\n",
      "|    ep_rew_mean     | -1.96e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 1349      |\n",
      "|    iterations      | 4000      |\n",
      "|    time_elapsed    | 59        |\n",
      "|    total_timesteps | 80000     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<MaskableA2C.MaskableA2C at 0x7243683736d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from environment3 import LifeStyleEnv\n",
    "from sb3_contrib.common.wrappers import ActionMasker\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "from MaskableA2C import MaskableA2C\n",
    "from stable_baselines3.common.torch_layers import CombinedExtractor\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def mask_fn(env: gym.Env) -> np.ndarray:\n",
    "    unwrapped_env = env\n",
    "    while hasattr(unwrapped_env, \"env\"):\n",
    "        unwrapped_env = unwrapped_env.env\n",
    "    return unwrapped_env.action_masks()\n",
    "\n",
    "def make_env():\n",
    "    env = LifeStyleEnv()\n",
    "    env = Monitor(env)\n",
    "    check_env(env, warn=True) \n",
    "    return env \n",
    "\n",
    "env = make_env()\n",
    "env = ActionMasker(env, mask_fn)\n",
    "\n",
    "eval_env = make_env()\n",
    "eval_env = ActionMasker(eval_env, mask_fn)\n",
    "\n",
    "eval_callback = EvalCallback(\n",
    "    eval_env,\n",
    "    best_model_save_path=\"./logs/a2c/a2c_best_model_test3\",\n",
    "    log_path=\"./logs/a2c/a2c_results_test3\",\n",
    "    eval_freq=5000,\n",
    "    n_eval_episodes=10,\n",
    "    deterministic=True,\n",
    "    render=False\n",
    ")\n",
    "\n",
    "model = MaskableA2C(\n",
    "    \"MultiInputPolicy\",  \n",
    "    env,\n",
    "    learning_rate=0.001,\n",
    "    n_steps=20,           \n",
    "    gamma=0.95,\n",
    "    gae_lambda=0.95,\n",
    "    vf_coef=0.5,\n",
    "    max_grad_norm=0.5,\n",
    "    verbose=1,\n",
    "    device=device,\n",
    "    policy_kwargs=dict(\n",
    "        features_extractor_class=CombinedExtractor,  \n",
    "        features_extractor_kwargs={},                \n",
    "        net_arch=[256, 256]\n",
    "    ),\n",
    "    tensorboard_log=\"./logs/a2c/a2c_tensorboard_test3/\"\n",
    ")\n",
    "\n",
    "model.learn(total_timesteps=80000, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53d234ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Using cpu device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./logs/a2c/a2c_tensorboard_test4/A2C_1\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 480      |\n",
      "|    ep_rew_mean        | 876      |\n",
      "| time/                 |          |\n",
      "|    fps                | 1552     |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.949   |\n",
      "|    explained_variance | -0.00681 |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 37.4     |\n",
      "|    value_loss         | 1.72e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 936       |\n",
      "|    ep_rew_mean        | 5.38e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 1549      |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 2         |\n",
      "|    total_timesteps    | 4000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.725    |\n",
      "|    explained_variance | -0.000462 |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 199       |\n",
      "|    policy_loss        | 13.8      |\n",
      "|    value_loss         | 970       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=5000, episode_reward=-13654.25 +/- 0.23\n",
      "Episode length: 1680.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1.68e+03  |\n",
      "|    mean_reward        | -1.37e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.698    |\n",
      "|    explained_variance | 1.05e-05  |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 249       |\n",
      "|    policy_loss        | 26.5      |\n",
      "|    value_loss         | 1.41e+03  |\n",
      "-------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 936      |\n",
      "|    ep_rew_mean        | 5.38e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 543      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.647   |\n",
      "|    explained_variance | 0.000171 |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 13.1     |\n",
      "|    value_loss         | 754      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1.21e+03 |\n",
      "|    ep_rew_mean        | 8.76e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 646      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.441   |\n",
      "|    explained_variance | 7.36e-05 |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 17.2     |\n",
      "|    value_loss         | 625      |\n",
      "------------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=-12108.99 +/- 0.00\n",
      "Episode length: 600.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 600       |\n",
      "|    mean_reward        | -1.21e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 10000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.417    |\n",
      "|    explained_variance | -5.78e-05 |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | 10        |\n",
      "|    value_loss         | 1.21e+03  |\n",
      "-------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.43e+03 |\n",
      "|    ep_rew_mean     | 1.22e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 618      |\n",
      "|    iterations      | 500      |\n",
      "|    time_elapsed    | 16       |\n",
      "|    total_timesteps | 10000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1.27e+03 |\n",
      "|    ep_rew_mean        | 1.15e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 689      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.364   |\n",
      "|    explained_variance | 8.75e-05 |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 36       |\n",
      "|    value_loss         | 938      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1.23e+03 |\n",
      "|    ep_rew_mean        | 1.15e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 750      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.584   |\n",
      "|    explained_variance | 6.55e-05 |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 13       |\n",
      "|    value_loss         | 529      |\n",
      "------------------------------------\n",
      "Eval num_timesteps=15000, episode_reward=-18419.11 +/- 0.00\n",
      "Episode length: 1128.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1.13e+03  |\n",
      "|    mean_reward        | -1.84e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 15000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.771    |\n",
      "|    explained_variance | 0.000108  |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 749       |\n",
      "|    policy_loss        | 12.8      |\n",
      "|    value_loss         | 240       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.21e+03  |\n",
      "|    ep_rew_mean        | 1.15e+04  |\n",
      "| time/                 |           |\n",
      "|    fps                | 647       |\n",
      "|    iterations         | 800       |\n",
      "|    time_elapsed       | 24        |\n",
      "|    total_timesteps    | 16000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.487    |\n",
      "|    explained_variance | -1.18e-05 |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 799       |\n",
      "|    policy_loss        | 20.6      |\n",
      "|    value_loss         | 101       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.21e+03  |\n",
      "|    ep_rew_mean        | 1.15e+04  |\n",
      "| time/                 |           |\n",
      "|    fps                | 692       |\n",
      "|    iterations         | 900       |\n",
      "|    time_elapsed       | 25        |\n",
      "|    total_timesteps    | 18000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.56e-11 |\n",
      "|    explained_variance | 0.417     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 899       |\n",
      "|    policy_loss        | -280      |\n",
      "|    value_loss         | 175       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=-37166.71 +/- 0.15\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -3.72e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 20000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.109    |\n",
      "|    explained_variance | 0.877     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | -15.4     |\n",
      "|    value_loss         | 11        |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.29e+03 |\n",
      "|    ep_rew_mean     | 1.08e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 566      |\n",
      "|    iterations      | 1000     |\n",
      "|    time_elapsed    | 35       |\n",
      "|    total_timesteps | 20000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1.36e+03 |\n",
      "|    ep_rew_mean        | 9e+03    |\n",
      "| time/                 |          |\n",
      "|    fps                | 601      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.329   |\n",
      "|    explained_variance | -1.32    |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 274      |\n",
      "|    value_loss         | 79.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1.42e+03 |\n",
      "|    ep_rew_mean        | 9.07e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 634      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0989  |\n",
      "|    explained_variance | -0.896   |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 1.86e+03 |\n",
      "|    value_loss         | 7.86e+03 |\n",
      "------------------------------------\n",
      "Eval num_timesteps=25000, episode_reward=-48847.94 +/- 0.65\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -4.88e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 25000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00951  |\n",
      "|    explained_variance | -0.491    |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 1249      |\n",
      "|    policy_loss        | 346       |\n",
      "|    value_loss         | 592       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1.47e+03 |\n",
      "|    ep_rew_mean        | 8.23e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 530      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 48       |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0153  |\n",
      "|    explained_variance | 0.862    |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -526     |\n",
      "|    value_loss         | 91.9     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.51e+03  |\n",
      "|    ep_rew_mean        | 8.25e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 557       |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 50        |\n",
      "|    total_timesteps    | 28000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.36e-17 |\n",
      "|    explained_variance | -0.781    |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | -1.84e+03 |\n",
      "|    value_loss         | 967       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=-34666.95 +/- 0.21\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -3.47e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 30000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.851    |\n",
      "|    explained_variance | 0.336     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | -387      |\n",
      "|    value_loss         | 227       |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.56e+03 |\n",
      "|    ep_rew_mean     | 7.35e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 502      |\n",
      "|    iterations      | 1500     |\n",
      "|    time_elapsed    | 59       |\n",
      "|    total_timesteps | 30000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1.59e+03 |\n",
      "|    ep_rew_mean        | 6.88e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 524      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 61       |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.081   |\n",
      "|    explained_variance | -1.27    |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | -446     |\n",
      "|    value_loss         | 616      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1.59e+03 |\n",
      "|    ep_rew_mean        | 6.88e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 545      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 62       |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.338   |\n",
      "|    explained_variance | 0.512    |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -231     |\n",
      "|    value_loss         | 1.31e+03 |\n",
      "------------------------------------\n",
      "Eval num_timesteps=35000, episode_reward=-8104.58 +/- 0.12\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 2.3e+03  |\n",
      "|    mean_reward        | -8.1e+03 |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 35000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0699  |\n",
      "|    explained_variance | 0.0731   |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 1749     |\n",
      "|    policy_loss        | 98.8     |\n",
      "|    value_loss         | 89.2     |\n",
      "------------------------------------\n",
      "New best mean reward!\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.63e+03  |\n",
      "|    ep_rew_mean        | 6.45e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 489       |\n",
      "|    iterations         | 1800      |\n",
      "|    time_elapsed       | 73        |\n",
      "|    total_timesteps    | 36000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.21e-25 |\n",
      "|    explained_variance | 0.737     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 1799      |\n",
      "|    policy_loss        | -439      |\n",
      "|    value_loss         | 65.8      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1.66e+03 |\n",
      "|    ep_rew_mean        | 6.18e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 508      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 74       |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.262   |\n",
      "|    explained_variance | -0.874   |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 748      |\n",
      "|    value_loss         | 1.09e+03 |\n",
      "------------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=-37781.74 +/- 0.08\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -3.78e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 40000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.2e-16  |\n",
      "|    explained_variance | 0.621     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 1999      |\n",
      "|    policy_loss        | -402      |\n",
      "|    value_loss         | 95.2      |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.69e+03 |\n",
      "|    ep_rew_mean     | 6.02e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 465      |\n",
      "|    iterations      | 2000     |\n",
      "|    time_elapsed    | 85       |\n",
      "|    total_timesteps | 40000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1.71e+03 |\n",
      "|    ep_rew_mean        | 5.79e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 481      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.396   |\n",
      "|    explained_variance | 0.446    |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -43.4    |\n",
      "|    value_loss         | 106      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1.74e+03 |\n",
      "|    ep_rew_mean        | 5.56e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 497      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 88       |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0783  |\n",
      "|    explained_variance | -0.609   |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 435      |\n",
      "|    value_loss         | 246      |\n",
      "------------------------------------\n",
      "Eval num_timesteps=45000, episode_reward=-44995.56 +/- 0.70\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 2.3e+03  |\n",
      "|    mean_reward        | -4.5e+04 |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 45000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.605   |\n",
      "|    explained_variance | -0.0674  |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 2249     |\n",
      "|    policy_loss        | 647      |\n",
      "|    value_loss         | 8.16e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.76e+03  |\n",
      "|    ep_rew_mean        | 5.55e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 470       |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 97        |\n",
      "|    total_timesteps    | 46000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0244   |\n",
      "|    explained_variance | -0.319    |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | -1.27e+03 |\n",
      "|    value_loss         | 429       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.78e+03  |\n",
      "|    ep_rew_mean        | 5.65e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 484       |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 98        |\n",
      "|    total_timesteps    | 48000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.61e-37 |\n",
      "|    explained_variance | 0.607     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | -470      |\n",
      "|    value_loss         | 84.2      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=-36750.64 +/- 0.19\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -3.68e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 50000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00395  |\n",
      "|    explained_variance | 0.717     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 2499      |\n",
      "|    policy_loss        | 116       |\n",
      "|    value_loss         | 42.9      |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.78e+03 |\n",
      "|    ep_rew_mean     | 5.65e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 454      |\n",
      "|    iterations      | 2500     |\n",
      "|    time_elapsed    | 110      |\n",
      "|    total_timesteps | 50000    |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.8e+03   |\n",
      "|    ep_rew_mean        | 4.87e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 466       |\n",
      "|    iterations         | 2600      |\n",
      "|    time_elapsed       | 111       |\n",
      "|    total_timesteps    | 52000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.38e-39 |\n",
      "|    explained_variance | 0.884     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 2599      |\n",
      "|    policy_loss        | -138      |\n",
      "|    value_loss         | 15.5      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.81e+03  |\n",
      "|    ep_rew_mean        | 4.58e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 479       |\n",
      "|    iterations         | 2700      |\n",
      "|    time_elapsed       | 112       |\n",
      "|    total_timesteps    | 54000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.132    |\n",
      "|    explained_variance | 0.197     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 2699      |\n",
      "|    policy_loss        | -1.17e+03 |\n",
      "|    value_loss         | 249       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=55000, episode_reward=-36254.11 +/- 0.01\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -3.63e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 55000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0595   |\n",
      "|    explained_variance | 0.125     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 2749      |\n",
      "|    policy_loss        | -539      |\n",
      "|    value_loss         | 160       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.83e+03  |\n",
      "|    ep_rew_mean        | 4.61e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 459       |\n",
      "|    iterations         | 2800      |\n",
      "|    time_elapsed       | 121       |\n",
      "|    total_timesteps    | 56000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.48e-28 |\n",
      "|    explained_variance | -0.664    |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 2799      |\n",
      "|    policy_loss        | -372      |\n",
      "|    value_loss         | 217       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.85e+03  |\n",
      "|    ep_rew_mean        | 4.23e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 471       |\n",
      "|    iterations         | 2900      |\n",
      "|    time_elapsed       | 123       |\n",
      "|    total_timesteps    | 58000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.94e-44 |\n",
      "|    explained_variance | 0.962     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 2899      |\n",
      "|    policy_loss        | -80.5     |\n",
      "|    value_loss         | 4.24      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=-37116.44 +/- 0.23\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -3.71e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 60000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.229    |\n",
      "|    explained_variance | -0.144    |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 2999      |\n",
      "|    policy_loss        | -500      |\n",
      "|    value_loss         | 1.12e+03  |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.86e+03 |\n",
      "|    ep_rew_mean     | 3.59e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 447      |\n",
      "|    iterations      | 3000     |\n",
      "|    time_elapsed    | 134      |\n",
      "|    total_timesteps | 60000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1.87e+03 |\n",
      "|    ep_rew_mean        | 3.34e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 458      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 135      |\n",
      "|    total_timesteps    | 62000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0964  |\n",
      "|    explained_variance | -0.344   |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -513     |\n",
      "|    value_loss         | 269      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.87e+03  |\n",
      "|    ep_rew_mean        | 3.34e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 468       |\n",
      "|    iterations         | 3200      |\n",
      "|    time_elapsed       | 136       |\n",
      "|    total_timesteps    | 64000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.66e-33 |\n",
      "|    explained_variance | 0.454     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 3199      |\n",
      "|    policy_loss        | -2.67e+03 |\n",
      "|    value_loss         | 328       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=65000, episode_reward=-37781.73 +/- 0.11\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -3.78e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 65000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0        |\n",
      "|    explained_variance | 0.853     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 3249      |\n",
      "|    policy_loss        | -66       |\n",
      "|    value_loss         | 15        |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1.89e+03 |\n",
      "|    ep_rew_mean        | 3.6e+03  |\n",
      "| time/                 |          |\n",
      "|    fps                | 446      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 147      |\n",
      "|    total_timesteps    | 66000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.5e-10 |\n",
      "|    explained_variance | 0.975    |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | -36      |\n",
      "|    value_loss         | 2.68     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.9e+03   |\n",
      "|    ep_rew_mean        | 3.03e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 456       |\n",
      "|    iterations         | 3400      |\n",
      "|    time_elapsed       | 149       |\n",
      "|    total_timesteps    | 68000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0        |\n",
      "|    explained_variance | 0.0803    |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 3399      |\n",
      "|    policy_loss        | -8.13e+03 |\n",
      "|    value_loss         | 2.69e+03  |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=-36983.20 +/- 0.02\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -3.7e+04  |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 70000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.08e-42 |\n",
      "|    explained_variance | 0.966     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 3499      |\n",
      "|    policy_loss        | 340       |\n",
      "|    value_loss         | 6.37      |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.91e+03 |\n",
      "|    ep_rew_mean     | 2.88e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 441      |\n",
      "|    iterations      | 3500     |\n",
      "|    time_elapsed    | 158      |\n",
      "|    total_timesteps | 70000    |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.92e+03  |\n",
      "|    ep_rew_mean        | 2.36e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 450       |\n",
      "|    iterations         | 3600      |\n",
      "|    time_elapsed       | 159       |\n",
      "|    total_timesteps    | 72000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.35e-19 |\n",
      "|    explained_variance | 0.456     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 3599      |\n",
      "|    policy_loss        | -2.85e+03 |\n",
      "|    value_loss         | 466       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1.93e+03 |\n",
      "|    ep_rew_mean        | 2.23e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 459      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 161      |\n",
      "|    total_timesteps    | 74000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.219   |\n",
      "|    explained_variance | 0.316    |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 162      |\n",
      "|    value_loss         | 122      |\n",
      "------------------------------------\n",
      "Eval num_timesteps=75000, episode_reward=-37781.76 +/- 0.02\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -3.78e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 75000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.32e-42 |\n",
      "|    explained_variance | 0.9       |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 3749      |\n",
      "|    policy_loss        | 987       |\n",
      "|    value_loss         | 34.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.94e+03  |\n",
      "|    ep_rew_mean        | 2.2e+03   |\n",
      "| time/                 |           |\n",
      "|    fps                | 440       |\n",
      "|    iterations         | 3800      |\n",
      "|    time_elapsed       | 172       |\n",
      "|    total_timesteps    | 76000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.06e-38 |\n",
      "|    explained_variance | 0.435     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 3799      |\n",
      "|    policy_loss        | -2.03e+03 |\n",
      "|    value_loss         | 199       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1.95e+03 |\n",
      "|    ep_rew_mean        | 2.22e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 449      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 173      |\n",
      "|    total_timesteps    | 78000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0571  |\n",
      "|    explained_variance | 0.0965   |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 28.7     |\n",
      "|    value_loss         | 183      |\n",
      "------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=-37781.77 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -3.78e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 80000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.98e-05 |\n",
      "|    explained_variance | 0.904     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 3999      |\n",
      "|    policy_loss        | 160       |\n",
      "|    value_loss         | 13.6      |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.95e+03 |\n",
      "|    ep_rew_mean     | 2.22e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 437      |\n",
      "|    iterations      | 4000     |\n",
      "|    time_elapsed    | 182      |\n",
      "|    total_timesteps | 80000    |\n",
      "---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<MaskableA2C.MaskableA2C at 0x724368477010>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from environment3 import LifeStyleEnv\n",
    "from sb3_contrib.common.wrappers import ActionMasker\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "from MaskableA2C import MaskableA2C\n",
    "from stable_baselines3.common.torch_layers import CombinedExtractor\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def mask_fn(env: gym.Env) -> np.ndarray:\n",
    "    unwrapped_env = env\n",
    "    while hasattr(unwrapped_env, \"env\"):\n",
    "        unwrapped_env = unwrapped_env.env\n",
    "    return unwrapped_env.action_masks()\n",
    "\n",
    "def make_env():\n",
    "    env = LifeStyleEnv()\n",
    "    env = Monitor(env)\n",
    "    check_env(env, warn=True) \n",
    "    return env \n",
    "\n",
    "env = make_env()\n",
    "env = ActionMasker(env, mask_fn)\n",
    "\n",
    "eval_env = make_env()\n",
    "eval_env = ActionMasker(eval_env, mask_fn)\n",
    "\n",
    "eval_callback = EvalCallback(\n",
    "    eval_env,\n",
    "    best_model_save_path=\"./logs/a2c/a2c_best_model_test4\",\n",
    "    log_path=\"./logs/a2c/a2c_results_test4\",\n",
    "    eval_freq=5000,\n",
    "    n_eval_episodes=10,\n",
    "    deterministic=True,\n",
    "    render=False\n",
    ")\n",
    "\n",
    "model = MaskableA2C(\n",
    "    \"MultiInputPolicy\",  \n",
    "    env,\n",
    "    learning_rate=0.001,\n",
    "    n_steps=20,           \n",
    "    gamma=0.95,\n",
    "    gae_lambda=0.95,\n",
    "    vf_coef=0.1,\n",
    "    max_grad_norm=0.5,\n",
    "    verbose=1,\n",
    "    device=device,\n",
    "    policy_kwargs=dict(\n",
    "        features_extractor_class=CombinedExtractor,  \n",
    "        features_extractor_kwargs={},                \n",
    "        net_arch=[256, 256]\n",
    "    ),\n",
    "    tensorboard_log=\"./logs/a2c/a2c_tensorboard_test4/\"\n",
    ")\n",
    "\n",
    "model.learn(total_timesteps=80000, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7a9a4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of logs/a2c/a2c_results_test3/evaluations.npz: ['timesteps', 'results', 'ep_lengths']\n",
      "Mean reward for VF_Coeff = 0.5: -4509.17\n",
      "Contents of logs/a2c/a2c_results_test4/evaluations.npz: ['timesteps', 'results', 'ep_lengths']\n",
      "Mean reward for VF_Coeff = 0.1: -32262.22\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA28AAAIjCAYAAACUIiNfAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAApHJJREFUeJzs3Xd8FNX6x/HPbnoIaZCGBEhooSqKRhAQBAHBgnoRFAuKYuOKvYuKXr1iAyvy8woWuCqKeKVJFKSJoICC9I6UFAghhEDa7u+PyW4Sk0DKJrObfN+v1752MjM78+zJBvLknPMci91utyMiIiIiIiJuzWp2ACIiIiIiInJmSt5EREREREQ8gJI3ERERERERD6DkTURERERExAMoeRMREREREfEASt5EREREREQ8gJI3ERERERERD6DkTURERERExAMoeRMREREREfEASt5ERMRtZWVlcfvttxMdHY3FYuH+++83OyTxcM899xwWi8XsMEREqkTJm4iIm3vvvfewWCwkJiaWefzIkSO8+uqr9OrVi4iICEJDQ7nwwgv54osvyr3mzp07ufPOO4mPj8ff35/g4GAuuugiJk2axMmTJ08bz8iRI7FYLM5HcHAwZ599Nq+//jo5OTnVeq9/99JLLzFt2jTuvvtuPv30U2666SaXXr8+KigoYOrUqfTu3Zvw8HD8/Pxo0aIFt956K7/99pvZ4YmIyGlY7Ha73ewgRESkfBdddBEHDx5kz549bN++nVatWpU4PmfOHK655hoGDRpEnz598Pb25uuvv2bx4sWMGzeO559/vsT5c+fOZejQofj5+XHzzTfTsWNHcnNzWb58OV9//TUjR45kypQp5cYzcuRIPv/8cz788EMAMjIy+Prrr/npp58YNmwYn3/+ucve+4UXXoi3tzfLly932TXrs5MnT3LNNdewYMECevXqxRVXXEF4eDh79uzhyy+/ZNu2bezbt4+mTZuaHWqNyc/PJz8/H39/f7NDERGpNCVvIiJubPfu3cTHxzNr1izuvPNO7r33Xp599tlS51itVpo3b+7cZ7fb6devHytWrODIkSM0aNDAeW7nzp1p2rQpixYtIiYmpsS1duzYwdy5cxk7dmy5MY0cOZKvvvqKrKws5z6bzUZiYiK//fYbBw4coEmTJlV+zzabjdzcXPz9/YmPj6d9+/bMmTOnytcrLj8/H5vNhq+vr0uu52nGjBnDu+++y5tvvllqCGpBQQFvvvkmw4cPr5PJ24kTJ5w/ByIinkrDJkVE3Nj06dMJCwtj8ODB/OMf/2D69OmlzomLiyuRuAFYLBaGDBlCTk4Ou3btcu6fMGECWVlZ/Oc//ymVuAG0atXqtIlbeaxWK7179wZgz549AOTk5PDss8/SqlUr/Pz8iI2N5dFHHy01tNJisTBmzBimT59Ohw4d8PPzY8GCBVgsFnbv3s3cuXOdQzQd105NTWXUqFFERUXh7+/P2Wefzccff1ziunv27MFisfDaa68xceJEWrZsiZ+fH5s2bXLOe9q2bRs33ngjISEhRERE8Mwzz2C32/nrr7+46qqrCA4OJjo6mtdff73EtXNzcxk3bhznnXceISEhNGjQgJ49e7J48eJyY5gyZYozhvPPP59ff/21VDtu2bKF6667joiICAICAmjbti1PPfVUiXMOHDjAbbfdRlRUFH5+fnTo0IGPPvrojN+j/fv388EHH3DppZeWOXfQy8uLhx9+uETitm7dOi677DKCg4MJCgqib9++/PLLLyVeN23aNCwWC8uXL+e+++5zDt298847yc3NJSMjg5tvvpmwsDDCwsJ49NFHKf534+Jt9Oabb9K8eXMCAgK4+OKL+fPPP0vca/369YwcOdI53Dc6OprbbruNI0eOlDjP8f3dtGkTN9xwA2FhYfTo0aPEseKSkpLo0aMHoaGhBAUF0bZtW5588skS51T2M1eR77eISGV5mx2AiIiUb/r06VxzzTX4+vpy/fXX8/777/Prr79y/vnnn/G1ycnJADRu3Ni577vvviM+Pp7u3bu7PNadO3cC0KhRI2w2G1deeSXLly9n9OjRtGvXjg0bNvDmm2+ybds2Zs+eXeK1ixYt4ssvv2TMmDE0btyYmJgYPv30Ux544AGaNm3KQw89BEBERAQnT56kd+/e7NixgzFjxhAXF8fMmTMZOXIkGRkZpZLPqVOncurUKUaPHo2fnx/h4eHOY8OGDaNdu3b8+9//Zu7cubz44ouEh4fzwQcfcMkll/DKK68wffp0Hn74Yc4//3x69eoFQGZmJh9++CHXX389d9xxB8ePH+c///kPAwYMYPXq1ZxzzjklYpgxYwbHjx/nzjvvxGKxMGHCBK655hp27dqFj48PYCQmPXv2xMfHh9GjR9OiRQt27tzJd999x7/+9S8AUlJSuPDCC50Jb0REBPPnz2fUqFFkZmaetqDL/Pnzyc/Pr/C8wY0bN9KzZ0+Cg4N59NFH8fHx4YMPPqB3794sWbKk1BzMf/7zn0RHR/P888/zyy+/MGXKFEJDQ/n5559p1qwZL730EvPmzePVV1+lY8eO3HzzzSVe/8knn3D8+HHuvfdeTp06xaRJk7jkkkvYsGEDUVFRgJFk7dq1i1tvvZXo6Gg2btzIlClT2LhxI7/88kuppGzo0KG0bt2al156ifIGGm3cuJHLL7+czp07M378ePz8/NixYwcrVqxwnlPZz1xFvt8iIlViFxERt/Tbb7/ZAXtSUpLdbrfbbTabvWnTpvaxY8ee8bVHjhyxR0ZG2nv27Oncd+zYMTtgv+qqq6oV1y233GJv0KCBPS0tzZ6WlmbfsWOH/aWXXrJbLBZ7586d7Xa73f7pp5/arVarfdmyZSVeO3nyZDtgX7FihXMfYLdarfaNGzeWulfz5s3tgwcPLrFv4sSJdsD+2WefOffl5ubau3XrZg8KCrJnZmba7Xa7fffu3XbAHhwcbE9NTS1xjWeffdYO2EePHu3cl5+fb2/atKndYrHY//3vfzv3Hz161B4QEGC/5ZZbSpybk5NT4ppHjx61R0VF2W+77TbnPkcMjRo1sqenpzv3f/vtt3bA/t133zn39erVy96wYUP73r17S1zXZrM5t0eNGmWPiYmxHz58uMQ5w4cPt4eEhNizs7Pt5XnggQfsgH3dunXlnlPckCFD7L6+vvadO3c69x08eNDesGFDe69evZz7pk6dagfsAwYMKBFrt27d7BaLxX7XXXc59zna+OKLL3buc7RRQECAff/+/c79q1atsgP2Bx54wLmvrPf33//+1w7Yly5d6tzn+P5ef/31pc53HHN488037YA9LS2t3Lao7GeuIt9vEZGq0LBJERE3NX36dKKioujTpw9gDC90FAQpKCgo93U2m40RI0aQkZHB22+/7dyfmZkJQMOGDasd24kTJ4iIiCAiIoJWrVrx5JNP0q1bN7755hsAZs6cSbt27UhISODw4cPOxyWXXAJQanjhxRdfTPv27St073nz5hEdHc3111/v3Ofj48N9991HVlYWS5YsKXH+tddeS0RERJnXuv32253bXl5edO3aFbvdzqhRo5z7Q0NDadu2bYnhp15eXs55czabjfT0dPLz8+natStr164tdZ9hw4YRFhbm/Lpnz54AzmumpaWxdOlSbrvtNpo1a1bitY7eJLvdztdff80VV1yB3W4v0a4DBgzg2LFjZd7boTLf/4KCAhYuXMiQIUOIj4937o+JieGGG25g+fLlzus5jBo1qkTPV2JiYqm2dLRx8bZ0GDJkCGeddZbz6wsuuIDExETmzZvn3BcQEODcPnXqFIcPH+bCCy8EKPO933XXXWd8r6GhoQB8++232Gy2Ms+p7GfuTN9vEZGqUvImIuKGCgoK+Pzzz+nTpw+7d+9mx44d7Nixg8TERFJSUvjxxx/Lfe0///lPFixYwIcffsjZZ5/t3B8cHAzA8ePHqx2fv78/SUlJJCUlsXTpUv766y9WrFjh/EV/+/btbNy40ZngOR5t2rQBjPlDxcXFxVX43nv37qV169ZYrSX/C2vXrp3zeEWv/fdEKSQkBH9//xJDTR37jx49WmLfxx9/TOfOnfH396dRo0ZEREQwd+5cjh07dsb7OH6xd1zT8Ut9x44dy401LS2NjIwMpkyZUqpdb731VqB0uxZXme9/Wloa2dnZtG3bttSxdu3aYbPZ+Ouvv0rsL6stAWJjY0vt/3tbArRu3brUvjZt2jjnOQKkp6czduxYoqKiCAgIICIiwvn9LavdK/K5GjZsGBdddBG33347UVFRDB8+nC+//LJEIlfZz9yZvt8iIlWlOW8iIm5o0aJFHDp0iM8//7zM0vvTp0+nf//+pfY///zzvPfee/z73/8uNbcpODiYJk2alCoCURVeXl7069ev3OM2m41OnTrxxhtvlHn877/QF+9RcbXTXdvLy6tC+4ASc6Y+++wzRo4cyZAhQ3jkkUeIjIzEy8uLl19+2Tn3r7LXPBNHMnHjjTdyyy23lHlO586dy319QkICABs2bCg1J88VynuPZe2vzPsu7rrrruPnn3/mkUce4ZxzziEoKAibzcbAgQPL7DWryOcqICCApUuXsnjxYubOncuCBQv44osvuOSSS1i4cGG57+t0XPH9FhEpi5I3ERE3NH36dCIjI3n33XdLHZs1axbffPMNkydPLvHL6bvvvstzzz3H/fffz2OPPVbmdS+//HKmTJnCypUr6datW43F37JlS/744w/69u1bqohEdTVv3pz169djs9lK9IRs2bLFebymffXVV84lHIq/v78v41BRjh7L0yXWERERNGzYkIKCgtMmzuW57LLL8PLy4rPPPjtj0ZKIiAgCAwPZunVrqWNbtmzBarWWSsCra/v27aX2bdu2jRYtWgBGr9WPP/7I888/z7hx4077usqyWq307duXvn378sYbb/DSSy/x1FNPsXjxYvr16+cWnzkREdCwSRERt3Py5ElmzZrF5Zdfzj/+8Y9SjzFjxnD8+HH+97//OV/zxRdfcN999zFixIhye7sAHn30URo0aMDtt99OSkpKqeM7d+5k0qRJ1X4P1113HQcOHOD//u//ynx/J06cqPK1Bw0aRHJyMl988YVzX35+Pm+//TZBQUFcfPHFVb52RTl6Vor3pKxatYqVK1dW6XoRERH06tWLjz76iH379pU45riHl5cX1157LV9//XWZSV5aWtpp7xEbG8sdd9zBwoULS8yFdLDZbLz++uvs378fLy8v+vfvz7ffflti2GJKSgozZsygR48ezmGYrjJ79mwOHDjg/Hr16tWsWrWKyy67DCi7zQEmTpxYrfump6eX2ufomXQsa+EOnzkREVDPm4iI2/nf//7H8ePHufLKK8s8fuGFFxIREcH06dMZNmwYq1ev5uabb6ZRo0b07du31Fpw3bt3d/bstGzZkhkzZjhL5N9888107NiR3Nxcfv75Z2f58+q66aab+PLLL7nrrrtYvHgxF110EQUFBWzZsoUvv/yS77//nq5du1bp2qNHj+aDDz5g5MiRrFmzhhYtWvDVV1+xYsUKJk6c6JKCLGdy+eWXM2vWLK6++moGDx7M7t27mTx5Mu3bty+xeHllvPXWW/To0YNzzz2X0aNHExcXx549e5g7dy6///47AP/+979ZvHgxiYmJ3HHHHbRv35709HTWrl3LDz/8UGYiUtzrr7/Ozp07ue+++5x/IAgLC2Pfvn3MnDmTLVu2MHz4cABefPFF5/pn99xzD97e3nzwwQfk5OQwYcKEKr3H02nVqhU9evTg7rvvJicnh4kTJ9KoUSMeffRRwBj226tXLyZMmEBeXh5nnXUWCxcuZPfu3dW67/jx41m6dCmDBw+mefPmpKam8t5779G0aVPn2nDu8JkTEQElbyIibmf69On4+/tz6aWXlnncarUyePBgpk+fzpEjR9i0aRO5ubmkpaVx2223lTp/6tSpJSoGXnnllaxfv55XX32Vb7/9lvfffx8/Pz86d+7M66+/zh133FHt92C1Wpk9ezZvvvkmn3zyCd988w2BgYHEx8czduxYZ+GSqggICOCnn37i8ccf5+OPPyYzM5O2bdsydepUlySeFTFy5EiSk5P54IMP+P7772nfvj2fffYZM2fO5KeffqrSNc8++2x++eUXnnnmGd5//31OnTpF8+bNue6665znREVFsXr1asaPH8+sWbN47733aNSoER06dOCVV1454z0CAwOZP38+06ZN4+OPP+aFF14gOzubJk2acMkllzB9+nRnxccOHTqwbNkynnjiCV5++WVsNhuJiYl89tlnpdZ4c4Wbb74Zq9XKxIkTSU1N5YILLuCdd94psZj8jBkz+Oc//8m7776L3W6nf//+zJ8/nyZNmlT5vldeeSV79uzho48+4vDhwzRu3JiLL76Y559/3ll0xR0+cyIiABa7Zs+KiIiISfbs2UNcXByvvvoqDz/8sNnhiIi4Nc15ExERERER8QBK3kRERERERDyAkjcREREREREPoDlvIiIiIiIiHkA9byIiIiIiIh5AyZuIiIiIiIgH0DpvJrHZbBw8eJCGDRtisVjMDkdERERERExit9s5fvw4TZo0wWotv39NyZtJDh48SGxsrNlhiIiIiIiIm/jrr79o2rRpuceVvJmkYcOGgPENCg4ONjkaz5WXl8fChQvp378/Pj4+ZodTb6jdzaF2N4fa3Rxqd3Oo3c2hdjeHO7V7ZmYmsbGxzhyhPEreTOIYKhkcHKzkrRry8vIIDAwkODjY9B+6+kTtbg61uznU7uZQu5tD7W4Otbs53LHdzzSdSgVLREREREREPICSNxEREREREQ+g5E1ERERERMQDKHkTERERERHxAEreREREREREPICSNxEREREREQ+g5E1ERERERMQDKHkTERERERHxAEreREREREREPICSNxEREREREQ+g5E1ERERERMQDKHkTERERERHxAEreREREREREPICSNxEREREREQ+g5E1ERERERMQDKHkTERERERHxAN5mByDmKrDZSdqUbHYYVZafX8AfRyx4bUzB29vL7HDqDbW7OfLzC9h+zMLe9GxiGwXhp7YXERGpV5S81XN5BTbu+myt2WFUkxcfbfvD7CDqIbW7Obx4Z9NyACIa+tEkxJ8moQHOx1mhxtcxIQE0DvLFYrGYHK+IiIi4ipK3es5iga7Nw8wOo8rsdjvpR48SHhamX1JrkdrdHDa7nf2pRzmW70VOvo204zmkHc/hj/3Hyjzf19taKrkr+bU/gb76b0BERMRT6H/tes7P24uv7u5udhhVlpeXx7x58xg06AJ8fHzMDqfeULubw9Hul13Wn6w8OJhxkgMZJznoeBw75dxOPZ5Dbr6NPUey2XMku9xrhgX6EBNSsteueHIX2dAfL6sSdBGR+sput3Mqz8bxnDyyTuWTlZNP1ql8jhc+n8jNx243O8qqKSgoIP2YZ/0fp+RNRMTDWCwWwhv4EN7Al45nhZR5Tm6+jZTMUxzIOMmhYyc5mHGqZKKXcYqsnHyOZudxNDuPTYcyy7yOt9VCVLA/ZxUmc01CA4j5W6IX7K8EXkTE3dhsdrLzCgoTrjyOl5F4ZeUYj6Jjec6vjxc7XmDz0OysArpHKXkTERGT+XpbiQ0PJDY8sNxzMk/lOZO5AxlGr92hjKJELznzFPk2OwcKe/jK09DPm5hiyZwz0Svs0YsK9sfXW8WNRUQqosBmL0yw8spOtkp8nfe35KvYs4t7xCwWCPLzpqGfN0H+3gT5eRPk70MDXy+sHjpCw26z0TD7oNlhVIqSNxGReirY34fgaB8SooPLPF5gs5N6/JSzp65UonfsJEez8ziek8/xlCy2pWSVeR2LBSIb+tHAQ+fX2e12TpzwYuK25ZrjWYvU7uZQu5ujwGbn6HEvnljzI9m5BS69tpfVQkNHsuXnXbTt71Py68KkrHhy1tDfm4aF5wX4eG6SVh5jOsIBs8OoFM/8n1RERGqcl9VCTIhRufK85mWfk52bXyKx+/vcu4MZp8gtsJGSmQPk1Gr8rmWBU+XPHZSaonY3h9rdHBagKHHz9baW7OUqkXh5E+TnU27i1bBYYubnbVUiXocoeRMRkSoL9PWmVWQQrSKDyjxus9k5ciKXgxknycm31XJ0rpGfn88vv6zkwgu74e2t/zZri9rdHGp3cxQU5LN29UoG9u1NWFAADfy8tJanlEk/lSIiUmOsVgsRDf2IaOhndihVlpeXR9omOL9FmKqr1iK1uznU7ubIy8sjdSM0Cw9Uu8tpaQa5iIiIiIiIB1DyJiIiIiIi4gGUvImIiIiIiHgAJW8iIiIiIiIeQMmbiIiIiIiIB1DyJiIiIiIi4gGUvImIiIiIiHgAJW8iIiIiIiIeQMmbiIiIiIiIB1DyJiIiIiIi4gGUvImIiIiIiHgAJW8iIiIiIiIeQMmbiIiIiIiIB1DyJiIiIiIi4gGUvImIiIiIiHgAJW8iIiIiIiIeQMmbiIiIiIiIB1DyJiIiIiIi4gGUvImIiIiIiHgAJW8iIiIiIiIeQMmbiIiIiIiIB1DyJiIiIiIi4gGUvImIiIiIiHgAJW8iIiIiIiIeQMmbiIiIiIiIB1DyJiIiIiIi4gGUvImIiIiIiHgAJW8iIlLz9q6Eo3vNjkJERMSjKXkTEZGalbIJpl4GX9xodiQiIiIeTcmbiIjUrL9+AeyQvAFys82ORkRExGMpeRMRkZqVvKFwww6Ht5kaioiIiCdT8iYiIjXLmbwBaVvMi0NERMTDKXkTEZGaYyuAlI1FX6duNi8WERERD6fkTUREak76LsgrNs9NPW8iIiJVpuRNRERqzqE/jGcvP+M5dZN5sYiIiHg4JW8iIlJzHPPd2gwwnjP2QU6WefGIiIh4MCVvIiJScxzJW8tLILCxsX14q3nxiIiIeDAlbyIiUnMcyVt0Z4hsZ2ynat6biIhIVSh5ExGRmnE8BU6kgsVqJG6O5C1NFSdFRESqQsmbiIjUDEevW6PW4BsIEQnG1+p5ExERqRIlbyIiUjOSCytNRncynp09b0reREREqkLJm4iI1AznfLfC5M3R83bsL8g5bk5MIiIiHkzJm4iI1Iy/J2+B4RAUZWynqeKkiIhIZXlM8vavf/2L7t27ExgYSGhoaJnn7Nu3j8GDBxMYGEhkZCSPPPII+fn5Jc756aefOPfcc/Hz86NVq1ZMmzat1HXeffddWrRogb+/P4mJiaxevbrE8VOnTnHvvffSqFEjgoKCuPbaa0lJSXHVWxUR8Xw5WXBkp7Ed3blov3Pem4qWiIiIVJbHJG+5ubkMHTqUu+++u8zjBQUFDB48mNzcXH7++Wc+/vhjpk2bxrhx45zn7N69m8GDB9OnTx9+//137r//fm6//Xa+//575zlffPEFDz74IM8++yxr167l7LPPZsCAAaSmpjrPeeCBB/juu++YOXMmS5Ys4eDBg1xzzTU19+ZFRDxN6ibADg1jICiiaL/mvYmIiFSZt9kBVNTzzz8PUGZPGcDChQvZtGkTP/zwA1FRUZxzzjm88MILPPbYYzz33HP4+voyefJk4uLieP311wFo164dy5cv580332TAgAEAvPHGG9xxxx3ceuutAEyePJm5c+fy0Ucf8fjjj3Ps2DH+85//MGPGDC655BIApk6dSrt27fjll1+48MILy4wvJyeHnJwc59eZmZkA5OXlkZeXV/0Gqqccbac2rF1qd3N4UrtbD6zDC7BFdqCgWLyW8NZ4A7aUTSX2uzNPave6RO1uDrW7OdTu5nCndq9oDB6TvJ3JypUr6dSpE1FRUc59AwYM4O6772bjxo106dKFlStX0q9fvxKvGzBgAPfffz9g9O6tWbOGJ554wnncarXSr18/Vq5cCcCaNWvIy8srcZ2EhASaNWvGypUry03eXn75ZWcCWtzChQsJDAys8vsWQ1JSktkh1Etqd3N4QrufvW8+LYAdWQFsnjfPuT886yg9gZy/1rGw2H5P4AntXhep3c2hdjeH2t0c7tDu2dnZFTqvziRvycnJJRI3wPl1cnLyac/JzMzk5MmTHD16lIKCgjLP2bJli/Mavr6+pebdRUVFOe9TlieeeIIHH3zQ+XVmZiaxsbH079+f4ODgyr1ZccrLyyMpKYlLL70UHx8fs8OpN9Tu5vCkdvf66E0A4i8aQly7QUUHTl0Er79IQN5RBl1yEfiHmBRhxXlSu9clandzqN3NoXY3hzu1u2NU3pmYmrw9/vjjvPLKK6c9Z/PmzSQkJNRSRDXHz88PPz+/Uvt9fHxM/7DUBWpHc6jdzeH27V6QD2lGQRLvs7pA8Vh9Ghvz4I4fwufoTmiWaFKQlef27V5Hqd3NoXY3h9rdHO7Q7hW9v6nJ20MPPcTIkSNPe058fHyFrhUdHV2qKqSjAmR0dLTz+e9VIVNSUggODiYgIAAvLy+8vLzKPKf4NXJzc8nIyCjR+1b8HBGReu3IDsg/Bb5BEBZX+nhkOzh+yEjwPCh5ExERMZup1SYjIiJISEg47cPX17dC1+rWrRsbNmwoURUyKSmJ4OBg2rdv7zznxx9/LPG6pKQkunXrBoCvry/nnXdeiXNsNhs//vij85zzzjsPHx+fEuds3bqVffv2Oc8REanXHOu7RXUEaxn/zUQUVpxMVcVJERGRyvCYOW/79u0jPT2dffv2UVBQwO+//w5Aq1atCAoKon///rRv356bbrqJCRMmkJyczNNPP829997rHK5411138c477/Doo49y2223sWjRIr788kvmzp3rvM+DDz7ILbfcQteuXbnggguYOHEiJ06ccFafDAkJYdSoUTz44IOEh4cTHBzMP//5T7p161ZusRIRkXoleb3x7Fic++8iC4fCp2mtNxERkcrwmORt3LhxfPzxx86vu3TpAsDixYvp3bs3Xl5ezJkzh7vvvptu3brRoEEDbrnlFsaPH+98TVxcHHPnzuWBBx5g0qRJNG3alA8//NC5TADAsGHDSEtLY9y4cSQnJ3POOeewYMGCEkVM3nzzTaxWK9deey05OTkMGDCA9957rxZaQUTEAzh63spL3tTzJiIiUiUek7xNmzat3DXeHJo3b868M5Se7t27N+vWrTvtOWPGjGHMmDHlHvf39+fdd9/l3XffPe11RETqHbu9AslbW+M5KxlOHoWAsNqJTURExMOZOudNRETqmOOHIPswWLyMwiRl8Q+G4KbGtnrfREREKkzJm4iIuI6j161xG/AJKP88zXsTERGpNCVvIiLiOmcqVuIQUZi8qedNRESkwpS8iYiI65xpvpuDY0hl6qaajUdERKQOUfImIiKu40jeYjqf/jxHxck09byJiIhUlJI3ERFxjZzjkL7L2I4607DJwoqTJ9LgxJGajUtERKSOUPImIiKukbLReA4+Cxo0Ov25fkEQ2szYVtESERGRClHyJiIirnGogsVKHJyLdSt5ExERqQglbyIi4hoVrTTp4FwuQPPeREREKkLJm4iIuEZFK006OHvelLyJiIhUhJI3ERGpvoK8ouGPle5507BJERGRivA2OwCRKjl5FLYtxGvbAtodzgX7QLMjEqnfDm+HghzwC4bQFhV7TeO2gAWyj0BWGgRF1GSEIiIiHk/Jm3iOjH2wZR5snQt7VoC9ACvQBihYMRH6PGZygCL1mGPIZFRHsFZwUIdvIIQ1h6N7jN43JW8iIiKnpeRN3JfdbhRA2DIPtsyFlA0lj0e2xxbZHuufX2Fd8jI0PQ9a9zMnVpH6rrLFShwi2hnJW+oWiOvl8rBERETqEiVv4l4K8mDPctg6D7bOh2N/FR2zWKFZN0gYDG0vg/B4CvLy2HfoCC2OLIavR8HonyA8zrTwReqtqiZvkQmwbT6kbnJ9TCIiInWMkjcx36lM2PGDkbBtWwg5x4qO+QRCy0uMhK31gDIX/t3Q9Eaa+WViPbgGvrgRRi0E3wa1+AZE6jm7vfKVJh0cFSe1XICIiMgZKXkTc2QeNJK1LfNg91Kw5RUdaxABbQYaCVt8b/AJOO2lbFYfCq6divWjvpDyJ3w3Fq75P7BYavY9iIgh84BRRMjqDREJlXuto+Jk6mYjCdTPrYiISLmUvEntsNuNX862zjUStoNrSx5v1KpwOORgaNoVrF6Vu35wExj6MXxyJWyYCU3OhW73uC5+ESmfo9etcVvw8a/caxu3MYZEn8qArBRoGO3y8EREROoKJW9Scwry4a9VRrGRrXONogROFmh6PiQMMhK2iDbVv1+Li6D/v2DBY7DwaWP4VlzP6l9XRE7PkbzFdK78a30CICwO0ncaf+BR8iYiIlIuJW/iWrknYOcio3dt2wI4mV50zMvPGAaZMNgYFtkwyvX3T7wTDqyBDV/CzJFw51IIOcv19xGRIlUtVuIQ2c5I3tK2QMs+rotLRESkjlHyJtWXlWZUi9syD3YthvxTRccCwoxEre0go/CIX1DNxmKxwBWTjL/gp2yAL2+CW+eDt1/N3lekPqtqsRKHiATYMsf4uRUREZFyKXmTqjm8vXA45Dz4azVgLzoW2rxw/togo7S/Vy1/zHwDYdinMKW30Qs37xG48q3ajUGkvjh1rGhIdFTHql0jUhUnRUREKkLJm1SMzQYHfitK2A5vK3k85hwjYUsYDJHtza8YFx4H//gPfPYPWPsxnHUunDfS3JhE6qLkP43nkFgIDK/aNRwVKlO3qOKkiIjIaSh5k/LlnYLdS4zhTFsXwInUomNWH6MYSNtBxsMd55W16gd9n4Efxxu9b1EdjUqWIuI61R0yCdC4NVi8jDUejx8yqseKiIhIKUrepKTsdNj2vVEdcsciyDtRdMwvGFpfaiRrrS8F/xDz4qyoHg/CgbVGAvrFTXDnEgiKNDsqkbrDFcmbtx+Ex8OR7ca8NyVvIiIiZVLyJsZ8lS3zjCGR+1aCvaDoWPBZ0PYyYzhk8x7g7WtamFViscCQ9+HDbcZQz5kj4eZvwcvH7MhE6gZnpckqLBNQXGRCUfLWqm/14xIREamDlLzVd2lb4d0LSu6L6mj0riUMMuayefr8E/9gGDYd/u8S2LsCFj4Dl/3b7KhEPF9+blGRker0vAFEtIPN30GaKk6KiIiUR8lbfde4jTFcKfisooQtrIXZUbleRBu4ejJ8MQJWvW8UMOl8ndlRiXi2w9ugIBf8QiC0WfWuFVmsaImIiIiUSclbfWexwD2rPG84ZFW0uxx6PgzLXoP/3WdUuIup5lAvkfqs+OLc1e2hj2xvPKdtVcVJERGRcljNDkDcQH1I3Bz6PGlUocw/CV/caBRoEZGqcUWxEofwlmD1htzjcGx/9a8nIiJSByl5k/rF6gXX/J8xNDRjL3x9O9gKzvgyESmDK5M3b19o1MrY1mLdIiIiZVLyJvVPYDgM+wy8A2Dnj7D4X2ZHJOJ57PaSwyZdwblYt4qWiIiIlEXJm9RP0Z3gyreN7WWvG1XuRKTijv0Fp46B1aco6aquyHbGs3reREREyqTkTeqvzkPhwnuM7W/ugrRt5sYj4kkcQyYjE1w3b1Y9byIiIqel5E3qt0vHG4uP52bB5zfAqUyzIxLxDIdctDh3cc6et61gs7nuuiIiInWEkjep37x8YOhUaNgEjmyH2Xfrl0aRinBlsRKH8HhjGGbeCWNYpoiIiJSg5E0kKNIoYOLlC1vmwPI3zI5IxP3VRPLm5QONWxvbGjopIiJSipI3EYCm58Gg14ztRS/C9h/MjUfEnZ08Csf2GdtRHV17bce8tzQlbyIiIn+n5E3E4bxb4NxbADt8PQrSd5sdkYh7Sv7TeA5tBgGhrr12ZHvjOVUVJ0VERP5OyZtIcYNehbO6wqkM+OJGyM02OyIR9+McMunCYiUOkep5ExERKY+SN5HivP3guk+gQQSk/Anf3WcsRiwiRWoyeYtwVJzcpuJBIiIif6PkTeTvQs6CodPA4gUbZsIv75sdkYh7SXYsE+DCYiUO4XHg5Qf5JyFjj+uvLyIi4sGUvImUpUUPGPAvY3vh07BnubnxiLiL/BxIK5yPVhPJm9ULGrcxtjXvTUREpAQlbyLlSbwLOl0H9gKYORKOHTA7IhHzpW0BWz74h0JI05q5h+a9iYiIlEnJm0h5LBa4YhJEdYITafDlTUavg0h9Vnx9N4ulZu7hWC5APW8iIiIlKHkTOR3fQBj2qdHLcGANzHvE7IhEzFWTxUocIh1FS9TzJiIiUpySN5EzCY+Df/wHsMDaj2HNNLMjEjGPI3mLqcHkzdHzdng72Apq7j4iIiIeRsmbSEW06geXPG1sz3sE9v9mbjwiZrDbSw6brClhLcDbH/JPwdE9NXcfERERD6PkTaSiej4ECZdDQS58cRNkpZodkUjtOroHcjLBy7eoImRNKFFxclPN3UdERMTDKHkTqSiLBYa8b/xSefygUYGyIM/sqERqj6PXLbIdePnU7L0i2xvPKloiIiLipORNpDL8g2HYdPBtCHtXwMJnzI5IpPbUxpBJBy0XICIiUoqSN5HKimgDV79vbK96H9Z/aW48IrWlNipNOkQUVpxUz5uIiIiTkjeRqmh3hTEHDuB/98Gh9ebGI1IbzOh5O7IdCvJr/n4iIiIeQMmbSFX1eQpa9oX8k/DFjZCdbnZEIjUnOx0y9xvbUR1r/n4hzcAn0CgQlL6r5u8nIiLiAZS8iVSV1Quu/RBCm0PGXvj6dq1JJXWXo9ctLM6Y+1nTrFaIaGtsa96biIgIoORNpHoCw2H4dPAOgJ0/wuJ/mR2RSM1ILhwaXBtDJh00701ERKQEJW8i1RXdCa5829he9jps/s7ceERqQm0WK3FQxUkREZESlLyJuELnoXDhPcb2N3dD2jZz4xFxtdosVuKgnjcREZESlLyJuMql46F5D8g9Dp/fAKcyzY5IxDXyTkHaVmO7NpO34hUn83Nr774iIiJuSsmbiKt4+cDQqdCwifHL5uy7wWYzOyqR6kvbDPYCCAiH4Ca1d9+QWPANAls+pO+svfuKiIi4KSVvIq4UFAnDPgUvX9gyB5a/YXZEItXnGDIZ0xksltq7r8UCEYW9b6ma9yYiIqLkTcTVmnaFQa8a24tehO0/mBuPSHWZMd/NwVm0RPPeRERElLyJ1ITzRsK5twB2+HoUpO82OyKRqjvkWCagFitNOjiLlqjnTURERMmbSE0Z9CqcdR6cyoAvboLcbLMjEqk8mw1S/jS21fMmIiJiKiVvIjXF2w+u+xQaREDKBvjuPrDbzY5KpHKO7obcLPDyg0ata//+jp63IzshP6f27y8iIuJGlLyJ1KSQs2DoNLB4wYaZsGqy2RGJVI5jvltUe/Dyrv37BzcBv2Cj2uWRHbV/fxERETei5E2kprXoAf1fNLa/fwr2LDc3HpHKMLNYCajipIiISDFK3kRqw4V3Q6ehRu/BzJFw7IDZEYlUjDN5M6FYiYPmvYmIiABK3kRqh8UCV7wFUZ3gRBp8eZPm74hncIfkTRUnRUREACVvIrXHN9BYwNs/FA6sgXmPmB2RyOmdOAzHDwIWY86bWdTzJiIiAih5E6ld4XFw7X8AC6z9GNZMMzsikfIlF67vFh4Pfg3Ni8PR85a+C/JOmReHiIiIyZS8idS21v3gkqeN7e+f0i+j4r7MLlbi0DDa6LG22+DwNnNjERERMZGSNxEz9HgQgqKN9bP2rzY7GpGyuUvyZrFAZGHvm4ZOiohIPabkTcQMVivE9za2dy42NRSRcrlDsRIHLRcgIiKi5E3ENI7kbddPZkYhUra8k0VDFGPcIHlTz5uIiIiSNxHTxF9sPB9cByePmhuLyN+lbjLmmDWIgKAos6NRz5uIiAhK3kTME9wEGrcF7LB7mdnRiJR0qLDSZHQnY86Z2Rw9b0f3QG62qaGIiIiYRcmbiJmcQyc1703cjLsUK3FoEAEB4YBdFSdFRKTeUvImYqaWfYxnzXsTd+NOxUpAFSdFRERQ8iZiruYXgcXLWHz46F6zoxEx2AogZaOx7S49b6B5byIiUu8peRMxk38wNO1qbO9eYm4sIg7puyHvBHgHQKNWZkdTRD1vIiJSzyl5EzGblgwQd5NcWKwkqgNYvcyNpThnz9smc+MQERExiZI3EbPFF5v3ZrOZGooIUJS8udOQSSjqecvYBzlZ5sYiIiJiAo9I3vbs2cOoUaOIi4sjICCAli1b8uyzz5Kbm1vivPXr19OzZ0/8/f2JjY1lwoQJpa41c+ZMEhIS8Pf3p1OnTsybN6/Ecbvdzrhx44iJiSEgIIB+/fqxffv2Euekp6czYsQIgoODCQ0NZdSoUWRl6RcJqaKmXcE3CLKPQMqfZkcj4n6VJh0aNDaqTgIc3mpuLCIiIibwiORty5Yt2Gw2PvjgAzZu3Mibb77J5MmTefLJJ53nZGZm0r9/f5o3b86aNWt49dVXee6555gyZYrznJ9//pnrr7+eUaNGsW7dOoYMGcKQIUP488+iX5gnTJjAW2+9xeTJk1m1ahUNGjRgwIABnDp1ynnOiBEj2LhxI0lJScyZM4elS5cyevTo2mkMqXu8fIzCJaChk+Ie3K3SZHHOoZOa9yYiIvWPt9kBVMTAgQMZOHCg8+v4+Hi2bt3K+++/z2uvvQbA9OnTyc3N5aOPPsLX15cOHTrw+++/88YbbzgTq0mTJjFw4EAeeeQRAF544QWSkpJ45513mDx5Mna7nYkTJ/L0009z1VVXAfDJJ58QFRXF7NmzGT58OJs3b2bBggX8+uuvdO1qFJp4++23GTRoEK+99hpNmjQp8z3k5OSQk5Pj/DozMxOAvLw88vLyXNxi9Yej7Ty9Da0teuK1/XtsOxdTcMHdZodzRnWl3T1NrbR7Vgo+WSnYsZAf3hrc7HtsbdwWrz3LKEjZiK2WYtPn3Rxqd3Oo3c2hdjeHO7V7RWPwiOStLMeOHSM8PNz59cqVK+nVqxe+vr7OfQMGDOCVV17h6NGjhIWFsXLlSh588MES1xkwYACzZ88GYPfu3SQnJ9OvXz/n8ZCQEBITE1m5ciXDhw9n5cqVhIaGOhM3gH79+mG1Wlm1ahVXX311mfG+/PLLPP/886X2L1y4kMDAwCq1gRRJSkoyO4RqaXjSyiWAbfdyFsyZjc3qe8bXuANPb3dPVZPtHpG5nu5All80i35wvwqoLQ7nczZweNMyfsmZd8bzXUmfd3Oo3c2hdjeH2t0c7tDu2dnZFTrPI5O3HTt28Pbbbzt73QCSk5OJi4srcV5UVJTzWFhYGMnJyc59xc9JTk52nlf8deWdExkZWeK4t7c34eHhznPK8sQTT5RIHDMzM4mNjaV///4EBwdX6H1LaXl5eSQlJXHppZfi4+NjdjhVZ7djnzQR7xOpXNaxEfYWPc2O6LTqTLt7mNpod+vPO2AnNGiZyKBBg2rkHtVh2RcGn04jkvRai0+fd3Oo3c2hdjeH2t0c7tTujlF5Z2Jq8vb444/zyiuvnPaczZs3k5CQ4Pz6wIEDDBw4kKFDh3LHHXfUdIgu4+fnh5+fX6n9Pj4+pn9Y6oI60Y4t+8D6L/DetxxaX2J2NBVSJ9rdA9Vou6cZi3Nbm5yD1R2/tzEdAbBk7sfHdgr8GtbarfV5N4fa3Rxqd3Oo3c3hDu1e0fubmrw99NBDjBw58rTnxMfHO7cPHjxInz596N69e4lCJADR0dGkpKSU2Of4Ojo6+rTnFD/u2BcTE1PinHPOOcd5Tmpqaolr5Ofnk56e7ny9SJXE94b1XxhFS/qOMzsaqa8OuekyAQ6B4RAUBVkpkLa1aJF7ERGResDUapMREREkJCSc9uGYw3bgwAF69+7Neeedx9SpU7FaS4berVs3li5dWmKyX1JSEm3btiUsLMx5zo8//ljidUlJSXTr1g2AuLg4oqOjS5yTmZnJqlWrnOd069aNjIwM1qxZ4zxn0aJF2Gw2EhMTXdg6Uu/EXWw8H1wHJ4+aG4vUT7kn4MgOY9sdK006OCtObjY3DhERkVrmEUsFOBK3Zs2a8dprr5GWlkZycnKJOWY33HADvr6+jBo1io0bN/LFF18wadKkEvPMxo4dy4IFC3j99dfZsmULzz33HL/99htjxowBwGKxcP/99/Piiy/yv//9jw0bNnDzzTfTpEkThgwZAkC7du0YOHAgd9xxB6tXr2bFihWMGTOG4cOHl1tpUqRCQs6Cxm3AboPdy8yORuqjlE2A3ejZCoo84+mmcSzWnablAkREpH7xiIIlSUlJ7Nixgx07dtC0adMSx+x2O2BUhVy4cCH33nsv5513Ho0bN2bcuHEl1l/r3r07M2bM4Omnn+bJJ5+kdevWzJ49m44dOzrPefTRRzlx4gSjR48mIyODHj16sGDBAvz9/Z3nTJ8+nTFjxtC3b1+sVivXXnstb731Vg23gtQL8X3g8DZj6GT7K82ORuqbZDcfMung7HnbZG4cIiIitcwjkreRI0eecW4cQOfOnVm27PQ9FkOHDmXo0KHlHrdYLIwfP57x48eXe054eDgzZsw4YzwilRbfG1Z/oMW6xRzOxbndPHmLbG88a6FuERGpZzxi2KRIvdHiIrB4QfpOyNhndjRS33hK8hbR1ng+fhBOZpgaioiISG1S8ibiTvxD4KzzjO1d7rdAstRhtgJIMZYJIPpsc2M5k4BQaFg4xzhtq6mhiIiI1CYlbyLuJr638bxrsalhSD1zZAfknwSfBhAeZ3Y0ZxZZOO8tTRUnRUSk/lDyJuJuWvYxnnctAZvN3Fik/nAMmYzqAFYvc2OpiIjCipOa9yYiIvWIkjcRd3NWV6P3I/swpG40OxqpLzyl0qSDet5ERKQeUvIm4m68fY3CJaCqk1J7PKVYiYN63kREpB5S8ibijhzz3nZq3pvUArsdDjl63jqbG0tFOSpOZiXDyaPmxiIiIlJLlLyJuKP4wnlve3+G/BxzY5G6LyvFGKZrsUJkO7OjqRj/YAhuamyr901EROoJJW8i7iiyHTSINKr//bXa7GikrnMMmWzcBnwDzY2lMjTvTURE6hnvipzUpUsXLBZLhS64du3aagUkIoDFYgyd3PClMe8trqfZEUlddugP49lT5rs5RCTAjh/U8yYiIvVGhXrehgwZwlVXXcVVV13FgAED2LlzJ35+fvTu3ZvevXvj7+/Pzp07GTBgQE3HK1J/ONd7+8nMKKQ+8LRiJQ6R7Y3n1E3mxiEiIlJLKtTz9uyzzzq3b7/9du677z5eeOGFUuf89ddfro1OpD5zJG8H1xoFGQLCTA1H6jCPTd4cwybV8yYiIvVDpee8zZw5k5tvvrnU/htvvJGvv/7aJUGJCBByljEHyW6DPcvNjkbqqpzjkL7L2I7ysOStcWHFyRNpcOKIubGIiIjUgkonbwEBAaxYsaLU/hUrVuDv7++SoESkkIZOSk1L2QTYoWEMBEWYHU3l+AVBaDNjW0VLRESkHqjQsMni7r//fu6++27Wrl3LBRdcAMCqVav46KOPeOaZZ1weoEi9Ft8bVk9R8iY1J9mxvpuH9bo5RLSDjH2Quhla9DA7GhERkRpV6eTt8ccfJz4+nkmTJvHZZ58B0K5dO6ZOncp1113n8gBF6rUWPYy1t47sgIy/IDTW7IikrnHOd/OQxbn/LjIBtn+veW8iIlIvVCp5y8/P56WXXuK2225ToiZSG/xD4KzzYP+vRu/buTeZHZHUNXWh5w20XICIiNQLlZrz5u3tzYQJE8jPz6+peETk7+L7GM8aOimuVpBfOOcNz03etFC3iIjUI5UuWNK3b1+WLFlSE7GISFmKFy2x2cyMROqaI9uhIAd8gyAszuxoqqZxW8AC2UcgK83saERERGpUpee8XXbZZTz++ONs2LCB8847jwYNGpQ4fuWVV7osOBEBmp4PPoGQfdhYjDi6o9kRSV3hmO8W1RGslf5bnnvwDYSw5nB0j9H75mkVM0VERCqh0snbPffcA8Abb7xR6pjFYqGgoKD6UYlIEW9faH4R7EiCXYuVvInrePp8N4eIdkbylroF4nqZHY2IiEiNqfSfWm02W7kPJW4iNaSl5r1JDXBWmvTw5C3SUbRkk7lxiIiI1DAPHScjUs845r3t/Rnyc0wNReoIu70oeYvx0GUCHBzJm5YLEBGROq7SwyYBTpw4wZIlS9i3bx+5ubkljt13330uCUxEiolsDw0i4ESasWyAFiOW6so8aBT5sHgVldv3VBGFFSdTNxtJqcVibjwiIiI1pNLJ27p16xg0aBDZ2dmcOHGC8PBwDh8+TGBgIJGRkUreRGqCxWL0vm2YaQydVPIm1eXodYtoCz7+5sZSXY3bGIvZn8qArBRoGG12RCIiIjWi0sMmH3jgAa644gqOHj1KQEAAv/zyC3v37uW8887jtddeq4kYRQSKhk7uXGxqGFJH1JX5bmAkn46lDlK13puIiNRdlU7efv/9dx566CGsViteXl7k5OQQGxvLhAkTePLJJ2siRhGBouTt4Fo4mWFmJFIX1JVKkw6a9yYiIvVApZM3Hx8frIXrAUVGRrJv3z4AQkJC+Ouvv1wbnYgUCWkKjVqD3QZ7lpsdjXi6utTzBiXnvYmIiNRRlU7eunTpwq+//grAxRdfzLhx45g+fTr3338/HTtq/SmRGuXofdOSAVIdpzLh6G5jO9rDK006qOdNRETqgUonby+99BIxMTEA/Otf/yIsLIy7776btLQ0pkyZ4vIARaQYZ/KmeW9SDSkbjefgphAYbm4sruLsedtiVJwUERGpgypdbbJr167O7cjISBYsWODSgETkNFr0MKrqHdkBGX9BaKzZEYknqmvz3QAatzaWPcg5BscPQXATsyMSERFxuUr3vH300Ufs3r27JmIRkTMJCIWzzjO2dy8xNRTxYHUxefP2g/B4Y1vz3kREpI6qdPL28ssv06pVK5o1a8ZNN93Ehx9+yI4dO2oiNhEpi+a9SXXVtWIlDo55b0reRESkjqp08rZ9+3b27dvHyy+/TGBgIK+99hpt27aladOm3HjjjTURo4gUVzx509weqayCvKLkpq4mb2lK3kREpG6qdPIGcNZZZzFixAjefPNNJk2axE033URKSgqff/65q+MTkb9rej74BMKJtKLCEyIVdXgbFOSCXzCENjc7GtcqXrRERESkDqp08rZw4UKefPJJunfvTqNGjXjiiScICwvjq6++Ii0trSZiFJHivP2g+UXGtoZOSmU5hkxGdQRrlf5+576cPW9b1SstIiJ1UqWrTQ4cOJCIiAgeeugh5s2bR2hoaA2EJSKnFd8bdiQZyVv3MWZHI57EkbzF1JH13YoLbwlWb8g9Dsf2qxqriIjUOZX+s+sbb7zBRRddxIQJE+jQoQM33HADU6ZMYdu2bTURn4iUxTHvbe8KyM81NRTxMIf+MJ7r2nw3AG9faNTK2NZi3SIiUgdVOnm7//77mTVrFocPH2bBggV0796dBQsW0LFjR5o2bVoTMYrI30W2hwYRkJcN+381OxrxFHZ73a006eCc96aiJSIiUvdUacKD3W5n7dq1JCUl8f3337N48WJsNhsRERGujk9EymK1QtzFxvauxebGIp7j2H44lWEMLXQkOXWNc96bet5ERKTuqXTydsUVV9CoUSMuuOACpk+fTps2bfj44485fPgw69atq4kYRaQsLfsYzypaIhXl6HWLSDAK39RF6nkTEZE6rNIFSxISErjzzjvp2bMnISEhNRGTiFSEo+ftwBo4dQz89fMoZ1DXh0xCyYqTNlvdq6gpIiL1WqWTt1dffdW5ferUKfz9/V0akIhUUGisUZzhyA7YsxwSBpsdkbi75PXGc11O3sLjweoDeSfg2F8QVsfWshMRkXqt0n+StNlsvPDCC5x11lkEBQWxa9cuAJ555hn+85//uDxAETkNR9XJnZr3JhXgTN7q4DIBDl4+0LiNsa2hkyIiUsdUOnl78cUXmTZtGhMmTMDX19e5v2PHjnz44YcuDU5EzsCRvGnem5zJyQzI2GdsR3c0NZQaF1k47y1NyZuIiNQtlU7ePvnkE6ZMmcKIESPw8vJy7j/77LPZskXVvURqVYueYLHCke1GJUGR8qT8aTyHNIOAMHNjqWkRhfPeUvV/koiI1C2VTt4OHDhAq1atSu232Wzk5eW5JCgRqaCAUGhyrrG9a4mpoYibqw/FShzU8yYiInVUpZO39u3bs2zZslL7v/rqK7p06eKSoESkEjR0UiqiPiVvjp63tG1GxUkREZE6otLVJseNG8ctt9zCgQMHsNlszJo1i61bt/LJJ58wZ86cmohRRE4nvjcse81I3ux2sFjMjkjcUX2oNOkQHgdefpB/EjL2GBUoRURE6oBK97xdddVVfPfdd/zwww80aNCAcePGsXnzZr777jsuvfTSmohRRE4n9gLwCYQTqZC6yexoxB3l5xbN/6oPyZvVq1jFSc17ExGRuqNKq5f27NmTpKQkUlNTyc7OZvny5fTv35/ffvvN1fGJyJl4+0Hz7sa2hk5KWdK2gC3PWMg9tJnZ0dQOzXsTEZE6qNLJW1ZWFidPniyx7/fff+eKK64gMTHRZYGJSCVo3pucjnO+W+f6M6w2ojB5U8+biIjUIRVO3v766y+6detGSEgIISEhPPjgg2RnZ3PzzTeTmJhIgwYN+Pnnn2syVhEpjyN527PCGCInUlx9KlbiEOkoWqKeNxERqTsqXLDkkUce4dSpU0yaNIlZs2YxadIkli1bRmJiIjt37qRp06Y1GaeInE5kBwhsDNmHYf+v0OIisyMSd1Kvk7dtYCsw5sGJiIh4uAr3vC1dupT333+fMWPG8Pnnn2O32xkxYgTvvPOOEjcRs1mtGjopZbPb62fyFtoCvAOgIAfSd5sdjYiIiEtUOHlLSUkhLi4OgMjISAIDA7nssstqLDARqSQlb1KWjH2QcwysPtC4rdnR1B6rFSIKK05q6KSIiNQRlSpYYrVaS2z7+vq6PCARqSJH8nZgDZw6Zmoo4kYcvW6RCeBdz/7NdizWraIlIiJSR1R4zpvdbqdNmzZYCiuVZWVl0aVLlxIJHUB6erprIxSRigmNhfCWkL4T9iyHhMFmRyTuwLk4d2dz4zCDlgsQEZE6psLJ29SpU2syDhFxhfjeRvK26yclb2IovkxAfaOeNxERqWMqnLzdcsstNRmHiLhCyz7w2380702K1MdiJQ6Onrcj26EgH7wq/F+eiIiIW6r0It0i4sZa9ACLFQ5vg2MHzI5GzJadDsf+MrajO5obixlCmoFPIBTkQvous6MRERGpNiVvInVJQBg06WJs715ibixivpQ/jefQ5uAfYm4sZrBaIaKwwqbmvYmISB2g5E2krnFUndy52NQwxA3U5yGTDpr3JiIidYiSN5G6pvh6b3a7mZGI2epzsRIHVZwUEZE6RMmbSF0TmwjeAXAiFVL1C2u9dsixTEA97nmLbG88q+dNRETqgEqX3iooKGDatGn8+OOPpKamYrPZShxftGiRy4ITkSrw9oPm3WHnj0bvW1R7syMSM+SdgsNbje2YetzzFlGs4mR+bv1bqFxEROqUSidvY8eOZdq0aQwePJiOHTs6F+0WETcS37sweVsM3e4xOxoxQ9oWsOUbRWyCzzI7GvOENAXfhpB73FgDMbKd2RGJiIhUWaWTt88//5wvv/ySQYMG1UQ8IuIKjnlve1aot6G+Kl6spD7/kc1iMSpOHvjNGEas5E1ERDxYpee8+fr60qpVq5qIRURcJaojBDaGvBPGL61S/6hYSRFn0RLNexMREc9W6eTtoYceYtKkSdhVxU7EfVmtEH+xsb3rJ1NDEZNomYAizuUCVMBHREQ8W6WHTS5fvpzFixczf/58OnTogI+PT4njs2bNcllwIlIN8b3hz6+N5K3Pk2ZHI7XJZlPyVpx63kREpI6odPIWGhrK1VdfXROxiIgrOea97f8NTh0D/xBTw5FalLHHKNDh5QeN25gdjfkcPW9HdkJ+jlGRVURExANVOnmbOnVqTcQhIq4W2gzC4yF9l1G4JEFFhuoNR69bZDvw8jn9ufVBcBPwC4acTDiyA6I6mB2RiIhIlWiRbpG6LL6P8ax5b/WLhkyWZLEUrfemeW8iIuLBKt3zBvDVV1/x5Zdfsm/fPnJzc0scW7t2rUsCExEXiO8Nv/1HyVt9o0qTpUUmwP7VmvcmIiIerdI9b2+99Ra33norUVFRrFu3jgsuuIBGjRqxa9cuLrvsspqIUUSqKq4nYIHDW+HYAbOjkdqinrfSItsbz+p5ExERD1bp5O29995jypQpvP322/j6+vLoo4+SlJTEfffdx7Fjx2oiRhGpqoAwaNLF2N69xNxYpHacOAKZhYm65nYViVDFSRER8XyVTt727dtH9+7dAQgICOD48eMA3HTTTfz3v/91bXQiUn2OqpMaOlk/pBT2uoXFgX+wubG4k8jCipPpuyDvlLmxiIiIVFGlk7fo6GjS09MBaNasGb/88gsAu3fv1sLdIu6oZbGiJfoZrfsOrTeeNWSypKAo8A8Fuw0ObzM7GhERkSqpdPJ2ySWX8L///Q+AW2+9lQceeIBLL72UYcOGaf03EXfU9ALwDoCsFA0Zqw8c891iVKykBIulqPdNPwciIuKhKl1tcsqUKdhsNgDuvfdeGjVqxM8//8yVV17JnXfe6fIARaSafPyheTfYuQh2Li76BVbqJlWaLF9EAuxbqaIlIiLisSqdvFmtVqzWog674cOHM3z4cJcGJSIuFt/bSN52/QTd7jE7GqkpeSeLhgRq2GRp6nkTEREPV6VFupctW8aNN95It27dOHDAqGr26aefsnz5cpcGJyIu4lise89yKMgzNxapOambwV4AgY2gYYzZ0bgfLdQtIiIertLJ29dff82AAQMICAhg3bp15OTkAHDs2DFeeukllwfocOWVV9KsWTP8/f2JiYnhpptu4uDBgyXOWb9+PT179sTf35/Y2FgmTJhQ6jozZ84kISEBf39/OnXqxLx580oct9vtjBs3jpiYGAICAujXrx/bt28vcU56ejojRowgODiY0NBQRo0aRVZWluvftIirRHU0fqHPOwH7fzM7Gqkpxdd3s1jMjcUdOXreju6B3GxTQxEREamKSidvL774IpMnT+b//u//8PHxce6/6KKLWLt2rUuDK65Pnz58+eWXbN26la+//pqdO3fyj3/8w3k8MzOT/v3707x5c9asWcOrr77Kc889x5QpU5zn/Pzzz1x//fWMGjWKdevWMWTIEIYMGcKff/7pPGfChAm89dZbTJ48mVWrVtGgQQMGDBjAqVNFpaVHjBjBxo0bSUpKYs6cOSxdupTRo0fX2HsXqTarFeIuNra1ZEDdpcW5T69BBASEA3ZVnBQREY9U6eRt69at9OrVq9T+kJAQMjIyXBFTmR544AEuvPBCmjdvTvfu3Xn88cf55ZdfyMszhoBNnz6d3NxcPvroIzp06MDw4cO57777eOONN5zXmDRpEgMHDuSRRx6hXbt2vPDCC5x77rm88847gNHrNnHiRJ5++mmuuuoqOnfuzCeffMLBgweZPXs2AJs3b2bBggV8+OGHJCYm0qNHD95++20+//zzUj2BIm7Fud7bYlPDkBqU7FgmQMVKyqSKkyIi4uEqXbAkOjqaHTt20KJFixL7ly9fTnx8vKviOq309HSmT59O9+7dnb1/K1eupFevXvj6+jrPGzBgAK+88gpHjx4lLCyMlStX8uCDD5a41oABA5yJ2e7du0lOTqZfv37O4yEhISQmJrJy5UqGDx/OypUrCQ0NpWvXrs5z+vXrh9VqZdWqVeUul5CTk+McYgpGTyFAXl6eMwGVynO0ndqwApr1wAew7/+N/Kx08GtY5Uup3c1x2na32/BO/hMLkNe4Peh7UyZr47Z47V1BQfJGbO0r1kb6vJtD7W4Otbs51O7mcKd2r2gMlU7e7rjjDsaOHctHH32ExWLh4MGDrFy5kocffphnnnmm0oFWxmOPPcY777xDdnY2F154IXPmzHEeS05OJi4ursT5UVFRzmNhYWEkJyc79xU/Jzk52Xle8deVd05kZGSJ497e3oSHhzvPKcvLL7/M888/X2r/woULCQwMPO37ljNLSkoyOwSP0NcviqCcFNbMeouUkC7Vvp7a3RxltXuDU8n0yztBgcWH+au3YbfsNCEy99ciLZ+zgbSNS1l1at4Zzy9On3dzqN3NoXY3h9rdHO7Q7tnZFZuLXenk7fHHH8dms9G3b1+ys7Pp1asXfn5+PPzww/zzn/+s9LVeeeWV056zefNmEhKMCmGPPPIIo0aNYu/evTz//PPcfPPNzJkzB4sHTMx/4oknSvT6ZWZmEhsbS//+/QkODjYxMs+Wl5dHUlISl156aYk5mFI2q2URrJ3G+Y1OYOs/qMrXUbub43Ttbtn8LWwGS3RHLht8hUkRuj/L3hD47BOiLOkMGlSxnwF93s2hdjeH2t0candzuFO7O0blnUmlkzeLxcJTTz3FI488wo4dO8jKyqJ9+/YEBQVVOsiHHnqIkSNHnvac4kMxGzduTOPGjWnTpg3t2rUjNjaWX375hW7duhEdHU1KSkqJ1zq+jo6Odj6XdU7x4459MTExJc4555xznOekpqaWuEZ+fj7p6enO15fFz88PPz+/Uvt9fHxM/7DUBWrHCmp1CaydhtfuJXi5oL3U7uYos93TNgFgjemMVd+T8sUYxVwsx/bhY8sBv4r/36XPuznU7uZQu5tD7W4Od2j3it6/Suu8Afj6+tK+fXsuuOCCKiVuABERESQkJJz2UXwOW3E2mw3AOY+sW7duLF26tMR40aSkJNq2bUtYWJjznB9//LHEdZKSkujWrRsAcXFxREdHlzgnMzOTVatWOc/p1q0bGRkZrFmzxnnOokWLsNlsJCYmVqkdRGpNi56ABQ5vhUwV2KlTVGmyYho0MqpOgvFzICIi4kEq3PN22223Vei8jz76qMrBlGfVqlX8+uuv9OjRg7CwMHbu3MkzzzxDy5YtnUnVDTfcwPPPP8+oUaN47LHH+PPPP5k0aRJvvvmm8zpjx47l4osv5vXXX2fw4MF8/vnn/Pbbb87lBCwWC/fffz8vvvgirVu3Ji4ujmeeeYYmTZowZMgQANq1a8fAgQO54447mDx5Mnl5eYwZM4bhw4fTpEkTl793EZcKDIcm58DBdbBrCZxzvdkRiascUqXJCotIgBNpkLoFzjrP7GhEREQqrMLJ27Rp02jevDldunTBbrfXZEylBAYGMmvWLJ599llOnDhBTEwMAwcO5Omnn3YORQwJCWHhwoXce++9nHfeeTRu3Jhx48aVWH+te/fuzJgxg6effponn3yS1q1bM3v2bDp27Og859FHH+XEiROMHj2ajIwMevTowYIFC/D393eeM336dMaMGUPfvn2xWq1ce+21vPXWW7XXICLVEd+nMHn7SclbXZGVClnJgAWiOpgdjfuLbAd7lkHaZrMjERERqZQKJ2933303//3vf9m9eze33norN954I+Hh4TUZm1OnTp1YtGjRGc/r3Lkzy5YtO+05Q4cOZejQoeUet1gsjB8/nvHjx5d7Tnh4ODNmzDhjPCJuKb43LH/DSN7sdmPtK/FsjiGTjVpWag5XvRVhFMEiVWu9iYiIZ6nwnLd3332XQ4cO8eijj/Ldd98RGxvLddddx/fff1/rPXEiUg2xieDtb/TUaKHiukHz3SpHC3WLiIiHqlTBEj8/P66//nqSkpLYtGkTHTp04J577qFFixZkZWXVVIwi4ko+/tDMmCvKrp9MDUVcRMlb5Th63o79BTnHzY1FRESkEqpcbdJqtWKxWLDb7RQUFLgyJhGpafG9jWclb3WDM3lTsZIKCQyHoChjO00VJ0VExHNUKnnLycnhv//9L5deeilt2rRhw4YNvPPOO+zbt6/KywWIiAla9jGe9yyHgrzTnyvuLTcbjmw3ttXzVnGOoZOpKloiIiKeo8IFS+655x4+//xzYmNjue222/jvf/9L48aNazI2EakpUZ0gIBxOpsOBNdDsQrMjkqpK3QR2m7F2maM3Sc4sop3R86x5byIi4kEqnLxNnjyZZs2aER8fz5IlS1iyZEmZ582aNctlwYlIDbFaIf5i2PgN7Fys5M2TJTvWd+ukyqGVEemoOLnJ3DhEREQqocLJ280334xFvxiI1B3xvY3kbddP0OcJs6ORqtJ8t6qJcAybVM+biIh4jkot0i0idUh84by3/b/CqUzwDzY3HqkaVZqsmoi2xvPxg3AyAwJCzYxGRESkQqpcbVJEPFxYcwiLA3sB7P3Z7GikKmwFkLLR2FbPW+UEhELDJsa2Kk6KiIiHUPImUp85lwxYbGoYUkXpuyAvG7wDoFFLs6PxPI55b2mqOCkiIp5ByZtIfab13jybo1hJVAewepkbiyfSvDcREfEwSt5E6rO4XoDFKJeeecjsaKSyDhWrNCmVp543ERHxMEreROqzwHBoco6xvbvs5T/EjalYSfWo501ERDyMkjeR+k5DJz2XI3mLOdvcODyVo+JkVjKcPGpuLCIiIhWg5E2kvnMkbzsXg91uaihSCcdT4EQqWKwQ2d7saDyTfzCExBrb6n0TEREPoORNpL6LvRC8/Y3eB5VM9xyOXrdGrcA30NxYPFmE5r2JiIjnUPImUt/5+EOzC41tDZ30HMkqVuISjqIlqUreRETE/Sl5ExGI72M8K3nzHCpW4hrOoiVK3kRExP0peRORonlve5ZDQZ6poUgFqefNNZzLBWjOm4iIuD8lbyIC0Z0hIAxyj8OBNWZHI2eSmwVHdhrb0Z3NjcXTNS6sOHkiDU4cMTcWERGRM1DyJiJgtULcxca2hk66PUvqZsAOQdEQFGl2OJ7NLwhCmxnbKloiIiJuTsmbiBhaat6bp7CkaL6bS2nem4iIeAglbyJicMx72/8r5Bw3NRQ5g5Q/jWclb66heW8iIuIhlLyJiCGshfGw5cOeFWZHI6dhUfLmWs6eNyVvIiLi3pS8iUgRR++bhk66LYu9AEvqJuMLFStxjUgt1C0iIp5ByZuIFFHy5vaCTiVjyT8FPg0gPM7scOqGxm0BC2Qfgaw0s6MREREpl5I3ESkSdzFgMXogjiebHY2UIfjkXmMjqgNYvcwNpq7wDTSGDIN630RExK0peRORIoHhEHO2sb1ribmxSJlCTu4zNmI0ZNKlIjXvTURE3J+SNxEpyTl0crGpYUjZnMmbipW4VkThvDfHfEIRERE3pORNREoqPu/NbjczEvk7u50Qx7BJJW+u5eh503IBIiLixpS8iUhJzS4ELz84fggObzM7GikuKxm//OPYLVaIbG92NHWLs+dts/5oISIibkvJm4iU5BMAzbsZ26o66Vac67s1am18n8R1GrcBixVOZUBWitnRiIiIlEnJm4iU5hg6uVPz3tyJJXkDAPaojiZHUgf5+ENY4dILqao4KSIi7knJm4iU5kje9iyHgjxTQ5Eijp43JW81RPPeRETEzSl5E5HSojtDQBjkHocDa82ORgpZUgp73qK1TECNKD7vTURExA0peROR0qxehQt2o3lv7iLnOJajuwGwR3YwOZg6Sj1vIiLi5pS8iUjZii8ZIObbswKAbJ9waNDY5GDqqOILdavipIiIuCElbyJSNkfytn815Bw3NRQBNswE4FBoV5MDqcMatQKLF+QcM5bKEBERcTNK3kSkbOFxENocbPmw92ezo6nfcrJg6zwA9od1MzmYOszbDxq1NLY1701ERNyQkjcRKZ+GTrqHrfMhLxt7WBwZgfFmR1O3qWiJiIi4MSVvIlK+ln2MZyVv5iocMmnrcA1YLCYHU8c5i5YoeRMREfej5E1EyteiF2CB1E1wPNnsaOqnE0dg548A2Dr8w+Rg6gFnz5sqToqIiPtR8iYi5WvQCGIK1xTbtcTcWOqrTd8Y8w5jzobGrc2Opu5z9rxtVcVJERFxO0reROT0NO/NXBu+Mp47DTU3jvoivCVYvY0F6o/tNzsaERGREpS8icjpFU/e1BNRuzL2wb6VgAU6XGN2NPWDt6+xZABosW4REXE7St5E5PSadQMvPzh+EA5vNzua+uXPr43nFj0g5CxzY6lPVHFSRETclJI3ETk9nwBodqGxvWuxubHUN84hkypUUquc897U8yYiIu5FyZuInJnmvdW+lE2Q8idYfaD9VWZHU784kjf1vImIiJtR8iYiZ+ZI3nYvg4J8U0OpNwrXdqN1fwgIMzeW+iaiWMVJm83cWERERIpR8iYiZxZzNviHGhX4Dq41O5q6z27XkEkzhceDly/knYBjf5kdjYiIiJO32QGIiAewekH8xbDpW2PoZHQXsyOq2/5aDcf2gW8QtBlodjT1j5c3NGoNqRuNoZNBTcyOSNxR3inISobjKXD8EGSlwPFk43EiDRpGQWR7YxhuZAcIigSLxeyoRcTDKXkTkYqJ720kbzsXQ/cHzI6mbnMMmUy4HHwDzY2lvopMMJK3tM0Q39fsaKQ25Z0sSsKykottFyZpjmTtVEblrhsQXiyZawdRHYzKpgGhNfEuRKSOUvImIhXjmPe2fzXkZpkaSp1WkAcbvzG2tTC3eRzz3lJVcbLOyD1RdhJW/OusZDh1rOLX9PKFhtEQFG08Ox6BjSHzAKRuMnpv03fByXTYu9x4FBd8VlFCF9neeES0NSr9ioj8jZI3EamYsDgIbQYZ+7DsW2l2NHXXrp8g+7Dxy58jYZbaF1m41luaKk66vZysYglYGT1mjoQtJ7Pi1/T2L5aURUHDGAgqfC7+dUBYxYZC5p2Ew9uMKrKOhC51M2TuN5K8zAOw44ei8y1W499cR0IXVZjUhbc0hvWKSL2lfwFEpGIsFojvA2s/xrJ7CdDd7IjqJseQyY7X6Jc0MzkrTm4DuypOmiLvJEGnDmHZu9z4g0aphKzwuTIjAbwDCnvH/paEOXrMHD1o/iGunZ/mE2AUfoo5u+T+U8eM3l3H/MrUzZCy0eilS99pPLbMKTrfyxcatynZSxfZDkJiwaoadCL1gX4zEJGKi+8Naz/GunsJNFXy5nK52bC58Bc1DZk0V3gcePlB/knI2Gt2NPXPwd/x/uxa+mYfhop0fvo0KDlssfgwxuI9Zn7B7lU0xD8EmiUaDwe73Sh4kuJI6Ir11OWdMNZ/TPmz5HV8g4z5c1HFErrI9kaRFBGpU5S8iUjFxV0MgCVtM35RGebGUhdtm2/8chbaDJqeb3Y09ZvVy+jhSNmAJU3z3mqVrQC+uw9L9mHyrX54hTbFEtykZA/Z34cx+jU0O2rXsViMpCsoElr2KdpvsxlLV6T+behl2laj9/HAb8ajuMDGxXrpHM8JRtIoIh5JyZuIVFyDRhDdGZLXE3F8k9nR1D3Otd2GulfvQH0VmVCYvG0F2pgdTf3x20dw6A/sfsH80Ppf9L3qenx8fMyOynxWK4Q1Nx5tLyvaX5AHR3YWS+iKFUnJPgx7lhmP4kJi/1YkpR00bgs+/rX7nuqrE4eNpPvwNuORthXvo3u4KNcb67wfIaodNG5tfE9Cmur/AylByZuIVE5878LkbaPZkdQt2emwPcnY7nSdubGIIdKY92Y5vAV8lLzViqw0WPQCALbeT5GTqh6iM/LyMf7Q4Ciy45CbDYe3lh56mXnA6ME79hdsX1h0vsUK4S3xikig3VE7lnWHoXErCGthVMTUHNzKsdmMgjRp24zvgyNZS9tqzGn8GwvQGGDd1pIHfBoYiVxEW2M0QERbI6kLjzO+91Lv6CdRRCqnZR/4+S0iMzcYw5vQfx4uselbsOVBVKfSv4SJOQqLlljStoLW6a4dSeOMIh4xZ2M7dyQs+N7siDyXbyA06WI8ijuZUTqhS90IJ4/Cke1Yj2w3+pnnFSuUYvU2euvCWpT9qM9r1eXnGr2chx1JWuHz4e2Ql13+60KaQUQbIxGLaEN+w1j+WPE955wViFf6duN66buMofSHfjcexVl9IDy+2DUKk7vGrcG3QU2+YzGZkjcRqZxm3bEHhOF/8ij527+HjleZHVHd4Bwy+Q9z45AijiT68DaIUcXJGrd3JfwxA7DA4DeMeYfiegGh0Lyb8XCw243lFFI3UZC8kb3rfqJFCFiP7YOje6EgB47uNh5l8Q81krjwuNKJXXDTutFrl5NVYpij8/nobrDll/0aqw80alk0BPI0CZY9L4/9m7Po3GcQXo5hwvm5xvXTtpadGB4u3M93Je8bElusl65Yb12DRq5vF6l1deCnSURqlY8/tnNuwmvlW1h/+z8lb65wbD/sXWFsd7zW3FikSGgL8A7Akn+SBjkpZkdTtxXkw9yHjO1zb4amXSEvz9yY6hOLxVkMxtasJxsONyN20CCsPj7G8L/jh+DonrIfJ1LhVEbZvUMAFi8IPV2vXVgtvMEKstuN+Wh/70VL22YMgSyPb1CxBK1YT1hYi+oNbfT2Na4T0bbkfpvNGP769xgPb4XsI0XDYnf+WPJ1gY3+FmMbzavzQEreRKTSbOfdinXl21j3LDOG3BTODZIq+nMWYIdm3Y1fcsQ9WK3GLzeH/iD41AGzo6nbVn9gDN0LCId+z5kdjRRntULIWcajxUWlj+eeMHrnnAnd7mLbjl67wq/L4ui1K+sR0rRm5nU5Knc6e9GKJT8nj5b/ugYRhT1nf+vVCj6rdpMfq9X4vyI0Flr1K3nsxJHSc+wOb4dj+4zEbt/PxqM4nwbG/Ma/J5/h8ZpX54aUvIlI5YXEcijkPJoc+w1WfQBXTDQ7Is/mWJhbQybdT0Q7OPQHDZW81ZzMg7D4JWO733MQGG5qOFJJvg2M9eWi2pc+ZrMZi6mX1WOXvrtivXYhTUsmdMWHZp6p1845H21rycIhR3acZj6axUiKig9zdDx7wmezQSNo0B2a/20t1twTRhL394Q1fWfhvLo/jEdxVm8jgSs+9DKiMHnVvDrTKHkTkSrZFXGpkbyt/wL6PeteQ188SdpWSF5v/CfZ4Wqzo5G/K5z31vCkkrca8/1TxjplTc+HLjeZHY24ktUKwU2Mx9+TCSij1+5vj4IcyNhrPHYvKf16/5DS8+uOHyxK1NJ3g72gnNh8oFGromTEkZg0am0Ue6lrfBtAk3OMR3EFeUY7OXvrthcldnkniub5bZlT8nWOeXWN2xi9dj6e2WaWggLCTnjWsHglbyJSJUeCErBHtseSugnWTYfuY8wOyTM5et1a9fOMv+rWN5FGb0LjrM1GFUSfxiYHVMfs+gk2zjLK1A9+3fhlX+qPM/bapZQxFLPwkZVi/EyW1WNU4h4Nyy61H9aibhRSqS4vHyNpjWgD7a4o2m+3G/PqSgy/LHzOPlz+vDoP4w3ENuoDjDU7lArTp1ZEqsZioaDr7XjPexBWT4EL71Z1uMqy24sNmRxqbixStrhe2MPi8D+6G9vCJ+Da/zM7orojPwfmPmxsn38HxJxtbjziXqxWCI4xHsUrYzrknoCMfSUTumP7ISiy5Nyt4CYqxlEVFosxZDWkKbTqW/JYdnrR0MvD242hqQWeWWDIZrdzPCfa7DAqRcmbiFSZveM/YNF4Y0jL9oXQ9jKzQ/IsB9YYv3D4BKrt3JVPAAVXvofXx4OwbvgSEgZDhyFmR1U3rHwHjmyHBpFwyVNmRyOexreBUSxLBbNqX2B46eUmPFRBXh67583Dkz5FGp8gIlXnE2iU9QZYNdncWDyRo9ctYbAmf7sxe9Pz2R51ufHFnPvheLKp8dQJGftgyavGdv8XjblLIiJyRkreRKR6zr/dmK+y6ydI3WJ2NJ6jIL9wiQCg03XmxiJntCX6auxRnYwy4t+OMYa8StUteALyT0LzHtBZn38RkYpS8iYi1RPWHNoOMrZXTzE3Fk+ye4lRJjsgHFr2MTsaOQO71Zv8q94HLz/YkQRrppodkufattCoXGf1hsGvaT6SiEglKHkTkepLvNN4/uNzOJlhaigeY8NXxnOHq7UIqqeISDCWxQCjvP2RnebG44nyTsL8R4ztC+/WfCURkUpS8iYi1deip1FSPe8E/D7d7GjcX95J2Pydsa0qk54l8W7j856XDd/caQx/lYpbPtEo0tOwCVz8uNnRiIh4HCVvIlJ9FgtcMNrYXj0FbOUsiiqGbd9D7nFjkdPYRLOjkcqwWmHI++AXDPt/hRVvmh2R5ziyE5YXttfAl8AvyNx4REQ8kJI3EXGNztcZFeOO7oHtSWZH494cVSY7XqtFiT1RaCwMKqyU+NO/4eDvpobjEex2mP8oFORAfB9oP8TsiEREPJJ+axAR1/BtULRswOoPzI3FnZ3MMNbEA1XZ82Sdh0G7K8GWbwyfzDtpdkTubfN3sOMH8PKFQSpSIiJSVUreRMR1zr8dsMDORZC2zexo3NPm/0FBrjFHMKqD2dFIVVkscPlEY4HptC3w43izI3JfuSeMpQEALhoLjVuZG4+IiAdT8iYirhPWQssGnIljyGSnf5gbh1Rfg0Zw1bvG9i/vwa4l5sbjrpZMgMz9ENoMejxodjQiIh5NyZuIuFZiYeGS32fAqWPmxuJuMg/B7mXGdsdrzY1FXKNNfzjvVmN79j1aKuPv0rbCyneM7csmgG+gufGIiHg4JW8i4lpxFxvrYeWdMBI4KbJxFmA3KkyGtTA7GnGV/i9CWJzRuzT/UbOjcR92O8x9yJgX2OYyaHuZ2RGJiHg8JW8i4lqllg2wmRuPO3EOmdTabnWKXxBcMwUsVlj/BWycbXZE7uHPr2HPMvD2h8v+bXY0IiJ1gpI3EXG9zsPALwTSdxkV5gQO74CD68DiBR2uNjsacbXYC4rmc825H44nmxqO6U5lwvdPGds9H1ZPs4iIiyh5ExHX8wuCc28ytldNNjcWd+HodWt5CTRobG4sUjMufgyiO8PJo/DtGGPYYH3108uQlQzhLeGi+8yORkSkzvC45C0nJ4dzzjkHi8XC77//XuLY+vXr6dmzJ/7+/sTGxjJhwoRSr585cyYJCQn4+/vTqVMn5s2bV+K43W5n3LhxxMTEEBAQQL9+/di+fXuJc9LT0xkxYgTBwcGEhoYyatQosrKyXP5eRTyac9mAH+Hw9jOeXqfZ7RoyWR94+8I1/wdefrAjCX77yOyIzJG8oeiPNoNeBW8/c+MREalDPC55e/TRR2nSpEmp/ZmZmfTv35/mzZuzZs0aXn31VZ577jmmTCkqV/7zzz9z/fXXM2rUKNatW8eQIUMYMmQIf/75p/OcCRMm8NZbbzF58mRWrVpFgwYNGDBgAKdOnXKeM2LECDZu3EhSUhJz5sxh6dKljB49umbfuIinCY+DNgON7dX/Z24sZju4DtJ3gncAJAwyOxqpSZEJ0O85Y3vh03Bkp6nh1DqbzShSYrdB+6ugVV+zIxIRqVM8KnmbP38+Cxcu5LXXXit1bPr06eTm5vLRRx/RoUMHhg8fzn333ccbb7zhPGfSpEkMHDiQRx55hHbt2vHCCy9w7rnn8s47Rhlju93OxIkTefrpp7nqqqvo3Lkzn3zyCQcPHmT27NkAbN68mQULFvDhhx+SmJhIjx49ePvtt/n88885ePBgrbSDiMdwLhsw3ZgDU19t+Mp4bnsZ+DU0NxapeYl3QVwvyMuGb+6EgnyzI6o9f8yAv1aBTwMY8LLZ0YiI1DneZgdQUSkpKdxxxx3Mnj2bwMDS68SsXLmSXr164evr69w3YMAAXnnlFY4ePUpYWBgrV67kwQdLLhA6YMAAZ2K2e/dukpOT6devn/N4SEgIiYmJrFy5kuHDh7Ny5UpCQ0Pp2rWr85x+/fphtVpZtWoVV19ddiGCnJwccnJynF9nZhq/yObl5ZGXl1f5BhEAZ9upDWtXhds9tgfejdtgObyNgrWfYTv/jlqIzs3YCvD+8yssQH77a7BX47Oqz7s5qtTug9/C+/96Ytn/KwVLX8dWHxanPnkU76RxWICCXo9gC4wEfd49jtrdHGp3c7hTu1c0Bo9I3ux2OyNHjuSuu+6ia9eu7Nmzp9Q5ycnJxMXFldgXFRXlPBYWFkZycrJzX/FzkpOTnecVf11550RGRpY47u3tTXh4uPOcsrz88ss8//zzpfYvXLiwzGRUKicpKcnsEOqlirR7C/8LOZttnFwykR9TY4xy6vVI4+MbuSgrhVyvBizYlot9x7wzv+gM9Hk3R2XbvWn0DZy39wMsS15hRbIfxwLjzvwiD9b5r2nEZR8h0/8sfjrSDPu86n/WQZ93s6jdzaF2N4c7tHt2dnaFzjM1eXv88cd55ZVXTnvO5s2bWbhwIcePH+eJJ56opchc74knnijR65eZmUlsbCz9+/cnODjYxMg8W15eHklJSVx66aX4+PiYHU69Ual2z+2F/a1vCMpJYXBCAPaW9WsOjNec743nztdy2aArq3Utfd7NUeV2t1+GbdYhrFv+x8VHppN/1Y/gE1BzgZrIcnAtXusWAxD4j/e4rPlF1b6mPu/mULubQ+1uDndqd8eovDMxNXl76KGHGDly5GnPiY+PZ9GiRaxcuRI/v5IVq7p27cqIESP4+OOPiY6OJiUlpcRxx9fR0dHO57LOKX7csS8mJqbEOeecc47znNTU1BLXyM/PJz093fn6svj5+ZWKH8DHx8f0D0tdoHY0R4Xa3ScMutwEv7yH928fQsLA2gnOHeSdgi1zAPA6exheLvqM6vNujiq1+5WTYP8qLIe34bP0ZRhYB+eB2Qrg+8cAO3Qehner3i69vD7v5lC7m0Ptbg53aPeK3t/U8UsREREkJCSc9uHr68tbb73FH3/8we+//87vv//uLO//xRdf8K9//QuAbt26sXTp0hLjRZOSkmjbti1hYWHOc3788ccSMSQlJdGtWzcA4uLiiI6OLnFOZmYmq1atcp7TrVs3MjIyWLNmjfOcRYsWYbPZSExMrIFWEqkDHMsG7EiqX9X3diRBzjFo2ASadTc7GjFDYDhc9a6x/ct7sOsnU8OpEWumGRVV/YLh0hfMjkZEpE7ziMknzZo1o2PHjs5HmzZtAGjZsiVNmzYF4IYbbsDX15dRo0axceNGvvjiCyZNmlRiqOLYsWNZsGABr7/+Olu2bOG5557jt99+Y8yYMQBYLBbuv/9+XnzxRf73v/+xYcMGbr75Zpo0acKQIUMAaNeuHQMHDuSOO+5g9erVrFixgjFjxjB8+PAylzAQEaBRS2jd39hePeX059YlzrXdrgWrR/xzKzWh9aVw3q3G9ux74GSGqeG4VFYa/Dje2L7kaWgYdfrzRUSkWurMbxMhISEsXLiQ3bt3c9555/HQQw8xbty4Euuvde/enRkzZjBlyhTOPvtsvvrqK2bPnk3Hjh2d5zz66KP885//ZPTo0Zx//vlkZWWxYMEC/P39nedMnz6dhIQE+vbty6BBg+jRo0eJ9eREpAyJdxrP66ZDznFzY6kNp47B1gXGdqfrzI1FzNf/RQiPh8wDMP9Rs6NxnR+ehVMZEN0Juo4yOxoRkTrPI6pN/l2LFi2w2+2l9nfu3Jlly5ad9rVDhw5l6NCh5R63WCyMHz+e8ePHl3tOeHg4M2bMqHjAIgLxfaBRaziyHX7/b9EacHXV5jlQkAON2xq/2Er95hcEV0+Bj/rD+i+MNf86lL20jMfY94uxhiPA4DfAyyN/pRAR8Sh1pudNRNyc1VrU+7Z6Cths5sZT05xDJoeCxWJuLOIeYs8Hx3pvcx6A4+UvL+P2CvJh7kPGdpebIPYCc+MREaknlLyJSO05ezj4NjR633YtMjuamnM8BXYvMbY7XWtuLOJeLn4MYs6Gk0fh2zFQxigSj7B6CqT8CQFh0K/0GqYiIlIzlLyJSO3xawhdRhjbq+rwPNGN34DdBmd1NeY5iTh4+xrDJ738jGqkv31kdkSVl3kIFr9kbPd7Dho0MjUcEZH6RMmbiNSuCwrnum1fWHeXDXAMmeysQiVShsgEI+kBWPi05/0cLHwaco8bf5zocrPZ0YiI1CtK3kSkdjVqCa0uBezw64dmR+N6R3bCgd/AYvX8ghRScxLvgrhekJcNs0Ybc8g8wa4l8OdXxud78OtaAkNEpJbpX10RqX2JdxnP6z6DnCxzY3G1P782nuN7Q1CkqaGIG7Na4ar3wC/ESPaXv2l2RGeWnwvzHja2u46CJueYGo6ISH2k5E1Eal/LSyC8JeRkwh//NTsa17HbYf2Xxnan8pckEQEgNBYGvWpsL/k3HFxnbjxn8su7cHgbNIgwFuQWEZFap+RNRGrf35cN8NSKe3+XvN6opOnlBwmXmx2NeILO10H7q8CWD7PuhLyTZkdUtoy/YMkEY/vSFyAg1NRwRETqKyVvImKOs68H3yDjL/m7FpsdjWs4CpW0HQj+webGIp7BYoHLJ0JQFBzeCj+4adn9BY8b8/OadTeW/BAREVMoeRMRc/gHwzl1aNkAWwFsKJzv1klVJqUSAsPhqneN7VXvw66fTA2nlO1JsGUOWLxg8GtadF5ExERK3kTEPI5lA7YtgPTd5sZSXXt/huMHjQIUrS81OxrxNK0vha63Gduz74GTGaaG45R3CuY9YmxfeDdEdTA3HhGRek7Jm4iYp3EraNWPOrFsgGPIZPsrwdvP3FjEM/V/0VjUPfNAUcJkthUT4ehuaBgDvR83OxoRkXpPyZuImOuCwsIlaz/13GUD8nNg07fGtqpMSlX5NoCrpxhrqG34EjZ+Y2486btg2RvG9oCXwK+hufGIiIiSNxExWat+Rm9DzjFY/4XZ0VTNjh/hVAYERUOLHmZHI54s9nzo+ZCxPecBOJ5sThx2O8x/DApyjDULteC8iIhbUPImIuayWovmvnnqsgGOIZMdrwWrl7mxiOe7+DGIORtOHoVv7zXnZ2LLXNi+EKw+MEhFSkRE3IWSNxEx3zk3GMsGpG2B3UvMjqZyco7D1vnGdmcNmRQX8PIxhk96+cGOH+C3/9Tu/XNPGEsDAFx0HzRuXbv3FxGRcil5ExHz+YcY674BrPrA3Fgqa8tcyD8JjVpBzDlmRyN1RWQCXFq45tvCZ+DIztq799LX4NhfENIMej5ce/cVEZEzUvImIu7BMXRy63w4usfUUCrFMWSy01ANLRPXuuBOiLvYWBx71mgoyK/5e6Ztg5/fNrYv+zf4Btb8PUVEpMKUvImIe4hoAy0vAeyw+v/MjqZistJg52Jju+M/zI1F6h6rFYa8Z6wdeOA3WP5mzd7Pbod5D4EtD1oPgLaDavZ+IiJSaUreRMR9JN5lPK/71Jh34+42zQZ7ATTpYqxZJ+JqIU1h0KvG9pJ/w8F1NXevP7+G3UvB2x8ue0U9ySIibkjJm4i4j1aXQlgcnPKQZQPWf2k8d7rO3Dikbut8HbQfArZ8Y/hk3knX3+NUJnz/lLHd40EIj3P9PUREpNqUvImI+7Ba4YI7jO1Vbr5sQPpu2L8asEDHa8yORuoyiwUuf9NYR/DwNvjhedff46d/Q1aysebiRWNdf30REXEJJW8i4l7OGQE+DSBtszGEy139+bXxHNcLGkabG4vUfYHhcNU7xvaq94vmWrpCykZYNdnYHvQq+Pi77toiIuJSSt5ExL0EhMLZw43t1VNMDaVcdnvJKpMitaH1pdB1lLH97b1wMqP617TbYe5DxtzNdldCq37Vv6aIiNQYJW8i4n6cywbMg6N7zY2lLCkbjQXFvXyh3RVmRyP1Sf8XILwlZB6AeY9U/3p//Bf2rTR6uwe+XP3riYhIjVLyJiLuJzIB4nuD3Qa/fmh2NKU5et1a9zd6CkVqi28DuPoDsFhhw5fw56yqX+vkUWMBcICLHzUqW4qIiFtT8iYi7smxbMDaTyA329xYirPZYMNXxnZnVZkUE8SeDz0fMrbnPACZh6p2nUUvQvZhaNwWLrzHdfGJiEiNUfImIu6pdX8IbQ6nMoweBnfx1y+QuR/8go0YRcxw8WMQc47x8/HtvZWvzHpgLfz6H2N78Ovg7evqCEVEpAYoeRMR92T1Kpr75k7LBjiGTLa7AnwCzI1F6i8vH7hmirGg9s4f4bf/VPy1tgKjSAl2o+BOXM8aC1NERFxLyZuIuK8uN4JPIKRuhD3LzY4G8nNh4zfGdqd/mBuLSERb6Pecsb3wGTi8o2KvW/sxHFxr9B73f7HGwhMREddT8iYi7qvEsgEfmBoKALsWG0UeGkRCi15mRyMCF9wJcRdDXjZ8MxoK8k9//onDRYt893lKaxSKiHgYJW8i4t4cQye3zIWMfebG4hgy2fEa8PI2NxYRAKsVhrwHfiFwYA0sf+P05//wrDFPLroTnH97rYQoIiKuo+RNRNxbZDujZ8FuKyqwYIacLCOBBOikKpPiRkKawuDXjO0lrxjFSMqybxWs+8zYHvyG/gAhIuKBlLyJiPtLvNN4Xvsx5J00J4at842haWFxcNa55sQgUp5OQ6H9ELDlwzd3lv45KcgvLFKCMZc09oJaD1FERKpPyZuIuL82AyG0mTHfzDF0sbY57ttpKFgs5sQgUh6LBS5/E4Ki4fA2+OG5ksd//RBSNoB/KPR73owIRUTEBZS8iYj7s3rB+XcY26s+qP1lA04cMcqxg6pMivsKDIer3jW2V02GnYuN7ePJsPhfxna/Z6FBY3PiExGRalPyJiKe4dybjGUDUv6EvT/X7r03zTaGo0V3Nsqzi7ir1v2g6yhj+9t7jd7qhU9DTiY0ORfOvcXc+EREpFqUvImIZwgIg86FhUJWTa7dezuGTHZWoRLxAP1fgPCWkHkAPvtH4efXAoNfN3qxRUTEYyl5ExHPUWLZgL9q554Z+2DfSsACHa6pnXuKVIdvA7hmCli84MBvxr6ut6nQjohIHaDkTUQ8R1QHaNET7AXwWy0tG/Dn18Zzix4Qclbt3FOkupp2hZ6F1SUDG0PfZ8yNR0REXELJm4h4FseyAWtqadmADV8ZzypUIp7m4sdg0Gtw41fGsGMREfF4St5ExLO0uQxCmsHJ9KLEqqakbDIKpFh9oN2VNXsvEVfz8oYL7oAmXcyOREREXMTb7ADk9AoKCsjLyzM7DLeVl5eHt7c3p06doqCgwOxwPIavry9Wq4f+7cbLG84fBT88C6s/MBYcrql11/4sTA5bX2qUYRcRERExkZI3N2W320lOTiYjI8PsUNya3W4nOjqav/76C4sWTq4wq9VKXFwcvr6+ZodSNefeDD/9G5I3GMVEmnd3/T3s9pILc4uIiIiYTMmbm3IkbpGRkQQGBioxKYfNZiMrK4ugoCDP7UmqZTabjYMHD3Lo0CGaNWvmmZ+twHDoPBTWfmIs2l0Tydtfq41Kk75B0Gag668vIiIiUklK3txQQUGBM3Fr1KiR2eG4NZvNRm5uLv7+/kreKiEiIoKDBw+Sn5+Pj4+P2eFUzQV3Gsnb5u/g2AHXV4J09LolXA6+ga69toiIiEgV6LddN+SY4xYYqF8YpWY4hkt69DzB6I7QvEfNLBtQkAcbvzG2NWRSRERE3ISSNzfmkcPZxCPUmc+Wc9mAaZB3ynXX3bUEsg8b62PF93bddUVERESqQcmbiHiutoMguClkHylaTNsVNnxpPHe8xqhuKSIiIuIGlLyJiOfy8oYLbje2V002KkRWV242bJ5jbGvIpIiIiLgRJW8i5ZgyZQqxsbFYrVYmTpxY7j4x2bm3gLc/JK+Hv1ZV/3rb5kPeCQhtBk3Pr/71RERERFxEyZu4xBVXXMHAgWWXU1+2bBkWi4X169ezZ88eLBZLqceNN95Y4Xt9/fXX9O7dm5CQEIKDg7nooot44YUXSE9Pd9XbITMzkzFjxvDYY49x4MABRo8eXea+mpCens6IESMIDg4mNDSUUaNGkZWVddrX9O7du1Sb3nXXXTUSn9sJDC/qIVv1QfWvt6FwYe5OQ2tu8W8RERGRKlDyJi4xatQokpKS2L9/f6ljU6dOpWvXrnTu3Nm574cffuDQoUPOx7vvvluh+zz11FMMGzaM888/n/nz57N+/XpefPFF/vjjDz799FOXvZ99+/aRl5fH4MGDiYmJITAwsMx9NWHEiBFs3LiRpKQk5syZw9KlSyuUKN5xxx0l2nTChAk1Ep9bchQu2fQtZB6s+nWy02F7krGtIZMiIiLiZpS8eQC73U52br4pD3sF5xBdfvnlREREMG3atBL7s7KymDlzJqNGjSqxv1GjRkRHRzsfISEhZ7zH6tWreemll3j99dd59dVX6d69Oy1atKBPnz589dVX3HLLLc5z33//fVq2bImvry9t27YtldhlZGRw++23ExERQXBwMJdccgl//PEHANOmTaNTp04AxMfHY7FYyty3Z8+eCrVNZWzevJkFCxbw4YcfkpiYSI8ePXj77bf5/PPPOXjw9ElJYGBgiTYNDg52eXxuK7oTNL+ocNmAj6p+nc3/A1seRHWEyHaui09ERETEBVRGzQOczCug/bjvTbn3pvEDCPQ988fE29ubm2++mWnTpvHUU085S9HPnDmTgoICrr/++mrHMn36dIKCgrjnnnvKPB4aGgrAN998w9ixY5k4cSL9+vVjzpw53HrrrTRt2pQ+ffoAMHToUAICApg/fz4hISF88MEH9O3bl23btjFs2DBiY2Pp168fq1evJjY2loYNG5baFxERUWYcHTp0YO/eveW+j549ezJ//vwyj61cuZLQ0FC6du3q3NevXz+sViurVq3i6quvPm37fPbZZ0RHR3PFFVfwzDPP1K+1Ai8YDXtXwG9ToefD4ONf+WusL1yYW71uIiIi4oaUvInL3Hbbbbz66qssWbKE3r17A8aQyWuvvbZUz1r37t2xWos6fpctW0aXLl1Oe/3t27cTHx+Pj4/Pac977bXXGDlypDPJe/DBB/nll1947bXX6NOnD8uXL2f16tWkpqbi5+fnfM3s2bP56quvGD16NI0aNQIgIiKC6OhogDL3lWXevHnOhdbLEhAQUO6x5ORkIiMjS+zz9vYmPDyc5OTkcl93ww030Lx5c5o0acL69et57LHH2Lp1K7NmzSr3NXVOwuUQfBZkHjAW2D6nkn8wOLbfSP4AOl7r+vhEREREqknJmwcI8PFi0/gBpt27ohISEujevTsfffQRvXv3ZseOHSxbtozx48eXOveLL76gXbuiYWmxsbFnvH5Fh3Bu3ry51Byxiy66iEmTJgHwxx9/kJWV5UzGHE6ePMnOnTsrdI/Tad68ebWvUVnF32+nTp2IiYmhb9++7Ny5k5YtW9Z6PKbw8obzR8GP441lA84eXrmCI3/OAuzQrDuEnvnzKCIiIlLblLx5AIvFUqGhi+5g1KhR/POf/+Tdd99l6tSptGzZkosvvrjUebGxsbRq1apS127Tpg3Lly8nLy/vjL1vp5OVlUVMTAw//fRTqWOOoZfVUZ1hk9HR0aSmppbYl5+fT3p6+ml7+/4uMTERgB07dtSf5A3g3JHw0ytw6HfY/yvEXlDx125wDJn8R01EJiIiIlJtKlgiLnXddddhtVqZMWMGn3zyCbfddptz/lt13XDDDWRlZfHee++VeTwjIwOAdu3asWLFihLHVqxYQfv27QE499xzSU5Oxtvbm1atWpV4NG7cuNpxzps3j99//73cx4cffljua7t160ZGRgZr1qxx7lu0aBE2m82ZkFXE77//DkBMTEyV34dHatCo2LIBkyv+urStxjpxVm9oP6RGQhMRERGpLs/ozhGPERQUxLBhw3jiiSfIzMxk5MiRLrt2YmIijz76KA899BAHDhzg6quvJjo6mvXr1/Ppp5/Ss2dPxo4dyyOPPMJ1111Hly5d6NevH9999x2zZs3ihx9+AIwCIN26dWPIkCFMmDCBNm3acPDgQebOncvVV19dolhIVVRn2GS7du0YOHAgd9xxB5MnTyYvL48xY8YwfPhwmjRpAsCBAwfo27cvn3zyCRdccAE7d+5kxowZDBo0iEaNGrF+/XoeeOABevXqVWJ5hnojcTT8/lnhsgGHILgCCayj161lXyMBFBEREXFD6nkTlxs1ahRHjx5lwIABzoTDVV555RVmzJjBqlWrGDBgAJ06deKpp56ic+fOzqUChgwZwqRJk3jttdfo0KEDH3zwAVOnTnUWUbFYLMybN49evXpx66230qZNG4YPH87evXuJiopyabxVMX36dBISEujbty+DBg2iR48eTJkyxXk8Ly+PrVu3kp2dDYCvry8//PAD/fv3JyEhgYceeohrr72W7777zqy3YK6Ys6FZN7DlV2zZALu9KHnrfF3NxiYiIiJSDep5E5fr1q1bucVFWrRoUeHCI+W57rrruO4645dsm81GZmYmwcHBJapX3n333dx9993lXqNhw4a89dZbvPXWW2UeP+ecc0rFWda+mhAeHs6MGTPKPf73NoyNjWXJkiU1HpdHuWA07FsJa6ZCr4fB26/8cw+sgaN7wCcQ2l5WayGKiIiIVJZ63kSk7ml3BTRsAifSjGUDTsfR65YwGHwb1HxsIiIiIlWk5E3cxl133UVQUFCZj7vuusvs8MSTePnA+bcZ26s+KP+8gvzCJQLQwtwiIiLi9jRsUtzG+PHjefjhh8s8FhwcXMvRiMc771ZY8iocXAv7f4OmZRSi2bMUTqRCQDi0vKT2YxQRERGpBCVv4jYiIyOJjIw0OwypKxo0ho7Xwh8zjGUDmpaxRMP6wiGTHa42eutERERE3JiGTYpI3ZU42njeOBuOJ5c8lncSNhdW5NSQSREREfEASt5EpO5q0gViE8GWB79NLXls2/eQexxCYo1zRERERNyckjcRqdsS7zSef/sI8nOL9juqTHa8Fqz6p1BERETcn35jEZG6rd2V0DDGKEyyabax72QGbF9obGvIpIiIiHgIJW8iUrd5+UDXUca2Y9mAzf+DglyIaAdRHcyLTURERKQSlLyJlGPKlCnExsZitVqZOHFiufvEA5w3Erx84cBvsH9N0ZDJzkPBYjE1NBEREZGKUvImLnHFFVcwcODAMo8tW7YMi8XC+vXr2bNnDxaLpdTjxhtvrPC9vv76a3r37k1ISAjBwcFcdNFFvPDCC6Snp7vq7ZCZmcmYMWN47LHHOHDgAKNHjy5zX01IT09nxIgRBAcHExoayqhRo8jKyjrta6ZMmULv3r0JDg7GYrGQkZFRI7F5rKAIY24bwKLxsHuZse3YJyIiIuIBlLyJS4waNYqkpCT2799f6tjUqVPp2rUrnTt3du774YcfOHTokPPx7rvvVug+Tz31FMOGDeP8889n/vz5rF+/nhdffJE//viDTz/91GXvZ9++feTl5TF48GBiYmIIDAwsc19NGDFiBBs3biQpKYk5c+awdOnSMyaK2dnZDBw4kCeffLJGYqoTLihsw10/AXajwmRYCxMDEhEREakcJW+ewG6H3BPmPOz2CoV4+eWXExERwbRp00rsz8rKYubMmYwaNarE/kaNGhEdHe18hISEnPEeq1ev5qWXXuL111/n1VdfpXv37rRo0YI+ffrw1VdfccsttzjPff/992nZsiW+vr60bdu2VGKXkZHB7bffTkREBMHBwVxyySX88ccfAEybNo1OnToBEB8fj8ViKXPfnj17KtQ2lbF582YWLFjAhx9+SGJiIj169ODtt9/m888/5+DBg+W+7v777+fxxx/nwgsvdHlMdcZZ50LT84u+VqESERER8TDeZgcgFZCXDS81MefeTx4E3wZnPM3b25ubb76ZadOm8dRTT2EpnEc0c+ZMCgoKuP7666sdyvTp0wkKCuKee+4p83hoaCgA33zzDWPHjmXixIn069ePOXPmcOutt9K0aVP69OkDwNChQwkICGD+/PmEhITwwQcf0LdvX7Zt28awYcOIjY2lX79+rF69mtjYWBo2bFhqX0RERJlxdOjQgb1795b7Pnr27Mn8+fPLPLZy5UpCQ0Pp2rWrc1+/fv2wWq2sWrWKq6++uiJNJeVJvAv2/woWL2g/xOxoRERERCpFyZu4zG233carr77KkiVL6N27N2AMmbz22mtL9ax1794da7G1tZYtW0aXLl1Oe/3t27cTHx+Pj4/Pac977bXXGDlypDPJe/DBB/nll1947bXX6NOnD8uXL2f16tWkpqbi5+fnfM3s2bP56quvGD16NI0aNQIgIiKC6OhogDL3lWXevHnk5eWVezwgIKDcY8nJyURGRpbY5+3tTXh4OMnJyad931IB7a8ykrdGrYx5cCIiIiIeRMmbJ/AJNHrAzLp3BSUkJNC9e3c++ugjevfuzY4dO1i2bBnjx48vde4XX3xBu3btnF/Hxsae8fr2Cg7h3Lx5c6k5YhdddBGTJk0C4I8//iArK8uZjDmcPHmSnTt3Vugep9O8efNqX0NqiJcPXPaK2VGIiIiIVImSN09gsVRo6KI7GDVqFP/85z959913mTp1Ki1btuTiiy8udV5sbCytWrWq1LXbtGnD8uXLycvLO2Pv2+lkZWURExPDTz/9VOqYY+hldVRn2GR0dDSpqakl9uXn55Oenn7a3j4RERERqfuUvIlLXXfddYwdO5YZM2bwySefcPfddzvnv1XXDTfcwFtvvcV7773H2LFjSx3PyMggNDSUdu3asWLFihIFTFasWEH79u0BOPfcc0lOTsbb25sWLVq4JLbiqjNsslu3bmRkZLBmzRrOO+88ABYtWoTNZiMxMdHlsYqIiIiI51DyJi4VFBTEsGHDeOKJJ8jMzGTkyJEuu3ZiYiKPPvooDz30EAcOHODqq68mOjqa9evX8+mnn9KzZ0/Gjh3LI488wnXXXUeXLl3o168f3333HbNmzeKHH34AjAIg3bp1Y8iQIUyYMIE2bdpw8OBB5s6dy9VXX12iWEhVVGfYZLt27Rg4cCB33HEHkydP/v/27j0qqnL/H/h7uMwwCMNF7gWCiWAICloc1LQTJF5WabW8RS5UjqVhiplpaYp6ykvmOejpaHVKu2iWLSUrQwkvqCEqgYqyyAump0AyxQEvMDCf3x/+2F8nQMvDMAy8X2vNWu7n+czez/6sJ6ePe+9nw2AwYMqUKRg9ejT8/G4uWvPzzz8jNjYWH330ER588EEAN5+VKysrw6lTpwAAx44dg7OzMwICAuDu7v4/nQ8RERERtQ58VQA1u6SkJFy+fBnx8fFKwdFcli5dig0bNiA3Nxfx8fEIDw/HnDlzEBERoVxpGz58ONLS0rB8+XKEhYXhnXfewdq1a5VFVFQqFbZt24b+/ftj/Pjx6Nq1K0aPHo2ffvoJ3t7ezTreu7F+/XqEhoYiNjYWQ4YMQb9+/fDuu+8q/QaDAcXFxbh27ZrStmbNGkRGRmLixIkAgP79+yMyMhJbt25t8fETERERkXnwyhs1u5iYmCYXFwkMDPzDC480ZeTIkRg5ciQAwGg0Qq/XQ6fTmaxeOXnyZEyePLnJfTg7O2PlypVYuXJlo/09e/ZsMM7G2szB3d0dGzZsaLK/sRympqYiNTXVzCMjIiIiIkuymitvgYGBUKlUJp8lS5aYxBw9ehQPPfQQHBwc4O/vj2XLljXYz6ZNmxAaGgoHBweEh4dj27ZtJv0ignnz5sHX1xdarRZxcXE4efKkScylS5eQkJAAnU4HV1dXJCUloaqqqvlPmoiIiIiI6P+zmuINABYuXIjS0lLl88ILLyh9er0eAwcORKdOnZCXl4c333wTqampJrebff/99xgzZgySkpKQn5+P4cOHY/jw4SgsLFRili1bhpUrV2LNmjXIzc1Fhw4dEB8fjxs3bigxCQkJOH78ODIzM/H1118jOzu7wdL09OdNmjQJTk5OjX4mTZpk6eEREREREVmUVd026ezs3ORy6evXr0dNTQ0++OADqNVqhIWFoaCgACtWrFAKq7S0NAwaNAgzZ84EACxatAiZmZn417/+hTVr1kBE8M9//hNz587FsGHDAAAfffQRvL29kZ6ejtGjR6OoqAgZGRk4dOiQsrDFqlWrMGTIECxfvrzZn/FqTxYuXIiXXnqp0T6dTtfCoyEiIiIial2sqnhbsmQJFi1ahICAADz99NOYPn067OxunkJOTg769+8PtVqtxMfHx2Pp0qW4fPky3NzckJOTgxdffNFkn/Hx8UhPTwcAlJSUoKysDHFxcUq/i4sLoqOjkZOTg9GjRyMnJweurq4mKxLGxcXBxsYGubm5eOKJJxode3V1Naqrq5VtvV4P4ObiE79fVt5gMEBEYDQaYTQa7yJT1snDwwMeHh5N9jeWi/pnv+rzRX+M0WiEiMBgMMDW1vZPf79+zt7ulQjU/Jh3y2DeLYN5twzm3TKYd8toTXn/o2OwmuJt6tSpiIqKgru7O77//nu88sorKC0txYoVKwDcXCo9KCjI5Dv1KweWlZXBzc0NZWVlDVYT9Pb2RllZmRJ36/eaivHy8jLpt7Ozg7u7uxLTmMWLF2PBggUN2nfs2AFHR8cG+/Px8UFlZSVqamqa3Cf9n8rKSksPwarU1NTg+vXryM7ORm1t7V3vJzMzsxlHRX8U824ZzLtlMO+WwbxbBvNuGa0h77euIn47Fi3eZs+ejaVLl942pqioCKGhoSZXzCIiIqBWq/Hcc89h8eLF0Gg05h7q/+yVV14xOQe9Xg9/f38MHDiwwS2BdXV1OHPmDGxsbHi74B2ICCorK+Hs7NxsLwNvD/R6PbRaLR555BHl6vWfYTAYkJmZiUcffRT29vZmGCE1hnm3DObdMph3y2DeLYN5t4zWlPf6u/LuxKLF24wZM+74EufOnTs32h4dHY3a2lqcPXsWISEh8PHxwYULF0xi6rfrn5NrKubW/vo2X19fk5iePXsqMeXl5Sb7qK2txaVLl5p8Hg8ANBpNo0Wmvb19g8lib28PNzc3XLx4ETY2NnB0dGRh0gSj0YiamhpUV1ebvCqAmmY0GnHx4kV06NABDg4O/9Pcamz+kvkx75bBvFsG824ZzLtlMO+W0Rry/kePb9HizdPTE56ennf13YKCAtjY2Ci3MMbExGDOnDkwGAzKyWdmZiIkJARubm5KTFZWFlJSUpT9ZGZmIiYmBgAQFBQEHx8fZGVlKcWaXq9Hbm6u8s6wmJgYVFRUIC8vD7169QIA7Ny5E0ajEdHR0Xd1Lo2pLwR/XyiSKRHB9evXodVqWeD+CTY2NggICGDOiIiIiKyIVTzzlpOTg9zcXPz1r3+Fs7MzcnJyMH36dDzzzDNKYfb0009jwYIFSEpKwqxZs1BYWIi0tDT84x//UPYzbdo0DBgwAG+99RaGDh2KjRs34vDhw8rrBFQqFVJSUvD3v/8dwcHBCAoKwmuvvQY/Pz8MHz4cANCtWzcMGjQIEydOxJo1a2AwGDBlyhSMHj26WVeaVKlU8PX1hZeXV6t4iLK1MhgMyM7ORv/+/S3+LybWRK1W80olERERkZWxiuJNo9Fg48aNSE1NRXV1NYKCgjB9+nSTZ8hcXFywY8cOJCcno1evXvDw8MC8efNM3r/Wp08fbNiwAXPnzsWrr76K4OBgpKeno3v37krMyy+/jKtXr+LZZ59FRUUF+vXrh4yMDDg4OCgx69evx5QpUxAbGwsbGxs89dRTWLlypVnO3dbW9q5WA2wvbG1tUVtbCwcHBxZvRERERNSmWUXxFhUVhQMHDtwxLiIiAnv37r1tzIgRIzBixIgm+1UqFRYuXIiFCxc2GePu7o4NGzbccTxERERERETNhfdNERERERERWQEWb0RERERERFbAKm6bbItEBMAff6cDNc5gMODatWvQ6/V85q0FMe+WwbxbBvNuGcy7ZTDvlsG8W0Zrynt9TVBfIzSFxZuFVFZWAgD8/f0tPBIiIiIiImoNKisr4eLi0mS/Su5U3pFZGI1G/PLLL3B2dua7tv4Her0e/v7+OH/+PHQ6naWH024w75bBvFsG824ZzLtlMO+WwbxbRmvKu4igsrISfn5+t32dE6+8WYiNjQ3uvfdeSw+jzdDpdBb/j649Yt4tg3m3DObdMph3y2DeLYN5t4zWkvfbXXGrxwVLiIiIiIiIrACLNyIiIiIiIivA4o2smkajwfz586HRaCw9lHaFebcM5t0ymHfLYN4tg3m3DObdMqwx71ywhIiIiIiIyArwyhsREREREZEVYPFGRERERERkBVi8ERERERERWQEWb0RERERERFaAxRu1uOzsbDz22GPw8/ODSqVCenq6Sb+IYN68efD19YVWq0VcXBxOnjxpEnPp0iUkJCRAp9PB1dUVSUlJqKqqMok5evQoHnroITg4OMDf3x/Lli1rMJZNmzYhNDQUDg4OCA8Px7Zt25r9fFuDxYsX44EHHoCzszO8vLwwfPhwFBcXm8TcuHEDycnJ6NixI5ycnPDUU0/hwoULJjHnzp3D0KFD4ejoCC8vL8ycORO1tbUmMbt370ZUVBQ0Gg26dOmCdevWNRjP22+/jcDAQDg4OCA6OhoHDx5s9nNuDVavXo2IiAjl5Z8xMTH49ttvlX7mvGUsWbIEKpUKKSkpShtz3/xSU1OhUqlMPqGhoUo/c24+P//8M5555hl07NgRWq0W4eHhOHz4sNLP39XmFxgY2GC+q1QqJCcnA+B8N5e6ujq89tprCAoKglarxX333YdFixbh1vUX2/x8F6IWtm3bNpkzZ45s3rxZAMiWLVtM+pcsWSIuLi6Snp4uR44ckccff1yCgoLk+vXrSsygQYOkR48ecuDAAdm7d6906dJFxowZo/RfuXJFvL29JSEhQQoLC+XTTz8VrVYr77zzjhKzf/9+sbW1lWXLlsmJEydk7ty5Ym9vL8eOHTN7DlpafHy8rF27VgoLC6WgoECGDBkiAQEBUlVVpcRMmjRJ/P39JSsrSw4fPix/+ctfpE+fPkp/bW2tdO/eXeLi4iQ/P1+2bdsmHh4e8sorrygxZ86cEUdHR3nxxRflxIkTsmrVKrG1tZWMjAwlZuPGjaJWq+WDDz6Q48ePy8SJE8XV1VUuXLjQMsloQVu3bpVvvvlGfvzxRykuLpZXX31V7O3tpbCwUESY85Zw8OBBCQwMlIiICJk2bZrSztw3v/nz50tYWJiUlpYqn19//VXpZ87N49KlS9KpUycZN26c5ObmypkzZ2T79u1y6tQpJYa/q82vvLzcZK5nZmYKANm1a5eIcL6by+uvvy4dO3aUr7/+WkpKSmTTpk3i5OQkaWlpSkxbn+8s3siifl+8GY1G8fHxkTfffFNpq6ioEI1GI59++qmIiJw4cUIAyKFDh5SYb7/9VlQqlfz8888iIvLvf/9b3NzcpLq6WomZNWuWhISEKNsjR46UoUOHmownOjpannvuuWY9x9aovLxcAMiePXtE5GaO7e3tZdOmTUpMUVGRAJCcnBwRuVl029jYSFlZmRKzevVq0el0Sp5ffvllCQsLMznWqFGjJD4+Xtl+8MEHJTk5Wdmuq6sTPz8/Wbx4cfOfaCvk5uYm//nPf5jzFlBZWSnBwcGSmZkpAwYMUIo35t485s+fLz169Gi0jzk3n1mzZkm/fv2a7OfvasuYNm2a3HfffWI0GjnfzWjo0KEyYcIEk7Ynn3xSEhISRKR9zHfeNkmtSklJCcrKyhAXF6e0ubi4IDo6Gjk5OQCAnJwcuLq6onfv3kpMXFwcbGxskJubq8T0798farVaiYmPj0dxcTEuX76sxNx6nPqY+uO0ZVeuXAEAuLu7AwDy8vJgMBhM8hEaGoqAgACTvIeHh8Pb21uJiY+Ph16vx/Hjx5WY2+W0pqYGeXl5JjE2NjaIi4tr83mvq6vDxo0bcfXqVcTExDDnLSA5ORlDhw5tkB/m3nxOnjwJPz8/dO7cGQkJCTh37hwA5tyctm7dit69e2PEiBHw8vJCZGQk3nvvPaWfv6vmV1NTg08++QQTJkyASqXifDejPn36ICsrCz/++CMA4MiRI9i3bx8GDx4MoH3MdxZv1KqUlZUBgMlfZvXb9X1lZWXw8vIy6bezs4O7u7tJTGP7uPUYTcXU97dVRqMRKSkp6Nu3L7p37w7gZi7UajVcXV1NYn+f97vNqV6vx/Xr13Hx4kXU1dW1q7wfO3YMTk5O0Gg0mDRpErZs2YL777+fOTezjRs34ocffsDixYsb9DH35hEdHY1169YhIyMDq1evRklJCR566CFUVlYy52Z05swZrF69GsHBwdi+fTsmT56MqVOn4sMPPwTA39WWkJ6ejoqKCowbNw4A/44xp9mzZ2P06NEIDQ2Fvb09IiMjkZKSgoSEBADtY77bmXXvRNTqJCcno7CwEPv27bP0UNqFkJAQFBQU4MqVK/jiiy+QmJiIPXv2WHpYbdr58+cxbdo0ZGZmwsHBwdLDaTfq/+UbACIiIhAdHY1OnTrh888/h1arteDI2jaj0YjevXvjjTfeAABERkaisLAQa9asQWJiooVH1z68//77GDx4MPz8/Cw9lDbv888/x/r167FhwwaEhYWhoKAAKSkp8PPzazfznVfeqFXx8fEBgAYrMl24cEHp8/HxQXl5uUl/bW0tLl26ZBLT2D5uPUZTMfX9bdGUKVPw9ddfY9euXbj33nuVdh8fH9TU1KCiosIk/vd5v9uc6nQ6aLVaeHh4wNbWtl3lXa1Wo0uXLujVqxcWL16MHj16IC0tjTk3o7y8PJSXlyMqKgp2dnaws7PDnj17sHLlStjZ2cHb25u5bwGurq7o2rUrTp06xfluRr6+vrj//vtN2rp166bcssrfVfP66aef8N133+Fvf/ub0sb5bj4zZ85Urr6Fh4dj7NixmD59unKXRXuY7yzeqFUJCgqCj48PsrKylDa9Xo/c3FzExMQAAGJiYlBRUYG8vDwlZufOnTAajYiOjlZisrOzYTAYlJjMzEyEhITAzc1Nibn1OPUx9cdpS0QEU6ZMwZYtW7Bz504EBQWZ9Pfq1Qv29vYm+SguLsa5c+dM8n7s2DGTv/AyMzOh0+mU/3G4U07VajV69eplEmM0GpGVldUm894Yo9GI6upq5tyMYmNjcezYMRQUFCif3r17IyEhQfkzc29+VVVVOH36NHx9fTnfzahv374NXv3y448/olOnTgD4u2pua9euhZeXF4YOHaq0cb6bz7Vr12BjY1q+2Nrawmg0Amgn892sy6EQNaKyslLy8/MlPz9fAMiKFSskPz9ffvrpJxG5ucSrq6urfPnll3L06FEZNmxYo0u8RkZGSm5uruzbt0+Cg4NNlnitqKgQb29vGTt2rBQWFsrGjRvF0dGxwRKvdnZ2snz5cikqKpL58+e32SWNJ0+eLC4uLrJ7926TpY2vXbumxEyaNEkCAgJk586dcvjwYYmJiZGYmBilv35Z44EDB0pBQYFkZGSIp6dno8saz5w5U4qKiuTtt99udFljjUYj69atkxMnTsizzz4rrq6uJitutRWzZ8+WPXv2SElJiRw9elRmz54tKpVKduzYISLMeUu6dbVJEebeHGbMmCG7d++WkpIS2b9/v8TFxYmHh4eUl5eLCHNuLgcPHhQ7Ozt5/fXX5eTJk7J+/XpxdHSUTz75RInh76p51NXVSUBAgMyaNatBH+e7eSQmJso999yjvCpg8+bN4uHhIS+//LIS09bnO4s3anG7du0SAA0+iYmJInJzmdfXXntNvL29RaPRSGxsrBQXF5vs47fffpMxY8aIk5OT6HQ6GT9+vFRWVprEHDlyRPr16ycajUbuueceWbJkSYOxfP7559K1a1dRq9USFhYm33zzjdnO25IayzcAWbt2rRJz/fp1ef7558XNzU0cHR3liSeekNLSUpP9nD17VgYPHixarVY8PDxkxowZYjAYTGJ27dolPXv2FLVaLZ07dzY5Rr1Vq1ZJQECAqNVqefDBB+XAgQPmOG2LmzBhgnTq1EnUarV4enpKbGysUriJMOct6ffFG3Pf/EaNGiW+vr6iVqvlnnvukVGjRpm8a4w5N5+vvvpKunfvLhqNRkJDQ+Xdd9816efvqnls375dADTIpQjnu7no9XqZNm2aBAQEiIODg3Tu3FnmzJljsqR/W5/vKpFbXklORERERERErRKfeSMiIiIiIrICLN6IiIiIiIisAIs3IiIiIiIiK8DijYiIiIiIyAqweCMiIiIiIrICLN6IiIiIiIisAIs3IiIiIiIiK8DijYiIiIiIyAqweCMiIroNlUqF9PT0u/7+uHHjMHz48GYbDxERtV8s3oiIyCqoVKrbflJTU5v87tmzZ6FSqVBQUNDiY0pLS8O6deua9bh/FgtIIqK2wc7SAyAiIvojSktLlT9/9tlnmDdvHoqLi5U2JyenVjkmS4yLiIjaJl55IyIiq+Dj46N8XFxcoFKplG0vLy+sWLEC9957LzQaDXr27ImMjAzlu0FBQQCAyMhIqFQqPPzwwwCAQ4cO4dFHH4WHhwdcXFwwYMAA/PDDD80yJh8fHzg5OTW46vXwww/jhRdeQEpKCtzc3ODt7Y333nsPV69exfjx4+Hs7IwuXbrg22+/NTlWYWEhBg8eDCcnJ3h7e2Ps2LG4ePGi0v/FF18gPDwcWq0WHTt2RFxcHK5evYrU1FR8+OGH+PLLL5Urgrt37wYAnD9/HiNHjoSrqyvc3d0xbNgwnD17Vtln/dgXLFgAT09P6HQ6TJo0CTU1NXc8LhERNT8Wb0REZPXS0tLw1ltvYfny5Th69Cji4+Px+OOP4+TJkwCAgwcPAgC+++47lJaWYvPmzQCAyspKJCYmYt++fThw4ACCg4MxZMgQVFZWmnW8H374ITw8PHDw4EG88MILmDx5MkaMGIE+ffrghx9+wMCBAzF27Fhcu3YNAFBRUYFHHnkEkZGROHz4MDIyMnDhwgWMHDkSwM0rgGPGjMGECRNQVFSE3bt348knn4SI4KWXXsLIkSMxaNAglJaWorS0FH369IHBYEB8fDycnZ2xd+9e7N+/H05OThg0aJBJcZaVlaXs89NPP8XmzZuxYMGCOx6XiIjMQIiIiKzM2rVrxcXFRdn28/OT119/3STmgQcekOeff15EREpKSgSA5Ofn33a/dXV14uzsLF999ZXSBkC2bNnyp8dULzExUYYNG6ZsDxgwQPr166ds19bWSocOHWTs2LFKW2lpqQCQnJwcERFZtGiRDBw40GS/58+fFwBSXFwseXl5AkDOnj3b6Nh+PwYRkY8//lhCQkLEaDQqbdXV1aLVamX79u3K99zd3eXq1atKzOrVq8XJyUnq6urueFwiImpevPJGRERWTa/X45dffkHfvn1N2vv27YuioqLbfvfChQuYOHEigoOD4eLiAp1Oh6qqKpw7d86cQ0ZERITyZ1tbW3Ts2BHh4eFKm7e3NwCgvLwcAHDkyBHs2rVLeYbOyckJoaGhAIDTp0+jR48eiI2NRXh4OEaMGIH33nsPly9fvu0Yjhw5glOnTsHZ2VnZp7u7O27cuIHTp08rcT169ICjo6OyHRMTg6qqKpw/f/6ujktERHePC5YQEVG7lZiYiN9++w1paWno1KkTNBoNYmJiTG4bNAd7e3uTbZVKZdKmUqkAAEajEQBQVVWFxx57DEuXLm2wL19fX9ja2iIzMxPff/89duzYgVWrVmHOnDnIzc1Vnvf7vaqqKvTq1Qvr169v0Ofp6fmHzuNujktERHePV96IiMiq6XQ6+Pn5Yf/+/Sbt+/fvx/333w8AUKvVAIC6uroGMVOnTsWQIUMQFhYGjUZjsghIaxEVFYXjx48jMDAQXbp0Mfl06NABwM2Cr2/fvliwYAHy8/OhVquxZcsWADfP//fnHhUVhZMnT8LLy6vBPl1cXJS4I0eO4Pr168r2gQMH4OTkBH9//zsel4iImheLNyIisnozZ87E0qVL8dlnn6G4uBizZ89GQUEBpk2bBgDw8vKCVqtVFvq4cuUKACA4OBgff/wxioqKkJubi4SEBGi1WkueSqOSk5Nx6dIljBkzBocOHcLp06exfft2jB8/HnV1dcjNzcUbb7yBw4cP49y5c9i8eTN+/fVXdOvWDQAQGBiIo0ePori4GBcvXoTBYEBCQgI8PDwwbNgw7N27FyUlJdi9ezemTp2K//73v8qxa2pqkJSUhBMnTmDbtm2YP38+pkyZAhsbmzsel4iImheLNyIisnpTp07Fiy++iBkzZiA8PBwZGRnYunUrgoODAQB2dnZYuXIl3nnnHfj5+WHYsGEAgPfffx+XL19GVFQUxo4di6lTp8LLy8uSp9Ko+iuLdXV1GDhwIMLDw5GSkgJXV1fY2NhAp9MhOzsbQ4YMQdeuXTF37ly89dZbGDx4MABg4sSJCAkJQe/eveHp6Yn9+/fD0dER2dnZCAgIwJNPPolu3bohKSkJN27cgE6nU44dGxuL4OBg9O/fH6NGjcLjjz+uvBD9TsclIqLmpRLher5ERETU0Lhx41BRUYH09HRLD4WIiMArb0RERERERFaBxRsREREREZEV4G2TREREREREVoBX3oiIiIiIiKwAizciIiIiIiIrwOKNiIiIiIjICrB4IyIiIiIisgIs3oiIiIiIiKwAizciIiIiIiIrwOKNiIiIiIjICrB4IyIiIiIisgL/D6NF65bxjKc5AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Two file paths for comparison\n",
    "file_paths = [\n",
    "    'logs/a2c/a2c_results_test3/evaluations.npz',\n",
    "    'logs/a2c/a2c_results_test4/evaluations.npz'\n",
    "]\n",
    "\n",
    "labels = ['VF_Coeff = 0.5', 'VF_Coeff = 0.1']  # Labels for the legend\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for file_path, label in zip(file_paths, labels):\n",
    "    try:\n",
    "        data = np.load(file_path)\n",
    "        print(f\"Contents of {file_path}: {data.files}\")\n",
    "        \n",
    "        timesteps = data['timesteps']\n",
    "        results = data['results']\n",
    "\n",
    "        mean_reward = np.mean(results)\n",
    "        print(f\"Mean reward for {label}: {mean_reward:.2f}\")\n",
    "        \n",
    "        # results might be a 2D array (num_eval, num_envs), take mean if needed\n",
    "        if results.ndim > 1:\n",
    "            results = results.mean(axis=1)\n",
    "\n",
    "        plt.plot(timesteps, results, label=label)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{file_path}' was not found.\")\n",
    "    except KeyError as e:\n",
    "        print(f\"Error: The key {e} was not found in the NPZ file. Check the contents using data.files.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred with {file_path}: {e}\")\n",
    "\n",
    "plt.title('A2C Performance Comparison')\n",
    "plt.xlabel('Total Timesteps')\n",
    "plt.ylabel('Mean Reward')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee3b49b",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3551e09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Using cuda device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./logs/a2c/a2c_tensorboard/A2C_2\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 556      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.11    |\n",
      "|    explained_variance | 0.00141  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 40.4     |\n",
      "|    value_loss         | 1.68e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.51e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 589      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.943   |\n",
      "|    explained_variance | -6.1e-05 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 15.4     |\n",
      "|    value_loss         | 1.01e+03 |\n",
      "------------------------------------\n",
      "Eval num_timesteps=5000, episode_reward=-22237.93 +/- 0.02\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -2.22e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.9      |\n",
      "|    explained_variance | 0.00296   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 249       |\n",
      "|    policy_loss        | 17.5      |\n",
      "|    value_loss         | 757       |\n",
      "-------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.78e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 161      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.849   |\n",
      "|    explained_variance | 5.31e-05 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 35.9     |\n",
      "|    value_loss         | 2.29e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 1.88e+04  |\n",
      "| time/                 |           |\n",
      "|    fps                | 198       |\n",
      "|    iterations         | 400       |\n",
      "|    time_elapsed       | 40        |\n",
      "|    total_timesteps    | 8000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.645    |\n",
      "|    explained_variance | -1.73e-05 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 399       |\n",
      "|    policy_loss        | 33.3      |\n",
      "|    value_loss         | 1.81e+03  |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=-6157.69 +/- 0.11\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -6.16e+03 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 10000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.632    |\n",
      "|    explained_variance | -3.31e-05 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | 9.25      |\n",
      "|    value_loss         | 923       |\n",
      "-------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.3e+03  |\n",
      "|    ep_rew_mean     | 1.93e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 141      |\n",
      "|    iterations      | 500      |\n",
      "|    time_elapsed    | 70       |\n",
      "|    total_timesteps | 10000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.94e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 162      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 73       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.663   |\n",
      "|    explained_variance | 2.16e-05 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 20.7     |\n",
      "|    value_loss         | 1.5e+03  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.97e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 182      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 76       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.676   |\n",
      "|    explained_variance | 1.1e-05  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 19.6     |\n",
      "|    value_loss         | 570      |\n",
      "------------------------------------\n",
      "Eval num_timesteps=15000, episode_reward=-11243.21 +/- 0.02\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.12e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 15000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.569    |\n",
      "|    explained_variance | 1.28e-05  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 749       |\n",
      "|    policy_loss        | 12.6      |\n",
      "|    value_loss         | 875       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 1.97e+04  |\n",
      "| time/                 |           |\n",
      "|    fps                | 149       |\n",
      "|    iterations         | 800       |\n",
      "|    time_elapsed       | 107       |\n",
      "|    total_timesteps    | 16000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.494    |\n",
      "|    explained_variance | -1.53e-05 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 799       |\n",
      "|    policy_loss        | 8.15      |\n",
      "|    value_loss         | 690       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.99e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 162      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 110      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.585   |\n",
      "|    explained_variance | 1.1e-05  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 7.65     |\n",
      "|    value_loss         | 439      |\n",
      "------------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=15659.83 +/- 0.04\n",
      "Episode length: 2160.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 2.16e+03 |\n",
      "|    mean_reward        | 1.57e+04 |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.561   |\n",
      "|    explained_variance | 1.06e-05 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 10.1     |\n",
      "|    value_loss         | 326      |\n",
      "------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.3e+03  |\n",
      "|    ep_rew_mean     | 2e+04    |\n",
      "| time/              |          |\n",
      "|    fps             | 144      |\n",
      "|    iterations      | 1000     |\n",
      "|    time_elapsed    | 138      |\n",
      "|    total_timesteps | 20000    |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 2.01e+04  |\n",
      "| time/                 |           |\n",
      "|    fps                | 155       |\n",
      "|    iterations         | 1100      |\n",
      "|    time_elapsed       | 141       |\n",
      "|    total_timesteps    | 22000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.429    |\n",
      "|    explained_variance | -0.000272 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1099      |\n",
      "|    policy_loss        | -0.581    |\n",
      "|    value_loss         | 74.1      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 2.01e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 165      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 144      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.344   |\n",
      "|    explained_variance | 1.46e-05 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 9.12     |\n",
      "|    value_loss         | 403      |\n",
      "------------------------------------\n",
      "Eval num_timesteps=25000, episode_reward=18712.39 +/- 0.04\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 2.3e+03  |\n",
      "|    mean_reward        | 1.87e+04 |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.341   |\n",
      "|    explained_variance | 0.0123   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1249     |\n",
      "|    policy_loss        | -0.765   |\n",
      "|    value_loss         | 34.8     |\n",
      "------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 2.02e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 174      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.415   |\n",
      "|    explained_variance | 0.00041  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 0.636    |\n",
      "|    value_loss         | 42.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 2.02e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 157      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 177      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00205 |\n",
      "|    explained_variance | -0.0535  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -837     |\n",
      "|    value_loss         | 1.46e+03 |\n",
      "------------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=-16163.12 +/- 0.10\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.62e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 30000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.6e-12  |\n",
      "|    explained_variance | 0.596     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | -167      |\n",
      "|    value_loss         | 116       |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.3e+03  |\n",
      "|    ep_rew_mean     | 1.78e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 144      |\n",
      "|    iterations      | 1500     |\n",
      "|    time_elapsed    | 207      |\n",
      "|    total_timesteps | 30000    |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 1.78e+04  |\n",
      "| time/                 |           |\n",
      "|    fps                | 151       |\n",
      "|    iterations         | 1600      |\n",
      "|    time_elapsed       | 210       |\n",
      "|    total_timesteps    | 32000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.68e-18 |\n",
      "|    explained_variance | -0.00117  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1599      |\n",
      "|    policy_loss        | -406      |\n",
      "|    value_loss         | 228       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 1.54e+04  |\n",
      "| time/                 |           |\n",
      "|    fps                | 158       |\n",
      "|    iterations         | 1700      |\n",
      "|    time_elapsed       | 213       |\n",
      "|    total_timesteps    | 34000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.19e-22 |\n",
      "|    explained_variance | 0.613     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1699      |\n",
      "|    policy_loss        | -541      |\n",
      "|    value_loss         | 68.8      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=35000, episode_reward=-16163.15 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.62e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 35000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.14e-19 |\n",
      "|    explained_variance | 0.485     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1749      |\n",
      "|    policy_loss        | -231      |\n",
      "|    value_loss         | 94        |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 1.33e+04  |\n",
      "| time/                 |           |\n",
      "|    fps                | 147       |\n",
      "|    iterations         | 1800      |\n",
      "|    time_elapsed       | 243       |\n",
      "|    total_timesteps    | 36000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.57e-08 |\n",
      "|    explained_variance | 0.601     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1799      |\n",
      "|    policy_loss        | -461      |\n",
      "|    value_loss         | 81.2      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.14e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 154      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 246      |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.301   |\n",
      "|    explained_variance | -0.549   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 36.6     |\n",
      "|    value_loss         | 690      |\n",
      "------------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=-16163.15 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.62e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 40000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.48e-21 |\n",
      "|    explained_variance | -0.729    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1999      |\n",
      "|    policy_loss        | -3.93e+03 |\n",
      "|    value_loss         | 2.17e+03  |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.3e+03  |\n",
      "|    ep_rew_mean     | 1.17e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 145      |\n",
      "|    iterations      | 2000     |\n",
      "|    time_elapsed    | 274      |\n",
      "|    total_timesteps | 40000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.07e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 151      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 277      |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.291   |\n",
      "|    explained_variance | -8.55    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 1.24e+03 |\n",
      "|    value_loss         | 7.32e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.09e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 156      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 280      |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.185   |\n",
      "|    explained_variance | 0.472    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -303     |\n",
      "|    value_loss         | 56.8     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=45000, episode_reward=-16163.15 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.62e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 45000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.24e-26 |\n",
      "|    explained_variance | 0.227     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2249      |\n",
      "|    policy_loss        | -1.5e+03  |\n",
      "|    value_loss         | 457       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 1.09e+04  |\n",
      "| time/                 |           |\n",
      "|    fps                | 147       |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 310       |\n",
      "|    total_timesteps    | 46000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.99e-05 |\n",
      "|    explained_variance | 0.449     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | 4.12e+03  |\n",
      "|    value_loss         | 3.15e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.04e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 313      |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.119   |\n",
      "|    explained_variance | 0.336    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | 63.8     |\n",
      "|    value_loss         | 65.7     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=-16163.15 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.62e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 50000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0534   |\n",
      "|    explained_variance | 0.886     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2499      |\n",
      "|    policy_loss        | -319      |\n",
      "|    value_loss         | 15.3      |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.3e+03  |\n",
      "|    ep_rew_mean     | 1.07e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 146      |\n",
      "|    iterations      | 2500     |\n",
      "|    time_elapsed    | 341      |\n",
      "|    total_timesteps | 50000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 9.56e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 345      |\n",
      "|    total_timesteps    | 52000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.412   |\n",
      "|    explained_variance | -0.667   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -71.7    |\n",
      "|    value_loss         | 78.2     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 9.81e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 155       |\n",
      "|    iterations         | 2700      |\n",
      "|    time_elapsed       | 348       |\n",
      "|    total_timesteps    | 54000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.21e-09 |\n",
      "|    explained_variance | 0.554     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2699      |\n",
      "|    policy_loss        | -1.61e+03 |\n",
      "|    value_loss         | 327       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=55000, episode_reward=-16163.15 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.62e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 55000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.51e-42 |\n",
      "|    explained_variance | 0.967     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2749      |\n",
      "|    policy_loss        | -47.8     |\n",
      "|    value_loss         | 3.05      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 9.02e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 378      |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.155   |\n",
      "|    explained_variance | 0.043    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 815      |\n",
      "|    value_loss         | 1.7e+03  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 9.27e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 381      |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0141  |\n",
      "|    explained_variance | 0.235    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -127     |\n",
      "|    value_loss         | 46.9     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=-11463.84 +/- 0.01\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.15e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 60000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00832  |\n",
      "|    explained_variance | 0.601     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2999      |\n",
      "|    policy_loss        | -439      |\n",
      "|    value_loss         | 170       |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.3e+03  |\n",
      "|    ep_rew_mean     | 9.49e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 146      |\n",
      "|    iterations      | 3000     |\n",
      "|    time_elapsed    | 410      |\n",
      "|    total_timesteps | 60000    |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 9.49e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 149       |\n",
      "|    iterations         | 3100      |\n",
      "|    time_elapsed       | 413       |\n",
      "|    total_timesteps    | 62000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0647   |\n",
      "|    explained_variance | 0.433     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3099      |\n",
      "|    policy_loss        | -1.58e+03 |\n",
      "|    value_loss         | 387       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 9.57e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 153       |\n",
      "|    iterations         | 3200      |\n",
      "|    time_elapsed       | 416       |\n",
      "|    total_timesteps    | 64000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.17e-38 |\n",
      "|    explained_variance | 0.977     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3199      |\n",
      "|    policy_loss        | -51.9     |\n",
      "|    value_loss         | 2.71      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=65000, episode_reward=-19339.50 +/- 0.35\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.93e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 65000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.247    |\n",
      "|    explained_variance | 0.0601    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3249      |\n",
      "|    policy_loss        | 243       |\n",
      "|    value_loss         | 2.26e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 8.65e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 446      |\n",
      "|    total_timesteps    | 66000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.157   |\n",
      "|    explained_variance | 0.682    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 31.5     |\n",
      "|    value_loss         | 30.3     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 8.85e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 151       |\n",
      "|    iterations         | 3400      |\n",
      "|    time_elapsed       | 449       |\n",
      "|    total_timesteps    | 68000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000922 |\n",
      "|    explained_variance | 0.832     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3399      |\n",
      "|    policy_loss        | -192      |\n",
      "|    value_loss         | 15.8      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=-16163.12 +/- 0.08\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.62e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 70000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0        |\n",
      "|    explained_variance | 0.857     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3499      |\n",
      "|    policy_loss        | -122      |\n",
      "|    value_loss         | 19.1      |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.3e+03  |\n",
      "|    ep_rew_mean     | 9.03e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 146      |\n",
      "|    iterations      | 3500     |\n",
      "|    time_elapsed    | 478      |\n",
      "|    total_timesteps | 70000    |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 8.22e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 149       |\n",
      "|    iterations         | 3600      |\n",
      "|    time_elapsed       | 481       |\n",
      "|    total_timesteps    | 72000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.58e-15 |\n",
      "|    explained_variance | 0.91      |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3599      |\n",
      "|    policy_loss        | -325      |\n",
      "|    value_loss         | 21.5      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 7.92e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 152      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 484      |\n",
      "|    total_timesteps    | 74000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.144   |\n",
      "|    explained_variance | 0.678    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | -49.2    |\n",
      "|    value_loss         | 24       |\n",
      "------------------------------------\n",
      "Eval num_timesteps=75000, episode_reward=-9015.76 +/- 0.03\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -9.02e+03 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 75000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.167    |\n",
      "|    explained_variance | 0.936     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3749      |\n",
      "|    policy_loss        | 129       |\n",
      "|    value_loss         | 10.8      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 7.92e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 147       |\n",
      "|    iterations         | 3800      |\n",
      "|    time_elapsed       | 514       |\n",
      "|    total_timesteps    | 76000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.69e-32 |\n",
      "|    explained_variance | 0.554     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3799      |\n",
      "|    policy_loss        | -124      |\n",
      "|    value_loss         | 10.7      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 8.16e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 150       |\n",
      "|    iterations         | 3900      |\n",
      "|    time_elapsed       | 517       |\n",
      "|    total_timesteps    | 78000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.59e-13 |\n",
      "|    explained_variance | 0.606     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3899      |\n",
      "|    policy_loss        | 628       |\n",
      "|    value_loss         | 82.4      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=-16163.14 +/- 0.03\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.62e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 80000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00443  |\n",
      "|    explained_variance | 0.915     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3999      |\n",
      "|    policy_loss        | 44.4      |\n",
      "|    value_loss         | 7.72      |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.3e+03  |\n",
      "|    ep_rew_mean     | 8.17e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 146      |\n",
      "|    iterations      | 4000     |\n",
      "|    time_elapsed    | 547      |\n",
      "|    total_timesteps | 80000    |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 7.48e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 148       |\n",
      "|    iterations         | 4100      |\n",
      "|    time_elapsed       | 550       |\n",
      "|    total_timesteps    | 82000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.29e-06 |\n",
      "|    explained_variance | 0.54      |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4099      |\n",
      "|    policy_loss        | -235      |\n",
      "|    value_loss         | 15.7      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 7.7e+03  |\n",
      "| time/                 |          |\n",
      "|    fps                | 151      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 554      |\n",
      "|    total_timesteps    | 84000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00399 |\n",
      "|    explained_variance | 0.929    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 231      |\n",
      "|    value_loss         | 13.8     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=85000, episode_reward=-16504.05 +/- 0.02\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.65e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 85000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00014  |\n",
      "|    explained_variance | 0.97      |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4249      |\n",
      "|    policy_loss        | 123       |\n",
      "|    value_loss         | 2.77      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 7.88e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 584      |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00405 |\n",
      "|    explained_variance | 0.883    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 266      |\n",
      "|    value_loss         | 13.5     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 7.72e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 149       |\n",
      "|    iterations         | 4400      |\n",
      "|    time_elapsed       | 587       |\n",
      "|    total_timesteps    | 88000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000467 |\n",
      "|    explained_variance | 0.843     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4399      |\n",
      "|    policy_loss        | 863       |\n",
      "|    value_loss         | 43.9      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=-16163.14 +/- 0.02\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.62e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 90000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.89e-08 |\n",
      "|    explained_variance | 0.836     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4499      |\n",
      "|    policy_loss        | 516       |\n",
      "|    value_loss         | 31.9      |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.3e+03  |\n",
      "|    ep_rew_mean     | 7.87e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 145      |\n",
      "|    iterations      | 4500     |\n",
      "|    time_elapsed    | 616      |\n",
      "|    total_timesteps | 90000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 7.87e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 620      |\n",
      "|    total_timesteps    | 92000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0102  |\n",
      "|    explained_variance | 0.339    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | -392     |\n",
      "|    value_loss         | 78.2     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 7.98e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 150       |\n",
      "|    iterations         | 4700      |\n",
      "|    time_elapsed       | 623       |\n",
      "|    total_timesteps    | 94000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.21e-21 |\n",
      "|    explained_variance | 0.813     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4699      |\n",
      "|    policy_loss        | 35.5      |\n",
      "|    value_loss         | 4.77      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=95000, episode_reward=-6378.08 +/- 0.03\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -6.38e+03 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 95000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0263   |\n",
      "|    explained_variance | 0.452     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4749      |\n",
      "|    policy_loss        | 26        |\n",
      "|    value_loss         | 39.4      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 8.16e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 653      |\n",
      "|    total_timesteps    | 96000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0364  |\n",
      "|    explained_variance | 0.909    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | -3.48    |\n",
      "|    value_loss         | 10.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 8.32e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 656      |\n",
      "|    total_timesteps    | 98000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00301 |\n",
      "|    explained_variance | 0.955    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 60.2     |\n",
      "|    value_loss         | 5.08     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=-7217.01 +/- 0.19\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -7.22e+03 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 100000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0753   |\n",
      "|    explained_variance | -0.0712   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4999      |\n",
      "|    policy_loss        | -21.3     |\n",
      "|    value_loss         | 23.9      |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.3e+03  |\n",
      "|    ep_rew_mean     | 8.31e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 145      |\n",
      "|    iterations      | 5000     |\n",
      "|    time_elapsed    | 686      |\n",
      "|    total_timesteps | 100000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 8.46e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 689      |\n",
      "|    total_timesteps    | 102000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00899 |\n",
      "|    explained_variance | 0.908    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | -73.4    |\n",
      "|    value_loss         | 13.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 8.59e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 692      |\n",
      "|    total_timesteps    | 104000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0831  |\n",
      "|    explained_variance | 0.816    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | -303     |\n",
      "|    value_loss         | 16.1     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=105000, episode_reward=-16081.17 +/- 0.06\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.61e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 105000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0206   |\n",
      "|    explained_variance | 0.924     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5249      |\n",
      "|    policy_loss        | -676      |\n",
      "|    value_loss         | 22.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 8.5e+03   |\n",
      "| time/                 |           |\n",
      "|    fps                | 146       |\n",
      "|    iterations         | 5300      |\n",
      "|    time_elapsed       | 722       |\n",
      "|    total_timesteps    | 106000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.28e-41 |\n",
      "|    explained_variance | 0.0993    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5299      |\n",
      "|    policy_loss        | 1.24e+04  |\n",
      "|    value_loss         | 3.33e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 8.5e+03   |\n",
      "| time/                 |           |\n",
      "|    fps                | 148       |\n",
      "|    iterations         | 5400      |\n",
      "|    time_elapsed       | 725       |\n",
      "|    total_timesteps    | 108000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.78e-28 |\n",
      "|    explained_variance | 0.263     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5399      |\n",
      "|    policy_loss        | -8.08e+03 |\n",
      "|    value_loss         | 2.13e+03  |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=110000, episode_reward=-16302.06 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.63e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 110000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.85e-06 |\n",
      "|    explained_variance | 0.809     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5499      |\n",
      "|    policy_loss        | 25.2      |\n",
      "|    value_loss         | 19        |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.3e+03  |\n",
      "|    ep_rew_mean     | 8.49e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 145      |\n",
      "|    iterations      | 5500     |\n",
      "|    time_elapsed    | 756      |\n",
      "|    total_timesteps | 110000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 7.98e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 147       |\n",
      "|    iterations         | 5600      |\n",
      "|    time_elapsed       | 759       |\n",
      "|    total_timesteps    | 112000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.9e-20  |\n",
      "|    explained_variance | 0.733     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5599      |\n",
      "|    policy_loss        | -1.56e+03 |\n",
      "|    value_loss         | 69        |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 8.14e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 762      |\n",
      "|    total_timesteps    | 114000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0519  |\n",
      "|    explained_variance | 0.783    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | -534     |\n",
      "|    value_loss         | 28.2     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=115000, episode_reward=-15208.00 +/- 0.20\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.52e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 115000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0747   |\n",
      "|    explained_variance | -1.23     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5749      |\n",
      "|    policy_loss        | 265       |\n",
      "|    value_loss         | 438       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 7.96e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 792      |\n",
      "|    total_timesteps    | 116000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0733  |\n",
      "|    explained_variance | 0.687    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | -332     |\n",
      "|    value_loss         | 17.3     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 8.12e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 148       |\n",
      "|    iterations         | 5900      |\n",
      "|    time_elapsed       | 795       |\n",
      "|    total_timesteps    | 118000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0        |\n",
      "|    explained_variance | -0.132    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5899      |\n",
      "|    policy_loss        | -4.43e+03 |\n",
      "|    value_loss         | 324       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=120000, episode_reward=-5603.71 +/- 0.08\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 2.3e+03  |\n",
      "|    mean_reward        | -5.6e+03 |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 120000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0253  |\n",
      "|    explained_variance | 0.663    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | -808     |\n",
      "|    value_loss         | 47.2     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.3e+03  |\n",
      "|    ep_rew_mean     | 8.08e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 145      |\n",
      "|    iterations      | 6000     |\n",
      "|    time_elapsed    | 825      |\n",
      "|    total_timesteps | 120000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 8.08e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 828      |\n",
      "|    total_timesteps    | 122000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0842  |\n",
      "|    explained_variance | 0.856    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | 331      |\n",
      "|    value_loss         | 21.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 8.2e+03  |\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 831      |\n",
      "|    total_timesteps    | 124000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0       |\n",
      "|    explained_variance | 0.208    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | -294     |\n",
      "|    value_loss         | 18.1     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=125000, episode_reward=-10624.26 +/- 0.01\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.06e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 125000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.8e-05  |\n",
      "|    explained_variance | 0.831     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6249      |\n",
      "|    policy_loss        | 132       |\n",
      "|    value_loss         | 17.6      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 8.23e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 861      |\n",
      "|    total_timesteps    | 126000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0571  |\n",
      "|    explained_variance | 0.604    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | 1.02e+03 |\n",
      "|    value_loss         | 89.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 8.36e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 6400     |\n",
      "|    time_elapsed       | 864      |\n",
      "|    total_timesteps    | 128000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0502  |\n",
      "|    explained_variance | 0.828    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6399     |\n",
      "|    policy_loss        | 251      |\n",
      "|    value_loss         | 15.6     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=130000, episode_reward=15407.18 +/- 0.02\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 2.3e+03  |\n",
      "|    mean_reward        | 1.54e+04 |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 130000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0463  |\n",
      "|    explained_variance | -0.114   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6499     |\n",
      "|    policy_loss        | -974     |\n",
      "|    value_loss         | 39.2     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.3e+03  |\n",
      "|    ep_rew_mean     | 8.43e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 145      |\n",
      "|    iterations      | 6500     |\n",
      "|    time_elapsed    | 894      |\n",
      "|    total_timesteps | 130000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 8.4e+03  |\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 6600     |\n",
      "|    time_elapsed       | 897      |\n",
      "|    total_timesteps    | 132000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.108   |\n",
      "|    explained_variance | 0.719    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6599     |\n",
      "|    policy_loss        | -947     |\n",
      "|    value_loss         | 73.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 8.47e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 901      |\n",
      "|    total_timesteps    | 134000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0855  |\n",
      "|    explained_variance | 0.898    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | 32.1     |\n",
      "|    value_loss         | 9.24     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=135000, episode_reward=6147.49 +/- 0.02\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 2.3e+03  |\n",
      "|    mean_reward        | 6.15e+03 |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 135000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0443  |\n",
      "|    explained_variance | 0.889    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6749     |\n",
      "|    policy_loss        | 32.8     |\n",
      "|    value_loss         | 13.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 8.58e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 6800     |\n",
      "|    time_elapsed       | 929      |\n",
      "|    total_timesteps    | 136000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0424  |\n",
      "|    explained_variance | -0.181   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6799     |\n",
      "|    policy_loss        | -220     |\n",
      "|    value_loss         | 38.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 8.58e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 6900     |\n",
      "|    time_elapsed       | 932      |\n",
      "|    total_timesteps    | 138000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00539 |\n",
      "|    explained_variance | 0.909    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6899     |\n",
      "|    policy_loss        | -476     |\n",
      "|    value_loss         | 12.4     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=140000, episode_reward=-1060.14 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.06e+03 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 140000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0397   |\n",
      "|    explained_variance | 0.91      |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6999      |\n",
      "|    policy_loss        | 69.5      |\n",
      "|    value_loss         | 7.46      |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.3e+03  |\n",
      "|    ep_rew_mean     | 8.69e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 145      |\n",
      "|    iterations      | 7000     |\n",
      "|    time_elapsed    | 962      |\n",
      "|    total_timesteps | 140000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 8.81e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 147       |\n",
      "|    iterations         | 7100      |\n",
      "|    time_elapsed       | 965       |\n",
      "|    total_timesteps    | 142000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000884 |\n",
      "|    explained_variance | 0.763     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7099      |\n",
      "|    policy_loss        | 97.2      |\n",
      "|    value_loss         | 5.37      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 8.91e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 968      |\n",
      "|    total_timesteps    | 144000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0948  |\n",
      "|    explained_variance | 0.96     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | 426      |\n",
      "|    value_loss         | 7.08     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=145000, episode_reward=-8660.59 +/- 0.01\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -8.66e+03 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 145000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.31e-23 |\n",
      "|    explained_variance | 0.7       |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7249      |\n",
      "|    policy_loss        | -262      |\n",
      "|    value_loss         | 7.76      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 9.02e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 7300     |\n",
      "|    time_elapsed       | 998      |\n",
      "|    total_timesteps    | 146000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00549 |\n",
      "|    explained_variance | 0.908    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7299     |\n",
      "|    policy_loss        | -373     |\n",
      "|    value_loss         | 5.94     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 9.12e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 147       |\n",
      "|    iterations         | 7400      |\n",
      "|    time_elapsed       | 1001      |\n",
      "|    total_timesteps    | 148000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.97e-05 |\n",
      "|    explained_variance | 0.869     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7399      |\n",
      "|    policy_loss        | -557      |\n",
      "|    value_loss         | 10.6      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=150000, episode_reward=-4578.80 +/- 0.01\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -4.58e+03 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 150000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0897   |\n",
      "|    explained_variance | 0.8       |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7499      |\n",
      "|    policy_loss        | -604      |\n",
      "|    value_loss         | 31.4      |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.3e+03  |\n",
      "|    ep_rew_mean     | 9.21e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 145      |\n",
      "|    iterations      | 7500     |\n",
      "|    time_elapsed    | 1031     |\n",
      "|    total_timesteps | 150000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 9.21e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 146       |\n",
      "|    iterations         | 7600      |\n",
      "|    time_elapsed       | 1034      |\n",
      "|    total_timesteps    | 152000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.14e-09 |\n",
      "|    explained_variance | 0.876     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7599      |\n",
      "|    policy_loss        | -277      |\n",
      "|    value_loss         | 10.6      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 9.3e+03   |\n",
      "| time/                 |           |\n",
      "|    fps                | 148       |\n",
      "|    iterations         | 7700      |\n",
      "|    time_elapsed       | 1037      |\n",
      "|    total_timesteps    | 154000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0        |\n",
      "|    explained_variance | -0.808    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7699      |\n",
      "|    policy_loss        | -8.08e+03 |\n",
      "|    value_loss         | 603       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=155000, episode_reward=-7917.99 +/- 0.01\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -7.92e+03 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 155000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0199   |\n",
      "|    explained_variance | 0.725     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7749      |\n",
      "|    policy_loss        | 737       |\n",
      "|    value_loss         | 129       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 9.31e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 1068     |\n",
      "|    total_timesteps    | 156000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00824 |\n",
      "|    explained_variance | 0.951    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | 86.9     |\n",
      "|    value_loss         | 4.62     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 9.38e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 7900     |\n",
      "|    time_elapsed       | 1071     |\n",
      "|    total_timesteps    | 158000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0382  |\n",
      "|    explained_variance | 0.75     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | -133     |\n",
      "|    value_loss         | 21.1     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=13745.25 +/- 0.01\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | 1.37e+04  |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 160000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000221 |\n",
      "|    explained_variance | 0.729     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7999      |\n",
      "|    policy_loss        | -543      |\n",
      "|    value_loss         | 7.99      |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.3e+03  |\n",
      "|    ep_rew_mean     | 9.47e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 145      |\n",
      "|    iterations      | 8000     |\n",
      "|    time_elapsed    | 1100     |\n",
      "|    total_timesteps | 160000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 9.55e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 146       |\n",
      "|    iterations         | 8100      |\n",
      "|    time_elapsed       | 1103      |\n",
      "|    total_timesteps    | 162000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000132 |\n",
      "|    explained_variance | 0.965     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8099      |\n",
      "|    policy_loss        | -123      |\n",
      "|    value_loss         | 3.58      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 9.63e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 8200     |\n",
      "|    time_elapsed       | 1106     |\n",
      "|    total_timesteps    | 164000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0151  |\n",
      "|    explained_variance | 0.954    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8199     |\n",
      "|    policy_loss        | -237     |\n",
      "|    value_loss         | 3.21     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=165000, episode_reward=-4958.04 +/- 0.02\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -4.96e+03 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 165000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00647  |\n",
      "|    explained_variance | 0.927     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8249      |\n",
      "|    policy_loss        | -255      |\n",
      "|    value_loss         | 6.69      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 9.71e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 146       |\n",
      "|    iterations         | 8300      |\n",
      "|    time_elapsed       | 1136      |\n",
      "|    total_timesteps    | 166000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.69e-12 |\n",
      "|    explained_variance | 0.857     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8299      |\n",
      "|    policy_loss        | -564      |\n",
      "|    value_loss         | 7.85      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 9.71e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 147       |\n",
      "|    iterations         | 8400      |\n",
      "|    time_elapsed       | 1139      |\n",
      "|    total_timesteps    | 168000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.124    |\n",
      "|    explained_variance | 0.766     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8399      |\n",
      "|    policy_loss        | -1.49e+03 |\n",
      "|    value_loss         | 70.6      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=170000, episode_reward=15501.36 +/- 0.02\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 2.3e+03  |\n",
      "|    mean_reward        | 1.55e+04 |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 170000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0949  |\n",
      "|    explained_variance | 0.899    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8499     |\n",
      "|    policy_loss        | 548      |\n",
      "|    value_loss         | 20.2     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.3e+03  |\n",
      "|    ep_rew_mean     | 9.79e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 145      |\n",
      "|    iterations      | 8500     |\n",
      "|    time_elapsed    | 1170     |\n",
      "|    total_timesteps | 170000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 9.87e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 8600     |\n",
      "|    time_elapsed       | 1173     |\n",
      "|    total_timesteps    | 172000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0509  |\n",
      "|    explained_variance | 0.127    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8599     |\n",
      "|    policy_loss        | -597     |\n",
      "|    value_loss         | 23.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 9.93e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 8700     |\n",
      "|    time_elapsed       | 1176     |\n",
      "|    total_timesteps    | 174000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0246  |\n",
      "|    explained_variance | 0.967    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8699     |\n",
      "|    policy_loss        | -71.8    |\n",
      "|    value_loss         | 3.06     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=175000, episode_reward=-12068.99 +/- 0.02\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.21e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 175000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.51e-40 |\n",
      "|    explained_variance | 0.745     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8749      |\n",
      "|    policy_loss        | 388       |\n",
      "|    value_loss         | 21.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 1e+04     |\n",
      "| time/                 |           |\n",
      "|    fps                | 145       |\n",
      "|    iterations         | 8800      |\n",
      "|    time_elapsed       | 1206      |\n",
      "|    total_timesteps    | 176000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000474 |\n",
      "|    explained_variance | 0.863     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8799      |\n",
      "|    policy_loss        | 328       |\n",
      "|    value_loss         | 17.3      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.01e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 8900     |\n",
      "|    time_elapsed       | 1209     |\n",
      "|    total_timesteps    | 178000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0       |\n",
      "|    explained_variance | 0.808    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8899     |\n",
      "|    policy_loss        | 697      |\n",
      "|    value_loss         | 10.8     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=180000, episode_reward=-16165.18 +/- 0.03\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.62e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 180000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.105    |\n",
      "|    explained_variance | 0.921     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8999      |\n",
      "|    policy_loss        | -92.7     |\n",
      "|    value_loss         | 7.66      |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.3e+03  |\n",
      "|    ep_rew_mean     | 1.01e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 145      |\n",
      "|    iterations      | 9000     |\n",
      "|    time_elapsed    | 1239     |\n",
      "|    total_timesteps | 180000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.02e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 9100     |\n",
      "|    time_elapsed       | 1242     |\n",
      "|    total_timesteps    | 182000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00241 |\n",
      "|    explained_variance | 0.916    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9099     |\n",
      "|    policy_loss        | 78.2     |\n",
      "|    value_loss         | 8.49     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 1.02e+04  |\n",
      "| time/                 |           |\n",
      "|    fps                | 147       |\n",
      "|    iterations         | 9200      |\n",
      "|    time_elapsed       | 1245      |\n",
      "|    total_timesteps    | 184000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.43e-05 |\n",
      "|    explained_variance | 0.872     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9199      |\n",
      "|    policy_loss        | -132      |\n",
      "|    value_loss         | 3.07      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=185000, episode_reward=10975.19 +/- 0.01\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 2.3e+03  |\n",
      "|    mean_reward        | 1.1e+04  |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 185000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0331  |\n",
      "|    explained_variance | 0.926    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9249     |\n",
      "|    policy_loss        | 327      |\n",
      "|    value_loss         | 11.7     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 1.03e+04  |\n",
      "| time/                 |           |\n",
      "|    fps                | 146       |\n",
      "|    iterations         | 9300      |\n",
      "|    time_elapsed       | 1273      |\n",
      "|    total_timesteps    | 186000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.53e-05 |\n",
      "|    explained_variance | 0.928     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9299      |\n",
      "|    policy_loss        | 203       |\n",
      "|    value_loss         | 6.97      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.03e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 9400     |\n",
      "|    time_elapsed       | 1276     |\n",
      "|    total_timesteps    | 188000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0646  |\n",
      "|    explained_variance | 0.945    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9399     |\n",
      "|    policy_loss        | 181      |\n",
      "|    value_loss         | 6.23     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=190000, episode_reward=-17156.84 +/- 0.02\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.72e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 190000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.32e-05 |\n",
      "|    explained_variance | 0.763     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9499      |\n",
      "|    policy_loss        | 171       |\n",
      "|    value_loss         | 6.14      |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.3e+03  |\n",
      "|    ep_rew_mean     | 1.04e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 145      |\n",
      "|    iterations      | 9500     |\n",
      "|    time_elapsed    | 1307     |\n",
      "|    total_timesteps | 190000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.05e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 9600     |\n",
      "|    time_elapsed       | 1310     |\n",
      "|    total_timesteps    | 192000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.102   |\n",
      "|    explained_variance | 0.921    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9599     |\n",
      "|    policy_loss        | -29.2    |\n",
      "|    value_loss         | 7.63     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.05e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 9700     |\n",
      "|    time_elapsed       | 1313     |\n",
      "|    total_timesteps    | 194000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0285  |\n",
      "|    explained_variance | 0.907    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9699     |\n",
      "|    policy_loss        | -97.8    |\n",
      "|    value_loss         | 6.42     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=195000, episode_reward=-10464.64 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.05e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 195000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.114    |\n",
      "|    explained_variance | 0.936     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9749      |\n",
      "|    policy_loss        | -216      |\n",
      "|    value_loss         | 6.19      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 1.06e+04  |\n",
      "| time/                 |           |\n",
      "|    fps                | 145       |\n",
      "|    iterations         | 9800      |\n",
      "|    time_elapsed       | 1343      |\n",
      "|    total_timesteps    | 196000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.27e-07 |\n",
      "|    explained_variance | 0.789     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9799      |\n",
      "|    policy_loss        | -491      |\n",
      "|    value_loss         | 6.15      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.06e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 9900     |\n",
      "|    time_elapsed       | 1346     |\n",
      "|    total_timesteps    | 198000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.136   |\n",
      "|    explained_variance | 0.926    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9899     |\n",
      "|    policy_loss        | -48.8    |\n",
      "|    value_loss         | 6.69     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=200000, episode_reward=-12163.50 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.22e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 200000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.131    |\n",
      "|    explained_variance | 0.917     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9999      |\n",
      "|    policy_loss        | 126       |\n",
      "|    value_loss         | 7.72      |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.3e+03  |\n",
      "|    ep_rew_mean     | 1.06e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 145      |\n",
      "|    iterations      | 10000    |\n",
      "|    time_elapsed    | 1376     |\n",
      "|    total_timesteps | 200000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.07e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 10100    |\n",
      "|    time_elapsed       | 1379     |\n",
      "|    total_timesteps    | 202000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.1e-13 |\n",
      "|    explained_variance | 0.796    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10099    |\n",
      "|    policy_loss        | -220     |\n",
      "|    value_loss         | 5.22     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.08e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 10200    |\n",
      "|    time_elapsed       | 1383     |\n",
      "|    total_timesteps    | 204000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.077   |\n",
      "|    explained_variance | 0.857    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10199    |\n",
      "|    policy_loss        | -164     |\n",
      "|    value_loss         | 12.4     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=205000, episode_reward=14436.34 +/- 0.18\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | 1.44e+04  |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 205000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.92e-06 |\n",
      "|    explained_variance | 0.71      |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10249     |\n",
      "|    policy_loss        | 327       |\n",
      "|    value_loss         | 24        |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.08e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 145      |\n",
      "|    iterations         | 10300    |\n",
      "|    time_elapsed       | 1412     |\n",
      "|    total_timesteps    | 206000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0846  |\n",
      "|    explained_variance | 0.903    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10299    |\n",
      "|    policy_loss        | -68.8    |\n",
      "|    value_loss         | 6.41     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 1.09e+04  |\n",
      "| time/                 |           |\n",
      "|    fps                | 146       |\n",
      "|    iterations         | 10400     |\n",
      "|    time_elapsed       | 1416      |\n",
      "|    total_timesteps    | 208000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.86e-11 |\n",
      "|    explained_variance | 0.887     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10399     |\n",
      "|    policy_loss        | -2.61e+03 |\n",
      "|    value_loss         | 50.3      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=210000, episode_reward=-7574.48 +/- 0.05\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -7.57e+03 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 210000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.134    |\n",
      "|    explained_variance | 0.85      |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10499     |\n",
      "|    policy_loss        | 58.5      |\n",
      "|    value_loss         | 14.7      |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.3e+03  |\n",
      "|    ep_rew_mean     | 1.09e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 145      |\n",
      "|    iterations      | 10500    |\n",
      "|    time_elapsed    | 1446     |\n",
      "|    total_timesteps | 210000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 1.1e+04   |\n",
      "| time/                 |           |\n",
      "|    fps                | 146       |\n",
      "|    iterations         | 10600     |\n",
      "|    time_elapsed       | 1449      |\n",
      "|    total_timesteps    | 212000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.91e-05 |\n",
      "|    explained_variance | -0.00316  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10599     |\n",
      "|    policy_loss        | -1.08e+03 |\n",
      "|    value_loss         | 117       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 1.1e+04   |\n",
      "| time/                 |           |\n",
      "|    fps                | 147       |\n",
      "|    iterations         | 10700     |\n",
      "|    time_elapsed       | 1452      |\n",
      "|    total_timesteps    | 214000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.24e-05 |\n",
      "|    explained_variance | 0.629     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10699     |\n",
      "|    policy_loss        | -507      |\n",
      "|    value_loss         | 11.2      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=215000, episode_reward=-8194.79 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -8.19e+03 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 215000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00527  |\n",
      "|    explained_variance | 0.91      |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10749     |\n",
      "|    policy_loss        | 102       |\n",
      "|    value_loss         | 8.07      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.1e+04  |\n",
      "| time/                 |          |\n",
      "|    fps                | 145      |\n",
      "|    iterations         | 10800    |\n",
      "|    time_elapsed       | 1483     |\n",
      "|    total_timesteps    | 216000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0451  |\n",
      "|    explained_variance | 0.949    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10799    |\n",
      "|    policy_loss        | -366     |\n",
      "|    value_loss         | 4.91     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.11e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 10900    |\n",
      "|    time_elapsed       | 1486     |\n",
      "|    total_timesteps    | 218000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0232  |\n",
      "|    explained_variance | 0.733    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10899    |\n",
      "|    policy_loss        | -4.63    |\n",
      "|    value_loss         | 19.9     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=220000, episode_reward=14213.73 +/- 0.02\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 2.3e+03  |\n",
      "|    mean_reward        | 1.42e+04 |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 220000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0       |\n",
      "|    explained_variance | 0.44     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10999    |\n",
      "|    policy_loss        | 2.17e+04 |\n",
      "|    value_loss         | 2.31e+03 |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.3e+03  |\n",
      "|    ep_rew_mean     | 1.11e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 145      |\n",
      "|    iterations      | 11000    |\n",
      "|    time_elapsed    | 1516     |\n",
      "|    total_timesteps | 220000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.11e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 11100    |\n",
      "|    time_elapsed       | 1519     |\n",
      "|    total_timesteps    | 222000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0776  |\n",
      "|    explained_variance | 0.878    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11099    |\n",
      "|    policy_loss        | -396     |\n",
      "|    value_loss         | 13.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.11e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 11200    |\n",
      "|    time_elapsed       | 1522     |\n",
      "|    total_timesteps    | 224000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00739 |\n",
      "|    explained_variance | 0.849    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11199    |\n",
      "|    policy_loss        | 301      |\n",
      "|    value_loss         | 22.7     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=225000, episode_reward=6505.73 +/- 0.10\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | 6.51e+03  |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 225000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000134 |\n",
      "|    explained_variance | 0.944     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11249     |\n",
      "|    policy_loss        | 60.7      |\n",
      "|    value_loss         | 6.52      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 1.12e+04  |\n",
      "| time/                 |           |\n",
      "|    fps                | 145       |\n",
      "|    iterations         | 11300     |\n",
      "|    time_elapsed       | 1552      |\n",
      "|    total_timesteps    | 226000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00087  |\n",
      "|    explained_variance | 0.477     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11299     |\n",
      "|    policy_loss        | -2.81e+03 |\n",
      "|    value_loss         | 47.5      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 1.12e+04  |\n",
      "| time/                 |           |\n",
      "|    fps                | 146       |\n",
      "|    iterations         | 11400     |\n",
      "|    time_elapsed       | 1555      |\n",
      "|    total_timesteps    | 228000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.25e-07 |\n",
      "|    explained_variance | 0.927     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11399     |\n",
      "|    policy_loss        | 141       |\n",
      "|    value_loss         | 7.39      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=230000, episode_reward=-9970.68 +/- 0.09\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -9.97e+03 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 230000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.11e-06 |\n",
      "|    explained_variance | 0.525     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11499     |\n",
      "|    policy_loss        | -1.24e+03 |\n",
      "|    value_loss         | 36.3      |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.3e+03  |\n",
      "|    ep_rew_mean     | 1.12e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 145      |\n",
      "|    iterations      | 11500    |\n",
      "|    time_elapsed    | 1586     |\n",
      "|    total_timesteps | 230000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 1.13e+04  |\n",
      "| time/                 |           |\n",
      "|    fps                | 145       |\n",
      "|    iterations         | 11600     |\n",
      "|    time_elapsed       | 1589      |\n",
      "|    total_timesteps    | 232000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.83e-10 |\n",
      "|    explained_variance | 0.806     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11599     |\n",
      "|    policy_loss        | -1.25e+03 |\n",
      "|    value_loss         | 16.7      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 1.13e+04  |\n",
      "| time/                 |           |\n",
      "|    fps                | 146       |\n",
      "|    iterations         | 11700     |\n",
      "|    time_elapsed       | 1592      |\n",
      "|    total_timesteps    | 234000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.19e-06 |\n",
      "|    explained_variance | 0.858     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11699     |\n",
      "|    policy_loss        | -1.1e+03  |\n",
      "|    value_loss         | 14.6      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=235000, episode_reward=15218.72 +/- 0.04\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 2.3e+03  |\n",
      "|    mean_reward        | 1.52e+04 |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 235000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0232  |\n",
      "|    explained_variance | 0.562    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11749    |\n",
      "|    policy_loss        | 437      |\n",
      "|    value_loss         | 16.8     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 1.13e+04  |\n",
      "| time/                 |           |\n",
      "|    fps                | 145       |\n",
      "|    iterations         | 11800     |\n",
      "|    time_elapsed       | 1622      |\n",
      "|    total_timesteps    | 236000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000762 |\n",
      "|    explained_variance | 0.901     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11799     |\n",
      "|    policy_loss        | 526       |\n",
      "|    value_loss         | 13        |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.12e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 11900    |\n",
      "|    time_elapsed       | 1625     |\n",
      "|    total_timesteps    | 238000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0       |\n",
      "|    explained_variance | 0.804    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11899    |\n",
      "|    policy_loss        | -415     |\n",
      "|    value_loss         | 5.16     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=240000, episode_reward=-16214.64 +/- 0.08\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.62e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 240000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00431  |\n",
      "|    explained_variance | 0.722     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11999     |\n",
      "|    policy_loss        | -1.69e+03 |\n",
      "|    value_loss         | 50.3      |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.3e+03  |\n",
      "|    ep_rew_mean     | 1.12e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 144      |\n",
      "|    iterations      | 12000    |\n",
      "|    time_elapsed    | 1655     |\n",
      "|    total_timesteps | 240000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.11e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 145      |\n",
      "|    iterations         | 12100    |\n",
      "|    time_elapsed       | 1658     |\n",
      "|    total_timesteps    | 242000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0314  |\n",
      "|    explained_variance | 0.641    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12099    |\n",
      "|    policy_loss        | 1.53e+03 |\n",
      "|    value_loss         | 36.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.11e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 12200    |\n",
      "|    time_elapsed       | 1661     |\n",
      "|    total_timesteps    | 244000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0       |\n",
      "|    explained_variance | 0.319    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12199    |\n",
      "|    policy_loss        | 3.53e+04 |\n",
      "|    value_loss         | 6.03e+03 |\n",
      "------------------------------------\n",
      "Eval num_timesteps=245000, episode_reward=774.38 +/- 0.27\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 2.3e+03  |\n",
      "|    mean_reward        | 774      |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 245000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0443  |\n",
      "|    explained_variance | 0.813    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12249    |\n",
      "|    policy_loss        | 14.8     |\n",
      "|    value_loss         | 110      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.1e+04  |\n",
      "| time/                 |          |\n",
      "|    fps                | 145      |\n",
      "|    iterations         | 12300    |\n",
      "|    time_elapsed       | 1691     |\n",
      "|    total_timesteps    | 246000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0411  |\n",
      "|    explained_variance | 0.794    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12299    |\n",
      "|    policy_loss        | 303      |\n",
      "|    value_loss         | 24.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.09e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 12400    |\n",
      "|    time_elapsed       | 1694     |\n",
      "|    total_timesteps    | 248000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0162  |\n",
      "|    explained_variance | 0.836    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12399    |\n",
      "|    policy_loss        | 7.98     |\n",
      "|    value_loss         | 15.4     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=250000, episode_reward=-566.76 +/- 0.13\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -567      |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 250000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.62e-10 |\n",
      "|    explained_variance | 0.822     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12499     |\n",
      "|    policy_loss        | 1.15e+03  |\n",
      "|    value_loss         | 14.1      |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.3e+03  |\n",
      "|    ep_rew_mean     | 1.09e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 144      |\n",
      "|    iterations      | 12500    |\n",
      "|    time_elapsed    | 1725     |\n",
      "|    total_timesteps | 250000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.08e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 145      |\n",
      "|    iterations         | 12600    |\n",
      "|    time_elapsed       | 1728     |\n",
      "|    total_timesteps    | 252000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0669  |\n",
      "|    explained_variance | 0.819    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12599    |\n",
      "|    policy_loss        | -127     |\n",
      "|    value_loss         | 17.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.07e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 12700    |\n",
      "|    time_elapsed       | 1731     |\n",
      "|    total_timesteps    | 254000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0378  |\n",
      "|    explained_variance | 0.847    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12699    |\n",
      "|    policy_loss        | 303      |\n",
      "|    value_loss         | 33.4     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=255000, episode_reward=13065.22 +/- 0.11\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 2.3e+03  |\n",
      "|    mean_reward        | 1.31e+04 |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 255000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0141  |\n",
      "|    explained_variance | 0.788    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12749    |\n",
      "|    policy_loss        | -84.2    |\n",
      "|    value_loss         | 19       |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 1.07e+04  |\n",
      "| time/                 |           |\n",
      "|    fps                | 145       |\n",
      "|    iterations         | 12800     |\n",
      "|    time_elapsed       | 1763      |\n",
      "|    total_timesteps    | 256000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.14e-06 |\n",
      "|    explained_variance | 0.483     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12799     |\n",
      "|    policy_loss        | 244       |\n",
      "|    value_loss         | 23.4      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.07e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 12900    |\n",
      "|    time_elapsed       | 1766     |\n",
      "|    total_timesteps    | 258000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0962  |\n",
      "|    explained_variance | 0.838    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12899    |\n",
      "|    policy_loss        | 84.5     |\n",
      "|    value_loss         | 17       |\n",
      "------------------------------------\n",
      "Eval num_timesteps=260000, episode_reward=-17253.68 +/- 0.23\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.73e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 260000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0163   |\n",
      "|    explained_variance | 0.492     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12999     |\n",
      "|    policy_loss        | 9.49      |\n",
      "|    value_loss         | 113       |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.3e+03  |\n",
      "|    ep_rew_mean     | 1.06e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 144      |\n",
      "|    iterations      | 13000    |\n",
      "|    time_elapsed    | 1797     |\n",
      "|    total_timesteps | 260000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.09e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 145      |\n",
      "|    iterations         | 13100    |\n",
      "|    time_elapsed       | 1800     |\n",
      "|    total_timesteps    | 262000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0       |\n",
      "|    explained_variance | 0.598    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13099    |\n",
      "|    policy_loss        | -1.2e+03 |\n",
      "|    value_loss         | 30       |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 1.12e+04  |\n",
      "| time/                 |           |\n",
      "|    fps                | 146       |\n",
      "|    iterations         | 13200     |\n",
      "|    time_elapsed       | 1803      |\n",
      "|    total_timesteps    | 264000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.24e-05 |\n",
      "|    explained_variance | 0.842     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13199     |\n",
      "|    policy_loss        | -72.3     |\n",
      "|    value_loss         | 14.4      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=265000, episode_reward=-294.28 +/- 0.09\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -294      |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 265000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0        |\n",
      "|    explained_variance | 0.615     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13249     |\n",
      "|    policy_loss        | -1.13e+04 |\n",
      "|    value_loss         | 382       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 1.15e+04  |\n",
      "| time/                 |           |\n",
      "|    fps                | 145       |\n",
      "|    iterations         | 13300     |\n",
      "|    time_elapsed       | 1833      |\n",
      "|    total_timesteps    | 266000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.48e-06 |\n",
      "|    explained_variance | 0.888     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13299     |\n",
      "|    policy_loss        | 158       |\n",
      "|    value_loss         | 9.97      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 1.19e+04  |\n",
      "| time/                 |           |\n",
      "|    fps                | 145       |\n",
      "|    iterations         | 13400     |\n",
      "|    time_elapsed       | 1836      |\n",
      "|    total_timesteps    | 268000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.47e-07 |\n",
      "|    explained_variance | 0.501     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13399     |\n",
      "|    policy_loss        | -1.7e+03  |\n",
      "|    value_loss         | 20        |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=270000, episode_reward=-15723.71 +/- 0.04\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.57e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 270000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000901 |\n",
      "|    explained_variance | -2.05     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13499     |\n",
      "|    policy_loss        | 2.84e+04  |\n",
      "|    value_loss         | 5.4e+03   |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.3e+03  |\n",
      "|    ep_rew_mean     | 1.18e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 144      |\n",
      "|    iterations      | 13500    |\n",
      "|    time_elapsed    | 1866     |\n",
      "|    total_timesteps | 270000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 1.18e+04  |\n",
      "| time/                 |           |\n",
      "|    fps                | 145       |\n",
      "|    iterations         | 13600     |\n",
      "|    time_elapsed       | 1869      |\n",
      "|    total_timesteps    | 272000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.15e-08 |\n",
      "|    explained_variance | 0.379     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13599     |\n",
      "|    policy_loss        | 1.2e+04   |\n",
      "|    value_loss         | 6.47e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 1.18e+04  |\n",
      "| time/                 |           |\n",
      "|    fps                | 146       |\n",
      "|    iterations         | 13700     |\n",
      "|    time_elapsed       | 1872      |\n",
      "|    total_timesteps    | 274000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00683  |\n",
      "|    explained_variance | -0.0314   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13699     |\n",
      "|    policy_loss        | -5.03e+03 |\n",
      "|    value_loss         | 247       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=275000, episode_reward=9297.61 +/- 0.03\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | 9.3e+03   |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 275000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.65e-05 |\n",
      "|    explained_variance | 0.583     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13749     |\n",
      "|    policy_loss        | 260       |\n",
      "|    value_loss         | 37.3      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 1.18e+04  |\n",
      "| time/                 |           |\n",
      "|    fps                | 145       |\n",
      "|    iterations         | 13800     |\n",
      "|    time_elapsed       | 1901      |\n",
      "|    total_timesteps    | 276000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0174   |\n",
      "|    explained_variance | 0.0745    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13799     |\n",
      "|    policy_loss        | -2.31e+04 |\n",
      "|    value_loss         | 2.49e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.19e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 145      |\n",
      "|    iterations         | 13900    |\n",
      "|    time_elapsed       | 1905     |\n",
      "|    total_timesteps    | 278000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0796  |\n",
      "|    explained_variance | 0.852    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13899    |\n",
      "|    policy_loss        | 129      |\n",
      "|    value_loss         | 12       |\n",
      "------------------------------------\n",
      "Eval num_timesteps=280000, episode_reward=3807.71 +/- 0.07\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | 3.81e+03  |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 280000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.02e-17 |\n",
      "|    explained_variance | 0.195     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13999     |\n",
      "|    policy_loss        | -171      |\n",
      "|    value_loss         | 23.7      |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.3e+03  |\n",
      "|    ep_rew_mean     | 1.19e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 144      |\n",
      "|    iterations      | 14000    |\n",
      "|    time_elapsed    | 1934     |\n",
      "|    total_timesteps | 280000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 1.22e+04  |\n",
      "| time/                 |           |\n",
      "|    fps                | 145       |\n",
      "|    iterations         | 14100     |\n",
      "|    time_elapsed       | 1937      |\n",
      "|    total_timesteps    | 282000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.03     |\n",
      "|    explained_variance | 0.806     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14099     |\n",
      "|    policy_loss        | -1.37e+03 |\n",
      "|    value_loss         | 21.9      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.22e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 14200    |\n",
      "|    time_elapsed       | 1941     |\n",
      "|    total_timesteps    | 284000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.127   |\n",
      "|    explained_variance | 0.625    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14199    |\n",
      "|    policy_loss        | -1.4e+03 |\n",
      "|    value_loss         | 26.6     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=285000, episode_reward=-16207.61 +/- 0.11\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.62e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 285000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.58e-14 |\n",
      "|    explained_variance | 0.459     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14249     |\n",
      "|    policy_loss        | -5.54e+03 |\n",
      "|    value_loss         | 169       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.23e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 145      |\n",
      "|    iterations         | 14300    |\n",
      "|    time_elapsed       | 1970     |\n",
      "|    total_timesteps    | 286000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.113   |\n",
      "|    explained_variance | -0.204   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14299    |\n",
      "|    policy_loss        | 110      |\n",
      "|    value_loss         | 1.07e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 1.23e+04  |\n",
      "| time/                 |           |\n",
      "|    fps                | 145       |\n",
      "|    iterations         | 14400     |\n",
      "|    time_elapsed       | 1973      |\n",
      "|    total_timesteps    | 288000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.11e-12 |\n",
      "|    explained_variance | -0.335    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14399     |\n",
      "|    policy_loss        | 328       |\n",
      "|    value_loss         | 219       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=290000, episode_reward=-19356.31 +/- 0.19\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.94e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 290000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0518   |\n",
      "|    explained_variance | -0.135    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14499     |\n",
      "|    policy_loss        | -399      |\n",
      "|    value_loss         | 2.61e+03  |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.3e+03  |\n",
      "|    ep_rew_mean     | 1.23e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 144      |\n",
      "|    iterations      | 14500    |\n",
      "|    time_elapsed    | 2003     |\n",
      "|    total_timesteps | 290000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.23e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 145      |\n",
      "|    iterations         | 14600    |\n",
      "|    time_elapsed       | 2006     |\n",
      "|    total_timesteps    | 292000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0777  |\n",
      "|    explained_variance | 0.494    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14599    |\n",
      "|    policy_loss        | -14.3    |\n",
      "|    value_loss         | 72.8     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 1.23e+04  |\n",
      "| time/                 |           |\n",
      "|    fps                | 146       |\n",
      "|    iterations         | 14700     |\n",
      "|    time_elapsed       | 2009      |\n",
      "|    total_timesteps    | 294000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.21e-05 |\n",
      "|    explained_variance | 0.439     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14699     |\n",
      "|    policy_loss        | -2.19e+03 |\n",
      "|    value_loss         | 567       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=295000, episode_reward=-16163.12 +/- 0.10\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.62e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 295000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0        |\n",
      "|    explained_variance | 0.474     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14749     |\n",
      "|    policy_loss        | 1.75e+04  |\n",
      "|    value_loss         | 1.44e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 1.25e+04  |\n",
      "| time/                 |           |\n",
      "|    fps                | 145       |\n",
      "|    iterations         | 14800     |\n",
      "|    time_elapsed       | 2040      |\n",
      "|    total_timesteps    | 296000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.37e-06 |\n",
      "|    explained_variance | 0.821     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14799     |\n",
      "|    policy_loss        | -275      |\n",
      "|    value_loss         | 18.4      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.22e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 145      |\n",
      "|    iterations         | 14900    |\n",
      "|    time_elapsed       | 2043     |\n",
      "|    total_timesteps    | 298000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.105   |\n",
      "|    explained_variance | 0.416    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14899    |\n",
      "|    policy_loss        | 29       |\n",
      "|    value_loss         | 614      |\n",
      "------------------------------------\n",
      "Eval num_timesteps=300000, episode_reward=-16163.15 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.62e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 300000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0258   |\n",
      "|    explained_variance | 0.509     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14999     |\n",
      "|    policy_loss        | -1.56e+04 |\n",
      "|    value_loss         | 1.05e+03  |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.3e+03  |\n",
      "|    ep_rew_mean     | 1.22e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 144      |\n",
      "|    iterations      | 15000    |\n",
      "|    time_elapsed    | 2073     |\n",
      "|    total_timesteps | 300000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.23e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 145      |\n",
      "|    iterations         | 15100    |\n",
      "|    time_elapsed       | 2077     |\n",
      "|    total_timesteps    | 302000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0166  |\n",
      "|    explained_variance | 0.509    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15099    |\n",
      "|    policy_loss        | 1.18e+04 |\n",
      "|    value_loss         | 5.34e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 1.23e+04  |\n",
      "| time/                 |           |\n",
      "|    fps                | 146       |\n",
      "|    iterations         | 15200     |\n",
      "|    time_elapsed       | 2080      |\n",
      "|    total_timesteps    | 304000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.07e-06 |\n",
      "|    explained_variance | 0.849     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15199     |\n",
      "|    policy_loss        | -1.01e+03 |\n",
      "|    value_loss         | 13.6      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=305000, episode_reward=-16163.15 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.62e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 305000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0        |\n",
      "|    explained_variance | -0.301    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15249     |\n",
      "|    policy_loss        | 910       |\n",
      "|    value_loss         | 123       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.24e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 15300    |\n",
      "|    time_elapsed       | 2113     |\n",
      "|    total_timesteps    | 306000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00011 |\n",
      "|    explained_variance | 0.966    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15299    |\n",
      "|    policy_loss        | 386      |\n",
      "|    value_loss         | 8.99     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.21e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 145      |\n",
      "|    iterations         | 15400    |\n",
      "|    time_elapsed       | 2116     |\n",
      "|    total_timesteps    | 308000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0151  |\n",
      "|    explained_variance | -0.562   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15399    |\n",
      "|    policy_loss        | -369     |\n",
      "|    value_loss         | 77.1     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=310000, episode_reward=-16163.15 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.62e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 310000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0        |\n",
      "|    explained_variance | 0.964     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15499     |\n",
      "|    policy_loss        | -876      |\n",
      "|    value_loss         | 4.29      |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.3e+03  |\n",
      "|    ep_rew_mean     | 1.22e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 144      |\n",
      "|    iterations      | 15500    |\n",
      "|    time_elapsed    | 2147     |\n",
      "|    total_timesteps | 310000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.22e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 145      |\n",
      "|    iterations         | 15600    |\n",
      "|    time_elapsed       | 2150     |\n",
      "|    total_timesteps    | 312000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0424  |\n",
      "|    explained_variance | 0.859    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15599    |\n",
      "|    policy_loss        | -949     |\n",
      "|    value_loss         | 17.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.19e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 145      |\n",
      "|    iterations         | 15700    |\n",
      "|    time_elapsed       | 2153     |\n",
      "|    total_timesteps    | 314000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0757  |\n",
      "|    explained_variance | 0.625    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15699    |\n",
      "|    policy_loss        | 122      |\n",
      "|    value_loss         | 116      |\n",
      "------------------------------------\n",
      "Eval num_timesteps=315000, episode_reward=-16179.58 +/- 0.07\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.62e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 315000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0288   |\n",
      "|    explained_variance | 0.485     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15749     |\n",
      "|    policy_loss        | -1.91e+03 |\n",
      "|    value_loss         | 72.6      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.19e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 15800    |\n",
      "|    time_elapsed       | 2183     |\n",
      "|    total_timesteps    | 316000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00635 |\n",
      "|    explained_variance | 0.797    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15799    |\n",
      "|    policy_loss        | -441     |\n",
      "|    value_loss         | 12.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.18e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 145      |\n",
      "|    iterations         | 15900    |\n",
      "|    time_elapsed       | 2187     |\n",
      "|    total_timesteps    | 318000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00483 |\n",
      "|    explained_variance | -2.86    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15899    |\n",
      "|    policy_loss        | 1.82e+04 |\n",
      "|    value_loss         | 1.55e+03 |\n",
      "------------------------------------\n",
      "Eval num_timesteps=320000, episode_reward=-16055.42 +/- 0.07\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.61e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 320000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.26e-35 |\n",
      "|    explained_variance | 0.0701    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15999     |\n",
      "|    policy_loss        | -1.25e+04 |\n",
      "|    value_loss         | 1.03e+03  |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.3e+03  |\n",
      "|    ep_rew_mean     | 1.18e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 144      |\n",
      "|    iterations      | 16000    |\n",
      "|    time_elapsed    | 2218     |\n",
      "|    total_timesteps | 320000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.18e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 16100    |\n",
      "|    time_elapsed       | 2221     |\n",
      "|    total_timesteps    | 322000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00619 |\n",
      "|    explained_variance | 0.824    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16099    |\n",
      "|    policy_loss        | 1.97e+03 |\n",
      "|    value_loss         | 33.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.18e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 145      |\n",
      "|    iterations         | 16200    |\n",
      "|    time_elapsed       | 2224     |\n",
      "|    total_timesteps    | 324000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0387  |\n",
      "|    explained_variance | 0.729    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16199    |\n",
      "|    policy_loss        | -562     |\n",
      "|    value_loss         | 39.9     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=325000, episode_reward=-16163.15 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.62e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 325000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0        |\n",
      "|    explained_variance | 0.567     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16249     |\n",
      "|    policy_loss        | -324      |\n",
      "|    value_loss         | 29.6      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.18e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 16300    |\n",
      "|    time_elapsed       | 2254     |\n",
      "|    total_timesteps    | 326000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0841  |\n",
      "|    explained_variance | 0.451    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16299    |\n",
      "|    policy_loss        | 1.18e+03 |\n",
      "|    value_loss         | 335      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 1.18e+04  |\n",
      "| time/                 |           |\n",
      "|    fps                | 145       |\n",
      "|    iterations         | 16400     |\n",
      "|    time_elapsed       | 2257      |\n",
      "|    total_timesteps    | 328000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00168  |\n",
      "|    explained_variance | 0.622     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16399     |\n",
      "|    policy_loss        | -1.71e+03 |\n",
      "|    value_loss         | 22.3      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=330000, episode_reward=11624.17 +/- 0.44\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 2.3e+03  |\n",
      "|    mean_reward        | 1.16e+04 |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 330000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00108 |\n",
      "|    explained_variance | 0.905    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16499    |\n",
      "|    policy_loss        | -504     |\n",
      "|    value_loss         | 8.87     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.3e+03  |\n",
      "|    ep_rew_mean     | 1.18e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 144      |\n",
      "|    iterations      | 16500    |\n",
      "|    time_elapsed    | 2287     |\n",
      "|    total_timesteps | 330000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 1.18e+04  |\n",
      "| time/                 |           |\n",
      "|    fps                | 144       |\n",
      "|    iterations         | 16600     |\n",
      "|    time_elapsed       | 2291      |\n",
      "|    total_timesteps    | 332000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.08e-07 |\n",
      "|    explained_variance | 0.445     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16599     |\n",
      "|    policy_loss        | -564      |\n",
      "|    value_loss         | 45.5      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 1.18e+04  |\n",
      "| time/                 |           |\n",
      "|    fps                | 145       |\n",
      "|    iterations         | 16700     |\n",
      "|    time_elapsed       | 2294      |\n",
      "|    total_timesteps    | 334000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0        |\n",
      "|    explained_variance | 0.894     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16699     |\n",
      "|    policy_loss        | -1.11e+03 |\n",
      "|    value_loss         | 13.2      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=335000, episode_reward=968.96 +/- 0.06\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 2.3e+03  |\n",
      "|    mean_reward        | 969      |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 335000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00238 |\n",
      "|    explained_variance | 0.71     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16749    |\n",
      "|    policy_loss        | -105     |\n",
      "|    value_loss         | 31       |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 1.16e+04  |\n",
      "| time/                 |           |\n",
      "|    fps                | 144       |\n",
      "|    iterations         | 16800     |\n",
      "|    time_elapsed       | 2324      |\n",
      "|    total_timesteps    | 336000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0        |\n",
      "|    explained_variance | 0.875     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16799     |\n",
      "|    policy_loss        | -8.76e+03 |\n",
      "|    value_loss         | 304       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.17e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 145      |\n",
      "|    iterations         | 16900    |\n",
      "|    time_elapsed       | 2327     |\n",
      "|    total_timesteps    | 338000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0524  |\n",
      "|    explained_variance | 0.926    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16899    |\n",
      "|    policy_loss        | 480      |\n",
      "|    value_loss         | 13.7     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=340000, episode_reward=-15503.78 +/- 0.07\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.55e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 340000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.75e-09 |\n",
      "|    explained_variance | 0.714     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16999     |\n",
      "|    policy_loss        | 140       |\n",
      "|    value_loss         | 8.31      |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.3e+03  |\n",
      "|    ep_rew_mean     | 1.14e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 144      |\n",
      "|    iterations      | 17000    |\n",
      "|    time_elapsed    | 2357     |\n",
      "|    total_timesteps | 340000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.18e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 17100    |\n",
      "|    time_elapsed       | 2360     |\n",
      "|    total_timesteps    | 342000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.103   |\n",
      "|    explained_variance | 0.942    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17099    |\n",
      "|    policy_loss        | 63       |\n",
      "|    value_loss         | 5.81     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.18e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 145      |\n",
      "|    iterations         | 17200    |\n",
      "|    time_elapsed       | 2363     |\n",
      "|    total_timesteps    | 344000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.118   |\n",
      "|    explained_variance | 0.83     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17199    |\n",
      "|    policy_loss        | -302     |\n",
      "|    value_loss         | 10.3     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=345000, episode_reward=-16523.24 +/- 0.01\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.65e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 345000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0514   |\n",
      "|    explained_variance | 0.948     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17249     |\n",
      "|    policy_loss        | 728       |\n",
      "|    value_loss         | 7.96      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.19e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 17300    |\n",
      "|    time_elapsed       | 2394     |\n",
      "|    total_timesteps    | 346000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0       |\n",
      "|    explained_variance | 0.573    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17299    |\n",
      "|    policy_loss        | -452     |\n",
      "|    value_loss         | 12.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.19e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 145      |\n",
      "|    iterations         | 17400    |\n",
      "|    time_elapsed       | 2397     |\n",
      "|    total_timesteps    | 348000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0009  |\n",
      "|    explained_variance | 0.785    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17399    |\n",
      "|    policy_loss        | -926     |\n",
      "|    value_loss         | 26.4     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=350000, episode_reward=-17156.83 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.72e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 350000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0272   |\n",
      "|    explained_variance | 0.852     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17499     |\n",
      "|    policy_loss        | 207       |\n",
      "|    value_loss         | 14.5      |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.3e+03  |\n",
      "|    ep_rew_mean     | 1.19e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 144      |\n",
      "|    iterations      | 17500    |\n",
      "|    time_elapsed    | 2427     |\n",
      "|    total_timesteps | 350000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 1.2e+04   |\n",
      "| time/                 |           |\n",
      "|    fps                | 144       |\n",
      "|    iterations         | 17600     |\n",
      "|    time_elapsed       | 2430      |\n",
      "|    total_timesteps    | 352000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.39e-06 |\n",
      "|    explained_variance | 0.835     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17599     |\n",
      "|    policy_loss        | 112       |\n",
      "|    value_loss         | 4.54      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.2e+04  |\n",
      "| time/                 |          |\n",
      "|    fps                | 145      |\n",
      "|    iterations         | 17700    |\n",
      "|    time_elapsed       | 2433     |\n",
      "|    total_timesteps    | 354000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00309 |\n",
      "|    explained_variance | 0.969    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17699    |\n",
      "|    policy_loss        | -55      |\n",
      "|    value_loss         | 2.95     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=355000, episode_reward=-17156.83 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.72e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 355000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.08e-27 |\n",
      "|    explained_variance | 0.601     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17749     |\n",
      "|    policy_loss        | -934      |\n",
      "|    value_loss         | 13.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 1.21e+04  |\n",
      "| time/                 |           |\n",
      "|    fps                | 144       |\n",
      "|    iterations         | 17800     |\n",
      "|    time_elapsed       | 2463      |\n",
      "|    total_timesteps    | 356000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.19e-05 |\n",
      "|    explained_variance | 0.921     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17799     |\n",
      "|    policy_loss        | 664       |\n",
      "|    value_loss         | 13.4      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.21e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 145      |\n",
      "|    iterations         | 17900    |\n",
      "|    time_elapsed       | 2466     |\n",
      "|    total_timesteps    | 358000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0       |\n",
      "|    explained_variance | 0.804    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17899    |\n",
      "|    policy_loss        | -575     |\n",
      "|    value_loss         | 5.01     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=360000, episode_reward=-17156.83 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.72e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 360000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.58e-06 |\n",
      "|    explained_variance | 0.976     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17999     |\n",
      "|    policy_loss        | 60.8      |\n",
      "|    value_loss         | 3.05      |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.3e+03  |\n",
      "|    ep_rew_mean     | 1.21e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 144      |\n",
      "|    iterations      | 18000    |\n",
      "|    time_elapsed    | 2496     |\n",
      "|    total_timesteps | 360000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 1.22e+04  |\n",
      "| time/                 |           |\n",
      "|    fps                | 144       |\n",
      "|    iterations         | 18100     |\n",
      "|    time_elapsed       | 2499      |\n",
      "|    total_timesteps    | 362000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.94e-08 |\n",
      "|    explained_variance | 0.951     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18099     |\n",
      "|    policy_loss        | -249      |\n",
      "|    value_loss         | 3.83      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 1.22e+04  |\n",
      "| time/                 |           |\n",
      "|    fps                | 145       |\n",
      "|    iterations         | 18200     |\n",
      "|    time_elapsed       | 2503      |\n",
      "|    total_timesteps    | 364000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.76e-12 |\n",
      "|    explained_variance | 0.847     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18199     |\n",
      "|    policy_loss        | 643       |\n",
      "|    value_loss         | 4.63      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=365000, episode_reward=-16883.04 +/- 0.06\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.69e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 365000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.39e-15 |\n",
      "|    explained_variance | 0.942     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18249     |\n",
      "|    policy_loss        | -800      |\n",
      "|    value_loss         | 4.02      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.22e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 18300    |\n",
      "|    time_elapsed       | 2533     |\n",
      "|    total_timesteps    | 366000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.088   |\n",
      "|    explained_variance | 0.964    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18299    |\n",
      "|    policy_loss        | 310      |\n",
      "|    value_loss         | 4.25     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 1.22e+04  |\n",
      "| time/                 |           |\n",
      "|    fps                | 145       |\n",
      "|    iterations         | 18400     |\n",
      "|    time_elapsed       | 2536      |\n",
      "|    total_timesteps    | 368000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.16e-09 |\n",
      "|    explained_variance | 0.301     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18399     |\n",
      "|    policy_loss        | -1.51e+03 |\n",
      "|    value_loss         | 102       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=370000, episode_reward=-16163.14 +/- 0.03\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.62e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 370000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.84e-16 |\n",
      "|    explained_variance | -0.78     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18499     |\n",
      "|    policy_loss        | -4.34e+03 |\n",
      "|    value_loss         | 1.07e+03  |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.3e+03  |\n",
      "|    ep_rew_mean     | 1.21e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 144      |\n",
      "|    iterations      | 18500    |\n",
      "|    time_elapsed    | 2566     |\n",
      "|    total_timesteps | 370000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 1.19e+04  |\n",
      "| time/                 |           |\n",
      "|    fps                | 144       |\n",
      "|    iterations         | 18600     |\n",
      "|    time_elapsed       | 2569      |\n",
      "|    total_timesteps    | 372000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00189  |\n",
      "|    explained_variance | 0.74      |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18599     |\n",
      "|    policy_loss        | -1.89e+03 |\n",
      "|    value_loss         | 32.8      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 1.16e+04  |\n",
      "| time/                 |           |\n",
      "|    fps                | 145       |\n",
      "|    iterations         | 18700     |\n",
      "|    time_elapsed       | 2572      |\n",
      "|    total_timesteps    | 374000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.35e-06 |\n",
      "|    explained_variance | 0.447     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18699     |\n",
      "|    policy_loss        | 1.79e+03  |\n",
      "|    value_loss         | 765       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=375000, episode_reward=2033.24 +/- 0.39\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 2.3e+03  |\n",
      "|    mean_reward        | 2.03e+03 |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 375000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0271  |\n",
      "|    explained_variance | 0.8      |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18749    |\n",
      "|    policy_loss        | -683     |\n",
      "|    value_loss         | 28.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.16e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 18800    |\n",
      "|    time_elapsed       | 2602     |\n",
      "|    total_timesteps    | 376000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0103  |\n",
      "|    explained_variance | 0.822    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18799    |\n",
      "|    policy_loss        | 2.42e+03 |\n",
      "|    value_loss         | 39.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.15e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 145      |\n",
      "|    iterations         | 18900    |\n",
      "|    time_elapsed       | 2606     |\n",
      "|    total_timesteps    | 378000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00921 |\n",
      "|    explained_variance | 0.461    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18899    |\n",
      "|    policy_loss        | 103      |\n",
      "|    value_loss         | 56.2     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=380000, episode_reward=14452.62 +/- 0.05\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | 1.45e+04  |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 380000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0981   |\n",
      "|    explained_variance | 0.487     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18999     |\n",
      "|    policy_loss        | -1.19e+03 |\n",
      "|    value_loss         | 37.7      |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.3e+03  |\n",
      "|    ep_rew_mean     | 1.15e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 144      |\n",
      "|    iterations      | 19000    |\n",
      "|    time_elapsed    | 2636     |\n",
      "|    total_timesteps | 380000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 1.15e+04  |\n",
      "| time/                 |           |\n",
      "|    fps                | 144       |\n",
      "|    iterations         | 19100     |\n",
      "|    time_elapsed       | 2639      |\n",
      "|    total_timesteps    | 382000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.24e-05 |\n",
      "|    explained_variance | 0.876     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19099     |\n",
      "|    policy_loss        | 2.65e+03  |\n",
      "|    value_loss         | 20.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 1.15e+04  |\n",
      "| time/                 |           |\n",
      "|    fps                | 145       |\n",
      "|    iterations         | 19200     |\n",
      "|    time_elapsed       | 2642      |\n",
      "|    total_timesteps    | 384000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.17e-12 |\n",
      "|    explained_variance | 0.807     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19199     |\n",
      "|    policy_loss        | -887      |\n",
      "|    value_loss         | 26.7      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=385000, episode_reward=-16163.14 +/- 0.03\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.62e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 385000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0        |\n",
      "|    explained_variance | 0.718     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19249     |\n",
      "|    policy_loss        | -6.14e+03 |\n",
      "|    value_loss         | 58.7      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 1.15e+04  |\n",
      "| time/                 |           |\n",
      "|    fps                | 144       |\n",
      "|    iterations         | 19300     |\n",
      "|    time_elapsed       | 2673      |\n",
      "|    total_timesteps    | 386000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.08e-10 |\n",
      "|    explained_variance | 0.0816    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19299     |\n",
      "|    policy_loss        | 1.9e+04   |\n",
      "|    value_loss         | 7.39e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.14e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 19400    |\n",
      "|    time_elapsed       | 2676     |\n",
      "|    total_timesteps    | 388000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0       |\n",
      "|    explained_variance | 0.898    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19399    |\n",
      "|    policy_loss        | 1.92e+03 |\n",
      "|    value_loss         | 16.6     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=390000, episode_reward=3573.55 +/- 0.17\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 2.3e+03  |\n",
      "|    mean_reward        | 3.57e+03 |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 390000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0389  |\n",
      "|    explained_variance | -1.98    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19499    |\n",
      "|    policy_loss        | 3.44e+03 |\n",
      "|    value_loss         | 1.33e+03 |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.3e+03  |\n",
      "|    ep_rew_mean     | 1.11e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 144      |\n",
      "|    iterations      | 19500    |\n",
      "|    time_elapsed    | 2707     |\n",
      "|    total_timesteps | 390000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 1.1e+04   |\n",
      "| time/                 |           |\n",
      "|    fps                | 144       |\n",
      "|    iterations         | 19600     |\n",
      "|    time_elapsed       | 2710      |\n",
      "|    total_timesteps    | 392000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.76e-19 |\n",
      "|    explained_variance | -1.94     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19599     |\n",
      "|    policy_loss        | -1.78e+04 |\n",
      "|    value_loss         | 1.41e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 1.07e+04  |\n",
      "| time/                 |           |\n",
      "|    fps                | 145       |\n",
      "|    iterations         | 19700     |\n",
      "|    time_elapsed       | 2713      |\n",
      "|    total_timesteps    | 394000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.99e-13 |\n",
      "|    explained_variance | 0.389     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19699     |\n",
      "|    policy_loss        | 1.55e+04  |\n",
      "|    value_loss         | 5.5e+03   |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=395000, episode_reward=9630.84 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | 9.63e+03  |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 395000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000226 |\n",
      "|    explained_variance | -0.788    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19749     |\n",
      "|    policy_loss        | -1.96e+03 |\n",
      "|    value_loss         | 96.6      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.07e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 19800    |\n",
      "|    time_elapsed       | 2743     |\n",
      "|    total_timesteps    | 396000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0229  |\n",
      "|    explained_variance | 0.671    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19799    |\n",
      "|    policy_loss        | -199     |\n",
      "|    value_loss         | 56.1     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 1.07e+04  |\n",
      "| time/                 |           |\n",
      "|    fps                | 144       |\n",
      "|    iterations         | 19900     |\n",
      "|    time_elapsed       | 2747      |\n",
      "|    total_timesteps    | 398000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000148 |\n",
      "|    explained_variance | 0.41      |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19899     |\n",
      "|    policy_loss        | -4.72e+03 |\n",
      "|    value_loss         | 147       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=400000, episode_reward=1495.67 +/- 0.06\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 2.3e+03  |\n",
      "|    mean_reward        | 1.5e+03  |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 400000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0705  |\n",
      "|    explained_variance | -1.21    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19999    |\n",
      "|    policy_loss        | -75.6    |\n",
      "|    value_loss         | 78       |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.3e+03  |\n",
      "|    ep_rew_mean     | 1.06e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 144      |\n",
      "|    iterations      | 20000    |\n",
      "|    time_elapsed    | 2777     |\n",
      "|    total_timesteps | 400000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 1.07e+04  |\n",
      "| time/                 |           |\n",
      "|    fps                | 144       |\n",
      "|    iterations         | 20100     |\n",
      "|    time_elapsed       | 2780      |\n",
      "|    total_timesteps    | 402000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.75e-27 |\n",
      "|    explained_variance | 0.622     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 20099     |\n",
      "|    policy_loss        | -2.3e+04  |\n",
      "|    value_loss         | 1.24e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.05e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 145      |\n",
      "|    iterations         | 20200    |\n",
      "|    time_elapsed       | 2783     |\n",
      "|    total_timesteps    | 404000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.115   |\n",
      "|    explained_variance | -0.0208  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 20199    |\n",
      "|    policy_loss        | 17.4     |\n",
      "|    value_loss         | 251      |\n",
      "------------------------------------\n",
      "Eval num_timesteps=405000, episode_reward=-16598.82 +/- 0.12\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.66e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 405000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.43e-09 |\n",
      "|    explained_variance | -0.041    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 20249     |\n",
      "|    policy_loss        | -1.25e+04 |\n",
      "|    value_loss         | 444       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.05e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 20300    |\n",
      "|    time_elapsed       | 2813     |\n",
      "|    total_timesteps    | 406000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00219 |\n",
      "|    explained_variance | 0.397    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 20299    |\n",
      "|    policy_loss        | 331      |\n",
      "|    value_loss         | 208      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.04e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 20400    |\n",
      "|    time_elapsed       | 2816     |\n",
      "|    total_timesteps    | 408000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00169 |\n",
      "|    explained_variance | -0.878   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 20399    |\n",
      "|    policy_loss        | 4.37e+03 |\n",
      "|    value_loss         | 8.93e+03 |\n",
      "------------------------------------\n",
      "Eval num_timesteps=410000, episode_reward=-7305.15 +/- 0.07\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -7.31e+03 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 410000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0279   |\n",
      "|    explained_variance | 0.636     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 20499     |\n",
      "|    policy_loss        | -296      |\n",
      "|    value_loss         | 29.7      |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.3e+03  |\n",
      "|    ep_rew_mean     | 1.04e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 144      |\n",
      "|    iterations      | 20500    |\n",
      "|    time_elapsed    | 2847     |\n",
      "|    total_timesteps | 410000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 1.04e+04  |\n",
      "| time/                 |           |\n",
      "|    fps                | 144       |\n",
      "|    iterations         | 20600     |\n",
      "|    time_elapsed       | 2850      |\n",
      "|    total_timesteps    | 412000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.82e-09 |\n",
      "|    explained_variance | 0.904     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 20599     |\n",
      "|    policy_loss        | 529       |\n",
      "|    value_loss         | 18.7      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 1.04e+04  |\n",
      "| time/                 |           |\n",
      "|    fps                | 145       |\n",
      "|    iterations         | 20700     |\n",
      "|    time_elapsed       | 2853      |\n",
      "|    total_timesteps    | 414000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0        |\n",
      "|    explained_variance | 0.778     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 20699     |\n",
      "|    policy_loss        | -1.13e+04 |\n",
      "|    value_loss         | 321       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=415000, episode_reward=9846.69 +/- 0.29\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 2.3e+03  |\n",
      "|    mean_reward        | 9.85e+03 |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 415000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0186  |\n",
      "|    explained_variance | 0.401    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 20749    |\n",
      "|    policy_loss        | 6.34e+03 |\n",
      "|    value_loss         | 7.27e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1.02e+04 |\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 20800    |\n",
      "|    time_elapsed       | 2883     |\n",
      "|    total_timesteps    | 416000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0354  |\n",
      "|    explained_variance | 0.0781   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 20799    |\n",
      "|    policy_loss        | 71.7     |\n",
      "|    value_loss         | 230      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 1.02e+04  |\n",
      "| time/                 |           |\n",
      "|    fps                | 144       |\n",
      "|    iterations         | 20900     |\n",
      "|    time_elapsed       | 2886      |\n",
      "|    total_timesteps    | 418000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0        |\n",
      "|    explained_variance | -1.11     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 20899     |\n",
      "|    policy_loss        | -1.73e+04 |\n",
      "|    value_loss         | 780       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=420000, episode_reward=4661.56 +/- 0.09\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | 4.66e+03  |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 420000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0386   |\n",
      "|    explained_variance | -4.85     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 20999     |\n",
      "|    policy_loss        | -1.16e+03 |\n",
      "|    value_loss         | 363       |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.3e+03  |\n",
      "|    ep_rew_mean     | 1e+04    |\n",
      "| time/              |          |\n",
      "|    fps             | 144      |\n",
      "|    iterations      | 21000    |\n",
      "|    time_elapsed    | 2916     |\n",
      "|    total_timesteps | 420000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 1e+04    |\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 21100    |\n",
      "|    time_elapsed       | 2919     |\n",
      "|    total_timesteps    | 422000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0433  |\n",
      "|    explained_variance | 0.431    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 21099    |\n",
      "|    policy_loss        | -168     |\n",
      "|    value_loss         | 57       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 9.89e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 145      |\n",
      "|    iterations         | 21200    |\n",
      "|    time_elapsed       | 2922     |\n",
      "|    total_timesteps    | 424000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00019 |\n",
      "|    explained_variance | -0.0492  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 21199    |\n",
      "|    policy_loss        | 4.15e+04 |\n",
      "|    value_loss         | 8.11e+03 |\n",
      "------------------------------------\n",
      "Eval num_timesteps=425000, episode_reward=-2467.46 +/- 0.04\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -2.47e+03 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 425000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.5e-06  |\n",
      "|    explained_variance | 0.407     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 21249     |\n",
      "|    policy_loss        | 3.06e+03  |\n",
      "|    value_loss         | 984       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 9.89e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 144      |\n",
      "|    iterations         | 21300    |\n",
      "|    time_elapsed       | 2952     |\n",
      "|    total_timesteps    | 426000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.037   |\n",
      "|    explained_variance | 0.328    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 21299    |\n",
      "|    policy_loss        | 534      |\n",
      "|    value_loss         | 182      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 9.82e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 144       |\n",
      "|    iterations         | 21400     |\n",
      "|    time_elapsed       | 2955      |\n",
      "|    total_timesteps    | 428000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000128 |\n",
      "|    explained_variance | 0.823     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 21399     |\n",
      "|    policy_loss        | 822       |\n",
      "|    value_loss         | 142       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=430000, episode_reward=-26676.18 +/- 0.00\n",
      "Episode length: 840.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 840       |\n",
      "|    mean_reward        | -2.67e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 430000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.41e-11 |\n",
      "|    explained_variance | 0.922     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 21499     |\n",
      "|    policy_loss        | -663      |\n",
      "|    value_loss         | 42        |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.3e+03  |\n",
      "|    ep_rew_mean     | 9.82e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 144      |\n",
      "|    iterations      | 21500    |\n",
      "|    time_elapsed    | 2968     |\n",
      "|    total_timesteps | 430000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 9.77e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 145      |\n",
      "|    iterations         | 21600    |\n",
      "|    time_elapsed       | 2971     |\n",
      "|    total_timesteps    | 432000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0391  |\n",
      "|    explained_variance | 0.0198   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 21599    |\n",
      "|    policy_loss        | -269     |\n",
      "|    value_loss         | 69.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 9.75e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 145      |\n",
      "|    iterations         | 21700    |\n",
      "|    time_elapsed       | 2974     |\n",
      "|    total_timesteps    | 434000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0       |\n",
      "|    explained_variance | 0.264    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 21699    |\n",
      "|    policy_loss        | 3.18e+03 |\n",
      "|    value_loss         | 64       |\n",
      "------------------------------------\n",
      "Eval num_timesteps=435000, episode_reward=-16163.12 +/- 0.08\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.62e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 435000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.23e-12 |\n",
      "|    explained_variance | -3.21     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 21749     |\n",
      "|    policy_loss        | 5.44e+03  |\n",
      "|    value_loss         | 971       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 9.53e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 145      |\n",
      "|    iterations         | 21800    |\n",
      "|    time_elapsed       | 3004     |\n",
      "|    total_timesteps    | 436000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0       |\n",
      "|    explained_variance | 0.971    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 21799    |\n",
      "|    policy_loss        | 2.62e+03 |\n",
      "|    value_loss         | 16.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 9.25e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 145      |\n",
      "|    iterations         | 21900    |\n",
      "|    time_elapsed       | 3007     |\n",
      "|    total_timesteps    | 438000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.264   |\n",
      "|    explained_variance | 0.187    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 21899    |\n",
      "|    policy_loss        | 57.7     |\n",
      "|    value_loss         | 688      |\n",
      "------------------------------------\n",
      "Eval num_timesteps=440000, episode_reward=-14940.05 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.49e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 440000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00678  |\n",
      "|    explained_variance | 0.757     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 21999     |\n",
      "|    policy_loss        | 2.41e+03  |\n",
      "|    value_loss         | 31        |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.3e+03  |\n",
      "|    ep_rew_mean     | 9.18e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 144      |\n",
      "|    iterations      | 22000    |\n",
      "|    time_elapsed    | 3038     |\n",
      "|    total_timesteps | 440000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 8.86e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 145      |\n",
      "|    iterations         | 22100    |\n",
      "|    time_elapsed       | 3041     |\n",
      "|    total_timesteps    | 442000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.1e-22 |\n",
      "|    explained_variance | 0.135    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 22099    |\n",
      "|    policy_loss        | 1.39e+04 |\n",
      "|    value_loss         | 7.68e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 8.86e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 145      |\n",
      "|    iterations         | 22200    |\n",
      "|    time_elapsed       | 3044     |\n",
      "|    total_timesteps    | 444000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.146   |\n",
      "|    explained_variance | 0.884    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 22199    |\n",
      "|    policy_loss        | 116      |\n",
      "|    value_loss         | 21.2     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=445000, episode_reward=-16163.15 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.62e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 445000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0        |\n",
      "|    explained_variance | -1.77     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 22249     |\n",
      "|    policy_loss        | -3.11e+04 |\n",
      "|    value_loss         | 1.54e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 8.84e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 145       |\n",
      "|    iterations         | 22300     |\n",
      "|    time_elapsed       | 3074      |\n",
      "|    total_timesteps    | 446000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.17e-05 |\n",
      "|    explained_variance | 0.859     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 22299     |\n",
      "|    policy_loss        | 522       |\n",
      "|    value_loss         | 17.4      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 8.61e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 145      |\n",
      "|    iterations         | 22400    |\n",
      "|    time_elapsed       | 3077     |\n",
      "|    total_timesteps    | 448000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.1e-05 |\n",
      "|    explained_variance | 0.801    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 22399    |\n",
      "|    policy_loss        | 1.39e+03 |\n",
      "|    value_loss         | 33.9     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=450000, episode_reward=507.49 +/- 0.17\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 2.3e+03  |\n",
      "|    mean_reward        | 507      |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 450000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00664 |\n",
      "|    explained_variance | 0.894    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 22499    |\n",
      "|    policy_loss        | -429     |\n",
      "|    value_loss         | 11.1     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.3e+03  |\n",
      "|    ep_rew_mean     | 8.6e+03  |\n",
      "| time/              |          |\n",
      "|    fps             | 144      |\n",
      "|    iterations      | 22500    |\n",
      "|    time_elapsed    | 3107     |\n",
      "|    total_timesteps | 450000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 8.68e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 145       |\n",
      "|    iterations         | 22600     |\n",
      "|    time_elapsed       | 3110      |\n",
      "|    total_timesteps    | 452000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.69e-20 |\n",
      "|    explained_variance | 0.892     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 22599     |\n",
      "|    policy_loss        | 441       |\n",
      "|    value_loss         | 10.7      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 8.67e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 145       |\n",
      "|    iterations         | 22700     |\n",
      "|    time_elapsed       | 3113      |\n",
      "|    total_timesteps    | 454000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0        |\n",
      "|    explained_variance | 0.887     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 22699     |\n",
      "|    policy_loss        | -1.25e+03 |\n",
      "|    value_loss         | 8.44      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=455000, episode_reward=-16163.13 +/- 0.06\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.62e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 455000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0        |\n",
      "|    explained_variance | 0.511     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 22749     |\n",
      "|    policy_loss        | -3.59e+03 |\n",
      "|    value_loss         | 58.8      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 8.55e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 145      |\n",
      "|    iterations         | 22800    |\n",
      "|    time_elapsed       | 3143     |\n",
      "|    total_timesteps    | 456000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.9e-15 |\n",
      "|    explained_variance | -1.54    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 22799    |\n",
      "|    policy_loss        | 3.54e+04 |\n",
      "|    value_loss         | 6.11e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 8.48e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 145       |\n",
      "|    iterations         | 22900     |\n",
      "|    time_elapsed       | 3146      |\n",
      "|    total_timesteps    | 458000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.14e-10 |\n",
      "|    explained_variance | 0.348     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 22899     |\n",
      "|    policy_loss        | -1.13e+03 |\n",
      "|    value_loss         | 219       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=460000, episode_reward=-13754.43 +/- 0.08\n",
      "Episode length: 1128.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1.13e+03  |\n",
      "|    mean_reward        | -1.38e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 460000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.78e-11 |\n",
      "|    explained_variance | 0.395     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 22999     |\n",
      "|    policy_loss        | -712      |\n",
      "|    value_loss         | 237       |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.3e+03  |\n",
      "|    ep_rew_mean     | 8.48e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 145      |\n",
      "|    iterations      | 23000    |\n",
      "|    time_elapsed    | 3162     |\n",
      "|    total_timesteps | 460000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 8.35e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 145      |\n",
      "|    iterations         | 23100    |\n",
      "|    time_elapsed       | 3165     |\n",
      "|    total_timesteps    | 462000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00255 |\n",
      "|    explained_variance | 0.364    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 23099    |\n",
      "|    policy_loss        | 2.4e+03  |\n",
      "|    value_loss         | 511      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 8.23e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 146       |\n",
      "|    iterations         | 23200     |\n",
      "|    time_elapsed       | 3168      |\n",
      "|    total_timesteps    | 464000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000249 |\n",
      "|    explained_variance | -0.0594   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 23199     |\n",
      "|    policy_loss        | 3.73e+03  |\n",
      "|    value_loss         | 1.51e+03  |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=465000, episode_reward=-17007.90 +/- 0.00\n",
      "Episode length: 1392.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1.39e+03  |\n",
      "|    mean_reward        | -1.7e+04  |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 465000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.08e-09 |\n",
      "|    explained_variance | 0.695     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 23249     |\n",
      "|    policy_loss        | 275       |\n",
      "|    value_loss         | 35.3      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 8.11e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 146       |\n",
      "|    iterations         | 23300     |\n",
      "|    time_elapsed       | 3188      |\n",
      "|    total_timesteps    | 466000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.77e-08 |\n",
      "|    explained_variance | -0.754    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 23299     |\n",
      "|    policy_loss        | 797       |\n",
      "|    value_loss         | 348       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 8e+03     |\n",
      "| time/                 |           |\n",
      "|    fps                | 146       |\n",
      "|    iterations         | 23400     |\n",
      "|    time_elapsed       | 3191      |\n",
      "|    total_timesteps    | 468000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.86e-20 |\n",
      "|    explained_variance | -0.284    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 23399     |\n",
      "|    policy_loss        | -1.93e+03 |\n",
      "|    value_loss         | 828       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=470000, episode_reward=-17072.17 +/- 0.00\n",
      "Episode length: 1392.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1.39e+03  |\n",
      "|    mean_reward        | -1.71e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 470000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000153 |\n",
      "|    explained_variance | 0.462     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 23499     |\n",
      "|    policy_loss        | -321      |\n",
      "|    value_loss         | 105       |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.3e+03  |\n",
      "|    ep_rew_mean     | 7.88e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 146      |\n",
      "|    iterations      | 23500    |\n",
      "|    time_elapsed    | 3210     |\n",
      "|    total_timesteps | 470000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 7.78e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 146       |\n",
      "|    iterations         | 23600     |\n",
      "|    time_elapsed       | 3213      |\n",
      "|    total_timesteps    | 472000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.83e-10 |\n",
      "|    explained_variance | -0.727    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 23599     |\n",
      "|    policy_loss        | 15        |\n",
      "|    value_loss         | 327       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 7.78e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 147       |\n",
      "|    iterations         | 23700     |\n",
      "|    time_elapsed       | 3217      |\n",
      "|    total_timesteps    | 474000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.99e-08 |\n",
      "|    explained_variance | 0.508     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 23699     |\n",
      "|    policy_loss        | 2.38e+03  |\n",
      "|    value_loss         | 537       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=475000, episode_reward=-29506.15 +/- 0.04\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -2.95e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 475000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0412   |\n",
      "|    explained_variance | 0.286     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 23749     |\n",
      "|    policy_loss        | 78.6      |\n",
      "|    value_loss         | 50        |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 7.74e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 23800    |\n",
      "|    time_elapsed       | 3247     |\n",
      "|    total_timesteps    | 476000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0267  |\n",
      "|    explained_variance | 0.471    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 23799    |\n",
      "|    policy_loss        | 1.12e+03 |\n",
      "|    value_loss         | 239      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 7.65e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 23900    |\n",
      "|    time_elapsed       | 3250     |\n",
      "|    total_timesteps    | 478000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0565  |\n",
      "|    explained_variance | 0.393    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 23899    |\n",
      "|    policy_loss        | -67.3    |\n",
      "|    value_loss         | 28.1     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=480000, episode_reward=-30156.29 +/- 0.21\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -3.02e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 480000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.28e-09 |\n",
      "|    explained_variance | 0.0831    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 23999     |\n",
      "|    policy_loss        | -1.38e+03 |\n",
      "|    value_loss         | 413       |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.3e+03  |\n",
      "|    ep_rew_mean     | 7.61e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 146      |\n",
      "|    iterations      | 24000    |\n",
      "|    time_elapsed    | 3280     |\n",
      "|    total_timesteps | 480000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 7.59e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 146       |\n",
      "|    iterations         | 24100     |\n",
      "|    time_elapsed       | 3283      |\n",
      "|    total_timesteps    | 482000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.87e-05 |\n",
      "|    explained_variance | 0.477     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 24099     |\n",
      "|    policy_loss        | 1.45e+03  |\n",
      "|    value_loss         | 435       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 7.53e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 24200    |\n",
      "|    time_elapsed       | 3286     |\n",
      "|    total_timesteps    | 484000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0212  |\n",
      "|    explained_variance | -0.448   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 24199    |\n",
      "|    policy_loss        | -87.9    |\n",
      "|    value_loss         | 520      |\n",
      "------------------------------------\n",
      "Eval num_timesteps=485000, episode_reward=-16751.21 +/- 0.19\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.68e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 485000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.109    |\n",
      "|    explained_variance | 0.496     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 24249     |\n",
      "|    policy_loss        | 332       |\n",
      "|    value_loss         | 222       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 7.49e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 146       |\n",
      "|    iterations         | 24300     |\n",
      "|    time_elapsed       | 3317      |\n",
      "|    total_timesteps    | 486000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.54e-05 |\n",
      "|    explained_variance | -0.452    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 24299     |\n",
      "|    policy_loss        | 190       |\n",
      "|    value_loss         | 107       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 7.36e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 146       |\n",
      "|    iterations         | 24400     |\n",
      "|    time_elapsed       | 3320      |\n",
      "|    total_timesteps    | 488000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.17e-10 |\n",
      "|    explained_variance | 0.306     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 24399     |\n",
      "|    policy_loss        | 3.91e+04  |\n",
      "|    value_loss         | 6.95e+03  |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=490000, episode_reward=-2017.18 +/- 0.15\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -2.02e+03 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 490000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.1e-12  |\n",
      "|    explained_variance | 0.777     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 24499     |\n",
      "|    policy_loss        | 419       |\n",
      "|    value_loss         | 11.4      |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.3e+03  |\n",
      "|    ep_rew_mean     | 7.36e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 146      |\n",
      "|    iterations      | 24500    |\n",
      "|    time_elapsed    | 3350     |\n",
      "|    total_timesteps | 490000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 7.34e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 24600    |\n",
      "|    time_elapsed       | 3353     |\n",
      "|    total_timesteps    | 492000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0358  |\n",
      "|    explained_variance | 0.938    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 24599    |\n",
      "|    policy_loss        | -96.1    |\n",
      "|    value_loss         | 7.83     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 7.11e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 24700    |\n",
      "|    time_elapsed       | 3356     |\n",
      "|    total_timesteps    | 494000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00164 |\n",
      "|    explained_variance | 0.288    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 24699    |\n",
      "|    policy_loss        | 485      |\n",
      "|    value_loss         | 1.61e+03 |\n",
      "------------------------------------\n",
      "Eval num_timesteps=495000, episode_reward=-22896.29 +/- 0.47\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -2.29e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 495000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0255   |\n",
      "|    explained_variance | -0.176    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 24749     |\n",
      "|    policy_loss        | -2.56e+03 |\n",
      "|    value_loss         | 1.44e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 7.08e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 24800    |\n",
      "|    time_elapsed       | 3386     |\n",
      "|    total_timesteps    | 496000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0332  |\n",
      "|    explained_variance | 0.669    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 24799    |\n",
      "|    policy_loss        | -54.3    |\n",
      "|    value_loss         | 67       |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 7.06e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 146       |\n",
      "|    iterations         | 24900     |\n",
      "|    time_elapsed       | 3389      |\n",
      "|    total_timesteps    | 498000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000111 |\n",
      "|    explained_variance | 0.938     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 24899     |\n",
      "|    policy_loss        | 372       |\n",
      "|    value_loss         | 6.82      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=500000, episode_reward=-16065.41 +/- 0.12\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.61e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 500000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.6e-30  |\n",
      "|    explained_variance | 0.63      |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 24999     |\n",
      "|    policy_loss        | 2.01e+03  |\n",
      "|    value_loss         | 24.4      |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.3e+03  |\n",
      "|    ep_rew_mean     | 7.1e+03  |\n",
      "| time/              |          |\n",
      "|    fps             | 146      |\n",
      "|    iterations      | 25000    |\n",
      "|    time_elapsed    | 3419     |\n",
      "|    total_timesteps | 500000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 7.27e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 146       |\n",
      "|    iterations         | 25100     |\n",
      "|    time_elapsed       | 3422      |\n",
      "|    total_timesteps    | 502000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0345   |\n",
      "|    explained_variance | 0.208     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 25099     |\n",
      "|    policy_loss        | -1.94e+03 |\n",
      "|    value_loss         | 244       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 7.27e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 25200    |\n",
      "|    time_elapsed       | 3425     |\n",
      "|    total_timesteps    | 504000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0109  |\n",
      "|    explained_variance | 0.199    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 25199    |\n",
      "|    policy_loss        | -57.5    |\n",
      "|    value_loss         | 603      |\n",
      "------------------------------------\n",
      "Eval num_timesteps=505000, episode_reward=-19720.25 +/- 0.14\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.97e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 505000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.77e-25 |\n",
      "|    explained_variance | -1.17     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 25249     |\n",
      "|    policy_loss        | -3.84e+03 |\n",
      "|    value_loss         | 214       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 7.27e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 146       |\n",
      "|    iterations         | 25300     |\n",
      "|    time_elapsed       | 3456      |\n",
      "|    total_timesteps    | 506000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.9e-22  |\n",
      "|    explained_variance | 0.434     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 25299     |\n",
      "|    policy_loss        | -1.76e+03 |\n",
      "|    value_loss         | 153       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 7.34e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 146       |\n",
      "|    iterations         | 25400     |\n",
      "|    time_elapsed       | 3459      |\n",
      "|    total_timesteps    | 508000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000137 |\n",
      "|    explained_variance | -0.666    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 25399     |\n",
      "|    policy_loss        | 108       |\n",
      "|    value_loss         | 89.9      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=510000, episode_reward=-25343.37 +/- 0.02\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -2.53e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 510000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00709  |\n",
      "|    explained_variance | 0.238     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 25499     |\n",
      "|    policy_loss        | 971       |\n",
      "|    value_loss         | 187       |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.3e+03  |\n",
      "|    ep_rew_mean     | 7.33e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 146      |\n",
      "|    iterations      | 25500    |\n",
      "|    time_elapsed    | 3489     |\n",
      "|    total_timesteps | 510000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 7.33e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 146       |\n",
      "|    iterations         | 25600     |\n",
      "|    time_elapsed       | 3492      |\n",
      "|    total_timesteps    | 512000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.25e-08 |\n",
      "|    explained_variance | -0.996    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 25599     |\n",
      "|    policy_loss        | 525       |\n",
      "|    value_loss         | 264       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 7.34e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 147       |\n",
      "|    iterations         | 25700     |\n",
      "|    time_elapsed       | 3495      |\n",
      "|    total_timesteps    | 514000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000408 |\n",
      "|    explained_variance | 0.662     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 25699     |\n",
      "|    policy_loss        | 959       |\n",
      "|    value_loss         | 274       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=515000, episode_reward=-22767.61 +/- 0.01\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -2.28e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 515000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.81e-13 |\n",
      "|    explained_variance | -1.45     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 25749     |\n",
      "|    policy_loss        | 1.71e+03  |\n",
      "|    value_loss         | 240       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 7.42e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 25800    |\n",
      "|    time_elapsed       | 3525     |\n",
      "|    total_timesteps    | 516000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0705  |\n",
      "|    explained_variance | 0.372    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 25799    |\n",
      "|    policy_loss        | -55.9    |\n",
      "|    value_loss         | 73       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 7.48e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 25900    |\n",
      "|    time_elapsed       | 3528     |\n",
      "|    total_timesteps    | 518000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0273  |\n",
      "|    explained_variance | -0.591   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 25899    |\n",
      "|    policy_loss        | 2.97e+03 |\n",
      "|    value_loss         | 235      |\n",
      "------------------------------------\n",
      "Eval num_timesteps=520000, episode_reward=-6475.09 +/- 0.06\n",
      "Episode length: 1368.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1.37e+03  |\n",
      "|    mean_reward        | -6.48e+03 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 520000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0149   |\n",
      "|    explained_variance | 0.56      |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 25999     |\n",
      "|    policy_loss        | -16       |\n",
      "|    value_loss         | 134       |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.3e+03  |\n",
      "|    ep_rew_mean     | 7.48e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 146      |\n",
      "|    iterations      | 26000    |\n",
      "|    time_elapsed    | 3547     |\n",
      "|    total_timesteps | 520000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 7.49e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 147       |\n",
      "|    iterations         | 26100     |\n",
      "|    time_elapsed       | 3550      |\n",
      "|    total_timesteps    | 522000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.72e-08 |\n",
      "|    explained_variance | 0.68      |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 26099     |\n",
      "|    policy_loss        | -1.38e+04 |\n",
      "|    value_loss         | 559       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 7.46e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 147       |\n",
      "|    iterations         | 26200     |\n",
      "|    time_elapsed       | 3553      |\n",
      "|    total_timesteps    | 524000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.97e-32 |\n",
      "|    explained_variance | 0.333     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 26199     |\n",
      "|    policy_loss        | 257       |\n",
      "|    value_loss         | 49.5      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=525000, episode_reward=-25343.34 +/- 0.06\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -2.53e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 525000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.45e-27 |\n",
      "|    explained_variance | 0.787     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 26249     |\n",
      "|    policy_loss        | -4.25e+03 |\n",
      "|    value_loss         | 137       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 7.56e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 146       |\n",
      "|    iterations         | 26300     |\n",
      "|    time_elapsed       | 3584      |\n",
      "|    total_timesteps    | 526000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.86e-20 |\n",
      "|    explained_variance | 0.609     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 26299     |\n",
      "|    policy_loss        | 398       |\n",
      "|    value_loss         | 165       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3e+03  |\n",
      "|    ep_rew_mean        | 7.87e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 26400    |\n",
      "|    time_elapsed       | 3587     |\n",
      "|    total_timesteps    | 528000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.2e-10 |\n",
      "|    explained_variance | 0.844    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 26399    |\n",
      "|    policy_loss        | 540      |\n",
      "|    value_loss         | 29.7     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=530000, episode_reward=-25343.36 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -2.53e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 530000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0        |\n",
      "|    explained_variance | 0.569     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 26499     |\n",
      "|    policy_loss        | -1.33e+03 |\n",
      "|    value_loss         | 93.1      |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.3e+03  |\n",
      "|    ep_rew_mean     | 7.88e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 146      |\n",
      "|    iterations      | 26500    |\n",
      "|    time_elapsed    | 3617     |\n",
      "|    total_timesteps | 530000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3e+03   |\n",
      "|    ep_rew_mean        | 8.14e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 146       |\n",
      "|    iterations         | 26600     |\n",
      "|    time_elapsed       | 3620      |\n",
      "|    total_timesteps    | 532000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.39e-32 |\n",
      "|    explained_variance | -0.0937   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 26599     |\n",
      "|    policy_loss        | 595       |\n",
      "|    value_loss         | 346       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.27e+03  |\n",
      "|    ep_rew_mean        | 8.24e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 147       |\n",
      "|    iterations         | 26700     |\n",
      "|    time_elapsed       | 3623      |\n",
      "|    total_timesteps    | 534000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.22e-05 |\n",
      "|    explained_variance | -0.883    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 26699     |\n",
      "|    policy_loss        | -3.7e+03  |\n",
      "|    value_loss         | 9.42e+03  |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=535000, episode_reward=-17653.57 +/- 0.02\n",
      "Episode length: 1008.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1.01e+03  |\n",
      "|    mean_reward        | -1.77e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 535000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0        |\n",
      "|    explained_variance | -0.989    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 26749     |\n",
      "|    policy_loss        | 1.37e+03  |\n",
      "|    value_loss         | 610       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.25e+03  |\n",
      "|    ep_rew_mean        | 8.33e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 147       |\n",
      "|    iterations         | 26800     |\n",
      "|    time_elapsed       | 3638      |\n",
      "|    total_timesteps    | 536000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0278   |\n",
      "|    explained_variance | 0.272     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 26799     |\n",
      "|    policy_loss        | -4.78e+03 |\n",
      "|    value_loss         | 768       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.23e+03  |\n",
      "|    ep_rew_mean        | 8.54e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 147       |\n",
      "|    iterations         | 26900     |\n",
      "|    time_elapsed       | 3641      |\n",
      "|    total_timesteps    | 538000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0        |\n",
      "|    explained_variance | 0.872     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 26899     |\n",
      "|    policy_loss        | -3.24e+03 |\n",
      "|    value_loss         | 19.9      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=540000, episode_reward=-11788.19 +/- 0.00\n",
      "Episode length: 1200.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1.2e+03   |\n",
      "|    mean_reward        | -1.18e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 540000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00209  |\n",
      "|    explained_variance | 0.61      |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 26999     |\n",
      "|    policy_loss        | -1.63e+03 |\n",
      "|    value_loss         | 35.1      |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.23e+03 |\n",
      "|    ep_rew_mean     | 8.26e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 147      |\n",
      "|    iterations      | 27000    |\n",
      "|    time_elapsed    | 3658     |\n",
      "|    total_timesteps | 540000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.23e+03 |\n",
      "|    ep_rew_mean        | 8.29e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 27100    |\n",
      "|    time_elapsed       | 3661     |\n",
      "|    total_timesteps    | 542000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0579  |\n",
      "|    explained_variance | 0.896    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 27099    |\n",
      "|    policy_loss        | 147      |\n",
      "|    value_loss         | 12.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.21e+03 |\n",
      "|    ep_rew_mean        | 8.03e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 27200    |\n",
      "|    time_elapsed       | 3664     |\n",
      "|    total_timesteps    | 544000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.193   |\n",
      "|    explained_variance | 0.708    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 27199    |\n",
      "|    policy_loss        | -2.9e+03 |\n",
      "|    value_loss         | 84.5     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=545000, episode_reward=455.68 +/- 0.00\n",
      "Episode length: 480.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 480      |\n",
      "|    mean_reward        | 456      |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 545000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.147   |\n",
      "|    explained_variance | 0.777    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 27249    |\n",
      "|    policy_loss        | 9.43     |\n",
      "|    value_loss         | 56       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.18e+03 |\n",
      "|    ep_rew_mean        | 7.79e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 27300    |\n",
      "|    time_elapsed       | 3672     |\n",
      "|    total_timesteps    | 546000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.1e-06 |\n",
      "|    explained_variance | 0.687    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 27299    |\n",
      "|    policy_loss        | -2.2e+03 |\n",
      "|    value_loss         | 29.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.18e+03 |\n",
      "|    ep_rew_mean        | 7.56e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 27400    |\n",
      "|    time_elapsed       | 3675     |\n",
      "|    total_timesteps    | 548000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0412  |\n",
      "|    explained_variance | 0.913    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 27399    |\n",
      "|    policy_loss        | 7.97     |\n",
      "|    value_loss         | 8.19     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=550000, episode_reward=1692.30 +/- 0.00\n",
      "Episode length: 960.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 960      |\n",
      "|    mean_reward        | 1.69e+03 |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 550000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0766  |\n",
      "|    explained_variance | 0.82     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 27499    |\n",
      "|    policy_loss        | -693     |\n",
      "|    value_loss         | 80.3     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.13e+03 |\n",
      "|    ep_rew_mean     | 7.41e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 149      |\n",
      "|    iterations      | 27500    |\n",
      "|    time_elapsed    | 3690     |\n",
      "|    total_timesteps | 550000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.13e+03 |\n",
      "|    ep_rew_mean        | 7.54e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 27600    |\n",
      "|    time_elapsed       | 3693     |\n",
      "|    total_timesteps    | 552000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00123 |\n",
      "|    explained_variance | 0.207    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 27599    |\n",
      "|    policy_loss        | 2.65e+04 |\n",
      "|    value_loss         | 3.02e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.13e+03 |\n",
      "|    ep_rew_mean        | 7.54e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 149      |\n",
      "|    iterations         | 27700    |\n",
      "|    time_elapsed       | 3696     |\n",
      "|    total_timesteps    | 554000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00543 |\n",
      "|    explained_variance | 0.835    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 27699    |\n",
      "|    policy_loss        | 6.55     |\n",
      "|    value_loss         | 26.3     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=555000, episode_reward=-3926.36 +/- 0.01\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -3.93e+03 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 555000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.36e-05 |\n",
      "|    explained_variance | 0.968     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 27749     |\n",
      "|    policy_loss        | -26.6     |\n",
      "|    value_loss         | 1.82      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.13e+03  |\n",
      "|    ep_rew_mean        | 7.34e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 149       |\n",
      "|    iterations         | 27800     |\n",
      "|    time_elapsed       | 3726      |\n",
      "|    total_timesteps    | 556000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.46e-05 |\n",
      "|    explained_variance | 0.983     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 27799     |\n",
      "|    policy_loss        | -776      |\n",
      "|    value_loss         | 3.14      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.13e+03  |\n",
      "|    ep_rew_mean        | 7.14e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 149       |\n",
      "|    iterations         | 27900     |\n",
      "|    time_elapsed       | 3729      |\n",
      "|    total_timesteps    | 558000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.51e-05 |\n",
      "|    explained_variance | 0.975     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 27899     |\n",
      "|    policy_loss        | -299      |\n",
      "|    value_loss         | 2.34      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=560000, episode_reward=-7069.65 +/- 0.02\n",
      "Episode length: 600.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 600       |\n",
      "|    mean_reward        | -7.07e+03 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 560000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0732   |\n",
      "|    explained_variance | 0.773     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 27999     |\n",
      "|    policy_loss        | 87        |\n",
      "|    value_loss         | 122       |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.12e+03 |\n",
      "|    ep_rew_mean     | 6.81e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 149      |\n",
      "|    iterations      | 28000    |\n",
      "|    time_elapsed    | 3739     |\n",
      "|    total_timesteps | 560000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.1e+03   |\n",
      "|    ep_rew_mean        | 6.67e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 150       |\n",
      "|    iterations         | 28100     |\n",
      "|    time_elapsed       | 3742      |\n",
      "|    total_timesteps    | 562000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.81e-06 |\n",
      "|    explained_variance | 0.948     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 28099     |\n",
      "|    policy_loss        | 440       |\n",
      "|    value_loss         | 3.79      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.07e+03 |\n",
      "|    ep_rew_mean        | 6.21e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 28200    |\n",
      "|    time_elapsed       | 3745     |\n",
      "|    total_timesteps    | 564000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0152  |\n",
      "|    explained_variance | 0.436    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 28199    |\n",
      "|    policy_loss        | 970      |\n",
      "|    value_loss         | 1.58e+03 |\n",
      "------------------------------------\n",
      "Eval num_timesteps=565000, episode_reward=-652.88 +/- 0.00\n",
      "Episode length: 1032.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 1.03e+03  |\n",
      "|    mean_reward        | -653      |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 565000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0347   |\n",
      "|    explained_variance | 0.428     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 28249     |\n",
      "|    policy_loss        | -1.85e+03 |\n",
      "|    value_loss         | 154       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.04e+03 |\n",
      "|    ep_rew_mean        | 5.92e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 150      |\n",
      "|    iterations         | 28300    |\n",
      "|    time_elapsed       | 3760     |\n",
      "|    total_timesteps    | 566000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0364  |\n",
      "|    explained_variance | 0.921    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 28299    |\n",
      "|    policy_loss        | 17.1     |\n",
      "|    value_loss         | 19.2     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.99e+03  |\n",
      "|    ep_rew_mean        | 5.64e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 150       |\n",
      "|    iterations         | 28400     |\n",
      "|    time_elapsed       | 3763      |\n",
      "|    total_timesteps    | 568000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000703 |\n",
      "|    explained_variance | 0.216     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 28399     |\n",
      "|    policy_loss        | -1.26e+04 |\n",
      "|    value_loss         | 2.08e+03  |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=570000, episode_reward=-7069.65 +/- 0.00\n",
      "Episode length: 600.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 600       |\n",
      "|    mean_reward        | -7.07e+03 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 570000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.56e-05 |\n",
      "|    explained_variance | 0.845     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 28499     |\n",
      "|    policy_loss        | -113      |\n",
      "|    value_loss         | 32.4      |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.94e+03 |\n",
      "|    ep_rew_mean     | 5.7e+03  |\n",
      "| time/              |          |\n",
      "|    fps             | 151      |\n",
      "|    iterations      | 28500    |\n",
      "|    time_elapsed    | 3773     |\n",
      "|    total_timesteps | 570000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1.87e+03 |\n",
      "|    ep_rew_mean        | 5.26e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 151      |\n",
      "|    iterations         | 28600    |\n",
      "|    time_elapsed       | 3776     |\n",
      "|    total_timesteps    | 572000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00189 |\n",
      "|    explained_variance | -1       |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 28599    |\n",
      "|    policy_loss        | 1.09e+04 |\n",
      "|    value_loss         | 3.56e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.8e+03   |\n",
      "|    ep_rew_mean        | 5.53e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 151       |\n",
      "|    iterations         | 28700     |\n",
      "|    time_elapsed       | 3779      |\n",
      "|    total_timesteps    | 574000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.3e-05  |\n",
      "|    explained_variance | -0.87     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 28699     |\n",
      "|    policy_loss        | -2.38e+03 |\n",
      "|    value_loss         | 383       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=575000, episode_reward=-7477.75 +/- 0.00\n",
      "Episode length: 504.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 504       |\n",
      "|    mean_reward        | -7.48e+03 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 575000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.96e-05 |\n",
      "|    explained_variance | 0.137     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 28749     |\n",
      "|    policy_loss        | 1.67e+03  |\n",
      "|    value_loss         | 298       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.73e+03  |\n",
      "|    ep_rew_mean        | 5.17e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 152       |\n",
      "|    iterations         | 28800     |\n",
      "|    time_elapsed       | 3788      |\n",
      "|    total_timesteps    | 576000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.24e-06 |\n",
      "|    explained_variance | 0.548     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 28799     |\n",
      "|    policy_loss        | -390      |\n",
      "|    value_loss         | 174       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.65e+03  |\n",
      "|    ep_rew_mean        | 4.65e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 152       |\n",
      "|    iterations         | 28900     |\n",
      "|    time_elapsed       | 3791      |\n",
      "|    total_timesteps    | 578000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.98e-05 |\n",
      "|    explained_variance | 0.907     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 28899     |\n",
      "|    policy_loss        | -935      |\n",
      "|    value_loss         | 141       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=580000, episode_reward=-26676.18 +/- 0.00\n",
      "Episode length: 840.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 840       |\n",
      "|    mean_reward        | -2.67e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 580000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.81e-05 |\n",
      "|    explained_variance | 0.635     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 28999     |\n",
      "|    policy_loss        | -379      |\n",
      "|    value_loss         | 130       |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.56e+03 |\n",
      "|    ep_rew_mean     | 4.38e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 152      |\n",
      "|    iterations      | 29000    |\n",
      "|    time_elapsed    | 3804     |\n",
      "|    total_timesteps | 580000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.49e+03  |\n",
      "|    ep_rew_mean        | 3.92e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 152       |\n",
      "|    iterations         | 29100     |\n",
      "|    time_elapsed       | 3807      |\n",
      "|    total_timesteps    | 582000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.92e-06 |\n",
      "|    explained_variance | 0.658     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 29099     |\n",
      "|    policy_loss        | 6.54e+03  |\n",
      "|    value_loss         | 2.49e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1.42e+03 |\n",
      "|    ep_rew_mean        | 4.18e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 153      |\n",
      "|    iterations         | 29200    |\n",
      "|    time_elapsed       | 3810     |\n",
      "|    total_timesteps    | 584000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.001   |\n",
      "|    explained_variance | -0.279   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 29199    |\n",
      "|    policy_loss        | 2.8e+03  |\n",
      "|    value_loss         | 4.15e+03 |\n",
      "------------------------------------\n",
      "Eval num_timesteps=585000, episode_reward=-4586.39 +/- 0.00\n",
      "Episode length: 552.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 552       |\n",
      "|    mean_reward        | -4.59e+03 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 585000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.22e-09 |\n",
      "|    explained_variance | -0.0365   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 29249     |\n",
      "|    policy_loss        | 3.44e+03  |\n",
      "|    value_loss         | 4.44e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1.37e+03 |\n",
      "|    ep_rew_mean        | 3.99e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 153      |\n",
      "|    iterations         | 29300    |\n",
      "|    time_elapsed       | 3819     |\n",
      "|    total_timesteps    | 586000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0169  |\n",
      "|    explained_variance | 0.915    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 29299    |\n",
      "|    policy_loss        | 203      |\n",
      "|    value_loss         | 38.1     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.3e+03   |\n",
      "|    ep_rew_mean        | 3.59e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 153       |\n",
      "|    iterations         | 29400     |\n",
      "|    time_elapsed       | 3822      |\n",
      "|    total_timesteps    | 588000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.002    |\n",
      "|    explained_variance | 0.718     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 29399     |\n",
      "|    policy_loss        | -4.11e+03 |\n",
      "|    value_loss         | 271       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=590000, episode_reward=-20778.07 +/- 0.00\n",
      "Episode length: 672.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 672       |\n",
      "|    mean_reward        | -2.08e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 590000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.45e-07 |\n",
      "|    explained_variance | 0.768     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 29499     |\n",
      "|    policy_loss        | -777      |\n",
      "|    value_loss         | 77.3      |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.23e+03 |\n",
      "|    ep_rew_mean     | 3.45e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 153      |\n",
      "|    iterations      | 29500    |\n",
      "|    time_elapsed    | 3833     |\n",
      "|    total_timesteps | 590000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1.16e+03 |\n",
      "|    ep_rew_mean        | 3.27e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 154      |\n",
      "|    iterations         | 29600    |\n",
      "|    time_elapsed       | 3836     |\n",
      "|    total_timesteps    | 592000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.8e-09 |\n",
      "|    explained_variance | 0.35     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 29599    |\n",
      "|    policy_loss        | 7.02e+03 |\n",
      "|    value_loss         | 748      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.08e+03  |\n",
      "|    ep_rew_mean        | 2.89e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 154       |\n",
      "|    iterations         | 29700     |\n",
      "|    time_elapsed       | 3839      |\n",
      "|    total_timesteps    | 594000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.09e-06 |\n",
      "|    explained_variance | 0.867     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 29699     |\n",
      "|    policy_loss        | -1.97e+03 |\n",
      "|    value_loss         | 47.2      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=595000, episode_reward=-11116.08 +/- 0.00\n",
      "Episode length: 672.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 672       |\n",
      "|    mean_reward        | -1.11e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 595000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0425   |\n",
      "|    explained_variance | 0.62      |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 29749     |\n",
      "|    policy_loss        | 499       |\n",
      "|    value_loss         | 252       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.03e+03  |\n",
      "|    ep_rew_mean        | 2.81e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 154       |\n",
      "|    iterations         | 29800     |\n",
      "|    time_elapsed       | 3850      |\n",
      "|    total_timesteps    | 596000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.2e-06  |\n",
      "|    explained_variance | 0.928     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 29799     |\n",
      "|    policy_loss        | -4.23e+03 |\n",
      "|    value_loss         | 174       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 959      |\n",
      "|    ep_rew_mean        | 2.28e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 155      |\n",
      "|    iterations         | 29900    |\n",
      "|    time_elapsed       | 3853     |\n",
      "|    total_timesteps    | 598000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00206 |\n",
      "|    explained_variance | 0.927    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 29899    |\n",
      "|    policy_loss        | -897     |\n",
      "|    value_loss         | 27.9     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=600000, episode_reward=-6072.11 +/- 0.00\n",
      "Episode length: 504.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 504       |\n",
      "|    mean_reward        | -6.07e+03 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 600000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00163  |\n",
      "|    explained_variance | 0.441     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 29999     |\n",
      "|    policy_loss        | 1.08e+04  |\n",
      "|    value_loss         | 406       |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 889      |\n",
      "|    ep_rew_mean     | 1.71e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 155      |\n",
      "|    iterations      | 30000    |\n",
      "|    time_elapsed    | 3862     |\n",
      "|    total_timesteps | 600000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 838       |\n",
      "|    ep_rew_mean        | 1.29e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 155       |\n",
      "|    iterations         | 30100     |\n",
      "|    time_elapsed       | 3865      |\n",
      "|    total_timesteps    | 602000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000216 |\n",
      "|    explained_variance | -0.136    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 30099     |\n",
      "|    policy_loss        | -1.5e+03  |\n",
      "|    value_loss         | 417       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 745       |\n",
      "|    ep_rew_mean        | 678       |\n",
      "| time/                 |           |\n",
      "|    fps                | 156       |\n",
      "|    iterations         | 30200     |\n",
      "|    time_elapsed       | 3868      |\n",
      "|    total_timesteps    | 604000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.26e-05 |\n",
      "|    explained_variance | 0.609     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 30199     |\n",
      "|    policy_loss        | 4.33e+03  |\n",
      "|    value_loss         | 117       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=605000, episode_reward=-10673.58 +/- 0.03\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.07e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 605000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.01e-07 |\n",
      "|    explained_variance | 0.869     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 30249     |\n",
      "|    policy_loss        | -330      |\n",
      "|    value_loss         | 11.7      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 736      |\n",
      "|    ep_rew_mean        | 518      |\n",
      "| time/                 |          |\n",
      "|    fps                | 155      |\n",
      "|    iterations         | 30300    |\n",
      "|    time_elapsed       | 3898     |\n",
      "|    total_timesteps    | 606000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0346  |\n",
      "|    explained_variance | 0.942    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 30299    |\n",
      "|    policy_loss        | -469     |\n",
      "|    value_loss         | 6.53     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 734      |\n",
      "|    ep_rew_mean        | 381      |\n",
      "| time/                 |          |\n",
      "|    fps                | 155      |\n",
      "|    iterations         | 30400    |\n",
      "|    time_elapsed       | 3901     |\n",
      "|    total_timesteps    | 608000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0836  |\n",
      "|    explained_variance | -1.94    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 30399    |\n",
      "|    policy_loss        | 4.47e+03 |\n",
      "|    value_loss         | 4.59e+03 |\n",
      "------------------------------------\n",
      "Eval num_timesteps=610000, episode_reward=-7484.05 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -7.48e+03 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 610000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.55e-08 |\n",
      "|    explained_variance | -2.35     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 30499     |\n",
      "|    policy_loss        | -7.17e+03 |\n",
      "|    value_loss         | 995       |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 708      |\n",
      "|    ep_rew_mean     | 508      |\n",
      "| time/              |          |\n",
      "|    fps             | 155      |\n",
      "|    iterations      | 30500    |\n",
      "|    time_elapsed    | 3931     |\n",
      "|    total_timesteps | 610000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 686      |\n",
      "|    ep_rew_mean        | 603      |\n",
      "| time/                 |          |\n",
      "|    fps                | 155      |\n",
      "|    iterations         | 30600    |\n",
      "|    time_elapsed       | 3934     |\n",
      "|    total_timesteps    | 612000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0309  |\n",
      "|    explained_variance | 0.783    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 30599    |\n",
      "|    policy_loss        | 353      |\n",
      "|    value_loss         | 159      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 667       |\n",
      "|    ep_rew_mean        | 663       |\n",
      "| time/                 |           |\n",
      "|    fps                | 155       |\n",
      "|    iterations         | 30700     |\n",
      "|    time_elapsed       | 3937      |\n",
      "|    total_timesteps    | 614000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0871   |\n",
      "|    explained_variance | -0.0867   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 30699     |\n",
      "|    policy_loss        | -1.52e+03 |\n",
      "|    value_loss         | 241       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=615000, episode_reward=-20761.14 +/- 0.00\n",
      "Episode length: 672.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 672       |\n",
      "|    mean_reward        | -2.08e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 615000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0384   |\n",
      "|    explained_variance | 0.299     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 30749     |\n",
      "|    policy_loss        | -1.37e+03 |\n",
      "|    value_loss         | 101       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 659      |\n",
      "|    ep_rew_mean        | 671      |\n",
      "| time/                 |          |\n",
      "|    fps                | 156      |\n",
      "|    iterations         | 30800    |\n",
      "|    time_elapsed       | 3948     |\n",
      "|    total_timesteps    | 616000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0203  |\n",
      "|    explained_variance | 0.842    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 30799    |\n",
      "|    policy_loss        | -537     |\n",
      "|    value_loss         | 202      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 615       |\n",
      "|    ep_rew_mean        | 802       |\n",
      "| time/                 |           |\n",
      "|    fps                | 156       |\n",
      "|    iterations         | 30900     |\n",
      "|    time_elapsed       | 3951      |\n",
      "|    total_timesteps    | 618000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000706 |\n",
      "|    explained_variance | 0.912     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 30899     |\n",
      "|    policy_loss        | -101      |\n",
      "|    value_loss         | 4.4       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=620000, episode_reward=-4473.97 +/- 0.01\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -4.47e+03 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 620000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.74e-06 |\n",
      "|    explained_variance | 0.951     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 30999     |\n",
      "|    policy_loss        | 70        |\n",
      "|    value_loss         | 5.29      |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 615      |\n",
      "|    ep_rew_mean     | 802      |\n",
      "| time/              |          |\n",
      "|    fps             | 155      |\n",
      "|    iterations      | 31000    |\n",
      "|    time_elapsed    | 3981     |\n",
      "|    total_timesteps | 620000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 619      |\n",
      "|    ep_rew_mean        | 774      |\n",
      "| time/                 |          |\n",
      "|    fps                | 156      |\n",
      "|    iterations         | 31100    |\n",
      "|    time_elapsed       | 3984     |\n",
      "|    total_timesteps    | 622000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00688 |\n",
      "|    explained_variance | 0.583    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 31099    |\n",
      "|    policy_loss        | 1.11e+03 |\n",
      "|    value_loss         | 203      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 606      |\n",
      "|    ep_rew_mean        | 810      |\n",
      "| time/                 |          |\n",
      "|    fps                | 156      |\n",
      "|    iterations         | 31200    |\n",
      "|    time_elapsed       | 3988     |\n",
      "|    total_timesteps    | 624000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0614  |\n",
      "|    explained_variance | 0.788    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 31199    |\n",
      "|    policy_loss        | -19.1    |\n",
      "|    value_loss         | 12       |\n",
      "------------------------------------\n",
      "Eval num_timesteps=625000, episode_reward=-4332.77 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -4.33e+03 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 625000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0052   |\n",
      "|    explained_variance | 0.338     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 31249     |\n",
      "|    policy_loss        | -3.32e+03 |\n",
      "|    value_loss         | 84.5      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 620       |\n",
      "|    ep_rew_mean        | 753       |\n",
      "| time/                 |           |\n",
      "|    fps                | 155       |\n",
      "|    iterations         | 31300     |\n",
      "|    time_elapsed       | 4018      |\n",
      "|    total_timesteps    | 626000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.52e-10 |\n",
      "|    explained_variance | -1.91     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 31299     |\n",
      "|    policy_loss        | 1.92e+03  |\n",
      "|    value_loss         | 727       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 614       |\n",
      "|    ep_rew_mean        | 763       |\n",
      "| time/                 |           |\n",
      "|    fps                | 156       |\n",
      "|    iterations         | 31400     |\n",
      "|    time_elapsed       | 4021      |\n",
      "|    total_timesteps    | 628000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.13e-09 |\n",
      "|    explained_variance | 0.816     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 31399     |\n",
      "|    policy_loss        | 974       |\n",
      "|    value_loss         | 9.57      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=630000, episode_reward=1506.71 +/- 0.01\n",
      "Episode length: 960.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 960       |\n",
      "|    mean_reward        | 1.51e+03  |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 630000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000282 |\n",
      "|    explained_variance | 0.717     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 31499     |\n",
      "|    policy_loss        | -2.91e+03 |\n",
      "|    value_loss         | 276       |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 619      |\n",
      "|    ep_rew_mean     | 740      |\n",
      "| time/              |          |\n",
      "|    fps             | 156      |\n",
      "|    iterations      | 31500    |\n",
      "|    time_elapsed    | 4035     |\n",
      "|    total_timesteps | 630000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 627       |\n",
      "|    ep_rew_mean        | 720       |\n",
      "| time/                 |           |\n",
      "|    fps                | 156       |\n",
      "|    iterations         | 31600     |\n",
      "|    time_elapsed       | 4038      |\n",
      "|    total_timesteps    | 632000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000503 |\n",
      "|    explained_variance | 0.896     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 31599     |\n",
      "|    policy_loss        | 819       |\n",
      "|    value_loss         | 26.7      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 624       |\n",
      "|    ep_rew_mean        | 717       |\n",
      "| time/                 |           |\n",
      "|    fps                | 156       |\n",
      "|    iterations         | 31700     |\n",
      "|    time_elapsed       | 4042      |\n",
      "|    total_timesteps    | 634000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0375   |\n",
      "|    explained_variance | 0.227     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 31699     |\n",
      "|    policy_loss        | -4.98e+03 |\n",
      "|    value_loss         | 268       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=635000, episode_reward=-16163.12 +/- 0.08\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.62e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 635000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000716 |\n",
      "|    explained_variance | 0.741     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 31749     |\n",
      "|    policy_loss        | 315       |\n",
      "|    value_loss         | 32.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 642       |\n",
      "|    ep_rew_mean        | 587       |\n",
      "| time/                 |           |\n",
      "|    fps                | 156       |\n",
      "|    iterations         | 31800     |\n",
      "|    time_elapsed       | 4072      |\n",
      "|    total_timesteps    | 636000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.97e-12 |\n",
      "|    explained_variance | 0.906     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 31799     |\n",
      "|    policy_loss        | -2.95e+03 |\n",
      "|    value_loss         | 24.5      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 660      |\n",
      "|    ep_rew_mean        | 415      |\n",
      "| time/                 |          |\n",
      "|    fps                | 156      |\n",
      "|    iterations         | 31900    |\n",
      "|    time_elapsed       | 4075     |\n",
      "|    total_timesteps    | 638000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00852 |\n",
      "|    explained_variance | 0.289    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 31899    |\n",
      "|    policy_loss        | 2.19e+04 |\n",
      "|    value_loss         | 1.97e+03 |\n",
      "------------------------------------\n",
      "Eval num_timesteps=640000, episode_reward=-16163.15 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.62e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 640000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.86e-08 |\n",
      "|    explained_variance | 0.965     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 31999     |\n",
      "|    policy_loss        | -3.44e+03 |\n",
      "|    value_loss         | 19.6      |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 660      |\n",
      "|    ep_rew_mean     | 415      |\n",
      "| time/              |          |\n",
      "|    fps             | 155      |\n",
      "|    iterations      | 32000    |\n",
      "|    time_elapsed    | 4104     |\n",
      "|    total_timesteps | 640000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 678       |\n",
      "|    ep_rew_mean        | 246       |\n",
      "| time/                 |           |\n",
      "|    fps                | 156       |\n",
      "|    iterations         | 32100     |\n",
      "|    time_elapsed       | 4107      |\n",
      "|    total_timesteps    | 642000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000387 |\n",
      "|    explained_variance | 0.967     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 32099     |\n",
      "|    policy_loss        | 837       |\n",
      "|    value_loss         | 6.21      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 696      |\n",
      "|    ep_rew_mean        | 74.8     |\n",
      "| time/                 |          |\n",
      "|    fps                | 156      |\n",
      "|    iterations         | 32200    |\n",
      "|    time_elapsed       | 4110     |\n",
      "|    total_timesteps    | 644000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0483  |\n",
      "|    explained_variance | 0.919    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 32199    |\n",
      "|    policy_loss        | 43.5     |\n",
      "|    value_loss         | 8.08     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=645000, episode_reward=-16163.15 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.62e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 645000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0989   |\n",
      "|    explained_variance | -0.956    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 32249     |\n",
      "|    policy_loss        | 2.31e+04  |\n",
      "|    value_loss         | 1.05e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 714      |\n",
      "|    ep_rew_mean        | -96.1    |\n",
      "| time/                 |          |\n",
      "|    fps                | 156      |\n",
      "|    iterations         | 32300    |\n",
      "|    time_elapsed       | 4138     |\n",
      "|    total_timesteps    | 646000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0358  |\n",
      "|    explained_variance | 0.975    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 32299    |\n",
      "|    policy_loss        | -577     |\n",
      "|    value_loss         | 3.02     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 733       |\n",
      "|    ep_rew_mean        | -265      |\n",
      "| time/                 |           |\n",
      "|    fps                | 156       |\n",
      "|    iterations         | 32400     |\n",
      "|    time_elapsed       | 4141      |\n",
      "|    total_timesteps    | 648000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.57e-20 |\n",
      "|    explained_variance | 0.875     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 32399     |\n",
      "|    policy_loss        | -991      |\n",
      "|    value_loss         | 16.8      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=650000, episode_reward=-16163.15 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.62e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 650000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0        |\n",
      "|    explained_variance | 0.765     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 32499     |\n",
      "|    policy_loss        | -2.18e+03 |\n",
      "|    value_loss         | 47.7      |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 751      |\n",
      "|    ep_rew_mean     | -433     |\n",
      "| time/              |          |\n",
      "|    fps             | 155      |\n",
      "|    iterations      | 32500    |\n",
      "|    time_elapsed    | 4172     |\n",
      "|    total_timesteps | 650000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 769       |\n",
      "|    ep_rew_mean        | -602      |\n",
      "| time/                 |           |\n",
      "|    fps                | 156       |\n",
      "|    iterations         | 32600     |\n",
      "|    time_elapsed       | 4175      |\n",
      "|    total_timesteps    | 652000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000857 |\n",
      "|    explained_variance | 0.559     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 32599     |\n",
      "|    policy_loss        | 1.56e+03  |\n",
      "|    value_loss         | 188       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 769       |\n",
      "|    ep_rew_mean        | -602      |\n",
      "| time/                 |           |\n",
      "|    fps                | 156       |\n",
      "|    iterations         | 32700     |\n",
      "|    time_elapsed       | 4178      |\n",
      "|    total_timesteps    | 654000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000664 |\n",
      "|    explained_variance | 0.958     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 32699     |\n",
      "|    policy_loss        | -305      |\n",
      "|    value_loss         | 4.24      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=655000, episode_reward=-16163.15 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.62e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 655000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00227  |\n",
      "|    explained_variance | 0.966     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 32749     |\n",
      "|    policy_loss        | -379      |\n",
      "|    value_loss         | 4.03      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 787      |\n",
      "|    ep_rew_mean        | -771     |\n",
      "| time/                 |          |\n",
      "|    fps                | 155      |\n",
      "|    iterations         | 32800    |\n",
      "|    time_elapsed       | 4209     |\n",
      "|    total_timesteps    | 656000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00292 |\n",
      "|    explained_variance | 0.958    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 32799    |\n",
      "|    policy_loss        | 490      |\n",
      "|    value_loss         | 5.87     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 806       |\n",
      "|    ep_rew_mean        | -935      |\n",
      "| time/                 |           |\n",
      "|    fps                | 156       |\n",
      "|    iterations         | 32900     |\n",
      "|    time_elapsed       | 4212      |\n",
      "|    total_timesteps    | 658000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0422   |\n",
      "|    explained_variance | 0.974     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 32899     |\n",
      "|    policy_loss        | -1.35e+03 |\n",
      "|    value_loss         | 5.79      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=660000, episode_reward=-16163.15 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.62e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 660000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0332   |\n",
      "|    explained_variance | 0.965     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 32999     |\n",
      "|    policy_loss        | 307       |\n",
      "|    value_loss         | 4.52      |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 824      |\n",
      "|    ep_rew_mean     | -1.1e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 155      |\n",
      "|    iterations      | 33000    |\n",
      "|    time_elapsed    | 4242     |\n",
      "|    total_timesteps | 660000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 843       |\n",
      "|    ep_rew_mean        | -1.26e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 155       |\n",
      "|    iterations         | 33100     |\n",
      "|    time_elapsed       | 4245      |\n",
      "|    total_timesteps    | 662000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.078    |\n",
      "|    explained_variance | -0.111    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 33099     |\n",
      "|    policy_loss        | -85.5     |\n",
      "|    value_loss         | 1.43e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 861       |\n",
      "|    ep_rew_mean        | -1.14e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 156       |\n",
      "|    iterations         | 33200     |\n",
      "|    time_elapsed       | 4249      |\n",
      "|    total_timesteps    | 664000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0773   |\n",
      "|    explained_variance | 0.828     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 33199     |\n",
      "|    policy_loss        | 13        |\n",
      "|    value_loss         | 63.6      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=665000, episode_reward=-23946.83 +/- 0.70\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -2.39e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 665000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0529   |\n",
      "|    explained_variance | -0.874    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 33249     |\n",
      "|    policy_loss        | 337       |\n",
      "|    value_loss         | 635       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 880       |\n",
      "|    ep_rew_mean        | -1.03e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 155       |\n",
      "|    iterations         | 33300     |\n",
      "|    time_elapsed       | 4279      |\n",
      "|    total_timesteps    | 666000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.13e-12 |\n",
      "|    explained_variance | 0.22      |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 33299     |\n",
      "|    policy_loss        | -3.21e+04 |\n",
      "|    value_loss         | 5.96e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 899       |\n",
      "|    ep_rew_mean        | -1.19e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 155       |\n",
      "|    iterations         | 33400     |\n",
      "|    time_elapsed       | 4282      |\n",
      "|    total_timesteps    | 668000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.29e-08 |\n",
      "|    explained_variance | 0.338     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 33399     |\n",
      "|    policy_loss        | 7.01e+03  |\n",
      "|    value_loss         | 821       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=670000, episode_reward=-16163.12 +/- 0.10\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.62e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 670000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.09e-34 |\n",
      "|    explained_variance | 0.988     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 33499     |\n",
      "|    policy_loss        | -401      |\n",
      "|    value_loss         | 1.24      |\n",
      "-------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 899       |\n",
      "|    ep_rew_mean     | -1.19e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 155       |\n",
      "|    iterations      | 33500     |\n",
      "|    time_elapsed    | 4313      |\n",
      "|    total_timesteps | 670000    |\n",
      "----------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 917       |\n",
      "|    ep_rew_mean        | -1.35e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 155       |\n",
      "|    iterations         | 33600     |\n",
      "|    time_elapsed       | 4316      |\n",
      "|    total_timesteps    | 672000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0634   |\n",
      "|    explained_variance | 0.937     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 33599     |\n",
      "|    policy_loss        | -1.05e+03 |\n",
      "|    value_loss         | 6.77      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 936       |\n",
      "|    ep_rew_mean        | -1.52e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 156       |\n",
      "|    iterations         | 33700     |\n",
      "|    time_elapsed       | 4319      |\n",
      "|    total_timesteps    | 674000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00257  |\n",
      "|    explained_variance | 0.964     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 33699     |\n",
      "|    policy_loss        | 152       |\n",
      "|    value_loss         | 4.13      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=675000, episode_reward=-12722.99 +/- 0.15\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.27e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 675000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0132   |\n",
      "|    explained_variance | -3.26     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 33749     |\n",
      "|    policy_loss        | 722       |\n",
      "|    value_loss         | 2.5e+03   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 954       |\n",
      "|    ep_rew_mean        | -1.65e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 155       |\n",
      "|    iterations         | 33800     |\n",
      "|    time_elapsed       | 4350      |\n",
      "|    total_timesteps    | 676000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0738   |\n",
      "|    explained_variance | 0.164     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 33799     |\n",
      "|    policy_loss        | -23.9     |\n",
      "|    value_loss         | 42.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 972       |\n",
      "|    ep_rew_mean        | -1.54e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 155       |\n",
      "|    iterations         | 33900     |\n",
      "|    time_elapsed       | 4353      |\n",
      "|    total_timesteps    | 678000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0        |\n",
      "|    explained_variance | 0.929     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 33899     |\n",
      "|    policy_loss        | -608      |\n",
      "|    value_loss         | 9.71      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=680000, episode_reward=-16163.12 +/- 0.10\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.62e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 680000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0        |\n",
      "|    explained_variance | 0.908     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 33999     |\n",
      "|    policy_loss        | -1.28e+03 |\n",
      "|    value_loss         | 16.2      |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 990      |\n",
      "|    ep_rew_mean     | -1.7e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 155      |\n",
      "|    iterations      | 34000    |\n",
      "|    time_elapsed    | 4383     |\n",
      "|    total_timesteps | 680000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.01e+03  |\n",
      "|    ep_rew_mean        | -1.87e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 155       |\n",
      "|    iterations         | 34100     |\n",
      "|    time_elapsed       | 4386      |\n",
      "|    total_timesteps    | 682000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0856   |\n",
      "|    explained_variance | 0.687     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 34099     |\n",
      "|    policy_loss        | -3.15e+03 |\n",
      "|    value_loss         | 42.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.01e+03  |\n",
      "|    ep_rew_mean        | -1.87e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 155       |\n",
      "|    iterations         | 34200     |\n",
      "|    time_elapsed       | 4390      |\n",
      "|    total_timesteps    | 684000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00786  |\n",
      "|    explained_variance | 0.963     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 34199     |\n",
      "|    policy_loss        | 1e+03     |\n",
      "|    value_loss         | 12        |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=685000, episode_reward=-16163.15 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.62e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 685000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.65e-24 |\n",
      "|    explained_variance | 0.961     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 34249     |\n",
      "|    policy_loss        | 1.36e+03  |\n",
      "|    value_loss         | 6.77      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.03e+03  |\n",
      "|    ep_rew_mean        | -2.03e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 155       |\n",
      "|    iterations         | 34300     |\n",
      "|    time_elapsed       | 4420      |\n",
      "|    total_timesteps    | 686000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.25e-08 |\n",
      "|    explained_variance | 0.957     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 34299     |\n",
      "|    policy_loss        | 324       |\n",
      "|    value_loss         | 4.8       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.04e+03  |\n",
      "|    ep_rew_mean        | -2.2e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 155       |\n",
      "|    iterations         | 34400     |\n",
      "|    time_elapsed       | 4423      |\n",
      "|    total_timesteps    | 688000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.14e-07 |\n",
      "|    explained_variance | 0.962     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 34399     |\n",
      "|    policy_loss        | -1.48e+03 |\n",
      "|    value_loss         | 5.15      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=690000, episode_reward=-16163.15 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.62e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 690000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.02     |\n",
      "|    explained_variance | 0.967     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 34499     |\n",
      "|    policy_loss        | -274      |\n",
      "|    value_loss         | 4.02      |\n",
      "-------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.06e+03  |\n",
      "|    ep_rew_mean     | -2.37e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 154       |\n",
      "|    iterations      | 34500     |\n",
      "|    time_elapsed    | 4454      |\n",
      "|    total_timesteps | 690000    |\n",
      "----------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.08e+03  |\n",
      "|    ep_rew_mean        | -2.53e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 155       |\n",
      "|    iterations         | 34600     |\n",
      "|    time_elapsed       | 4457      |\n",
      "|    total_timesteps    | 692000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00934  |\n",
      "|    explained_variance | 0.962     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 34599     |\n",
      "|    policy_loss        | 319       |\n",
      "|    value_loss         | 4.06      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.1e+03   |\n",
      "|    ep_rew_mean        | -2.7e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 155       |\n",
      "|    iterations         | 34700     |\n",
      "|    time_elapsed       | 4460      |\n",
      "|    total_timesteps    | 694000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.28e-16 |\n",
      "|    explained_variance | 0.931     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 34699     |\n",
      "|    policy_loss        | -689      |\n",
      "|    value_loss         | 8.68      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=695000, episode_reward=-16163.15 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.62e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 695000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.13e-09 |\n",
      "|    explained_variance | 0.96      |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 34749     |\n",
      "|    policy_loss        | -40.7     |\n",
      "|    value_loss         | 4.02      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.12e+03  |\n",
      "|    ep_rew_mean        | -2.87e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 154       |\n",
      "|    iterations         | 34800     |\n",
      "|    time_elapsed       | 4490      |\n",
      "|    total_timesteps    | 696000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.15     |\n",
      "|    explained_variance | 0.783     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 34799     |\n",
      "|    policy_loss        | -6.22e+03 |\n",
      "|    value_loss         | 88.8      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.13e+03  |\n",
      "|    ep_rew_mean        | -3.03e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 155       |\n",
      "|    iterations         | 34900     |\n",
      "|    time_elapsed       | 4494      |\n",
      "|    total_timesteps    | 698000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.19e-05 |\n",
      "|    explained_variance | 0.621     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 34899     |\n",
      "|    policy_loss        | 6.62e+03  |\n",
      "|    value_loss         | 719       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=700000, episode_reward=-16163.15 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.62e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 700000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.89e-07 |\n",
      "|    explained_variance | 0.988     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 34999     |\n",
      "|    policy_loss        | -32.1     |\n",
      "|    value_loss         | 1.39      |\n",
      "-------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.13e+03  |\n",
      "|    ep_rew_mean     | -3.03e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 154       |\n",
      "|    iterations      | 35000     |\n",
      "|    time_elapsed    | 4524      |\n",
      "|    total_timesteps | 700000    |\n",
      "----------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.15e+03  |\n",
      "|    ep_rew_mean        | -3.2e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 155       |\n",
      "|    iterations         | 35100     |\n",
      "|    time_elapsed       | 4527      |\n",
      "|    total_timesteps    | 702000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.18e-05 |\n",
      "|    explained_variance | 0.973     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 35099     |\n",
      "|    policy_loss        | 866       |\n",
      "|    value_loss         | 7.26      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.17e+03  |\n",
      "|    ep_rew_mean        | -3.37e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 155       |\n",
      "|    iterations         | 35200     |\n",
      "|    time_elapsed       | 4530      |\n",
      "|    total_timesteps    | 704000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.21e-35 |\n",
      "|    explained_variance | 0.135     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 35199     |\n",
      "|    policy_loss        | -5.48e+04 |\n",
      "|    value_loss         | 4.55e+03  |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=705000, episode_reward=-16163.15 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.62e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 705000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00763  |\n",
      "|    explained_variance | 0.452     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 35249     |\n",
      "|    policy_loss        | 8.42e+03  |\n",
      "|    value_loss         | 430       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.19e+03  |\n",
      "|    ep_rew_mean        | -3.36e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 154       |\n",
      "|    iterations         | 35300     |\n",
      "|    time_elapsed       | 4561      |\n",
      "|    total_timesteps    | 706000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0097   |\n",
      "|    explained_variance | 0.657     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 35299     |\n",
      "|    policy_loss        | 7.93      |\n",
      "|    value_loss         | 61.8      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.21e+03  |\n",
      "|    ep_rew_mean        | -3.22e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 155       |\n",
      "|    iterations         | 35400     |\n",
      "|    time_elapsed       | 4564      |\n",
      "|    total_timesteps    | 708000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0        |\n",
      "|    explained_variance | 0.429     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 35399     |\n",
      "|    policy_loss        | -3.33e+04 |\n",
      "|    value_loss         | 1.32e+03  |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=710000, episode_reward=-9381.57 +/- 0.06\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -9.38e+03 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 710000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.132    |\n",
      "|    explained_variance | -0.208    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 35499     |\n",
      "|    policy_loss        | 4.25e+03  |\n",
      "|    value_loss         | 3.63e+03  |\n",
      "-------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.22e+03  |\n",
      "|    ep_rew_mean     | -3.34e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 154       |\n",
      "|    iterations      | 35500     |\n",
      "|    time_elapsed    | 4594      |\n",
      "|    total_timesteps | 710000    |\n",
      "----------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.24e+03  |\n",
      "|    ep_rew_mean        | -3.2e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 154       |\n",
      "|    iterations         | 35600     |\n",
      "|    time_elapsed       | 4598      |\n",
      "|    total_timesteps    | 712000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.57e-12 |\n",
      "|    explained_variance | 0.553     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 35599     |\n",
      "|    policy_loss        | -1.14e+04 |\n",
      "|    value_loss         | 132       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.26e+03  |\n",
      "|    ep_rew_mean        | -3.15e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 155       |\n",
      "|    iterations         | 35700     |\n",
      "|    time_elapsed       | 4601      |\n",
      "|    total_timesteps    | 714000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.76e-35 |\n",
      "|    explained_variance | -0.194    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 35699     |\n",
      "|    policy_loss        | 2.08e+03  |\n",
      "|    value_loss         | 167       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=715000, episode_reward=5776.45 +/- 0.02\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | 5.78e+03  |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 715000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.34e-22 |\n",
      "|    explained_variance | 0.786     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 35749     |\n",
      "|    policy_loss        | -5.24e+03 |\n",
      "|    value_loss         | 34.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.26e+03  |\n",
      "|    ep_rew_mean        | -3.15e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 154       |\n",
      "|    iterations         | 35800     |\n",
      "|    time_elapsed       | 4631      |\n",
      "|    total_timesteps    | 716000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0        |\n",
      "|    explained_variance | 0.853     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 35799     |\n",
      "|    policy_loss        | 4.27e+03  |\n",
      "|    value_loss         | 32.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.28e+03  |\n",
      "|    ep_rew_mean        | -3.13e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 154       |\n",
      "|    iterations         | 35900     |\n",
      "|    time_elapsed       | 4634      |\n",
      "|    total_timesteps    | 718000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.14e-11 |\n",
      "|    explained_variance | 0.925     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 35899     |\n",
      "|    policy_loss        | -2.66e+03 |\n",
      "|    value_loss         | 14.8      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=720000, episode_reward=-16163.14 +/- 0.02\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.62e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 720000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0        |\n",
      "|    explained_variance | 0.895     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 35999     |\n",
      "|    policy_loss        | 1.81e+03  |\n",
      "|    value_loss         | 14.6      |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.29e+03 |\n",
      "|    ep_rew_mean     | -3.3e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 154      |\n",
      "|    iterations      | 36000    |\n",
      "|    time_elapsed    | 4665     |\n",
      "|    total_timesteps | 720000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.31e+03  |\n",
      "|    ep_rew_mean        | -3.36e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 154       |\n",
      "|    iterations         | 36100     |\n",
      "|    time_elapsed       | 4668      |\n",
      "|    total_timesteps    | 722000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0257   |\n",
      "|    explained_variance | 0.453     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 36099     |\n",
      "|    policy_loss        | -1.04e+03 |\n",
      "|    value_loss         | 59.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.33e+03  |\n",
      "|    ep_rew_mean        | -3.27e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 154       |\n",
      "|    iterations         | 36200     |\n",
      "|    time_elapsed       | 4671      |\n",
      "|    total_timesteps    | 724000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0        |\n",
      "|    explained_variance | 0.918     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 36199     |\n",
      "|    policy_loss        | -2.08e+03 |\n",
      "|    value_loss         | 13.1      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=725000, episode_reward=-5845.35 +/- 0.01\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -5.85e+03 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 725000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.94e-22 |\n",
      "|    explained_variance | 0.939     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 36249     |\n",
      "|    policy_loss        | 601       |\n",
      "|    value_loss         | 7.37      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.35e+03  |\n",
      "|    ep_rew_mean        | -3.39e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 154       |\n",
      "|    iterations         | 36300     |\n",
      "|    time_elapsed       | 4702      |\n",
      "|    total_timesteps    | 726000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0256   |\n",
      "|    explained_variance | 0.0278    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 36299     |\n",
      "|    policy_loss        | 188       |\n",
      "|    value_loss         | 2.53e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.36e+03  |\n",
      "|    ep_rew_mean        | -3.29e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 154       |\n",
      "|    iterations         | 36400     |\n",
      "|    time_elapsed       | 4705      |\n",
      "|    total_timesteps    | 728000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00766  |\n",
      "|    explained_variance | -0.414    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 36399     |\n",
      "|    policy_loss        | -2.6e+03  |\n",
      "|    value_loss         | 197       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=730000, episode_reward=-13677.87 +/- 0.02\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.37e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 730000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.165    |\n",
      "|    explained_variance | 0.784     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 36499     |\n",
      "|    policy_loss        | -8.51e+03 |\n",
      "|    value_loss         | 88.9      |\n",
      "-------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.38e+03  |\n",
      "|    ep_rew_mean     | -3.15e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 154       |\n",
      "|    iterations      | 36500     |\n",
      "|    time_elapsed    | 4735      |\n",
      "|    total_timesteps | 730000    |\n",
      "----------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.39e+03  |\n",
      "|    ep_rew_mean        | -3.01e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 154       |\n",
      "|    iterations         | 36600     |\n",
      "|    time_elapsed       | 4738      |\n",
      "|    total_timesteps    | 732000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0659   |\n",
      "|    explained_variance | 0.68      |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 36599     |\n",
      "|    policy_loss        | -3.24e+03 |\n",
      "|    value_loss         | 59.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.39e+03  |\n",
      "|    ep_rew_mean        | -3.01e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 154       |\n",
      "|    iterations         | 36700     |\n",
      "|    time_elapsed       | 4741      |\n",
      "|    total_timesteps    | 734000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.25e-19 |\n",
      "|    explained_variance | 0.889     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 36699     |\n",
      "|    policy_loss        | 1.17e+03  |\n",
      "|    value_loss         | 19.9      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=735000, episode_reward=2178.31 +/- 0.20\n",
      "Episode length: 2232.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.23e+03  |\n",
      "|    mean_reward        | 2.18e+03  |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 735000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000765 |\n",
      "|    explained_variance | 0.587     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 36749     |\n",
      "|    policy_loss        | 51.7      |\n",
      "|    value_loss         | 312       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.41e+03  |\n",
      "|    ep_rew_mean        | -2.98e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 154       |\n",
      "|    iterations         | 36800     |\n",
      "|    time_elapsed       | 4771      |\n",
      "|    total_timesteps    | 736000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0214   |\n",
      "|    explained_variance | 0.475     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 36799     |\n",
      "|    policy_loss        | 107       |\n",
      "|    value_loss         | 161       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.44e+03  |\n",
      "|    ep_rew_mean        | -2.77e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 154       |\n",
      "|    iterations         | 36900     |\n",
      "|    time_elapsed       | 4775      |\n",
      "|    total_timesteps    | 738000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0261   |\n",
      "|    explained_variance | 0.111     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 36899     |\n",
      "|    policy_loss        | -27.7     |\n",
      "|    value_loss         | 150       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=740000, episode_reward=-16248.09 +/- 0.10\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.62e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 740000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000229 |\n",
      "|    explained_variance | 0.819     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 36999     |\n",
      "|    policy_loss        | -602      |\n",
      "|    value_loss         | 16        |\n",
      "-------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.45e+03  |\n",
      "|    ep_rew_mean     | -2.62e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 153       |\n",
      "|    iterations      | 37000     |\n",
      "|    time_elapsed    | 4806      |\n",
      "|    total_timesteps | 740000    |\n",
      "----------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.45e+03  |\n",
      "|    ep_rew_mean        | -2.62e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 154       |\n",
      "|    iterations         | 37100     |\n",
      "|    time_elapsed       | 4809      |\n",
      "|    total_timesteps    | 742000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0655   |\n",
      "|    explained_variance | 0.327     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 37099     |\n",
      "|    policy_loss        | 605       |\n",
      "|    value_loss         | 384       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.47e+03  |\n",
      "|    ep_rew_mean        | -2.63e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 154       |\n",
      "|    iterations         | 37200     |\n",
      "|    time_elapsed       | 4812      |\n",
      "|    total_timesteps    | 744000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.127    |\n",
      "|    explained_variance | 0.284     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 37199     |\n",
      "|    policy_loss        | -42.2     |\n",
      "|    value_loss         | 547       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=745000, episode_reward=15283.97 +/- 0.12\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | 1.53e+04  |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 745000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.77e-16 |\n",
      "|    explained_variance | 0.318     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 37249     |\n",
      "|    policy_loss        | -1.43e+03 |\n",
      "|    value_loss         | 35.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.49e+03  |\n",
      "|    ep_rew_mean        | -2.53e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 154       |\n",
      "|    iterations         | 37300     |\n",
      "|    time_elapsed       | 4842      |\n",
      "|    total_timesteps    | 746000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0        |\n",
      "|    explained_variance | 0.269     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 37299     |\n",
      "|    policy_loss        | -3.86e+04 |\n",
      "|    value_loss         | 1.84e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.51e+03  |\n",
      "|    ep_rew_mean        | -2.52e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 154       |\n",
      "|    iterations         | 37400     |\n",
      "|    time_elapsed       | 4845      |\n",
      "|    total_timesteps    | 748000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00967  |\n",
      "|    explained_variance | 0.949     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 37399     |\n",
      "|    policy_loss        | -456      |\n",
      "|    value_loss         | 5.96      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=750000, episode_reward=2304.09 +/- 0.30\n",
      "Episode length: 1320.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1.32e+03 |\n",
      "|    mean_reward        | 2.3e+03  |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 750000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0273  |\n",
      "|    explained_variance | -0.145   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 37499    |\n",
      "|    policy_loss        | 165      |\n",
      "|    value_loss         | 217      |\n",
      "------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.53e+03  |\n",
      "|    ep_rew_mean     | -2.57e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 154       |\n",
      "|    iterations      | 37500     |\n",
      "|    time_elapsed    | 4864      |\n",
      "|    total_timesteps | 750000    |\n",
      "----------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.54e+03  |\n",
      "|    ep_rew_mean        | -2.47e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 154       |\n",
      "|    iterations         | 37600     |\n",
      "|    time_elapsed       | 4867      |\n",
      "|    total_timesteps    | 752000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.161    |\n",
      "|    explained_variance | 0.145     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 37599     |\n",
      "|    policy_loss        | -96.5     |\n",
      "|    value_loss         | 98.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.56e+03  |\n",
      "|    ep_rew_mean        | -2.37e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 154       |\n",
      "|    iterations         | 37700     |\n",
      "|    time_elapsed       | 4870      |\n",
      "|    total_timesteps    | 754000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0        |\n",
      "|    explained_variance | 0.817     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 37699     |\n",
      "|    policy_loss        | 1.14e+03  |\n",
      "|    value_loss         | 70.8      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=755000, episode_reward=351.58 +/- 0.00\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | 352       |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 755000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000279 |\n",
      "|    explained_variance | -0.00809  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 37749     |\n",
      "|    policy_loss        | 102       |\n",
      "|    value_loss         | 345       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.56e+03  |\n",
      "|    ep_rew_mean        | -2.37e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 154       |\n",
      "|    iterations         | 37800     |\n",
      "|    time_elapsed       | 4900      |\n",
      "|    total_timesteps    | 756000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.74e-05 |\n",
      "|    explained_variance | 0.458     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 37799     |\n",
      "|    policy_loss        | 5.34e+03  |\n",
      "|    value_loss         | 118       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.58e+03  |\n",
      "|    ep_rew_mean        | -2.26e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 154       |\n",
      "|    iterations         | 37900     |\n",
      "|    time_elapsed       | 4903      |\n",
      "|    total_timesteps    | 758000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.96e-36 |\n",
      "|    explained_variance | 0.907     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 37899     |\n",
      "|    policy_loss        | 1.38e+03  |\n",
      "|    value_loss         | 12.4      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=760000, episode_reward=-12786.98 +/- 0.06\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.28e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 760000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.113    |\n",
      "|    explained_variance | 0.638     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 37999     |\n",
      "|    policy_loss        | 307       |\n",
      "|    value_loss         | 148       |\n",
      "-------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.6e+03   |\n",
      "|    ep_rew_mean     | -2.32e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 154       |\n",
      "|    iterations      | 38000     |\n",
      "|    time_elapsed    | 4934      |\n",
      "|    total_timesteps | 760000    |\n",
      "----------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.62e+03  |\n",
      "|    ep_rew_mean        | -2.28e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 154       |\n",
      "|    iterations         | 38100     |\n",
      "|    time_elapsed       | 4937      |\n",
      "|    total_timesteps    | 762000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.312    |\n",
      "|    explained_variance | 0.25      |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 38099     |\n",
      "|    policy_loss        | 35.5      |\n",
      "|    value_loss         | 352       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1.63e+03 |\n",
      "|    ep_rew_mean        | -2.2e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 154      |\n",
      "|    iterations         | 38200    |\n",
      "|    time_elapsed       | 4940     |\n",
      "|    total_timesteps    | 764000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0       |\n",
      "|    explained_variance | 0.612    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 38199    |\n",
      "|    policy_loss        | 2.1e+03  |\n",
      "|    value_loss         | 48.5     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=765000, episode_reward=7630.22 +/- 0.57\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 2.3e+03  |\n",
      "|    mean_reward        | 7.63e+03 |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 765000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0486  |\n",
      "|    explained_variance | 0.973    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 38249    |\n",
      "|    policy_loss        | 239      |\n",
      "|    value_loss         | 4.08     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.65e+03  |\n",
      "|    ep_rew_mean        | -2.37e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 154       |\n",
      "|    iterations         | 38300     |\n",
      "|    time_elapsed       | 4971      |\n",
      "|    total_timesteps    | 766000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.155    |\n",
      "|    explained_variance | 0.192     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 38299     |\n",
      "|    policy_loss        | 7.17      |\n",
      "|    value_loss         | 800       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.66e+03  |\n",
      "|    ep_rew_mean        | -2.26e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 154       |\n",
      "|    iterations         | 38400     |\n",
      "|    time_elapsed       | 4974      |\n",
      "|    total_timesteps    | 768000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.132    |\n",
      "|    explained_variance | -0.0668   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 38399     |\n",
      "|    policy_loss        | -2e+03    |\n",
      "|    value_loss         | 136       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=770000, episode_reward=-16163.13 +/- 0.05\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.62e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 770000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.04e-19 |\n",
      "|    explained_variance | 0.377     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 38499     |\n",
      "|    policy_loss        | 1.65e+04  |\n",
      "|    value_loss         | 2.09e+03  |\n",
      "-------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.68e+03  |\n",
      "|    ep_rew_mean     | -2.35e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 153       |\n",
      "|    iterations      | 38500     |\n",
      "|    time_elapsed    | 5005      |\n",
      "|    total_timesteps | 770000    |\n",
      "----------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.68e+03  |\n",
      "|    ep_rew_mean        | -2.35e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 154       |\n",
      "|    iterations         | 38600     |\n",
      "|    time_elapsed       | 5008      |\n",
      "|    total_timesteps    | 772000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0491   |\n",
      "|    explained_variance | 0.971     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 38599     |\n",
      "|    policy_loss        | -1.23e+03 |\n",
      "|    value_loss         | 3.36      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.7e+03   |\n",
      "|    ep_rew_mean        | -2.53e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 154       |\n",
      "|    iterations         | 38700     |\n",
      "|    time_elapsed       | 5011      |\n",
      "|    total_timesteps    | 774000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.04e-31 |\n",
      "|    explained_variance | 0.972     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 38699     |\n",
      "|    policy_loss        | 345       |\n",
      "|    value_loss         | 4.77      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=775000, episode_reward=1464.89 +/- 0.64\n",
      "Episode length: 1704.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1.7e+03  |\n",
      "|    mean_reward        | 1.46e+03 |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 775000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.188   |\n",
      "|    explained_variance | 0.0969   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 38749    |\n",
      "|    policy_loss        | 2.11     |\n",
      "|    value_loss         | 295      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.72e+03  |\n",
      "|    ep_rew_mean        | -2.66e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 154       |\n",
      "|    iterations         | 38800     |\n",
      "|    time_elapsed       | 5034      |\n",
      "|    total_timesteps    | 776000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0184   |\n",
      "|    explained_variance | -1.24     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 38799     |\n",
      "|    policy_loss        | 1.14e+03  |\n",
      "|    value_loss         | 212       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.74e+03  |\n",
      "|    ep_rew_mean        | -2.59e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 154       |\n",
      "|    iterations         | 38900     |\n",
      "|    time_elapsed       | 5037      |\n",
      "|    total_timesteps    | 778000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0        |\n",
      "|    explained_variance | 0.981     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 38899     |\n",
      "|    policy_loss        | -1.7e+03  |\n",
      "|    value_loss         | 3.57      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=780000, episode_reward=-16163.12 +/- 0.08\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.62e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 780000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0        |\n",
      "|    explained_variance | 0.872     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 38999     |\n",
      "|    policy_loss        | -2.53e+03 |\n",
      "|    value_loss         | 18.9      |\n",
      "-------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.76e+03  |\n",
      "|    ep_rew_mean     | -2.79e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 153       |\n",
      "|    iterations      | 39000     |\n",
      "|    time_elapsed    | 5067      |\n",
      "|    total_timesteps | 780000    |\n",
      "----------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.78e+03  |\n",
      "|    ep_rew_mean        | -2.81e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 154       |\n",
      "|    iterations         | 39100     |\n",
      "|    time_elapsed       | 5070      |\n",
      "|    total_timesteps    | 782000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00925  |\n",
      "|    explained_variance | 0.682     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 39099     |\n",
      "|    policy_loss        | -1.61     |\n",
      "|    value_loss         | 43.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.79e+03  |\n",
      "|    ep_rew_mean        | -2.66e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 154       |\n",
      "|    iterations         | 39200     |\n",
      "|    time_elapsed       | 5074      |\n",
      "|    total_timesteps    | 784000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0171   |\n",
      "|    explained_variance | 0.243     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 39199     |\n",
      "|    policy_loss        | -2.14e+03 |\n",
      "|    value_loss         | 766       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=785000, episode_reward=-15693.85 +/- 0.12\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.57e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 785000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.91e-15 |\n",
      "|    explained_variance | -0.792    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 39249     |\n",
      "|    policy_loss        | -2.78e+03 |\n",
      "|    value_loss         | 232       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.79e+03  |\n",
      "|    ep_rew_mean        | -2.66e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 153       |\n",
      "|    iterations         | 39300     |\n",
      "|    time_elapsed       | 5104      |\n",
      "|    total_timesteps    | 786000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0        |\n",
      "|    explained_variance | 0.458     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 39299     |\n",
      "|    policy_loss        | -2.05e+04 |\n",
      "|    value_loss         | 2.08e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.8e+03   |\n",
      "|    ep_rew_mean        | -2.52e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 154       |\n",
      "|    iterations         | 39400     |\n",
      "|    time_elapsed       | 5107      |\n",
      "|    total_timesteps    | 788000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0        |\n",
      "|    explained_variance | 0.968     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 39399     |\n",
      "|    policy_loss        | 1.25e+03  |\n",
      "|    value_loss         | 4.69      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=790000, episode_reward=3351.59 +/- 0.23\n",
      "Episode length: 1992.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1.99e+03 |\n",
      "|    mean_reward        | 3.35e+03 |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 790000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00734 |\n",
      "|    explained_variance | -0.904   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 39499    |\n",
      "|    policy_loss        | 101      |\n",
      "|    value_loss         | 4.34e+03 |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.81e+03 |\n",
      "|    ep_rew_mean     | -2.7e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 153      |\n",
      "|    iterations      | 39500    |\n",
      "|    time_elapsed    | 5134     |\n",
      "|    total_timesteps | 790000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.83e+03  |\n",
      "|    ep_rew_mean        | -2.72e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 154       |\n",
      "|    iterations         | 39600     |\n",
      "|    time_elapsed       | 5137      |\n",
      "|    total_timesteps    | 792000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0        |\n",
      "|    explained_variance | 0.22      |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 39599     |\n",
      "|    policy_loss        | -1.43e+04 |\n",
      "|    value_loss         | 1.13e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.85e+03  |\n",
      "|    ep_rew_mean        | -2.79e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 154       |\n",
      "|    iterations         | 39700     |\n",
      "|    time_elapsed       | 5141      |\n",
      "|    total_timesteps    | 794000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.16     |\n",
      "|    explained_variance | 0.259     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 39699     |\n",
      "|    policy_loss        | -80.2     |\n",
      "|    value_loss         | 57.2      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=795000, episode_reward=-16163.12 +/- 0.08\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | -1.62e+04 |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 795000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0        |\n",
      "|    explained_variance | 0.32      |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 39749     |\n",
      "|    policy_loss        | -5.81e+03 |\n",
      "|    value_loss         | 1.39e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.86e+03  |\n",
      "|    ep_rew_mean        | -2.72e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 153       |\n",
      "|    iterations         | 39800     |\n",
      "|    time_elapsed       | 5172      |\n",
      "|    total_timesteps    | 796000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0        |\n",
      "|    explained_variance | 0.723     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 39799     |\n",
      "|    policy_loss        | -8.62e+03 |\n",
      "|    value_loss         | 61.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.88e+03  |\n",
      "|    ep_rew_mean        | -2.81e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 154       |\n",
      "|    iterations         | 39900     |\n",
      "|    time_elapsed       | 5175      |\n",
      "|    total_timesteps    | 798000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0417   |\n",
      "|    explained_variance | -0.0442   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 39899     |\n",
      "|    policy_loss        | -533      |\n",
      "|    value_loss         | 135       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=800000, episode_reward=17181.03 +/- 0.44\n",
      "Episode length: 2304.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.3e+03   |\n",
      "|    mean_reward        | 1.72e+04  |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 800000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.77e-06 |\n",
      "|    explained_variance | 0.0424    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 39999     |\n",
      "|    policy_loss        | 1.65e+04  |\n",
      "|    value_loss         | 8.17e+03  |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.89e+03 |\n",
      "|    ep_rew_mean     | -2.8e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 153      |\n",
      "|    iterations      | 40000    |\n",
      "|    time_elapsed    | 5205     |\n",
      "|    total_timesteps | 800000   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<MaskableA2C.MaskableA2C at 0x768d7c6107f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from environment3 import LifeStyleEnv\n",
    "from sb3_contrib.common.wrappers import ActionMasker\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "from MaskableA2C import MaskableA2C\n",
    "from stable_baselines3.common.torch_layers import CombinedExtractor\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def mask_fn(env: gym.Env) -> np.ndarray:\n",
    "    unwrapped_env = env\n",
    "    while hasattr(unwrapped_env, \"env\"):\n",
    "        unwrapped_env = unwrapped_env.env\n",
    "    return unwrapped_env.action_masks()\n",
    "\n",
    "def make_env():\n",
    "    env = LifeStyleEnv()\n",
    "    env = Monitor(env)\n",
    "    check_env(env, warn=True) \n",
    "    return env \n",
    "\n",
    "env = make_env()\n",
    "env = ActionMasker(env, mask_fn)\n",
    "\n",
    "eval_env = make_env()\n",
    "eval_env = ActionMasker(eval_env, mask_fn)\n",
    "\n",
    "eval_callback = EvalCallback(\n",
    "    eval_env,\n",
    "    best_model_save_path=\"./logs/a2c/a2c_best_model\",\n",
    "    log_path=\"./logs/a2c/a2c_results\",\n",
    "    eval_freq=5000,\n",
    "    n_eval_episodes=10,\n",
    "    deterministic=True,\n",
    "    render=False\n",
    ")\n",
    "\n",
    "model = MaskableA2C(\n",
    "    \"MultiInputPolicy\",  \n",
    "    env,\n",
    "    learning_rate=0.0005,\n",
    "    n_steps=20,           \n",
    "    gamma=0.95,\n",
    "    gae_lambda=0.95,\n",
    "    vf_coef=0.5,\n",
    "    max_grad_norm=0.5,\n",
    "    verbose=1,\n",
    "    device=device,\n",
    "    policy_kwargs=dict(\n",
    "        features_extractor_class=CombinedExtractor,  \n",
    "        features_extractor_kwargs={},                \n",
    "        net_arch=[256, 256]\n",
    "    ),\n",
    "    tensorboard_log=\"./logs/a2c/a2c_tensorboard/\"\n",
    ")\n",
    "\n",
    "model.learn(total_timesteps=800000, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12a0cda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Final Evaluation...\n",
      "-------------------------------------------------------------------------------------------------------------------------------------\n",
      "| Day | Timeslot   | Action     | Event      | BMI      | Stress   | Energy   | Hunger   | Cal. Intake  | Cal. Burned  | Reward   |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------\n",
      "| 0   | 1          | 8          | sleep      | 24.22    | 46.00    | 54.00    | 48.00    | 0.00         | 66.15        | 1.11     |\n",
      "| 0   | 2          | 8          | sleep      | 24.22    | 42.00    | 58.00    | 46.00    | 0.00         | 132.30       | 2.41     |\n",
      "| 0   | 3          | 8          | sleep      | 24.22    | 38.00    | 62.00    | 44.00    | 0.00         | 198.45       | 3.69     |\n",
      "| 0   | 4          | 8          | sleep      | 24.22    | 34.00    | 66.00    | 42.00    | 0.00         | 264.60       | 4.95     |\n",
      "| 0   | 5          | 8          | sleep      | 24.22    | 30.00    | 70.00    | 40.00    | 0.00         | 330.75       | 6.18     |\n",
      "| 0   | 6          | 8          | sleep      | 24.22    | 26.00    | 74.00    | 38.00    | 0.00         | 396.90       | 7.39     |\n",
      "| 0   | 7          | 0          | action     | 24.22    | 26.00    | 94.00    | 18.00    | 350.00       | 396.90       | 6.18     |\n",
      "| 0   | 8          | 0          | action     | 24.22    | 26.00    | 100.00   | 0.00     | 700.00       | 396.90       | 4.78     |\n",
      "| 0   | 9          | 6          | action     | 24.22    | 16.00    | 100.00   | 2.00     | 700.00       | 485.10       | 7.18     |\n",
      "| 0   | 10         | 6          | action     | 24.22    | 6.00     | 100.00   | 4.00     | 700.00       | 573.30       | 9.57     |\n",
      "| 0   | 11         | 8          | work       | 24.22    | 11.00    | 95.00    | 9.00     | 700.00       | 720.30       | 9.23     |\n",
      "| 0   | 12         | 8          | work       | 24.22    | 16.00    | 90.00    | 14.00    | 700.00       | 867.30       | 8.90     |\n",
      "| 0   | 13         | 6          | action     | 24.22    | 6.00     | 100.00   | 16.00    | 700.00       | 955.50       | 11.29    |\n",
      "| 0   | 14         | 8          | work       | 24.22    | 11.00    | 95.00    | 21.00    | 700.00       | 1102.50      | 8.95     |\n",
      "| 0   | 15         | 8          | work       | 24.22    | 16.00    | 90.00    | 26.00    | 700.00       | 1249.50      | 6.62     |\n",
      "| 0   | 16         | 8          | work       | 24.22    | 21.00    | 85.00    | 31.00    | 700.00       | 1396.50      | 4.27     |\n",
      "| 0   | 17         | 8          | work       | 24.22    | 26.00    | 80.00    | 36.00    | 700.00       | 1543.50      | 1.83     |\n",
      "| 0   | 18         | 8          | work       | 24.22    | 31.00    | 75.00    | 41.00    | 700.00       | 1690.50      | -0.77    |\n",
      "| 0   | 19         | 0          | action     | 24.22    | 31.00    | 95.00    | 21.00    | 1050.00      | 1690.50      | 8.20     |\n",
      "| 0   | 20         | 0          | action     | 24.22    | 31.00    | 100.00   | 1.00     | 1400.00      | 1690.50      | 6.79     |\n",
      "| 0   | 21         | 6          | action     | 24.22    | 21.00    | 100.00   | 3.00     | 1400.00      | 1778.70      | 9.19     |\n",
      "| 0   | 22         | 6          | action     | 24.22    | 11.00    | 100.00   | 5.00     | 1400.00      | 1866.90      | 11.59    |\n",
      "| 0   | 23         | 8          | sleep      | 24.22    | 7.00     | 100.00   | 3.00     | 1400.00      | 1933.05      | 12.69    |\n",
      "| 1   | 0          | 8          | sleep      | 24.19    | 3.00     | 100.00   | 1.00     | 0.00         | 0.00         | 23.56    |\n",
      "| 1   | 1          | 8          | sleep      | 24.19    | 0.00     | 100.00   | 0.00     | 0.00         | 66.08        | 11.30    |\n",
      "| 1   | 2          | 8          | sleep      | 24.19    | 0.00     | 100.00   | 0.00     | 0.00         | 132.15       | 9.59     |\n",
      "| 1   | 3          | 8          | sleep      | 24.19    | 0.00     | 100.00   | 0.00     | 0.00         | 198.23       | 7.89     |\n",
      "| 1   | 4          | 8          | sleep      | 24.19    | 0.00     | 100.00   | 0.00     | 0.00         | 264.31       | 6.19     |\n",
      "| 1   | 5          | 8          | sleep      | 24.19    | 0.00     | 100.00   | 0.00     | 0.00         | 330.38       | 4.49     |\n",
      "| 1   | 6          | 8          | sleep      | 24.19    | 0.00     | 100.00   | 0.00     | 0.00         | 396.46       | 2.78     |\n",
      "| 1   | 7          | 0          | action     | 24.19    | 0.00     | 100.00   | 0.00     | 350.00       | 396.46       | 11.38    |\n",
      "| 1   | 8          | 0          | action     | 24.19    | 0.00     | 100.00   | 0.00     | 700.00       | 396.46       | 9.98     |\n",
      "| 1   | 9          | 6          | action     | 24.19    | 0.00     | 100.00   | 2.00     | 700.00       | 484.56       | 10.37    |\n",
      "| 1   | 10         | 6          | action     | 24.19    | 0.00     | 100.00   | 4.00     | 700.00       | 572.66       | 10.77    |\n",
      "| 1   | 11         | 8          | work       | 24.19    | 5.00     | 95.00    | 9.00     | 700.00       | 719.50       | 10.43    |\n",
      "| 1   | 12         | 8          | work       | 24.19    | 10.00    | 90.00    | 14.00    | 700.00       | 866.34       | 10.09    |\n",
      "| 1   | 13         | 6          | action     | 24.19    | 0.00     | 100.00   | 16.00    | 700.00       | 954.44       | 12.49    |\n",
      "| 1   | 14         | 8          | work       | 24.19    | 5.00     | 95.00    | 21.00    | 700.00       | 1101.27      | 10.15    |\n",
      "| 1   | 15         | 8          | work       | 24.19    | 10.00    | 90.00    | 26.00    | 700.00       | 1248.11      | 7.81     |\n",
      "| 1   | 16         | 8          | work       | 24.19    | 15.00    | 85.00    | 31.00    | 700.00       | 1394.95      | 5.47     |\n",
      "| 1   | 17         | 8          | work       | 24.19    | 20.00    | 80.00    | 36.00    | 700.00       | 1541.78      | 3.02     |\n",
      "| 1   | 18         | 8          | work       | 24.19    | 25.00    | 75.00    | 41.00    | 700.00       | 1688.62      | 0.42     |\n",
      "| 1   | 19         | 0          | action     | 24.19    | 25.00    | 95.00    | 21.00    | 1050.00      | 1688.62      | 9.39     |\n",
      "| 1   | 20         | 0          | action     | 24.19    | 25.00    | 100.00   | 1.00     | 1400.00      | 1688.62      | 7.99     |\n",
      "| 1   | 21         | 6          | action     | 24.19    | 15.00    | 100.00   | 3.00     | 1400.00      | 1776.72      | 10.38    |\n",
      "| 1   | 22         | 6          | action     | 24.19    | 5.00     | 100.00   | 5.00     | 1400.00      | 1864.82      | 12.78    |\n",
      "| 1   | 23         | 8          | sleep      | 24.19    | 1.00     | 100.00   | 3.00     | 1400.00      | 1930.90      | 13.88    |\n",
      "| 2   | 0          | 8          | sleep      | 24.17    | 0.00     | 100.00   | 1.00     | 0.00         | 0.00         | 24.15    |\n",
      "| 2   | 1          | 8          | sleep      | 24.17    | 0.00     | 100.00   | 0.00     | 0.00         | 66.00        | 11.30    |\n",
      "| 2   | 2          | 8          | sleep      | 24.17    | 0.00     | 100.00   | 0.00     | 0.00         | 132.01       | 9.59     |\n",
      "| 2   | 3          | 8          | sleep      | 24.17    | 0.00     | 100.00   | 0.00     | 0.00         | 198.01       | 7.89     |\n",
      "| 2   | 4          | 8          | sleep      | 24.17    | 0.00     | 100.00   | 0.00     | 0.00         | 264.01       | 6.19     |\n",
      "| 2   | 5          | 8          | sleep      | 24.17    | 0.00     | 100.00   | 0.00     | 0.00         | 330.02       | 4.49     |\n",
      "| 2   | 6          | 8          | sleep      | 24.17    | 0.00     | 100.00   | 0.00     | 0.00         | 396.02       | 2.78     |\n",
      "| 2   | 7          | 0          | action     | 24.17    | 0.00     | 100.00   | 0.00     | 350.00       | 396.02       | 11.38    |\n",
      "| 2   | 8          | 0          | action     | 24.17    | 0.00     | 100.00   | 0.00     | 700.00       | 396.02       | 9.98     |\n",
      "| 2   | 9          | 6          | action     | 24.17    | 0.00     | 100.00   | 2.00     | 700.00       | 484.02       | 10.37    |\n",
      "| 2   | 10         | 6          | action     | 24.17    | 0.00     | 100.00   | 4.00     | 700.00       | 572.03       | 10.77    |\n",
      "| 2   | 11         | 8          | work       | 24.17    | 5.00     | 95.00    | 9.00     | 700.00       | 718.70       | 10.43    |\n",
      "| 2   | 12         | 8          | work       | 24.17    | 10.00    | 90.00    | 14.00    | 700.00       | 865.38       | 10.09    |\n",
      "| 2   | 13         | 6          | action     | 24.17    | 0.00     | 100.00   | 16.00    | 700.00       | 953.38       | 12.48    |\n",
      "| 2   | 14         | 8          | work       | 24.17    | 5.00     | 95.00    | 21.00    | 700.00       | 1100.05      | 10.14    |\n",
      "| 2   | 15         | 8          | work       | 24.17    | 10.00    | 90.00    | 26.00    | 700.00       | 1246.73      | 7.80     |\n",
      "| 2   | 16         | 8          | work       | 24.17    | 15.00    | 85.00    | 31.00    | 700.00       | 1393.40      | 5.46     |\n",
      "| 2   | 17         | 8          | work       | 24.17    | 20.00    | 80.00    | 36.00    | 700.00       | 1540.07      | 3.01     |\n",
      "| 2   | 18         | 8          | work       | 24.17    | 25.00    | 75.00    | 41.00    | 700.00       | 1686.75      | 0.41     |\n",
      "| 2   | 19         | 0          | action     | 24.17    | 25.00    | 95.00    | 21.00    | 1050.00      | 1686.75      | 9.38     |\n",
      "| 2   | 20         | 0          | action     | 24.17    | 25.00    | 100.00   | 1.00     | 1400.00      | 1686.75      | 7.98     |\n",
      "| 2   | 21         | 6          | action     | 24.17    | 15.00    | 100.00   | 3.00     | 1400.00      | 1774.75      | 10.37    |\n",
      "| 2   | 22         | 6          | action     | 24.17    | 5.00     | 100.00   | 5.00     | 1400.00      | 1862.76      | 12.77    |\n",
      "| 2   | 23         | 8          | sleep      | 24.17    | 1.00     | 100.00   | 3.00     | 1400.00      | 1928.76      | 13.87    |\n",
      "| 3   | 0          | 8          | sleep      | 24.14    | 0.00     | 100.00   | 1.00     | 0.00         | 0.00         | 24.14    |\n",
      "| 3   | 1          | 8          | sleep      | 24.14    | 0.00     | 100.00   | 0.00     | 0.00         | 65.93        | 11.30    |\n",
      "| 3   | 2          | 8          | sleep      | 24.14    | 0.00     | 100.00   | 0.00     | 0.00         | 131.86       | 9.59     |\n",
      "| 3   | 3          | 8          | sleep      | 24.14    | 0.00     | 100.00   | 0.00     | 0.00         | 197.79       | 7.89     |\n",
      "| 3   | 4          | 8          | sleep      | 24.14    | 0.00     | 100.00   | 0.00     | 0.00         | 263.72       | 6.19     |\n",
      "| 3   | 5          | 8          | sleep      | 24.14    | 0.00     | 100.00   | 0.00     | 0.00         | 329.65       | 4.48     |\n",
      "| 3   | 6          | 8          | sleep      | 24.14    | 0.00     | 100.00   | 0.00     | 0.00         | 395.58       | 2.78     |\n",
      "| 3   | 7          | 0          | action     | 24.14    | 0.00     | 100.00   | 0.00     | 350.00       | 395.58       | 11.38    |\n",
      "| 3   | 8          | 0          | action     | 24.14    | 0.00     | 100.00   | 0.00     | 700.00       | 395.58       | 9.97     |\n",
      "| 3   | 9          | 6          | action     | 24.14    | 0.00     | 100.00   | 2.00     | 700.00       | 483.49       | 10.37    |\n",
      "| 3   | 10         | 6          | action     | 24.14    | 0.00     | 100.00   | 4.00     | 700.00       | 571.40       | 10.77    |\n",
      "| 3   | 11         | 8          | work       | 24.14    | 5.00     | 95.00    | 9.00     | 700.00       | 717.91       | 10.42    |\n",
      "| 3   | 12         | 8          | work       | 24.14    | 10.00    | 90.00    | 14.00    | 700.00       | 864.42       | 10.08    |\n",
      "| 3   | 13         | 6          | action     | 24.14    | 0.00     | 100.00   | 16.00    | 700.00       | 952.33       | 12.48    |\n",
      "| 3   | 14         | 8          | work       | 24.14    | 5.00     | 95.00    | 21.00    | 700.00       | 1098.84      | 10.14    |\n",
      "| 3   | 15         | 8          | work       | 24.14    | 10.00    | 90.00    | 26.00    | 700.00       | 1245.35      | 7.80     |\n",
      "| 3   | 16         | 8          | work       | 24.14    | 15.00    | 85.00    | 31.00    | 700.00       | 1391.86      | 5.45     |\n",
      "| 3   | 17         | 8          | work       | 24.14    | 20.00    | 80.00    | 36.00    | 700.00       | 1538.37      | 3.01     |\n",
      "| 3   | 18         | 8          | work       | 24.14    | 25.00    | 75.00    | 41.00    | 700.00       | 1684.88      | 0.41     |\n",
      "| 3   | 19         | 0          | action     | 24.14    | 25.00    | 95.00    | 21.00    | 1050.00      | 1684.88      | 9.37     |\n",
      "| 3   | 20         | 0          | action     | 24.14    | 25.00    | 100.00   | 1.00     | 1400.00      | 1684.88      | 7.97     |\n",
      "| 3   | 21         | 6          | action     | 24.14    | 15.00    | 100.00   | 3.00     | 1400.00      | 1772.79      | 10.37    |\n",
      "| 3   | 22         | 6          | action     | 24.14    | 5.00     | 100.00   | 5.00     | 1400.00      | 1860.70      | 12.76    |\n",
      "| 3   | 23         | 8          | sleep      | 24.14    | 1.00     | 100.00   | 3.00     | 1400.00      | 1926.63      | 13.86    |\n",
      "| 4   | 0          | 8          | sleep      | 24.11    | 0.00     | 100.00   | 1.00     | 0.00         | 0.00         | 24.14    |\n",
      "| 4   | 1          | 8          | sleep      | 24.11    | 0.00     | 100.00   | 0.00     | 0.00         | 65.86        | 11.30    |\n",
      "| 4   | 2          | 8          | sleep      | 24.11    | 0.00     | 100.00   | 0.00     | 0.00         | 131.71       | 9.59     |\n",
      "| 4   | 3          | 8          | sleep      | 24.11    | 0.00     | 100.00   | 0.00     | 0.00         | 197.57       | 7.89     |\n",
      "| 4   | 4          | 8          | sleep      | 24.11    | 0.00     | 100.00   | 0.00     | 0.00         | 263.43       | 6.19     |\n",
      "| 4   | 5          | 8          | sleep      | 24.11    | 0.00     | 100.00   | 0.00     | 0.00         | 329.29       | 4.48     |\n",
      "| 4   | 6          | 8          | sleep      | 24.11    | 0.00     | 100.00   | 0.00     | 0.00         | 395.14       | 2.78     |\n",
      "| 4   | 7          | 0          | action     | 24.11    | 0.00     | 100.00   | 0.00     | 350.00       | 395.14       | 11.38    |\n",
      "| 4   | 8          | 0          | action     | 24.11    | 0.00     | 100.00   | 0.00     | 700.00       | 395.14       | 9.97     |\n",
      "| 4   | 9          | 6          | action     | 24.11    | 0.00     | 100.00   | 2.00     | 700.00       | 482.95       | 10.37    |\n",
      "| 4   | 10         | 6          | action     | 24.11    | 0.00     | 100.00   | 4.00     | 700.00       | 570.76       | 10.76    |\n",
      "| 4   | 11         | 8          | work       | 24.11    | 5.00     | 95.00    | 9.00     | 700.00       | 717.11       | 10.42    |\n",
      "| 4   | 12         | 8          | work       | 24.11    | 10.00    | 90.00    | 14.00    | 700.00       | 863.46       | 10.08    |\n",
      "| 4   | 13         | 6          | action     | 24.11    | 0.00     | 100.00   | 16.00    | 700.00       | 951.27       | 12.48    |\n",
      "| 4   | 14         | 8          | work       | 24.11    | 5.00     | 95.00    | 21.00    | 700.00       | 1097.62      | 10.13    |\n",
      "| 4   | 15         | 8          | work       | 24.11    | 10.00    | 90.00    | 26.00    | 700.00       | 1243.97      | 7.79     |\n",
      "| 4   | 16         | 8          | work       | 24.11    | 15.00    | 85.00    | 31.00    | 700.00       | 1390.32      | 5.45     |\n",
      "| 4   | 17         | 8          | work       | 24.11    | 20.00    | 80.00    | 36.00    | 700.00       | 1536.67      | 3.00     |\n",
      "| 4   | 18         | 8          | work       | 24.11    | 25.00    | 75.00    | 41.00    | 700.00       | 1683.02      | 0.40     |\n",
      "| 4   | 19         | 0          | action     | 24.11    | 25.00    | 95.00    | 21.00    | 1050.00      | 1683.02      | 9.37     |\n",
      "| 4   | 20         | 0          | action     | 24.11    | 25.00    | 100.00   | 1.00     | 1400.00      | 1683.02      | 7.96     |\n",
      "| 4   | 21         | 6          | action     | 24.11    | 15.00    | 100.00   | 3.00     | 1400.00      | 1770.83      | 10.36    |\n",
      "| 4   | 22         | 6          | action     | 24.11    | 5.00     | 100.00   | 5.00     | 1400.00      | 1858.64      | 12.75    |\n",
      "| 4   | 23         | 8          | sleep      | 24.11    | 1.00     | 100.00   | 3.00     | 1400.00      | 1924.50      | 13.85    |\n",
      "| 5   | 0          | 8          | sleep      | 24.09    | 0.00     | 100.00   | 1.00     | 0.00         | 0.00         | 24.13    |\n",
      "| 5   | 1          | 8          | sleep      | 24.09    | 0.00     | 100.00   | 0.00     | 0.00         | 65.79        | 11.30    |\n",
      "| 5   | 2          | 8          | sleep      | 24.09    | 0.00     | 100.00   | 0.00     | 0.00         | 131.57       | 9.59     |\n",
      "| 5   | 3          | 8          | sleep      | 24.09    | 0.00     | 100.00   | 0.00     | 0.00         | 197.36       | 7.89     |\n",
      "| 5   | 4          | 8          | sleep      | 24.09    | 0.00     | 100.00   | 0.00     | 0.00         | 263.14       | 6.18     |\n",
      "| 5   | 5          | 8          | sleep      | 24.09    | 0.00     | 100.00   | 0.00     | 0.00         | 328.93       | 4.48     |\n",
      "| 5   | 6          | 8          | sleep      | 24.09    | 0.00     | 100.00   | 0.00     | 0.00         | 394.71       | 2.78     |\n",
      "| 5   | 7          | 0          | action     | 24.09    | 0.00     | 100.00   | 0.00     | 350.00       | 394.71       | 11.37    |\n",
      "| 5   | 8          | 0          | action     | 24.09    | 0.00     | 100.00   | 0.00     | 700.00       | 394.71       | 9.97     |\n",
      "| 5   | 9          | 6          | action     | 24.09    | 0.00     | 100.00   | 2.00     | 700.00       | 482.42       | 10.37    |\n",
      "| 5   | 10         | 6          | action     | 24.09    | 0.00     | 100.00   | 4.00     | 700.00       | 570.14       | 10.76    |\n",
      "| 5   | 11         | 8          | work       | 24.09    | 5.00     | 95.00    | 9.00     | 700.00       | 716.33       | 10.42    |\n",
      "| 5   | 12         | 8          | work       | 24.09    | 10.00    | 90.00    | 14.00    | 700.00       | 862.51       | 10.08    |\n",
      "| 5   | 13         | 6          | action     | 24.09    | 0.00     | 100.00   | 16.00    | 700.00       | 950.23       | 12.47    |\n",
      "| 5   | 14         | 8          | work       | 24.09    | 5.00     | 95.00    | 21.00    | 700.00       | 1096.42      | 10.13    |\n",
      "| 5   | 15         | 8          | work       | 24.09    | 10.00    | 90.00    | 26.00    | 700.00       | 1242.61      | 7.79     |\n",
      "| 5   | 16         | 8          | work       | 24.09    | 15.00    | 85.00    | 31.00    | 700.00       | 1388.80      | 5.44     |\n",
      "| 5   | 17         | 8          | work       | 24.09    | 20.00    | 80.00    | 36.00    | 700.00       | 1534.98      | 2.99     |\n",
      "| 5   | 18         | 8          | work       | 24.09    | 25.00    | 75.00    | 41.00    | 700.00       | 1681.17      | 0.39     |\n",
      "| 5   | 19         | 0          | action     | 24.09    | 25.00    | 95.00    | 21.00    | 1050.00      | 1681.17      | 9.36     |\n",
      "| 5   | 20         | 0          | action     | 24.09    | 25.00    | 100.00   | 1.00     | 1400.00      | 1681.17      | 7.96     |\n",
      "| 5   | 21         | 6          | action     | 24.09    | 15.00    | 100.00   | 3.00     | 1400.00      | 1768.89      | 10.35    |\n",
      "| 5   | 22         | 6          | action     | 24.09    | 5.00     | 100.00   | 5.00     | 1400.00      | 1856.60      | 12.74    |\n",
      "| 5   | 23         | 8          | sleep      | 24.09    | 1.00     | 100.00   | 3.00     | 1400.00      | 1922.38      | 13.84    |\n",
      "| 6   | 0          | 8          | sleep      | 24.06    | 0.00     | 100.00   | 1.00     | 0.00         | 0.00         | 24.12    |\n",
      "| 6   | 1          | 8          | sleep      | 24.06    | 0.00     | 100.00   | 0.00     | 0.00         | 65.71        | 11.30    |\n",
      "| 6   | 2          | 8          | sleep      | 24.06    | 0.00     | 100.00   | 0.00     | 0.00         | 131.43       | 9.59     |\n",
      "| 6   | 3          | 8          | sleep      | 24.06    | 0.00     | 100.00   | 0.00     | 0.00         | 197.14       | 7.89     |\n",
      "| 6   | 4          | 8          | sleep      | 24.06    | 0.00     | 100.00   | 0.00     | 0.00         | 262.85       | 6.18     |\n",
      "| 6   | 5          | 8          | sleep      | 24.06    | 0.00     | 100.00   | 0.00     | 0.00         | 328.56       | 4.48     |\n",
      "| 6   | 6          | 8          | sleep      | 24.06    | 0.00     | 100.00   | 0.00     | 0.00         | 394.28       | 2.77     |\n",
      "| 6   | 7          | 0          | action     | 24.06    | 0.00     | 100.00   | 0.00     | 350.00       | 394.28       | 11.37    |\n",
      "| 6   | 8          | 0          | action     | 24.06    | 0.00     | 100.00   | 0.00     | 700.00       | 394.28       | 9.97     |\n",
      "| 6   | 9          | 6          | action     | 24.06    | 0.00     | 100.00   | 2.00     | 700.00       | 481.89       | 10.36    |\n",
      "| 6   | 10         | 6          | action     | 24.06    | 0.00     | 100.00   | 4.00     | 700.00       | 569.51       | 10.76    |\n",
      "| 6   | 11         | 8          | work       | 24.06    | 5.00     | 95.00    | 9.00     | 700.00       | 715.54       | 10.42    |\n",
      "| 6   | 12         | 8          | work       | 24.06    | 10.00    | 90.00    | 14.00    | 700.00       | 861.57       | 10.07    |\n",
      "| 6   | 13         | 6          | action     | 24.06    | 0.00     | 100.00   | 16.00    | 700.00       | 949.19       | 12.47    |\n",
      "| 6   | 14         | 8          | work       | 24.06    | 5.00     | 95.00    | 21.00    | 700.00       | 1095.21      | 10.12    |\n",
      "| 6   | 15         | 8          | work       | 24.06    | 10.00    | 90.00    | 26.00    | 700.00       | 1241.24      | 7.78     |\n",
      "| 6   | 16         | 8          | work       | 24.06    | 15.00    | 85.00    | 31.00    | 700.00       | 1387.27      | 5.43     |\n",
      "| 6   | 17         | 8          | work       | 24.06    | 20.00    | 80.00    | 36.00    | 700.00       | 1533.30      | 2.98     |\n",
      "| 6   | 18         | 8          | work       | 24.06    | 25.00    | 75.00    | 41.00    | 700.00       | 1679.33      | 0.38     |\n",
      "| 6   | 19         | 0          | action     | 24.06    | 25.00    | 95.00    | 21.00    | 1050.00      | 1679.33      | 9.35     |\n",
      "| 6   | 20         | 0          | action     | 24.06    | 25.00    | 100.00   | 1.00     | 1400.00      | 1679.33      | 7.95     |\n",
      "| 6   | 21         | 6          | action     | 24.06    | 15.00    | 100.00   | 3.00     | 1400.00      | 1766.95      | 10.34    |\n",
      "| 6   | 22         | 6          | action     | 24.06    | 5.00     | 100.00   | 5.00     | 1400.00      | 1854.56      | 12.74    |\n",
      "| 6   | 23         | 8          | sleep      | 24.06    | 1.00     | 100.00   | 3.00     | 1400.00      | 1920.28      | 13.83    |\n",
      "| 7   | 0          | 8          | sleep      | 24.04    | 0.00     | 100.00   | 1.00     | 0.00         | 0.00         | 24.12    |\n",
      "| 7   | 1          | 8          | sleep      | 24.04    | 0.00     | 100.00   | 0.00     | 0.00         | 65.64        | 11.30    |\n",
      "| 7   | 2          | 8          | sleep      | 24.04    | 0.00     | 100.00   | 0.00     | 0.00         | 131.28       | 9.59     |\n",
      "| 7   | 3          | 8          | sleep      | 24.04    | 0.00     | 100.00   | 0.00     | 0.00         | 196.92       | 7.89     |\n",
      "| 7   | 4          | 8          | sleep      | 24.04    | 0.00     | 100.00   | 0.00     | 0.00         | 262.56       | 6.18     |\n",
      "| 7   | 5          | 8          | sleep      | 24.04    | 0.00     | 100.00   | 0.00     | 0.00         | 328.20       | 4.48     |\n",
      "| 7   | 6          | 8          | sleep      | 24.04    | 0.00     | 100.00   | 0.00     | 0.00         | 393.85       | 2.77     |\n",
      "| 7   | 7          | 0          | action     | 24.04    | 0.00     | 100.00   | 0.00     | 350.00       | 393.85       | 11.37    |\n",
      "| 7   | 8          | 0          | action     | 24.04    | 0.00     | 100.00   | 0.00     | 700.00       | 393.85       | 9.97     |\n",
      "| 7   | 9          | 6          | action     | 24.04    | 0.00     | 100.00   | 2.00     | 700.00       | 481.37       | 10.36    |\n",
      "| 7   | 10         | 6          | action     | 24.04    | 0.00     | 100.00   | 4.00     | 700.00       | 568.89       | 10.76    |\n",
      "| 7   | 11         | 8          | work       | 24.04    | 5.00     | 95.00    | 9.00     | 700.00       | 714.76       | 10.41    |\n",
      "| 7   | 12         | 8          | work       | 24.04    | 10.00    | 90.00    | 14.00    | 700.00       | 860.63       | 10.07    |\n",
      "| 7   | 13         | 6          | action     | 24.04    | 0.00     | 100.00   | 16.00    | 700.00       | 948.15       | 12.46    |\n",
      "| 7   | 14         | 8          | work       | 24.04    | 5.00     | 95.00    | 21.00    | 700.00       | 1094.02      | 10.12    |\n",
      "| 7   | 15         | 8          | work       | 24.04    | 10.00    | 90.00    | 26.00    | 700.00       | 1239.88      | 7.78     |\n",
      "| 7   | 16         | 8          | work       | 24.04    | 15.00    | 85.00    | 31.00    | 700.00       | 1385.75      | 5.43     |\n",
      "| 7   | 17         | 8          | work       | 24.04    | 20.00    | 80.00    | 36.00    | 700.00       | 1531.62      | 2.98     |\n",
      "| 7   | 18         | 8          | work       | 24.04    | 25.00    | 75.00    | 41.00    | 700.00       | 1677.49      | 0.37     |\n",
      "| 7   | 19         | 0          | action     | 24.04    | 25.00    | 95.00    | 21.00    | 1050.00      | 1677.49      | 9.34     |\n",
      "| 7   | 20         | 0          | action     | 24.04    | 25.00    | 100.00   | 1.00     | 1400.00      | 1677.49      | 7.94     |\n",
      "| 7   | 21         | 6          | action     | 24.04    | 15.00    | 100.00   | 3.00     | 1400.00      | 1765.01      | 10.33    |\n",
      "| 7   | 22         | 6          | action     | 24.04    | 5.00     | 100.00   | 5.00     | 1400.00      | 1852.53      | 12.73    |\n",
      "| 7   | 23         | 8          | sleep      | 24.04    | 1.00     | 100.00   | 3.00     | 1400.00      | 1918.17      | 13.82    |\n",
      "| 8   | 0          | 8          | sleep      | 24.01    | 0.00     | 100.00   | 1.00     | 0.00         | 0.00         | 24.11    |\n",
      "| 8   | 1          | 8          | sleep      | 24.01    | 0.00     | 100.00   | 0.00     | 0.00         | 65.57        | 11.30    |\n",
      "| 8   | 2          | 8          | sleep      | 24.01    | 0.00     | 100.00   | 0.00     | 0.00         | 131.14       | 9.59     |\n",
      "| 8   | 3          | 8          | sleep      | 24.01    | 0.00     | 100.00   | 0.00     | 0.00         | 196.71       | 7.89     |\n",
      "| 8   | 4          | 8          | sleep      | 24.01    | 0.00     | 100.00   | 0.00     | 0.00         | 262.28       | 6.18     |\n",
      "| 8   | 5          | 8          | sleep      | 24.01    | 0.00     | 100.00   | 0.00     | 0.00         | 327.85       | 4.48     |\n",
      "| 8   | 6          | 8          | sleep      | 24.01    | 0.00     | 100.00   | 0.00     | 0.00         | 393.42       | 2.77     |\n",
      "| 8   | 7          | 0          | action     | 24.01    | 0.00     | 100.00   | 0.00     | 350.00       | 393.42       | 11.37    |\n",
      "| 8   | 8          | 6          | action     | 24.01    | 0.00     | 100.00   | 2.00     | 350.00       | 480.84       | 11.76    |\n",
      "| 8   | 9          | 6          | action     | 24.01    | 0.00     | 100.00   | 4.00     | 350.00       | 568.27       | 12.16    |\n",
      "| 8   | 10         | 0          | action     | 24.01    | 0.00     | 100.00   | 0.00     | 700.00       | 568.27       | 10.75    |\n",
      "| 8   | 11         | 8          | work       | 24.01    | 5.00     | 95.00    | 5.00     | 700.00       | 713.98       | 10.41    |\n",
      "| 8   | 12         | 8          | work       | 24.01    | 10.00    | 90.00    | 10.00    | 700.00       | 859.69       | 10.06    |\n",
      "| 8   | 13         | 6          | action     | 24.01    | 0.00     | 100.00   | 12.00    | 700.00       | 947.11       | 12.46    |\n",
      "| 8   | 14         | 8          | work       | 24.01    | 5.00     | 95.00    | 17.00    | 700.00       | 1092.82      | 12.11    |\n",
      "| 8   | 15         | 8          | work       | 24.01    | 10.00    | 90.00    | 22.00    | 700.00       | 1238.53      | 11.77    |\n",
      "| 8   | 16         | 8          | work       | 24.01    | 15.00    | 85.00    | 27.00    | 700.00       | 1384.24      | 9.42     |\n",
      "| 8   | 17         | 8          | work       | 24.01    | 20.00    | 80.00    | 32.00    | 700.00       | 1529.95      | 7.07     |\n",
      "| 8   | 18         | 8          | work       | 24.01    | 25.00    | 75.00    | 37.00    | 700.00       | 1675.66      | 4.59     |\n",
      "| 8   | 19         | 0          | action     | 24.01    | 25.00    | 95.00    | 17.00    | 1050.00      | 1675.66      | 9.33     |\n",
      "| 8   | 20         | 0          | action     | 24.01    | 25.00    | 100.00   | 0.00     | 1400.00      | 1675.66      | 7.93     |\n",
      "| 8   | 21         | 6          | action     | 24.01    | 15.00    | 100.00   | 2.00     | 1400.00      | 1763.08      | 10.33    |\n",
      "| 8   | 22         | 6          | action     | 24.01    | 5.00     | 100.00   | 4.00     | 1400.00      | 1850.51      | 12.72    |\n",
      "| 8   | 23         | 8          | sleep      | 24.01    | 1.00     | 100.00   | 2.00     | 1400.00      | 1916.08      | 13.81    |\n",
      "| 9   | 0          | 8          | sleep      | 23.98    | 0.00     | 100.00   | 0.00     | 0.00         | 0.00         | 24.10    |\n",
      "| 9   | 1          | 8          | sleep      | 23.98    | 0.00     | 100.00   | 0.00     | 0.00         | 65.50        | 11.29    |\n",
      "| 9   | 2          | 8          | sleep      | 23.98    | 0.00     | 100.00   | 0.00     | 0.00         | 131.00       | 9.59     |\n",
      "| 9   | 3          | 8          | sleep      | 23.98    | 0.00     | 100.00   | 0.00     | 0.00         | 196.49       | 7.88     |\n",
      "| 9   | 4          | 8          | sleep      | 23.98    | 0.00     | 100.00   | 0.00     | 0.00         | 261.99       | 6.18     |\n",
      "| 9   | 5          | 8          | sleep      | 23.98    | 0.00     | 100.00   | 0.00     | 0.00         | 327.49       | 4.47     |\n",
      "| 9   | 6          | 8          | sleep      | 23.98    | 0.00     | 100.00   | 0.00     | 0.00         | 392.99       | 2.77     |\n",
      "| 9   | 7          | 0          | action     | 23.98    | 0.00     | 100.00   | 0.00     | 350.00       | 392.99       | 11.37    |\n",
      "| 9   | 8          | 6          | action     | 23.98    | 0.00     | 100.00   | 2.00     | 350.00       | 480.32       | 11.76    |\n",
      "| 9   | 9          | 6          | action     | 23.98    | 0.00     | 100.00   | 4.00     | 350.00       | 567.65       | 12.15    |\n",
      "| 9   | 10         | 0          | action     | 23.98    | 0.00     | 100.00   | 0.00     | 700.00       | 567.65       | 10.75    |\n",
      "| 9   | 11         | 8          | work       | 23.98    | 5.00     | 95.00    | 5.00     | 700.00       | 713.20       | 10.41    |\n",
      "| 9   | 12         | 8          | work       | 23.98    | 10.00    | 90.00    | 10.00    | 700.00       | 858.75       | 10.06    |\n",
      "| 9   | 13         | 6          | action     | 23.98    | 0.00     | 100.00   | 12.00    | 700.00       | 946.08       | 12.45    |\n",
      "| 9   | 14         | 8          | work       | 23.98    | 5.00     | 95.00    | 17.00    | 700.00       | 1091.63      | 12.11    |\n",
      "| 9   | 15         | 8          | work       | 23.98    | 10.00    | 90.00    | 22.00    | 700.00       | 1237.18      | 11.76    |\n",
      "| 9   | 16         | 8          | work       | 23.98    | 15.00    | 85.00    | 27.00    | 700.00       | 1382.73      | 9.42     |\n",
      "| 9   | 17         | 8          | work       | 23.98    | 20.00    | 80.00    | 32.00    | 700.00       | 1528.28      | 7.06     |\n",
      "| 9   | 18         | 8          | work       | 23.98    | 25.00    | 75.00    | 37.00    | 700.00       | 1673.83      | 4.58     |\n",
      "| 9   | 19         | 0          | action     | 23.98    | 25.00    | 95.00    | 17.00    | 1050.00      | 1673.83      | 9.33     |\n",
      "| 9   | 20         | 0          | action     | 23.98    | 25.00    | 100.00   | 0.00     | 1400.00      | 1673.83      | 7.92     |\n",
      "| 9   | 21         | 6          | action     | 23.98    | 15.00    | 100.00   | 2.00     | 1400.00      | 1761.17      | 10.32    |\n",
      "| 9   | 22         | 6          | action     | 23.98    | 5.00     | 100.00   | 4.00     | 1400.00      | 1848.50      | 12.71    |\n",
      "| 9   | 23         | 8          | sleep      | 23.98    | 1.00     | 100.00   | 2.00     | 1400.00      | 1913.99      | 13.81    |\n",
      "| 10  | 0          | 8          | sleep      | 23.96    | 0.00     | 100.00   | 0.00     | 0.00         | 0.00         | 24.10    |\n",
      "| 10  | 1          | 8          | sleep      | 23.96    | 0.00     | 100.00   | 0.00     | 0.00         | 65.43        | 11.29    |\n",
      "| 10  | 2          | 8          | sleep      | 23.96    | 0.00     | 100.00   | 0.00     | 0.00         | 130.85       | 9.59     |\n",
      "| 10  | 3          | 8          | sleep      | 23.96    | 0.00     | 100.00   | 0.00     | 0.00         | 196.28       | 7.88     |\n",
      "| 10  | 4          | 8          | sleep      | 23.96    | 0.00     | 100.00   | 0.00     | 0.00         | 261.71       | 6.18     |\n",
      "| 10  | 5          | 8          | sleep      | 23.96    | 0.00     | 100.00   | 0.00     | 0.00         | 327.13       | 4.47     |\n",
      "| 10  | 6          | 8          | sleep      | 23.96    | 0.00     | 100.00   | 0.00     | 0.00         | 392.56       | 2.77     |\n",
      "| 10  | 7          | 0          | action     | 23.96    | 0.00     | 100.00   | 0.00     | 350.00       | 392.56       | 11.36    |\n",
      "| 10  | 8          | 6          | action     | 23.96    | 0.00     | 100.00   | 2.00     | 350.00       | 479.80       | 11.76    |\n",
      "| 10  | 9          | 6          | action     | 23.96    | 0.00     | 100.00   | 4.00     | 350.00       | 567.03       | 12.15    |\n",
      "| 10  | 10         | 0          | action     | 23.96    | 0.00     | 100.00   | 0.00     | 700.00       | 567.03       | 10.75    |\n",
      "| 10  | 11         | 8          | work       | 23.96    | 5.00     | 95.00    | 5.00     | 700.00       | 712.42       | 10.40    |\n",
      "| 10  | 12         | 8          | work       | 23.96    | 10.00    | 90.00    | 10.00    | 700.00       | 857.82       | 10.06    |\n",
      "| 10  | 13         | 6          | action     | 23.96    | 0.00     | 100.00   | 12.00    | 700.00       | 945.05       | 12.45    |\n",
      "| 10  | 14         | 8          | work       | 23.96    | 5.00     | 95.00    | 17.00    | 700.00       | 1090.45      | 12.10    |\n",
      "| 10  | 15         | 8          | work       | 23.96    | 10.00    | 90.00    | 22.00    | 700.00       | 1235.84      | 11.76    |\n",
      "| 10  | 16         | 8          | work       | 23.96    | 15.00    | 85.00    | 27.00    | 700.00       | 1381.23      | 9.41     |\n",
      "| 10  | 17         | 8          | work       | 23.96    | 20.00    | 80.00    | 32.00    | 700.00       | 1526.62      | 7.05     |\n",
      "| 10  | 18         | 8          | work       | 23.96    | 25.00    | 75.00    | 37.00    | 700.00       | 1672.02      | 4.57     |\n",
      "| 10  | 19         | 0          | action     | 23.96    | 25.00    | 95.00    | 17.00    | 1050.00      | 1672.02      | 9.32     |\n",
      "| 10  | 20         | 0          | action     | 23.96    | 25.00    | 100.00   | 0.00     | 1400.00      | 1672.02      | 7.92     |\n",
      "| 10  | 21         | 6          | action     | 23.96    | 15.00    | 100.00   | 2.00     | 1400.00      | 1759.25      | 10.31    |\n",
      "| 10  | 22         | 6          | action     | 23.96    | 5.00     | 100.00   | 4.00     | 1400.00      | 1846.49      | 12.70    |\n",
      "| 10  | 23         | 8          | sleep      | 23.96    | 1.00     | 100.00   | 2.00     | 1400.00      | 1911.92      | 13.80    |\n",
      "| 11  | 0          | 8          | sleep      | 23.93    | 0.00     | 100.00   | 0.00     | 0.00         | 0.00         | 24.09    |\n",
      "| 11  | 1          | 8          | sleep      | 23.93    | 0.00     | 100.00   | 0.00     | 0.00         | 65.36        | 11.29    |\n",
      "| 11  | 2          | 8          | sleep      | 23.93    | 0.00     | 100.00   | 0.00     | 0.00         | 130.71       | 9.59     |\n",
      "| 11  | 3          | 8          | sleep      | 23.93    | 0.00     | 100.00   | 0.00     | 0.00         | 196.07       | 7.88     |\n",
      "| 11  | 4          | 8          | sleep      | 23.93    | 0.00     | 100.00   | 0.00     | 0.00         | 261.42       | 6.18     |\n",
      "| 11  | 5          | 8          | sleep      | 23.93    | 0.00     | 100.00   | 0.00     | 0.00         | 326.78       | 4.47     |\n",
      "| 11  | 6          | 8          | sleep      | 23.93    | 0.00     | 100.00   | 0.00     | 0.00         | 392.14       | 2.76     |\n",
      "| 11  | 7          | 0          | action     | 23.93    | 0.00     | 100.00   | 0.00     | 350.00       | 392.14       | 11.36    |\n",
      "| 11  | 8          | 0          | action     | 23.93    | 0.00     | 100.00   | 0.00     | 700.00       | 392.14       | 9.96     |\n",
      "| 11  | 9          | 6          | action     | 23.93    | 0.00     | 100.00   | 2.00     | 700.00       | 479.28       | 10.35    |\n",
      "| 11  | 10         | 6          | action     | 23.93    | 0.00     | 100.00   | 4.00     | 700.00       | 566.42       | 10.75    |\n",
      "| 11  | 11         | 8          | work       | 23.93    | 5.00     | 95.00    | 9.00     | 700.00       | 711.65       | 10.40    |\n",
      "| 11  | 12         | 8          | work       | 23.93    | 10.00    | 90.00    | 14.00    | 700.00       | 856.89       | 10.05    |\n",
      "| 11  | 13         | 6          | action     | 23.93    | 0.00     | 100.00   | 16.00    | 700.00       | 944.03       | 12.44    |\n",
      "| 11  | 14         | 8          | work       | 23.93    | 5.00     | 95.00    | 21.00    | 700.00       | 1089.27      | 10.10    |\n",
      "| 11  | 15         | 8          | work       | 23.93    | 10.00    | 90.00    | 26.00    | 700.00       | 1234.50      | 7.75     |\n",
      "| 11  | 16         | 8          | work       | 23.93    | 15.00    | 85.00    | 31.00    | 700.00       | 1379.74      | 5.40     |\n",
      "| 11  | 17         | 8          | work       | 23.93    | 20.00    | 80.00    | 36.00    | 700.00       | 1524.97      | 2.95     |\n",
      "| 11  | 18         | 8          | work       | 23.93    | 25.00    | 75.00    | 41.00    | 700.00       | 1670.21      | 0.34     |\n",
      "| 11  | 19         | 0          | action     | 23.93    | 25.00    | 95.00    | 21.00    | 1050.00      | 1670.21      | 9.31     |\n",
      "| 11  | 20         | 0          | action     | 23.93    | 25.00    | 100.00   | 1.00     | 1400.00      | 1670.21      | 7.91     |\n",
      "| 11  | 21         | 6          | action     | 23.93    | 15.00    | 100.00   | 3.00     | 1400.00      | 1757.35      | 10.30    |\n",
      "| 11  | 22         | 6          | action     | 23.93    | 5.00     | 100.00   | 5.00     | 1400.00      | 1844.49      | 12.69    |\n",
      "| 11  | 23         | 8          | sleep      | 23.93    | 1.00     | 100.00   | 3.00     | 1400.00      | 1909.85      | 13.79    |\n",
      "| 12  | 0          | 8          | sleep      | 23.90    | 0.00     | 100.00   | 1.00     | 0.00         | 0.00         | 24.08    |\n",
      "| 12  | 1          | 8          | sleep      | 23.90    | 0.00     | 100.00   | 0.00     | 0.00         | 65.29        | 11.29    |\n",
      "| 12  | 2          | 8          | sleep      | 23.90    | 0.00     | 100.00   | 0.00     | 0.00         | 130.57       | 9.59     |\n",
      "| 12  | 3          | 8          | sleep      | 23.90    | 0.00     | 100.00   | 0.00     | 0.00         | 195.86       | 7.88     |\n",
      "| 12  | 4          | 8          | sleep      | 23.90    | 0.00     | 100.00   | 0.00     | 0.00         | 261.14       | 6.18     |\n",
      "| 12  | 5          | 8          | sleep      | 23.90    | 0.00     | 100.00   | 0.00     | 0.00         | 326.43       | 4.47     |\n",
      "| 12  | 6          | 8          | sleep      | 23.90    | 0.00     | 100.00   | 0.00     | 0.00         | 391.71       | 2.76     |\n",
      "| 12  | 7          | 0          | action     | 23.90    | 0.00     | 100.00   | 0.00     | 350.00       | 391.71       | 11.36    |\n",
      "| 12  | 8          | 6          | action     | 23.90    | 0.00     | 100.00   | 2.00     | 350.00       | 478.76       | 11.75    |\n",
      "| 12  | 9          | 0          | action     | 23.90    | 0.00     | 100.00   | 0.00     | 700.00       | 478.76       | 10.35    |\n",
      "| 12  | 10         | 6          | action     | 23.90    | 0.00     | 100.00   | 2.00     | 700.00       | 565.81       | 10.74    |\n",
      "| 12  | 11         | 8          | work       | 23.90    | 5.00     | 95.00    | 7.00     | 700.00       | 710.88       | 10.40    |\n",
      "| 12  | 12         | 8          | work       | 23.90    | 10.00    | 90.00    | 12.00    | 700.00       | 855.96       | 10.05    |\n",
      "| 12  | 13         | 6          | action     | 23.90    | 0.00     | 100.00   | 14.00    | 700.00       | 943.01       | 12.44    |\n",
      "| 12  | 14         | 8          | work       | 23.90    | 5.00     | 95.00    | 19.00    | 700.00       | 1088.09      | 12.09    |\n",
      "| 12  | 15         | 8          | work       | 23.90    | 10.00    | 90.00    | 24.00    | 700.00       | 1233.17      | 9.75     |\n",
      "| 12  | 16         | 8          | work       | 23.90    | 15.00    | 85.00    | 29.00    | 700.00       | 1378.25      | 7.40     |\n",
      "| 12  | 17         | 8          | work       | 23.90    | 20.00    | 80.00    | 34.00    | 700.00       | 1523.32      | 5.00     |\n",
      "| 12  | 18         | 8          | work       | 23.90    | 25.00    | 75.00    | 39.00    | 700.00       | 1668.40      | 2.46     |\n",
      "| 12  | 19         | 0          | action     | 23.90    | 25.00    | 95.00    | 19.00    | 1050.00      | 1668.40      | 9.30     |\n",
      "| 12  | 20         | 0          | action     | 23.90    | 25.00    | 100.00   | 0.00     | 1400.00      | 1668.40      | 7.90     |\n",
      "| 12  | 21         | 6          | action     | 23.90    | 15.00    | 100.00   | 2.00     | 1400.00      | 1755.45      | 10.29    |\n",
      "| 12  | 22         | 6          | action     | 23.90    | 5.00     | 100.00   | 4.00     | 1400.00      | 1842.50      | 12.69    |\n",
      "| 12  | 23         | 8          | sleep      | 23.90    | 1.00     | 100.00   | 2.00     | 1400.00      | 1907.78      | 13.78    |\n",
      "| 13  | 0          | 8          | sleep      | 23.88    | 0.00     | 100.00   | 0.00     | 0.00         | 0.00         | 24.08    |\n",
      "| 13  | 1          | 8          | sleep      | 23.88    | 0.00     | 100.00   | 0.00     | 0.00         | 65.21        | 11.29    |\n",
      "| 13  | 2          | 8          | sleep      | 23.88    | 0.00     | 100.00   | 0.00     | 0.00         | 130.43       | 9.59     |\n",
      "| 13  | 3          | 8          | sleep      | 23.88    | 0.00     | 100.00   | 0.00     | 0.00         | 195.64       | 7.88     |\n",
      "| 13  | 4          | 8          | sleep      | 23.88    | 0.00     | 100.00   | 0.00     | 0.00         | 260.86       | 6.17     |\n",
      "| 13  | 5          | 8          | sleep      | 23.88    | 0.00     | 100.00   | 0.00     | 0.00         | 326.07       | 4.47     |\n",
      "| 13  | 6          | 8          | sleep      | 23.88    | 0.00     | 100.00   | 0.00     | 0.00         | 391.29       | 2.76     |\n",
      "| 13  | 7          | 0          | action     | 23.88    | 0.00     | 100.00   | 0.00     | 350.00       | 391.29       | 11.36    |\n",
      "| 13  | 8          | 6          | action     | 23.88    | 0.00     | 100.00   | 2.00     | 350.00       | 478.24       | 11.75    |\n",
      "| 13  | 9          | 6          | action     | 23.88    | 0.00     | 100.00   | 4.00     | 350.00       | 565.20       | 12.14    |\n",
      "| 13  | 10         | 0          | action     | 23.88    | 0.00     | 100.00   | 0.00     | 700.00       | 565.20       | 10.74    |\n",
      "| 13  | 11         | 8          | work       | 23.88    | 5.00     | 95.00    | 5.00     | 700.00       | 710.12       | 10.39    |\n",
      "| 13  | 12         | 8          | work       | 23.88    | 10.00    | 90.00    | 10.00    | 700.00       | 855.04       | 10.05    |\n",
      "| 13  | 13         | 6          | action     | 23.88    | 0.00     | 100.00   | 12.00    | 700.00       | 941.99       | 12.44    |\n",
      "| 13  | 14         | 8          | work       | 23.88    | 5.00     | 95.00    | 17.00    | 700.00       | 1086.92      | 12.09    |\n",
      "| 13  | 15         | 8          | work       | 23.88    | 10.00    | 90.00    | 22.00    | 700.00       | 1231.84      | 11.74    |\n",
      "| 13  | 16         | 8          | work       | 23.88    | 15.00    | 85.00    | 27.00    | 700.00       | 1376.76      | 9.39     |\n",
      "| 13  | 17         | 8          | work       | 23.88    | 20.00    | 80.00    | 32.00    | 700.00       | 1521.68      | 7.03     |\n",
      "| 13  | 18         | 8          | work       | 23.88    | 25.00    | 75.00    | 37.00    | 700.00       | 1666.61      | 4.55     |\n",
      "| 13  | 19         | 0          | action     | 23.88    | 25.00    | 95.00    | 17.00    | 1050.00      | 1666.61      | 9.30     |\n",
      "| 13  | 20         | 0          | action     | 23.88    | 25.00    | 100.00   | 0.00     | 1400.00      | 1666.61      | 7.89     |\n",
      "| 13  | 21         | 6          | action     | 23.88    | 15.00    | 100.00   | 2.00     | 1400.00      | 1753.56      | 10.29    |\n",
      "| 13  | 22         | 6          | action     | 23.88    | 5.00     | 100.00   | 4.00     | 1400.00      | 1840.51      | 12.68    |\n",
      "| 13  | 23         | 8          | sleep      | 23.88    | 1.00     | 100.00   | 2.00     | 1400.00      | 1905.73      | 13.77    |\n",
      "| 14  | 0          | 8          | sleep      | 23.85    | 0.00     | 100.00   | 0.00     | 0.00         | 0.00         | 24.07    |\n",
      "| 14  | 1          | 8          | sleep      | 23.85    | 0.00     | 100.00   | 0.00     | 0.00         | 65.14        | 11.29    |\n",
      "| 14  | 2          | 8          | sleep      | 23.85    | 0.00     | 100.00   | 0.00     | 0.00         | 130.29       | 9.59     |\n",
      "| 14  | 3          | 8          | sleep      | 23.85    | 0.00     | 100.00   | 0.00     | 0.00         | 195.43       | 7.88     |\n",
      "| 14  | 4          | 8          | sleep      | 23.85    | 0.00     | 100.00   | 0.00     | 0.00         | 260.58       | 6.17     |\n",
      "| 14  | 5          | 8          | sleep      | 23.85    | 0.00     | 100.00   | 0.00     | 0.00         | 325.72       | 4.47     |\n",
      "| 14  | 6          | 8          | sleep      | 23.85    | 0.00     | 100.00   | 0.00     | 0.00         | 390.87       | 2.76     |\n",
      "| 14  | 7          | 0          | action     | 23.85    | 0.00     | 100.00   | 0.00     | 350.00       | 390.87       | 11.36    |\n",
      "| 14  | 8          | 6          | action     | 23.85    | 0.00     | 100.00   | 2.00     | 350.00       | 477.73       | 11.75    |\n",
      "| 14  | 9          | 6          | action     | 23.85    | 0.00     | 100.00   | 4.00     | 350.00       | 564.59       | 12.14    |\n",
      "| 14  | 10         | 0          | action     | 23.85    | 0.00     | 100.00   | 0.00     | 700.00       | 564.59       | 10.74    |\n",
      "| 14  | 11         | 8          | work       | 23.85    | 5.00     | 95.00    | 5.00     | 700.00       | 709.36       | 10.39    |\n",
      "| 14  | 12         | 8          | work       | 23.85    | 10.00    | 90.00    | 10.00    | 700.00       | 854.12       | 10.04    |\n",
      "| 14  | 13         | 6          | action     | 23.85    | 0.00     | 100.00   | 12.00    | 700.00       | 940.98       | 12.43    |\n",
      "| 14  | 14         | 8          | work       | 23.85    | 5.00     | 95.00    | 17.00    | 700.00       | 1085.75      | 12.08    |\n",
      "| 14  | 15         | 8          | work       | 23.85    | 10.00    | 90.00    | 22.00    | 700.00       | 1230.52      | 11.73    |\n",
      "| 14  | 16         | 8          | work       | 23.85    | 15.00    | 85.00    | 27.00    | 700.00       | 1375.28      | 9.39     |\n",
      "| 14  | 17         | 8          | work       | 23.85    | 20.00    | 80.00    | 32.00    | 700.00       | 1520.05      | 7.03     |\n",
      "| 14  | 18         | 8          | work       | 23.85    | 25.00    | 75.00    | 37.00    | 700.00       | 1664.81      | 4.54     |\n",
      "| 14  | 19         | 0          | action     | 23.85    | 25.00    | 95.00    | 17.00    | 1050.00      | 1664.81      | 9.29     |\n",
      "| 14  | 20         | 0          | action     | 23.85    | 25.00    | 100.00   | 0.00     | 1400.00      | 1664.81      | 7.89     |\n",
      "| 14  | 21         | 6          | action     | 23.85    | 15.00    | 100.00   | 2.00     | 1400.00      | 1751.67      | 10.28    |\n",
      "| 14  | 22         | 6          | action     | 23.85    | 5.00     | 100.00   | 4.00     | 1400.00      | 1838.53      | 12.67    |\n",
      "| 14  | 23         | 8          | sleep      | 23.85    | 1.00     | 100.00   | 2.00     | 1400.00      | 1903.68      | 13.76    |\n",
      "| 15  | 0          | 8          | sleep      | 23.83    | 0.00     | 100.00   | 0.00     | 0.00         | 0.00         | 24.06    |\n",
      "| 15  | 1          | 8          | sleep      | 23.83    | 0.00     | 100.00   | 0.00     | 0.00         | 65.08        | 11.29    |\n",
      "| 15  | 2          | 8          | sleep      | 23.83    | 0.00     | 100.00   | 0.00     | 0.00         | 130.15       | 9.59     |\n",
      "| 15  | 3          | 8          | sleep      | 23.83    | 0.00     | 100.00   | 0.00     | 0.00         | 195.23       | 7.88     |\n",
      "| 15  | 4          | 8          | sleep      | 23.83    | 0.00     | 100.00   | 0.00     | 0.00         | 260.30       | 6.17     |\n",
      "| 15  | 5          | 8          | sleep      | 23.83    | 0.00     | 100.00   | 0.00     | 0.00         | 325.38       | 4.46     |\n",
      "| 15  | 6          | 8          | sleep      | 23.83    | 0.00     | 100.00   | 0.00     | 0.00         | 390.45       | 2.76     |\n",
      "| 15  | 7          | 0          | action     | 23.83    | 0.00     | 100.00   | 0.00     | 350.00       | 390.45       | 11.36    |\n",
      "| 15  | 8          | 6          | action     | 23.83    | 0.00     | 100.00   | 2.00     | 350.00       | 477.22       | 11.75    |\n",
      "| 15  | 9          | 6          | action     | 23.83    | 0.00     | 100.00   | 4.00     | 350.00       | 563.98       | 12.14    |\n",
      "| 15  | 10         | 0          | action     | 23.83    | 0.00     | 100.00   | 0.00     | 700.00       | 563.98       | 10.74    |\n",
      "| 15  | 11         | 8          | work       | 23.83    | 5.00     | 95.00    | 5.00     | 700.00       | 708.60       | 10.39    |\n",
      "| 15  | 12         | 8          | work       | 23.83    | 10.00    | 90.00    | 10.00    | 700.00       | 853.21       | 10.04    |\n",
      "| 15  | 13         | 6          | action     | 23.83    | 0.00     | 100.00   | 12.00    | 700.00       | 939.97       | 12.43    |\n",
      "| 15  | 14         | 8          | work       | 23.83    | 5.00     | 95.00    | 17.00    | 700.00       | 1084.59      | 12.08    |\n",
      "| 15  | 15         | 8          | work       | 23.83    | 10.00    | 90.00    | 22.00    | 700.00       | 1229.20      | 11.73    |\n",
      "| 15  | 16         | 8          | work       | 23.83    | 15.00    | 85.00    | 27.00    | 700.00       | 1373.81      | 9.38     |\n",
      "| 15  | 17         | 8          | work       | 23.83    | 20.00    | 80.00    | 32.00    | 700.00       | 1518.42      | 7.02     |\n",
      "| 15  | 18         | 8          | work       | 23.83    | 25.00    | 75.00    | 37.00    | 700.00       | 1663.03      | 4.53     |\n",
      "| 15  | 19         | 0          | action     | 23.83    | 25.00    | 95.00    | 17.00    | 1050.00      | 1663.03      | 9.28     |\n",
      "| 15  | 20         | 0          | action     | 23.83    | 25.00    | 100.00   | 0.00     | 1400.00      | 1663.03      | 7.88     |\n",
      "| 15  | 21         | 6          | action     | 23.83    | 15.00    | 100.00   | 2.00     | 1400.00      | 1749.80      | 10.27    |\n",
      "| 15  | 22         | 6          | action     | 23.83    | 5.00     | 100.00   | 4.00     | 1400.00      | 1836.56      | 12.66    |\n",
      "| 15  | 23         | 8          | sleep      | 23.83    | 1.00     | 100.00   | 2.00     | 1400.00      | 1901.64      | 13.75    |\n",
      "| 16  | 0          | 8          | sleep      | 23.80    | 0.00     | 100.00   | 0.00     | 0.00         | 0.00         | 24.06    |\n",
      "| 16  | 1          | 8          | sleep      | 23.80    | 0.00     | 100.00   | 0.00     | 0.00         | 65.01        | 11.29    |\n",
      "| 16  | 2          | 8          | sleep      | 23.80    | 0.00     | 100.00   | 0.00     | 0.00         | 130.01       | 9.59     |\n",
      "| 16  | 3          | 8          | sleep      | 23.80    | 0.00     | 100.00   | 0.00     | 0.00         | 195.02       | 7.88     |\n",
      "| 16  | 4          | 8          | sleep      | 23.80    | 0.00     | 100.00   | 0.00     | 0.00         | 260.02       | 6.17     |\n",
      "| 16  | 5          | 8          | sleep      | 23.80    | 0.00     | 100.00   | 0.00     | 0.00         | 325.03       | 4.46     |\n",
      "| 16  | 6          | 8          | sleep      | 23.80    | 0.00     | 100.00   | 0.00     | 0.00         | 390.03       | 2.76     |\n",
      "| 16  | 7          | 0          | action     | 23.80    | 0.00     | 100.00   | 0.00     | 350.00       | 390.03       | 11.35    |\n",
      "| 16  | 8          | 6          | action     | 23.80    | 0.00     | 100.00   | 2.00     | 350.00       | 476.71       | 11.74    |\n",
      "| 16  | 9          | 6          | action     | 23.80    | 0.00     | 100.00   | 4.00     | 350.00       | 563.38       | 12.13    |\n",
      "| 16  | 10         | 0          | action     | 23.80    | 0.00     | 100.00   | 0.00     | 700.00       | 563.38       | 10.73    |\n",
      "| 16  | 11         | 8          | work       | 23.80    | 5.00     | 95.00    | 5.00     | 700.00       | 707.84       | 10.38    |\n",
      "| 16  | 12         | 8          | work       | 23.80    | 10.00    | 90.00    | 10.00    | 700.00       | 852.30       | 10.03    |\n",
      "| 16  | 13         | 6          | action     | 23.80    | 0.00     | 100.00   | 12.00    | 700.00       | 938.97       | 12.42    |\n",
      "| 16  | 14         | 8          | work       | 23.80    | 5.00     | 95.00    | 17.00    | 700.00       | 1083.43      | 12.07    |\n",
      "| 16  | 15         | 8          | work       | 23.80    | 10.00    | 90.00    | 22.00    | 700.00       | 1227.88      | 11.72    |\n",
      "| 16  | 16         | 8          | work       | 23.80    | 15.00    | 85.00    | 27.00    | 700.00       | 1372.34      | 9.37     |\n",
      "| 16  | 17         | 8          | work       | 23.80    | 20.00    | 80.00    | 32.00    | 700.00       | 1516.80      | 7.01     |\n",
      "| 16  | 18         | 8          | work       | 23.80    | 25.00    | 75.00    | 37.00    | 700.00       | 1661.25      | 4.52     |\n",
      "| 16  | 19         | 0          | action     | 23.80    | 25.00    | 95.00    | 17.00    | 1050.00      | 1661.25      | 9.27     |\n",
      "| 16  | 20         | 0          | action     | 23.80    | 25.00    | 100.00   | 0.00     | 1400.00      | 1661.25      | 7.87     |\n",
      "| 16  | 21         | 6          | action     | 23.80    | 15.00    | 100.00   | 2.00     | 1400.00      | 1747.93      | 10.26    |\n",
      "| 16  | 22         | 6          | action     | 23.80    | 5.00     | 100.00   | 4.00     | 1400.00      | 1834.60      | 12.65    |\n",
      "| 16  | 23         | 8          | sleep      | 23.80    | 1.00     | 100.00   | 2.00     | 1400.00      | 1899.61      | 13.74    |\n",
      "| 17  | 0          | 8          | sleep      | 23.78    | 0.00     | 100.00   | 0.00     | 0.00         | 0.00         | 24.05    |\n",
      "| 17  | 1          | 8          | sleep      | 23.78    | 0.00     | 100.00   | 0.00     | 0.00         | 64.94        | 11.29    |\n",
      "| 17  | 2          | 8          | sleep      | 23.78    | 0.00     | 100.00   | 0.00     | 0.00         | 129.87       | 9.58     |\n",
      "| 17  | 3          | 8          | sleep      | 23.78    | 0.00     | 100.00   | 0.00     | 0.00         | 194.81       | 7.88     |\n",
      "| 17  | 4          | 8          | sleep      | 23.78    | 0.00     | 100.00   | 0.00     | 0.00         | 259.75       | 6.17     |\n",
      "| 17  | 5          | 8          | sleep      | 23.78    | 0.00     | 100.00   | 0.00     | 0.00         | 324.68       | 4.46     |\n",
      "| 17  | 6          | 8          | sleep      | 23.78    | 0.00     | 100.00   | 0.00     | 0.00         | 389.62       | 2.75     |\n",
      "| 17  | 7          | 0          | action     | 23.78    | 0.00     | 100.00   | 0.00     | 350.00       | 389.62       | 11.35    |\n",
      "| 17  | 8          | 6          | action     | 23.78    | 0.00     | 100.00   | 2.00     | 350.00       | 476.20       | 11.74    |\n",
      "| 17  | 9          | 6          | action     | 23.78    | 0.00     | 100.00   | 4.00     | 350.00       | 562.78       | 12.13    |\n",
      "| 17  | 10         | 0          | action     | 23.78    | 0.00     | 100.00   | 0.00     | 700.00       | 562.78       | 10.73    |\n",
      "| 17  | 11         | 8          | work       | 23.78    | 5.00     | 95.00    | 5.00     | 700.00       | 707.08       | 10.38    |\n",
      "| 17  | 12         | 8          | work       | 23.78    | 10.00    | 90.00    | 10.00    | 700.00       | 851.39       | 10.03    |\n",
      "| 17  | 13         | 6          | action     | 23.78    | 0.00     | 100.00   | 12.00    | 700.00       | 937.97       | 12.42    |\n",
      "| 17  | 14         | 8          | work       | 23.78    | 5.00     | 95.00    | 17.00    | 700.00       | 1082.27      | 12.07    |\n",
      "| 17  | 15         | 8          | work       | 23.78    | 10.00    | 90.00    | 22.00    | 700.00       | 1226.57      | 11.72    |\n",
      "| 17  | 16         | 8          | work       | 23.78    | 15.00    | 85.00    | 27.00    | 700.00       | 1370.88      | 9.37     |\n",
      "| 17  | 17         | 8          | work       | 23.78    | 20.00    | 80.00    | 32.00    | 700.00       | 1515.18      | 7.00     |\n",
      "| 17  | 18         | 8          | work       | 23.78    | 25.00    | 75.00    | 37.00    | 700.00       | 1659.48      | 4.52     |\n",
      "| 17  | 19         | 0          | action     | 23.78    | 25.00    | 95.00    | 17.00    | 1050.00      | 1659.48      | 9.27     |\n",
      "| 17  | 20         | 0          | action     | 23.78    | 25.00    | 100.00   | 0.00     | 1400.00      | 1659.48      | 7.86     |\n",
      "| 17  | 21         | 6          | action     | 23.78    | 15.00    | 100.00   | 2.00     | 1400.00      | 1746.06      | 10.25    |\n",
      "| 17  | 22         | 6          | action     | 23.78    | 5.00     | 100.00   | 4.00     | 1400.00      | 1832.65      | 12.64    |\n",
      "| 17  | 23         | 8          | sleep      | 23.78    | 1.00     | 100.00   | 2.00     | 1400.00      | 1897.58      | 13.74    |\n",
      "| 18  | 0          | 8          | sleep      | 23.75    | 0.00     | 100.00   | 0.00     | 0.00         | 0.00         | 24.04    |\n",
      "| 18  | 1          | 8          | sleep      | 23.75    | 0.00     | 100.00   | 0.00     | 0.00         | 64.87        | 11.29    |\n",
      "| 18  | 2          | 8          | sleep      | 23.75    | 0.00     | 100.00   | 0.00     | 0.00         | 129.73       | 9.58     |\n",
      "| 18  | 3          | 8          | sleep      | 23.75    | 0.00     | 100.00   | 0.00     | 0.00         | 194.60       | 7.88     |\n",
      "| 18  | 4          | 8          | sleep      | 23.75    | 0.00     | 100.00   | 0.00     | 0.00         | 259.47       | 6.17     |\n",
      "| 18  | 5          | 8          | sleep      | 23.75    | 0.00     | 100.00   | 0.00     | 0.00         | 324.34       | 4.46     |\n",
      "| 18  | 6          | 8          | sleep      | 23.75    | 0.00     | 100.00   | 0.00     | 0.00         | 389.20       | 2.75     |\n",
      "| 18  | 7          | 0          | action     | 23.75    | 0.00     | 100.00   | 0.00     | 350.00       | 389.20       | 11.35    |\n",
      "| 18  | 8          | 6          | action     | 23.75    | 0.00     | 100.00   | 2.00     | 350.00       | 475.69       | 11.74    |\n",
      "| 18  | 9          | 6          | action     | 23.75    | 0.00     | 100.00   | 4.00     | 350.00       | 562.18       | 12.13    |\n",
      "| 18  | 10         | 0          | action     | 23.75    | 0.00     | 100.00   | 0.00     | 700.00       | 562.18       | 10.73    |\n",
      "| 18  | 11         | 8          | work       | 23.75    | 5.00     | 95.00    | 5.00     | 700.00       | 706.33       | 10.38    |\n",
      "| 18  | 12         | 8          | work       | 23.75    | 10.00    | 90.00    | 10.00    | 700.00       | 850.48       | 10.03    |\n",
      "| 18  | 13         | 6          | action     | 23.75    | 0.00     | 100.00   | 12.00    | 700.00       | 936.97       | 12.42    |\n",
      "| 18  | 14         | 8          | work       | 23.75    | 5.00     | 95.00    | 17.00    | 700.00       | 1081.12      | 12.06    |\n",
      "| 18  | 15         | 8          | work       | 23.75    | 10.00    | 90.00    | 22.00    | 700.00       | 1225.27      | 11.71    |\n",
      "| 18  | 16         | 8          | work       | 23.75    | 15.00    | 85.00    | 27.00    | 700.00       | 1369.42      | 9.36     |\n",
      "| 18  | 17         | 8          | work       | 23.75    | 20.00    | 80.00    | 32.00    | 700.00       | 1513.57      | 7.00     |\n",
      "| 18  | 18         | 8          | work       | 23.75    | 25.00    | 75.00    | 37.00    | 700.00       | 1657.72      | 4.51     |\n",
      "| 18  | 19         | 0          | action     | 23.75    | 25.00    | 95.00    | 17.00    | 1050.00      | 1657.72      | 9.26     |\n",
      "| 18  | 20         | 0          | action     | 23.75    | 25.00    | 100.00   | 0.00     | 1400.00      | 1657.72      | 7.86     |\n",
      "| 18  | 21         | 6          | action     | 23.75    | 15.00    | 100.00   | 2.00     | 1400.00      | 1744.21      | 10.25    |\n",
      "| 18  | 22         | 6          | action     | 23.75    | 5.00     | 100.00   | 4.00     | 1400.00      | 1830.70      | 12.64    |\n",
      "| 18  | 23         | 8          | sleep      | 23.75    | 1.00     | 100.00   | 2.00     | 1400.00      | 1895.56      | 13.73    |\n",
      "| 19  | 0          | 8          | sleep      | 23.73    | 0.00     | 100.00   | 0.00     | 0.00         | 0.00         | 24.04    |\n",
      "| 19  | 1          | 8          | sleep      | 23.73    | 0.00     | 100.00   | 0.00     | 0.00         | 64.80        | 11.29    |\n",
      "| 19  | 2          | 8          | sleep      | 23.73    | 0.00     | 100.00   | 0.00     | 0.00         | 129.60       | 9.58     |\n",
      "| 19  | 3          | 8          | sleep      | 23.73    | 0.00     | 100.00   | 0.00     | 0.00         | 194.40       | 7.87     |\n",
      "| 19  | 4          | 8          | sleep      | 23.73    | 0.00     | 100.00   | 0.00     | 0.00         | 259.19       | 6.17     |\n",
      "| 19  | 5          | 8          | sleep      | 23.73    | 0.00     | 100.00   | 0.00     | 0.00         | 323.99       | 4.46     |\n",
      "| 19  | 6          | 8          | sleep      | 23.73    | 0.00     | 100.00   | 0.00     | 0.00         | 388.79       | 2.75     |\n",
      "| 19  | 7          | 0          | action     | 23.73    | 0.00     | 100.00   | 0.00     | 350.00       | 388.79       | 11.35    |\n",
      "| 19  | 8          | 6          | action     | 23.73    | 0.00     | 100.00   | 2.00     | 350.00       | 475.19       | 11.74    |\n",
      "| 19  | 9          | 6          | action     | 23.73    | 0.00     | 100.00   | 4.00     | 350.00       | 561.59       | 12.13    |\n",
      "| 19  | 10         | 0          | action     | 23.73    | 0.00     | 100.00   | 0.00     | 700.00       | 561.59       | 10.73    |\n",
      "| 19  | 11         | 8          | work       | 23.73    | 5.00     | 95.00    | 5.00     | 700.00       | 705.58       | 10.37    |\n",
      "| 19  | 12         | 8          | work       | 23.73    | 10.00    | 90.00    | 10.00    | 700.00       | 849.58       | 10.02    |\n",
      "| 19  | 13         | 6          | action     | 23.73    | 0.00     | 100.00   | 12.00    | 700.00       | 935.98       | 12.41    |\n",
      "| 19  | 14         | 8          | work       | 23.73    | 5.00     | 95.00    | 17.00    | 700.00       | 1079.97      | 12.06    |\n",
      "| 19  | 15         | 8          | work       | 23.73    | 10.00    | 90.00    | 22.00    | 700.00       | 1223.97      | 11.71    |\n",
      "| 19  | 16         | 8          | work       | 23.73    | 15.00    | 85.00    | 27.00    | 700.00       | 1367.97      | 9.36     |\n",
      "| 19  | 17         | 8          | work       | 23.73    | 20.00    | 80.00    | 32.00    | 700.00       | 1511.96      | 6.99     |\n",
      "| 19  | 18         | 8          | work       | 23.73    | 25.00    | 75.00    | 37.00    | 700.00       | 1655.96      | 4.50     |\n",
      "| 19  | 19         | 0          | action     | 23.73    | 25.00    | 95.00    | 17.00    | 1050.00      | 1655.96      | 9.25     |\n",
      "| 19  | 20         | 0          | action     | 23.73    | 25.00    | 100.00   | 0.00     | 1400.00      | 1655.96      | 7.85     |\n",
      "| 19  | 21         | 6          | action     | 23.73    | 15.00    | 100.00   | 2.00     | 1400.00      | 1742.36      | 10.24    |\n",
      "| 19  | 22         | 6          | action     | 23.73    | 5.00     | 100.00   | 4.00     | 1400.00      | 1828.76      | 12.63    |\n",
      "| 19  | 23         | 8          | sleep      | 23.73    | 1.00     | 100.00   | 2.00     | 1400.00      | 1893.55      | 13.72    |\n",
      "| 20  | 0          | 8          | sleep      | 23.70    | 0.00     | 100.00   | 0.00     | 0.00         | 0.00         | 24.03    |\n",
      "| 20  | 1          | 8          | sleep      | 23.70    | 0.00     | 100.00   | 0.00     | 0.00         | 64.73        | 11.29    |\n",
      "| 20  | 2          | 8          | sleep      | 23.70    | 0.00     | 100.00   | 0.00     | 0.00         | 129.46       | 9.58     |\n",
      "| 20  | 3          | 8          | sleep      | 23.70    | 0.00     | 100.00   | 0.00     | 0.00         | 194.19       | 7.87     |\n",
      "| 20  | 4          | 8          | sleep      | 23.70    | 0.00     | 100.00   | 0.00     | 0.00         | 258.92       | 6.17     |\n",
      "| 20  | 5          | 8          | sleep      | 23.70    | 0.00     | 100.00   | 0.00     | 0.00         | 323.65       | 4.46     |\n",
      "| 20  | 6          | 8          | sleep      | 23.70    | 0.00     | 100.00   | 0.00     | 0.00         | 388.38       | 2.75     |\n",
      "| 20  | 7          | 0          | action     | 23.70    | 0.00     | 100.00   | 0.00     | 350.00       | 388.38       | 11.35    |\n",
      "| 20  | 8          | 6          | action     | 23.70    | 0.00     | 100.00   | 2.00     | 350.00       | 474.69       | 11.74    |\n",
      "| 20  | 9          | 6          | action     | 23.70    | 0.00     | 100.00   | 4.00     | 350.00       | 560.99       | 12.12    |\n",
      "| 20  | 10         | 0          | action     | 23.70    | 0.00     | 100.00   | 0.00     | 700.00       | 560.99       | 10.72    |\n",
      "| 20  | 11         | 8          | work       | 23.70    | 5.00     | 95.00    | 5.00     | 700.00       | 704.84       | 10.37    |\n",
      "| 20  | 12         | 8          | work       | 23.70    | 10.00    | 90.00    | 10.00    | 700.00       | 848.68       | 10.02    |\n",
      "| 20  | 13         | 6          | action     | 23.70    | 0.00     | 100.00   | 12.00    | 700.00       | 934.99       | 12.41    |\n",
      "| 20  | 14         | 8          | work       | 23.70    | 5.00     | 95.00    | 17.00    | 700.00       | 1078.83      | 12.05    |\n",
      "| 20  | 15         | 8          | work       | 23.70    | 10.00    | 90.00    | 22.00    | 700.00       | 1222.68      | 11.70    |\n",
      "| 20  | 16         | 8          | work       | 23.70    | 15.00    | 85.00    | 27.00    | 700.00       | 1366.52      | 9.35     |\n",
      "| 20  | 17         | 8          | work       | 23.70    | 20.00    | 80.00    | 32.00    | 700.00       | 1510.36      | 6.98     |\n",
      "| 20  | 18         | 8          | work       | 23.70    | 25.00    | 75.00    | 37.00    | 700.00       | 1654.21      | 4.49     |\n",
      "| 20  | 19         | 0          | action     | 23.70    | 25.00    | 95.00    | 17.00    | 1050.00      | 1654.21      | 9.24     |\n",
      "| 20  | 20         | 0          | action     | 23.70    | 25.00    | 100.00   | 0.00     | 1400.00      | 1654.21      | 7.84     |\n",
      "| 20  | 21         | 6          | action     | 23.70    | 15.00    | 100.00   | 2.00     | 1400.00      | 1740.52      | 10.23    |\n",
      "| 20  | 22         | 6          | action     | 23.70    | 5.00     | 100.00   | 4.00     | 1400.00      | 1826.82      | 12.62    |\n",
      "| 20  | 23         | 8          | sleep      | 23.70    | 1.00     | 100.00   | 2.00     | 1400.00      | 1891.55      | 13.71    |\n",
      "| 21  | 0          | 8          | sleep      | 23.68    | 0.00     | 100.00   | 0.00     | 0.00         | 0.00         | 24.03    |\n",
      "| 21  | 1          | 8          | sleep      | 23.68    | 0.00     | 100.00   | 0.00     | 0.00         | 64.66        | 11.29    |\n",
      "| 21  | 2          | 8          | sleep      | 23.68    | 0.00     | 100.00   | 0.00     | 0.00         | 129.32       | 9.58     |\n",
      "| 21  | 3          | 8          | sleep      | 23.68    | 0.00     | 100.00   | 0.00     | 0.00         | 193.98       | 7.87     |\n",
      "| 21  | 4          | 8          | sleep      | 23.68    | 0.00     | 100.00   | 0.00     | 0.00         | 258.65       | 6.16     |\n",
      "| 21  | 5          | 8          | sleep      | 23.68    | 0.00     | 100.00   | 0.00     | 0.00         | 323.31       | 4.45     |\n",
      "| 21  | 6          | 8          | sleep      | 23.68    | 0.00     | 100.00   | 0.00     | 0.00         | 387.97       | 2.75     |\n",
      "| 21  | 7          | 0          | action     | 23.68    | 0.00     | 100.00   | 0.00     | 350.00       | 387.97       | 11.35    |\n",
      "| 21  | 8          | 6          | action     | 23.68    | 0.00     | 100.00   | 2.00     | 350.00       | 474.19       | 11.73    |\n",
      "| 21  | 9          | 6          | action     | 23.68    | 0.00     | 100.00   | 4.00     | 350.00       | 560.40       | 12.12    |\n",
      "| 21  | 10         | 0          | action     | 23.68    | 0.00     | 100.00   | 0.00     | 700.00       | 560.40       | 10.72    |\n",
      "| 21  | 11         | 8          | work       | 23.68    | 5.00     | 95.00    | 5.00     | 700.00       | 704.09       | 10.37    |\n",
      "| 21  | 12         | 8          | work       | 23.68    | 10.00    | 90.00    | 10.00    | 700.00       | 847.79       | 10.01    |\n",
      "| 21  | 13         | 6          | action     | 23.68    | 0.00     | 100.00   | 12.00    | 700.00       | 934.00       | 12.40    |\n",
      "| 21  | 14         | 8          | work       | 23.68    | 5.00     | 95.00    | 17.00    | 700.00       | 1077.69      | 12.05    |\n",
      "| 21  | 15         | 8          | work       | 23.68    | 10.00    | 90.00    | 22.00    | 700.00       | 1221.39      | 11.70    |\n",
      "| 21  | 16         | 8          | work       | 23.68    | 15.00    | 85.00    | 27.00    | 700.00       | 1365.08      | 9.34     |\n",
      "| 21  | 17         | 8          | work       | 23.68    | 20.00    | 80.00    | 32.00    | 700.00       | 1508.77      | 6.98     |\n",
      "| 21  | 18         | 8          | work       | 23.68    | 25.00    | 75.00    | 37.00    | 700.00       | 1652.46      | 4.49     |\n",
      "| 21  | 19         | 0          | action     | 23.68    | 25.00    | 95.00    | 17.00    | 1050.00      | 1652.46      | 9.24     |\n",
      "| 21  | 20         | 0          | action     | 23.68    | 25.00    | 100.00   | 0.00     | 1400.00      | 1652.46      | 7.84     |\n",
      "| 21  | 21         | 6          | action     | 23.68    | 15.00    | 100.00   | 2.00     | 1400.00      | 1738.68      | 10.22    |\n",
      "| 21  | 22         | 6          | action     | 23.68    | 5.00     | 100.00   | 4.00     | 1400.00      | 1824.90      | 12.61    |\n",
      "| 21  | 23         | 8          | sleep      | 23.68    | 1.00     | 100.00   | 2.00     | 1400.00      | 1889.56      | 13.70    |\n",
      "| 22  | 0          | 8          | sleep      | 23.65    | 0.00     | 100.00   | 0.00     | 0.00         | 0.00         | 24.02    |\n",
      "| 22  | 1          | 8          | sleep      | 23.65    | 0.00     | 100.00   | 0.00     | 0.00         | 64.59        | 11.29    |\n",
      "| 22  | 2          | 8          | sleep      | 23.65    | 0.00     | 100.00   | 0.00     | 0.00         | 129.19       | 9.58     |\n",
      "| 22  | 3          | 8          | sleep      | 23.65    | 0.00     | 100.00   | 0.00     | 0.00         | 193.78       | 7.87     |\n",
      "| 22  | 4          | 8          | sleep      | 23.65    | 0.00     | 100.00   | 0.00     | 0.00         | 258.37       | 6.16     |\n",
      "| 22  | 5          | 8          | sleep      | 23.65    | 0.00     | 100.00   | 0.00     | 0.00         | 322.97       | 4.45     |\n",
      "| 22  | 6          | 8          | sleep      | 23.65    | 0.00     | 100.00   | 0.00     | 0.00         | 387.56       | 2.74     |\n",
      "| 22  | 7          | 0          | action     | 23.65    | 0.00     | 100.00   | 0.00     | 350.00       | 387.56       | 11.34    |\n",
      "| 22  | 8          | 6          | action     | 23.65    | 0.00     | 100.00   | 2.00     | 350.00       | 473.69       | 11.73    |\n",
      "| 22  | 9          | 6          | action     | 23.65    | 0.00     | 100.00   | 4.00     | 350.00       | 559.81       | 12.12    |\n",
      "| 22  | 10         | 0          | action     | 23.65    | 0.00     | 100.00   | 0.00     | 700.00       | 559.81       | 10.72    |\n",
      "| 22  | 11         | 8          | work       | 23.65    | 5.00     | 95.00    | 5.00     | 700.00       | 703.35       | 10.37    |\n",
      "| 22  | 12         | 8          | work       | 23.65    | 10.00    | 90.00    | 10.00    | 700.00       | 846.89       | 10.01    |\n",
      "| 22  | 13         | 6          | action     | 23.65    | 0.00     | 100.00   | 12.00    | 700.00       | 933.02       | 12.40    |\n",
      "| 22  | 14         | 8          | work       | 23.65    | 5.00     | 95.00    | 17.00    | 700.00       | 1076.56      | 12.04    |\n",
      "| 22  | 15         | 8          | work       | 23.65    | 10.00    | 90.00    | 22.00    | 700.00       | 1220.10      | 11.69    |\n",
      "| 22  | 16         | 8          | work       | 23.65    | 15.00    | 85.00    | 27.00    | 700.00       | 1363.64      | 9.34     |\n",
      "| 22  | 17         | 8          | work       | 23.65    | 20.00    | 80.00    | 32.00    | 700.00       | 1507.18      | 6.97     |\n",
      "| 22  | 18         | 8          | work       | 23.65    | 25.00    | 75.00    | 37.00    | 700.00       | 1650.73      | 4.48     |\n",
      "| 22  | 19         | 0          | action     | 23.65    | 25.00    | 95.00    | 17.00    | 1050.00      | 1650.73      | 9.23     |\n",
      "| 22  | 20         | 0          | action     | 23.65    | 25.00    | 100.00   | 0.00     | 1400.00      | 1650.73      | 7.83     |\n",
      "| 22  | 21         | 6          | action     | 23.65    | 15.00    | 100.00   | 2.00     | 1400.00      | 1736.85      | 10.22    |\n",
      "| 22  | 22         | 6          | action     | 23.65    | 5.00     | 100.00   | 4.00     | 1400.00      | 1822.98      | 12.60    |\n",
      "| 22  | 23         | 8          | sleep      | 23.65    | 1.00     | 100.00   | 2.00     | 1400.00      | 1887.57      | 13.69    |\n",
      "| 23  | 0          | 8          | sleep      | 23.63    | 0.00     | 100.00   | 0.00     | 0.00         | 0.00         | 24.01    |\n",
      "| 23  | 1          | 8          | sleep      | 23.63    | 0.00     | 100.00   | 0.00     | 0.00         | 64.53        | 11.29    |\n",
      "| 23  | 2          | 8          | sleep      | 23.63    | 0.00     | 100.00   | 0.00     | 0.00         | 129.05       | 9.58     |\n",
      "| 23  | 3          | 8          | sleep      | 23.63    | 0.00     | 100.00   | 0.00     | 0.00         | 193.58       | 7.87     |\n",
      "| 23  | 4          | 8          | sleep      | 23.63    | 0.00     | 100.00   | 0.00     | 0.00         | 258.10       | 6.16     |\n",
      "| 23  | 5          | 8          | sleep      | 23.63    | 0.00     | 100.00   | 0.00     | 0.00         | 322.63       | 4.45     |\n",
      "| 23  | 6          | 8          | sleep      | 23.63    | 0.00     | 100.00   | 0.00     | 0.00         | 387.16       | 2.74     |\n",
      "| 23  | 7          | 0          | action     | 23.63    | 0.00     | 100.00   | 0.00     | 350.00       | 387.16       | 11.34    |\n",
      "| 23  | 8          | 6          | action     | 23.63    | 0.00     | 100.00   | 2.00     | 350.00       | 473.19       | 11.73    |\n",
      "| 23  | 9          | 6          | action     | 23.63    | 0.00     | 100.00   | 4.00     | 350.00       | 559.22       | 12.12    |\n",
      "| 23  | 10         | 0          | action     | 23.63    | 0.00     | 100.00   | 0.00     | 700.00       | 559.22       | 10.72    |\n",
      "| 23  | 11         | 8          | work       | 23.63    | 5.00     | 95.00    | 5.00     | 700.00       | 702.62       | 10.36    |\n",
      "| 23  | 12         | 8          | work       | 23.63    | 10.00    | 90.00    | 10.00    | 700.00       | 846.01       | 10.01    |\n",
      "| 23  | 13         | 6          | action     | 23.63    | 0.00     | 100.00   | 12.00    | 700.00       | 932.04       | 12.39    |\n",
      "| 23  | 14         | 8          | work       | 23.63    | 5.00     | 95.00    | 17.00    | 700.00       | 1075.43      | 12.04    |\n",
      "| 23  | 15         | 8          | work       | 23.63    | 10.00    | 90.00    | 22.00    | 700.00       | 1218.82      | 11.69    |\n",
      "| 23  | 16         | 8          | work       | 23.63    | 15.00    | 85.00    | 27.00    | 700.00       | 1362.21      | 9.33     |\n",
      "| 23  | 17         | 8          | work       | 23.63    | 20.00    | 80.00    | 32.00    | 700.00       | 1505.60      | 6.96     |\n",
      "| 23  | 18         | 8          | work       | 23.63    | 25.00    | 75.00    | 37.00    | 700.00       | 1648.99      | 4.47     |\n",
      "| 23  | 19         | 0          | action     | 23.63    | 25.00    | 95.00    | 17.00    | 1050.00      | 1648.99      | 9.22     |\n",
      "| 23  | 20         | 0          | action     | 23.63    | 25.00    | 100.00   | 0.00     | 1400.00      | 1648.99      | 7.82     |\n",
      "| 23  | 21         | 6          | action     | 23.63    | 15.00    | 100.00   | 2.00     | 1400.00      | 1735.03      | 10.21    |\n",
      "| 23  | 22         | 6          | action     | 23.63    | 5.00     | 100.00   | 4.00     | 1400.00      | 1821.06      | 12.60    |\n",
      "| 23  | 23         | 8          | sleep      | 23.63    | 1.00     | 100.00   | 2.00     | 1400.00      | 1885.59      | 13.69    |\n",
      "| 24  | 0          | 8          | sleep      | 23.60    | 0.00     | 100.00   | 0.00     | 0.00         | 0.00         | 24.01    |\n",
      "| 24  | 1          | 8          | sleep      | 23.60    | 0.00     | 100.00   | 0.00     | 0.00         | 64.46        | 11.29    |\n",
      "| 24  | 2          | 8          | sleep      | 23.60    | 0.00     | 100.00   | 0.00     | 0.00         | 128.92       | 9.58     |\n",
      "| 24  | 3          | 8          | sleep      | 23.60    | 0.00     | 100.00   | 0.00     | 0.00         | 193.38       | 7.87     |\n",
      "| 24  | 4          | 8          | sleep      | 23.60    | 0.00     | 100.00   | 0.00     | 0.00         | 257.83       | 6.16     |\n",
      "| 24  | 5          | 8          | sleep      | 23.60    | 0.00     | 100.00   | 0.00     | 0.00         | 322.29       | 4.45     |\n",
      "| 24  | 6          | 8          | sleep      | 23.60    | 0.00     | 100.00   | 0.00     | 0.00         | 386.75       | 2.74     |\n",
      "| 24  | 7          | 0          | action     | 23.60    | 0.00     | 100.00   | 0.00     | 350.00       | 386.75       | 11.34    |\n",
      "| 24  | 8          | 6          | action     | 23.60    | 0.00     | 100.00   | 2.00     | 350.00       | 472.69       | 11.73    |\n",
      "| 24  | 9          | 6          | action     | 23.60    | 0.00     | 100.00   | 4.00     | 350.00       | 558.64       | 12.11    |\n",
      "| 24  | 10         | 0          | action     | 23.60    | 0.00     | 100.00   | 0.00     | 700.00       | 558.64       | 10.71    |\n",
      "| 24  | 11         | 8          | work       | 23.60    | 5.00     | 95.00    | 5.00     | 700.00       | 701.88       | 10.36    |\n",
      "| 24  | 12         | 8          | work       | 23.60    | 10.00    | 90.00    | 10.00    | 700.00       | 845.12       | 10.00    |\n",
      "| 24  | 13         | 6          | action     | 23.60    | 0.00     | 100.00   | 12.00    | 700.00       | 931.07       | 12.39    |\n",
      "| 24  | 14         | 8          | work       | 23.60    | 5.00     | 95.00    | 17.00    | 700.00       | 1074.31      | 12.04    |\n",
      "| 24  | 15         | 8          | work       | 23.60    | 10.00    | 90.00    | 22.00    | 700.00       | 1217.55      | 11.68    |\n",
      "| 24  | 16         | 8          | work       | 23.60    | 15.00    | 85.00    | 27.00    | 700.00       | 1360.79      | 9.32     |\n",
      "| 24  | 17         | 8          | work       | 23.60    | 20.00    | 80.00    | 32.00    | 700.00       | 1504.03      | 6.96     |\n",
      "| 24  | 18         | 8          | work       | 23.60    | 25.00    | 75.00    | 37.00    | 700.00       | 1647.27      | 4.46     |\n",
      "| 24  | 19         | 0          | action     | 23.60    | 25.00    | 95.00    | 17.00    | 1050.00      | 1647.27      | 9.21     |\n",
      "| 24  | 20         | 0          | action     | 23.60    | 25.00    | 100.00   | 0.00     | 1400.00      | 1647.27      | 7.81     |\n",
      "| 24  | 21         | 6          | action     | 23.60    | 15.00    | 100.00   | 2.00     | 1400.00      | 1733.21      | 10.20    |\n",
      "| 24  | 22         | 6          | action     | 23.60    | 5.00     | 100.00   | 4.00     | 1400.00      | 1819.16      | 12.59    |\n",
      "| 24  | 23         | 8          | sleep      | 23.60    | 1.00     | 100.00   | 2.00     | 1400.00      | 1883.62      | 13.68    |\n",
      "| 25  | 0          | 8          | sleep      | 23.58    | 0.00     | 100.00   | 0.00     | 0.00         | 0.00         | 24.00    |\n",
      "| 25  | 1          | 8          | sleep      | 23.58    | 0.00     | 100.00   | 0.00     | 0.00         | 64.39        | 11.29    |\n",
      "| 25  | 2          | 8          | sleep      | 23.58    | 0.00     | 100.00   | 0.00     | 0.00         | 128.78       | 9.58     |\n",
      "| 25  | 3          | 8          | sleep      | 23.58    | 0.00     | 100.00   | 0.00     | 0.00         | 193.17       | 7.87     |\n",
      "| 25  | 4          | 8          | sleep      | 23.58    | 0.00     | 100.00   | 0.00     | 0.00         | 257.56       | 6.16     |\n",
      "| 25  | 5          | 8          | sleep      | 23.58    | 0.00     | 100.00   | 0.00     | 0.00         | 321.96       | 4.45     |\n",
      "| 25  | 6          | 8          | sleep      | 23.58    | 0.00     | 100.00   | 0.00     | 0.00         | 386.35       | 2.74     |\n",
      "| 25  | 7          | 0          | action     | 23.58    | 0.00     | 100.00   | 0.00     | 350.00       | 386.35       | 11.34    |\n",
      "| 25  | 8          | 6          | action     | 23.58    | 0.00     | 100.00   | 2.00     | 350.00       | 472.20       | 11.73    |\n",
      "| 25  | 9          | 6          | action     | 23.58    | 0.00     | 100.00   | 4.00     | 350.00       | 558.06       | 12.11    |\n",
      "| 25  | 10         | 0          | action     | 23.58    | 0.00     | 100.00   | 0.00     | 700.00       | 558.06       | 10.71    |\n",
      "| 25  | 11         | 8          | work       | 23.58    | 5.00     | 95.00    | 5.00     | 700.00       | 701.15       | 10.36    |\n",
      "| 25  | 12         | 8          | work       | 23.58    | 10.00    | 90.00    | 10.00    | 700.00       | 844.24       | 10.00    |\n",
      "| 25  | 13         | 6          | action     | 23.58    | 0.00     | 100.00   | 12.00    | 700.00       | 930.09       | 12.39    |\n",
      "| 25  | 14         | 8          | work       | 23.58    | 5.00     | 95.00    | 17.00    | 700.00       | 1073.18      | 12.03    |\n",
      "| 25  | 15         | 8          | work       | 23.58    | 10.00    | 90.00    | 22.00    | 700.00       | 1216.28      | 11.67    |\n",
      "| 25  | 16         | 8          | work       | 23.58    | 15.00    | 85.00    | 27.00    | 700.00       | 1359.37      | 9.32     |\n",
      "| 25  | 17         | 8          | work       | 23.58    | 20.00    | 80.00    | 32.00    | 700.00       | 1502.46      | 6.95     |\n",
      "| 25  | 18         | 8          | work       | 23.58    | 25.00    | 75.00    | 37.00    | 700.00       | 1645.55      | 4.46     |\n",
      "| 25  | 19         | 0          | action     | 23.58    | 25.00    | 95.00    | 17.00    | 1050.00      | 1645.55      | 9.21     |\n",
      "| 25  | 20         | 0          | action     | 23.58    | 25.00    | 100.00   | 0.00     | 1400.00      | 1645.55      | 7.81     |\n",
      "| 25  | 21         | 6          | action     | 23.58    | 15.00    | 100.00   | 2.00     | 1400.00      | 1731.40      | 10.19    |\n",
      "| 25  | 22         | 6          | action     | 23.58    | 5.00     | 100.00   | 4.00     | 1400.00      | 1817.26      | 12.58    |\n",
      "| 25  | 23         | 8          | sleep      | 23.58    | 1.00     | 100.00   | 2.00     | 1400.00      | 1881.65      | 13.67    |\n",
      "| 26  | 0          | 8          | sleep      | 23.55    | 0.00     | 100.00   | 0.00     | 0.00         | 0.00         | 23.99    |\n",
      "| 26  | 1          | 8          | sleep      | 23.55    | 0.00     | 100.00   | 0.00     | 0.00         | 64.32        | 11.29    |\n",
      "| 26  | 2          | 8          | sleep      | 23.55    | 0.00     | 100.00   | 0.00     | 0.00         | 128.65       | 9.58     |\n",
      "| 26  | 3          | 8          | sleep      | 23.55    | 0.00     | 100.00   | 0.00     | 0.00         | 192.97       | 7.87     |\n",
      "| 26  | 4          | 8          | sleep      | 23.55    | 0.00     | 100.00   | 0.00     | 0.00         | 257.30       | 6.16     |\n",
      "| 26  | 5          | 8          | sleep      | 23.55    | 0.00     | 100.00   | 0.00     | 0.00         | 321.62       | 4.45     |\n",
      "| 26  | 6          | 8          | sleep      | 23.55    | 0.00     | 100.00   | 0.00     | 0.00         | 385.94       | 2.74     |\n",
      "| 26  | 7          | 0          | action     | 23.55    | 0.00     | 100.00   | 0.00     | 350.00       | 385.94       | 11.34    |\n",
      "| 26  | 8          | 6          | action     | 23.55    | 0.00     | 100.00   | 2.00     | 350.00       | 471.71       | 11.72    |\n",
      "| 26  | 9          | 0          | action     | 23.55    | 0.00     | 100.00   | 0.00     | 700.00       | 471.71       | 10.32    |\n",
      "| 26  | 10         | 6          | action     | 23.55    | 0.00     | 100.00   | 2.00     | 700.00       | 557.48       | 10.71    |\n",
      "| 26  | 11         | 8          | work       | 23.55    | 5.00     | 95.00    | 7.00     | 700.00       | 700.42       | 10.35    |\n",
      "| 26  | 12         | 8          | work       | 23.55    | 10.00    | 90.00    | 12.00    | 700.00       | 843.36       | 10.00    |\n",
      "| 26  | 13         | 6          | action     | 23.55    | 0.00     | 100.00   | 14.00    | 700.00       | 929.13       | 12.38    |\n",
      "| 26  | 14         | 8          | work       | 23.55    | 5.00     | 95.00    | 19.00    | 700.00       | 1072.07      | 12.03    |\n",
      "| 26  | 15         | 8          | work       | 23.55    | 10.00    | 90.00    | 24.00    | 700.00       | 1215.01      | 9.67     |\n",
      "| 26  | 16         | 8          | work       | 23.55    | 15.00    | 85.00    | 29.00    | 700.00       | 1357.95      | 7.31     |\n",
      "| 26  | 17         | 8          | work       | 23.55    | 20.00    | 80.00    | 34.00    | 700.00       | 1500.90      | 4.91     |\n",
      "| 26  | 18         | 8          | work       | 23.55    | 25.00    | 75.00    | 39.00    | 700.00       | 1643.84      | 2.35     |\n",
      "| 26  | 19         | 0          | action     | 23.55    | 25.00    | 95.00    | 19.00    | 1050.00      | 1643.84      | 9.20     |\n",
      "| 26  | 20         | 0          | action     | 23.55    | 25.00    | 100.00   | 0.00     | 1400.00      | 1643.84      | 7.80     |\n",
      "| 26  | 21         | 6          | action     | 23.55    | 15.00    | 100.00   | 2.00     | 1400.00      | 1729.60      | 10.19    |\n",
      "| 26  | 22         | 6          | action     | 23.55    | 5.00     | 100.00   | 4.00     | 1400.00      | 1815.37      | 12.57    |\n",
      "| 26  | 23         | 8          | sleep      | 23.55    | 1.00     | 100.00   | 2.00     | 1400.00      | 1879.69      | 13.66    |\n",
      "| 27  | 0          | 8          | sleep      | 23.53    | 0.00     | 100.00   | 0.00     | 0.00         | 0.00         | 23.99    |\n",
      "| 27  | 1          | 8          | sleep      | 23.53    | 0.00     | 100.00   | 0.00     | 0.00         | 64.26        | 11.29    |\n",
      "| 27  | 2          | 8          | sleep      | 23.53    | 0.00     | 100.00   | 0.00     | 0.00         | 128.51       | 9.58     |\n",
      "| 27  | 3          | 8          | sleep      | 23.53    | 0.00     | 100.00   | 0.00     | 0.00         | 192.77       | 7.87     |\n",
      "| 27  | 4          | 8          | sleep      | 23.53    | 0.00     | 100.00   | 0.00     | 0.00         | 257.03       | 6.16     |\n",
      "| 27  | 5          | 8          | sleep      | 23.53    | 0.00     | 100.00   | 0.00     | 0.00         | 321.29       | 4.45     |\n",
      "| 27  | 6          | 8          | sleep      | 23.53    | 0.00     | 100.00   | 0.00     | 0.00         | 385.54       | 2.73     |\n",
      "| 27  | 7          | 0          | action     | 23.53    | 0.00     | 100.00   | 0.00     | 350.00       | 385.54       | 11.34    |\n",
      "| 27  | 8          | 0          | action     | 23.53    | 0.00     | 100.00   | 0.00     | 700.00       | 385.54       | 9.94     |\n",
      "| 27  | 9          | 6          | action     | 23.53    | 0.00     | 100.00   | 2.00     | 700.00       | 471.22       | 10.32    |\n",
      "| 27  | 10         | 6          | action     | 23.53    | 0.00     | 100.00   | 4.00     | 700.00       | 556.90       | 10.71    |\n",
      "| 27  | 11         | 8          | work       | 23.53    | 5.00     | 95.00    | 9.00     | 700.00       | 699.69       | 10.35    |\n",
      "| 27  | 12         | 8          | work       | 23.53    | 10.00    | 90.00    | 14.00    | 700.00       | 842.48       | 9.99     |\n",
      "| 27  | 13         | 6          | action     | 23.53    | 0.00     | 100.00   | 16.00    | 700.00       | 928.16       | 12.38    |\n",
      "| 27  | 14         | 8          | work       | 23.53    | 5.00     | 95.00    | 21.00    | 700.00       | 1070.96      | 10.02    |\n",
      "| 27  | 15         | 8          | work       | 23.53    | 10.00    | 90.00    | 26.00    | 700.00       | 1213.75      | 7.66     |\n",
      "| 27  | 16         | 8          | work       | 23.53    | 15.00    | 85.00    | 31.00    | 700.00       | 1356.54      | 5.30     |\n",
      "| 27  | 17         | 8          | work       | 23.53    | 20.00    | 80.00    | 36.00    | 700.00       | 1499.34      | 2.84     |\n",
      "| 27  | 18         | 8          | work       | 23.53    | 25.00    | 75.00    | 41.00    | 700.00       | 1642.13      | 0.22     |\n",
      "| 27  | 19         | 0          | action     | 23.53    | 25.00    | 95.00    | 21.00    | 1050.00      | 1642.13      | 9.19     |\n",
      "| 27  | 20         | 0          | action     | 23.53    | 25.00    | 100.00   | 1.00     | 1400.00      | 1642.13      | 7.79     |\n",
      "| 27  | 21         | 6          | action     | 23.53    | 15.00    | 100.00   | 3.00     | 1400.00      | 1727.81      | 10.18    |\n",
      "| 27  | 22         | 6          | action     | 23.53    | 5.00     | 100.00   | 5.00     | 1400.00      | 1813.48      | 12.56    |\n",
      "| 27  | 23         | 8          | sleep      | 23.53    | 1.00     | 100.00   | 3.00     | 1400.00      | 1877.74      | 13.65    |\n",
      "| 28  | 0          | 8          | sleep      | 23.50    | 0.00     | 100.00   | 1.00     | 0.00         | 0.00         | 23.98    |\n",
      "| 28  | 1          | 8          | sleep      | 23.50    | 0.00     | 100.00   | 0.00     | 0.00         | 64.19        | 11.29    |\n",
      "| 28  | 2          | 8          | sleep      | 23.50    | 0.00     | 100.00   | 0.00     | 0.00         | 128.38       | 9.58     |\n",
      "| 28  | 3          | 8          | sleep      | 23.50    | 0.00     | 100.00   | 0.00     | 0.00         | 192.57       | 7.87     |\n",
      "| 28  | 4          | 8          | sleep      | 23.50    | 0.00     | 100.00   | 0.00     | 0.00         | 256.76       | 6.16     |\n",
      "| 28  | 5          | 8          | sleep      | 23.50    | 0.00     | 100.00   | 0.00     | 0.00         | 320.95       | 4.44     |\n",
      "| 28  | 6          | 8          | sleep      | 23.50    | 0.00     | 100.00   | 0.00     | 0.00         | 385.14       | 2.73     |\n",
      "| 28  | 7          | 0          | action     | 23.50    | 0.00     | 100.00   | 0.00     | 350.00       | 385.14       | 11.33    |\n",
      "| 28  | 8          | 0          | action     | 23.50    | 0.00     | 100.00   | 0.00     | 700.00       | 385.14       | 9.94     |\n",
      "| 28  | 9          | 6          | action     | 23.50    | 0.00     | 100.00   | 2.00     | 700.00       | 470.73       | 10.32    |\n",
      "| 28  | 10         | 6          | action     | 23.50    | 0.00     | 100.00   | 4.00     | 700.00       | 556.32       | 10.71    |\n",
      "| 28  | 11         | 8          | work       | 23.50    | 5.00     | 95.00    | 9.00     | 700.00       | 698.97       | 10.35    |\n",
      "| 28  | 12         | 8          | work       | 23.50    | 10.00    | 90.00    | 14.00    | 700.00       | 841.61       | 9.99     |\n",
      "| 28  | 13         | 6          | action     | 23.50    | 0.00     | 100.00   | 16.00    | 700.00       | 927.20       | 12.37    |\n",
      "| 28  | 14         | 8          | work       | 23.50    | 5.00     | 95.00    | 21.00    | 700.00       | 1069.85      | 10.02    |\n",
      "| 28  | 15         | 8          | work       | 23.50    | 10.00    | 90.00    | 26.00    | 700.00       | 1212.49      | 7.66     |\n",
      "| 28  | 16         | 8          | work       | 23.50    | 15.00    | 85.00    | 31.00    | 700.00       | 1355.14      | 5.30     |\n",
      "| 28  | 17         | 8          | work       | 23.50    | 20.00    | 80.00    | 36.00    | 700.00       | 1497.79      | 2.83     |\n",
      "| 28  | 18         | 8          | work       | 23.50    | 25.00    | 75.00    | 41.00    | 700.00       | 1640.43      | 0.21     |\n",
      "| 28  | 19         | 0          | action     | 23.50    | 25.00    | 95.00    | 21.00    | 1050.00      | 1640.43      | 9.18     |\n",
      "| 28  | 20         | 0          | action     | 23.50    | 25.00    | 100.00   | 1.00     | 1400.00      | 1640.43      | 7.79     |\n",
      "| 28  | 21         | 6          | action     | 23.50    | 15.00    | 100.00   | 3.00     | 1400.00      | 1726.02      | 10.17    |\n",
      "| 28  | 22         | 6          | action     | 23.50    | 5.00     | 100.00   | 5.00     | 1400.00      | 1811.61      | 12.56    |\n",
      "| 28  | 23         | 8          | sleep      | 23.50    | 1.00     | 100.00   | 3.00     | 1400.00      | 1875.80      | 13.64    |\n",
      "| 29  | 0          | 8          | sleep      | 23.48    | 0.00     | 100.00   | 1.00     | 0.00         | 0.00         | 23.97    |\n",
      "| 29  | 1          | 8          | sleep      | 23.48    | 0.00     | 100.00   | 0.00     | 0.00         | 64.12        | 11.29    |\n",
      "| 29  | 2          | 8          | sleep      | 23.48    | 0.00     | 100.00   | 0.00     | 0.00         | 128.25       | 9.58     |\n",
      "| 29  | 3          | 8          | sleep      | 23.48    | 0.00     | 100.00   | 0.00     | 0.00         | 192.37       | 7.87     |\n",
      "| 29  | 4          | 8          | sleep      | 23.48    | 0.00     | 100.00   | 0.00     | 0.00         | 256.50       | 6.15     |\n",
      "| 29  | 5          | 8          | sleep      | 23.48    | 0.00     | 100.00   | 0.00     | 0.00         | 320.62       | 4.44     |\n",
      "| 29  | 6          | 8          | sleep      | 23.48    | 0.00     | 100.00   | 0.00     | 0.00         | 384.75       | 2.73     |\n",
      "| 29  | 7          | 0          | action     | 23.48    | 0.00     | 100.00   | 0.00     | 350.00       | 384.75       | 11.33    |\n",
      "| 29  | 8          | 0          | action     | 23.48    | 0.00     | 100.00   | 0.00     | 700.00       | 384.75       | 9.93     |\n",
      "| 29  | 9          | 6          | action     | 23.48    | 0.00     | 100.00   | 2.00     | 700.00       | 470.25       | 10.32    |\n",
      "| 29  | 10         | 6          | action     | 23.48    | 0.00     | 100.00   | 4.00     | 700.00       | 555.75       | 10.70    |\n",
      "| 29  | 11         | 8          | work       | 23.48    | 5.00     | 95.00    | 9.00     | 700.00       | 698.24       | 10.34    |\n",
      "| 29  | 12         | 8          | work       | 23.48    | 10.00    | 90.00    | 14.00    | 700.00       | 840.74       | 9.99     |\n",
      "| 29  | 13         | 6          | action     | 23.48    | 0.00     | 100.00   | 16.00    | 700.00       | 926.24       | 12.37    |\n",
      "| 29  | 14         | 8          | work       | 23.48    | 5.00     | 95.00    | 21.00    | 700.00       | 1068.74      | 10.01    |\n",
      "| 29  | 15         | 8          | work       | 23.48    | 10.00    | 90.00    | 26.00    | 700.00       | 1211.24      | 7.65     |\n",
      "| 29  | 16         | 8          | work       | 23.48    | 15.00    | 85.00    | 31.00    | 700.00       | 1353.74      | 5.29     |\n",
      "| 29  | 17         | 8          | work       | 23.48    | 20.00    | 80.00    | 36.00    | 700.00       | 1496.24      | 2.83     |\n",
      "| 29  | 18         | 8          | work       | 23.48    | 25.00    | 75.00    | 41.00    | 700.00       | 1638.74      | 0.21     |\n",
      "| 29  | 19         | 0          | action     | 23.48    | 25.00    | 95.00    | 21.00    | 1050.00      | 1638.74      | 9.18     |\n",
      "| 29  | 20         | 0          | action     | 23.48    | 25.00    | 100.00   | 1.00     | 1400.00      | 1638.74      | 7.78     |\n",
      "| 29  | 21         | 6          | action     | 23.48    | 15.00    | 100.00   | 3.00     | 1400.00      | 1724.24      | 10.16    |\n",
      "| 29  | 22         | 6          | action     | 23.48    | 5.00     | 100.00   | 5.00     | 1400.00      | 1809.74      | 12.55    |\n",
      "| 29  | 23         | 8          | sleep      | 23.48    | 1.00     | 100.00   | 3.00     | 1400.00      | 1873.86      | 13.64    |\n",
      "| 30  | 0          | 8          | sleep      | 23.46    | 0.00     | 100.00   | 1.00     | 0.00         | 0.00         | 23.97    |\n",
      "| 30  | 1          | 8          | sleep      | 23.46    | 0.00     | 100.00   | 0.00     | 0.00         | 64.06        | 11.29    |\n",
      "| 30  | 2          | 8          | sleep      | 23.46    | 0.00     | 100.00   | 0.00     | 0.00         | 128.12       | 9.58     |\n",
      "| 30  | 3          | 8          | sleep      | 23.46    | 0.00     | 100.00   | 0.00     | 0.00         | 192.18       | 7.86     |\n",
      "| 30  | 4          | 8          | sleep      | 23.46    | 0.00     | 100.00   | 0.00     | 0.00         | 256.23       | 6.15     |\n",
      "| 30  | 5          | 8          | sleep      | 23.46    | 0.00     | 100.00   | 0.00     | 0.00         | 320.29       | 4.44     |\n",
      "| 30  | 6          | 8          | sleep      | 23.46    | 0.00     | 100.00   | 0.00     | 0.00         | 384.35       | 2.73     |\n",
      "| 30  | 7          | 0          | action     | 23.46    | 0.00     | 100.00   | 0.00     | 350.00       | 384.35       | 11.33    |\n",
      "| 30  | 8          | 0          | action     | 23.46    | 0.00     | 100.00   | 0.00     | 700.00       | 384.35       | 9.93     |\n",
      "| 30  | 9          | 6          | action     | 23.46    | 0.00     | 100.00   | 2.00     | 700.00       | 469.76       | 10.32    |\n",
      "| 30  | 10         | 6          | action     | 23.46    | 0.00     | 100.00   | 4.00     | 700.00       | 555.17       | 10.70    |\n",
      "| 30  | 11         | 8          | work       | 23.46    | 5.00     | 95.00    | 9.00     | 700.00       | 697.53       | 10.34    |\n",
      "| 30  | 12         | 8          | work       | 23.46    | 10.00    | 90.00    | 14.00    | 700.00       | 839.88       | 9.98     |\n",
      "| 30  | 13         | 6          | action     | 23.46    | 0.00     | 100.00   | 16.00    | 700.00       | 925.29       | 12.37    |\n",
      "| 30  | 14         | 8          | work       | 23.46    | 5.00     | 95.00    | 21.00    | 700.00       | 1067.64      | 10.01    |\n",
      "| 30  | 15         | 8          | work       | 23.46    | 10.00    | 90.00    | 26.00    | 700.00       | 1209.99      | 7.65     |\n",
      "| 30  | 16         | 8          | work       | 23.46    | 15.00    | 85.00    | 31.00    | 700.00       | 1352.35      | 5.28     |\n",
      "| 30  | 17         | 8          | work       | 23.46    | 20.00    | 80.00    | 36.00    | 700.00       | 1494.70      | 2.82     |\n",
      "| 30  | 18         | 8          | work       | 23.46    | 25.00    | 75.00    | 41.00    | 700.00       | 1637.05      | 0.20     |\n",
      "| 30  | 19         | 0          | action     | 23.46    | 25.00    | 95.00    | 21.00    | 1050.00      | 1637.05      | 9.17     |\n",
      "| 30  | 20         | 0          | action     | 23.46    | 25.00    | 100.00   | 1.00     | 1400.00      | 1637.05      | 7.77     |\n",
      "| 30  | 21         | 6          | action     | 23.46    | 15.00    | 100.00   | 3.00     | 1400.00      | 1722.46      | 10.16    |\n",
      "| 30  | 22         | 6          | action     | 23.46    | 5.00     | 100.00   | 5.00     | 1400.00      | 1807.87      | 12.54    |\n",
      "| 30  | 23         | 8          | sleep      | 23.46    | 1.00     | 100.00   | 3.00     | 1400.00      | 1871.93      | 13.63    |\n",
      "| 31  | 0          | 8          | sleep      | 23.43    | 0.00     | 100.00   | 1.00     | 0.00         | 0.00         | 23.96    |\n",
      "| 31  | 1          | 8          | sleep      | 23.43    | 0.00     | 100.00   | 0.00     | 0.00         | 63.99        | 11.29    |\n",
      "| 31  | 2          | 8          | sleep      | 23.43    | 0.00     | 100.00   | 0.00     | 0.00         | 127.99       | 9.58     |\n",
      "| 31  | 3          | 8          | sleep      | 23.43    | 0.00     | 100.00   | 0.00     | 0.00         | 191.98       | 7.86     |\n",
      "| 31  | 4          | 8          | sleep      | 23.43    | 0.00     | 100.00   | 0.00     | 0.00         | 255.97       | 6.15     |\n",
      "| 31  | 5          | 8          | sleep      | 23.43    | 0.00     | 100.00   | 0.00     | 0.00         | 319.96       | 4.44     |\n",
      "| 31  | 6          | 8          | sleep      | 23.43    | 0.00     | 100.00   | 0.00     | 0.00         | 383.96       | 2.73     |\n",
      "| 31  | 7          | 0          | action     | 23.43    | 0.00     | 100.00   | 0.00     | 350.00       | 383.96       | 11.33    |\n",
      "| 31  | 8          | 0          | action     | 23.43    | 0.00     | 100.00   | 0.00     | 700.00       | 383.96       | 9.93     |\n",
      "| 31  | 9          | 6          | action     | 23.43    | 0.00     | 100.00   | 2.00     | 700.00       | 469.28       | 10.31    |\n",
      "| 31  | 10         | 6          | action     | 23.43    | 0.00     | 100.00   | 4.00     | 700.00       | 554.60       | 10.70    |\n",
      "| 31  | 11         | 8          | work       | 23.43    | 5.00     | 95.00    | 9.00     | 700.00       | 696.81       | 10.34    |\n",
      "| 31  | 12         | 8          | work       | 23.43    | 10.00    | 90.00    | 14.00    | 700.00       | 839.02       | 9.98     |\n",
      "| 31  | 13         | 6          | action     | 23.43    | 0.00     | 100.00   | 16.00    | 700.00       | 924.34       | 12.36    |\n",
      "| 31  | 14         | 8          | work       | 23.43    | 5.00     | 95.00    | 21.00    | 700.00       | 1066.55      | 10.00    |\n",
      "| 31  | 15         | 8          | work       | 23.43    | 10.00    | 90.00    | 26.00    | 700.00       | 1208.75      | 7.64     |\n",
      "| 31  | 16         | 8          | work       | 23.43    | 15.00    | 85.00    | 31.00    | 700.00       | 1350.96      | 5.28     |\n",
      "| 31  | 17         | 8          | work       | 23.43    | 20.00    | 80.00    | 36.00    | 700.00       | 1493.16      | 2.81     |\n",
      "| 31  | 18         | 8          | work       | 23.43    | 25.00    | 75.00    | 41.00    | 700.00       | 1635.37      | 0.19     |\n",
      "| 31  | 19         | 0          | action     | 23.43    | 25.00    | 95.00    | 21.00    | 1050.00      | 1635.37      | 9.16     |\n",
      "| 31  | 20         | 0          | action     | 23.43    | 25.00    | 100.00   | 1.00     | 1400.00      | 1635.37      | 7.76     |\n",
      "| 31  | 21         | 6          | action     | 23.43    | 15.00    | 100.00   | 3.00     | 1400.00      | 1720.69      | 10.15    |\n",
      "| 31  | 22         | 6          | action     | 23.43    | 5.00     | 100.00   | 5.00     | 1400.00      | 1806.02      | 12.53    |\n",
      "| 31  | 23         | 8          | sleep      | 23.43    | 1.00     | 100.00   | 3.00     | 1400.00      | 1870.01      | 13.62    |\n",
      "| 32  | 0          | 8          | sleep      | 23.41    | 0.00     | 100.00   | 1.00     | 0.00         | 0.00         | 23.96    |\n",
      "| 32  | 1          | 8          | sleep      | 23.41    | 0.00     | 100.00   | 0.00     | 0.00         | 63.93        | 11.29    |\n",
      "| 32  | 2          | 8          | sleep      | 23.41    | 0.00     | 100.00   | 0.00     | 0.00         | 127.85       | 9.58     |\n",
      "| 32  | 3          | 8          | sleep      | 23.41    | 0.00     | 100.00   | 0.00     | 0.00         | 191.78       | 7.86     |\n",
      "| 32  | 4          | 8          | sleep      | 23.41    | 0.00     | 100.00   | 0.00     | 0.00         | 255.71       | 6.15     |\n",
      "| 32  | 5          | 8          | sleep      | 23.41    | 0.00     | 100.00   | 0.00     | 0.00         | 319.64       | 4.44     |\n",
      "| 32  | 6          | 8          | sleep      | 23.41    | 0.00     | 100.00   | 0.00     | 0.00         | 383.56       | 2.73     |\n",
      "| 32  | 7          | 0          | action     | 23.41    | 0.00     | 100.00   | 0.00     | 350.00       | 383.56       | 11.33    |\n",
      "| 32  | 8          | 0          | action     | 23.41    | 0.00     | 100.00   | 0.00     | 700.00       | 383.56       | 9.93     |\n",
      "| 32  | 9          | 6          | action     | 23.41    | 0.00     | 100.00   | 2.00     | 700.00       | 468.80       | 10.31    |\n",
      "| 32  | 10         | 6          | action     | 23.41    | 0.00     | 100.00   | 4.00     | 700.00       | 554.04       | 10.70    |\n",
      "| 32  | 11         | 8          | work       | 23.41    | 5.00     | 95.00    | 9.00     | 700.00       | 696.10       | 10.34    |\n",
      "| 32  | 12         | 8          | work       | 23.41    | 10.00    | 90.00    | 14.00    | 700.00       | 838.16       | 9.97     |\n",
      "| 32  | 13         | 6          | action     | 23.41    | 0.00     | 100.00   | 16.00    | 700.00       | 923.39       | 12.36    |\n",
      "| 32  | 14         | 8          | work       | 23.41    | 5.00     | 95.00    | 21.00    | 700.00       | 1065.45      | 10.00    |\n",
      "| 32  | 15         | 8          | work       | 23.41    | 10.00    | 90.00    | 26.00    | 700.00       | 1207.51      | 7.64     |\n",
      "| 32  | 16         | 8          | work       | 23.41    | 15.00    | 85.00    | 31.00    | 700.00       | 1349.57      | 5.27     |\n",
      "| 32  | 17         | 8          | work       | 23.41    | 20.00    | 80.00    | 36.00    | 700.00       | 1491.63      | 2.81     |\n",
      "| 32  | 18         | 8          | work       | 23.41    | 25.00    | 75.00    | 41.00    | 700.00       | 1633.69      | 0.18     |\n",
      "| 32  | 19         | 0          | action     | 23.41    | 25.00    | 95.00    | 21.00    | 1050.00      | 1633.69      | 9.16     |\n",
      "| 32  | 20         | 0          | action     | 23.41    | 25.00    | 100.00   | 1.00     | 1400.00      | 1633.69      | 7.76     |\n",
      "| 32  | 21         | 6          | action     | 23.41    | 15.00    | 100.00   | 3.00     | 1400.00      | 1718.93      | 10.14    |\n",
      "| 32  | 22         | 6          | action     | 23.41    | 5.00     | 100.00   | 5.00     | 1400.00      | 1804.17      | 12.52    |\n",
      "| 32  | 23         | 8          | sleep      | 23.41    | 1.00     | 100.00   | 3.00     | 1400.00      | 1868.09      | 13.61    |\n",
      "| 33  | 0          | 8          | sleep      | 23.38    | 0.00     | 100.00   | 1.00     | 0.00         | 0.00         | 23.95    |\n",
      "| 33  | 1          | 8          | sleep      | 23.38    | 0.00     | 100.00   | 0.00     | 0.00         | 63.86        | 11.29    |\n",
      "| 33  | 2          | 8          | sleep      | 23.38    | 0.00     | 100.00   | 0.00     | 0.00         | 127.72       | 9.57     |\n",
      "| 33  | 3          | 8          | sleep      | 23.38    | 0.00     | 100.00   | 0.00     | 0.00         | 191.59       | 7.86     |\n",
      "| 33  | 4          | 8          | sleep      | 23.38    | 0.00     | 100.00   | 0.00     | 0.00         | 255.45       | 6.15     |\n",
      "| 33  | 5          | 8          | sleep      | 23.38    | 0.00     | 100.00   | 0.00     | 0.00         | 319.31       | 4.44     |\n",
      "| 33  | 6          | 8          | sleep      | 23.38    | 0.00     | 100.00   | 0.00     | 0.00         | 383.17       | 2.72     |\n",
      "| 33  | 7          | 0          | action     | 23.38    | 0.00     | 100.00   | 0.00     | 350.00       | 383.17       | 11.33    |\n",
      "| 33  | 8          | 0          | action     | 23.38    | 0.00     | 100.00   | 0.00     | 700.00       | 383.17       | 9.93     |\n",
      "| 33  | 9          | 6          | action     | 23.38    | 0.00     | 100.00   | 2.00     | 700.00       | 468.32       | 10.31    |\n",
      "| 33  | 10         | 6          | action     | 23.38    | 0.00     | 100.00   | 4.00     | 700.00       | 553.47       | 10.69    |\n",
      "| 33  | 11         | 8          | work       | 23.38    | 5.00     | 95.00    | 9.00     | 700.00       | 695.38       | 10.33    |\n",
      "| 33  | 12         | 8          | work       | 23.38    | 10.00    | 90.00    | 14.00    | 700.00       | 837.30       | 9.97     |\n",
      "| 33  | 13         | 6          | action     | 23.38    | 0.00     | 100.00   | 16.00    | 700.00       | 922.45       | 12.35    |\n",
      "| 33  | 14         | 8          | work       | 23.38    | 5.00     | 95.00    | 21.00    | 700.00       | 1064.36      | 9.99     |\n",
      "| 33  | 15         | 8          | work       | 23.38    | 10.00    | 90.00    | 26.00    | 700.00       | 1206.28      | 7.63     |\n",
      "| 33  | 16         | 8          | work       | 23.38    | 15.00    | 85.00    | 31.00    | 700.00       | 1348.20      | 5.27     |\n",
      "| 33  | 17         | 8          | work       | 23.38    | 20.00    | 80.00    | 36.00    | 700.00       | 1490.11      | 2.80     |\n",
      "| 33  | 18         | 8          | work       | 23.38    | 25.00    | 75.00    | 41.00    | 700.00       | 1632.03      | 0.18     |\n",
      "| 33  | 19         | 0          | action     | 23.38    | 25.00    | 95.00    | 21.00    | 1050.00      | 1632.03      | 9.15     |\n",
      "| 33  | 20         | 0          | action     | 23.38    | 25.00    | 100.00   | 1.00     | 1400.00      | 1632.03      | 7.75     |\n",
      "| 33  | 21         | 6          | action     | 23.38    | 15.00    | 100.00   | 3.00     | 1400.00      | 1717.18      | 10.13    |\n",
      "| 33  | 22         | 6          | action     | 23.38    | 5.00     | 100.00   | 5.00     | 1400.00      | 1802.32      | 12.52    |\n",
      "| 33  | 23         | 8          | sleep      | 23.38    | 1.00     | 100.00   | 3.00     | 1400.00      | 1866.19      | 13.60    |\n",
      "| 34  | 0          | 8          | sleep      | 23.36    | 0.00     | 100.00   | 1.00     | 0.00         | 0.00         | 23.94    |\n",
      "| 34  | 1          | 8          | sleep      | 23.36    | 0.00     | 100.00   | 0.00     | 0.00         | 63.80        | 11.29    |\n",
      "| 34  | 2          | 8          | sleep      | 23.36    | 0.00     | 100.00   | 0.00     | 0.00         | 127.59       | 9.57     |\n",
      "| 34  | 3          | 8          | sleep      | 23.36    | 0.00     | 100.00   | 0.00     | 0.00         | 191.39       | 7.86     |\n",
      "| 34  | 4          | 8          | sleep      | 23.36    | 0.00     | 100.00   | 0.00     | 0.00         | 255.19       | 6.15     |\n",
      "| 34  | 5          | 8          | sleep      | 23.36    | 0.00     | 100.00   | 0.00     | 0.00         | 318.98       | 4.44     |\n",
      "| 34  | 6          | 8          | sleep      | 23.36    | 0.00     | 100.00   | 0.00     | 0.00         | 382.78       | 2.72     |\n",
      "| 34  | 7          | 0          | action     | 23.36    | 0.00     | 100.00   | 0.00     | 350.00       | 382.78       | 11.32    |\n",
      "| 34  | 8          | 0          | action     | 23.36    | 0.00     | 100.00   | 0.00     | 700.00       | 382.78       | 9.93     |\n",
      "| 34  | 9          | 6          | action     | 23.36    | 0.00     | 100.00   | 2.00     | 700.00       | 467.84       | 10.31    |\n",
      "| 34  | 10         | 6          | action     | 23.36    | 0.00     | 100.00   | 4.00     | 700.00       | 552.91       | 10.69    |\n",
      "| 34  | 11         | 8          | work       | 23.36    | 5.00     | 95.00    | 9.00     | 700.00       | 694.68       | 10.33    |\n",
      "| 34  | 12         | 8          | work       | 23.36    | 10.00    | 90.00    | 14.00    | 700.00       | 836.45       | 9.97     |\n",
      "| 34  | 13         | 6          | action     | 23.36    | 0.00     | 100.00   | 16.00    | 700.00       | 921.51       | 12.35    |\n",
      "| 34  | 14         | 8          | work       | 23.36    | 5.00     | 95.00    | 21.00    | 700.00       | 1063.28      | 9.99     |\n",
      "| 34  | 15         | 8          | work       | 23.36    | 10.00    | 90.00    | 26.00    | 700.00       | 1205.05      | 7.63     |\n",
      "| 34  | 16         | 8          | work       | 23.36    | 15.00    | 85.00    | 31.00    | 700.00       | 1346.82      | 5.26     |\n",
      "| 34  | 17         | 8          | work       | 23.36    | 20.00    | 80.00    | 36.00    | 700.00       | 1488.59      | 2.79     |\n",
      "| 34  | 18         | 8          | work       | 23.36    | 25.00    | 75.00    | 41.00    | 700.00       | 1630.36      | 0.17     |\n",
      "| 34  | 19         | 0          | action     | 23.36    | 25.00    | 95.00    | 21.00    | 1050.00      | 1630.36      | 9.14     |\n",
      "| 34  | 20         | 0          | action     | 23.36    | 25.00    | 100.00   | 1.00     | 1400.00      | 1630.36      | 7.74     |\n",
      "| 34  | 21         | 6          | action     | 23.36    | 15.00    | 100.00   | 3.00     | 1400.00      | 1715.43      | 10.13    |\n",
      "| 34  | 22         | 6          | action     | 23.36    | 5.00     | 100.00   | 5.00     | 1400.00      | 1800.49      | 12.51    |\n",
      "| 34  | 23         | 8          | sleep      | 23.36    | 1.00     | 100.00   | 3.00     | 1400.00      | 1864.29      | 13.60    |\n",
      "| 35  | 0          | 8          | sleep      | 23.34    | 0.00     | 100.00   | 1.00     | 0.00         | 0.00         | 23.94    |\n",
      "| 35  | 1          | 8          | sleep      | 23.34    | 0.00     | 100.00   | 0.00     | 0.00         | 63.73        | 11.29    |\n",
      "| 35  | 2          | 8          | sleep      | 23.34    | 0.00     | 100.00   | 0.00     | 0.00         | 127.46       | 9.57     |\n",
      "| 35  | 3          | 8          | sleep      | 23.34    | 0.00     | 100.00   | 0.00     | 0.00         | 191.20       | 7.86     |\n",
      "| 35  | 4          | 8          | sleep      | 23.34    | 0.00     | 100.00   | 0.00     | 0.00         | 254.93       | 6.15     |\n",
      "| 35  | 5          | 8          | sleep      | 23.34    | 0.00     | 100.00   | 0.00     | 0.00         | 318.66       | 4.43     |\n",
      "| 35  | 6          | 8          | sleep      | 23.34    | 0.00     | 100.00   | 0.00     | 0.00         | 382.39       | 2.72     |\n",
      "| 35  | 7          | 0          | action     | 23.34    | 0.00     | 100.00   | 0.00     | 350.00       | 382.39       | 11.32    |\n",
      "| 35  | 8          | 0          | action     | 23.34    | 0.00     | 100.00   | 0.00     | 700.00       | 382.39       | 9.92     |\n",
      "| 35  | 9          | 6          | action     | 23.34    | 0.00     | 100.00   | 2.00     | 700.00       | 467.37       | 10.31    |\n",
      "| 35  | 10         | 6          | action     | 23.34    | 0.00     | 100.00   | 4.00     | 700.00       | 552.34       | 10.69    |\n",
      "| 35  | 11         | 8          | work       | 23.34    | 5.00     | 95.00    | 9.00     | 700.00       | 693.97       | 10.33    |\n",
      "| 35  | 12         | 8          | work       | 23.34    | 10.00    | 90.00    | 14.00    | 700.00       | 835.60       | 9.96     |\n",
      "| 35  | 13         | 6          | action     | 23.34    | 0.00     | 100.00   | 16.00    | 700.00       | 920.57       | 12.35    |\n",
      "| 35  | 14         | 8          | work       | 23.34    | 5.00     | 95.00    | 21.00    | 700.00       | 1062.20      | 9.98     |\n",
      "| 35  | 15         | 8          | work       | 23.34    | 10.00    | 90.00    | 26.00    | 700.00       | 1203.83      | 7.62     |\n",
      "| 35  | 16         | 8          | work       | 23.34    | 15.00    | 85.00    | 31.00    | 700.00       | 1345.45      | 5.26     |\n",
      "| 35  | 17         | 8          | work       | 23.34    | 20.00    | 80.00    | 36.00    | 700.00       | 1487.08      | 2.79     |\n",
      "| 35  | 18         | 8          | work       | 23.34    | 25.00    | 75.00    | 41.00    | 700.00       | 1628.71      | 0.16     |\n",
      "| 35  | 19         | 0          | action     | 23.34    | 25.00    | 95.00    | 21.00    | 1050.00      | 1628.71      | 9.14     |\n",
      "| 35  | 20         | 0          | action     | 23.34    | 25.00    | 100.00   | 1.00     | 1400.00      | 1628.71      | 7.74     |\n",
      "| 35  | 21         | 6          | action     | 23.34    | 15.00    | 100.00   | 3.00     | 1400.00      | 1713.68      | 10.12    |\n",
      "| 35  | 22         | 6          | action     | 23.34    | 5.00     | 100.00   | 5.00     | 1400.00      | 1798.66      | 12.50    |\n",
      "| 35  | 23         | 8          | sleep      | 23.34    | 1.00     | 100.00   | 3.00     | 1400.00      | 1862.39      | 13.59    |\n",
      "| 36  | 0          | 8          | sleep      | 23.31    | 0.00     | 100.00   | 1.00     | 0.00         | 0.00         | 23.93    |\n",
      "| 36  | 1          | 8          | sleep      | 23.31    | 0.00     | 100.00   | 0.00     | 0.00         | 63.67        | 11.29    |\n",
      "| 36  | 2          | 8          | sleep      | 23.31    | 0.00     | 100.00   | 0.00     | 0.00         | 127.33       | 9.57     |\n",
      "| 36  | 3          | 8          | sleep      | 23.31    | 0.00     | 100.00   | 0.00     | 0.00         | 191.00       | 7.86     |\n",
      "| 36  | 4          | 8          | sleep      | 23.31    | 0.00     | 100.00   | 0.00     | 0.00         | 254.67       | 6.15     |\n",
      "| 36  | 5          | 8          | sleep      | 23.31    | 0.00     | 100.00   | 0.00     | 0.00         | 318.34       | 4.43     |\n",
      "| 36  | 6          | 8          | sleep      | 23.31    | 0.00     | 100.00   | 0.00     | 0.00         | 382.00       | 2.72     |\n",
      "| 36  | 7          | 0          | action     | 23.31    | 0.00     | 100.00   | 0.00     | 350.00       | 382.00       | 11.32    |\n",
      "| 36  | 8          | 0          | action     | 23.31    | 0.00     | 100.00   | 0.00     | 700.00       | 382.00       | 9.92     |\n",
      "| 36  | 9          | 6          | action     | 23.31    | 0.00     | 100.00   | 2.00     | 700.00       | 466.89       | 10.31    |\n",
      "| 36  | 10         | 6          | action     | 23.31    | 0.00     | 100.00   | 4.00     | 700.00       | 551.78       | 10.69    |\n",
      "| 36  | 11         | 8          | work       | 23.31    | 5.00     | 95.00    | 9.00     | 700.00       | 693.27       | 10.32    |\n",
      "| 36  | 12         | 8          | work       | 23.31    | 10.00    | 90.00    | 14.00    | 700.00       | 834.75       | 9.96     |\n",
      "| 36  | 13         | 6          | action     | 23.31    | 0.00     | 100.00   | 16.00    | 700.00       | 919.64       | 12.34    |\n",
      "| 36  | 14         | 8          | work       | 23.31    | 5.00     | 95.00    | 21.00    | 700.00       | 1061.12      | 9.98     |\n",
      "| 36  | 15         | 8          | work       | 23.31    | 10.00    | 90.00    | 26.00    | 700.00       | 1202.61      | 7.62     |\n",
      "| 36  | 16         | 8          | work       | 23.31    | 15.00    | 85.00    | 31.00    | 700.00       | 1344.09      | 5.25     |\n",
      "| 36  | 17         | 8          | work       | 23.31    | 20.00    | 80.00    | 36.00    | 700.00       | 1485.57      | 2.78     |\n",
      "| 36  | 18         | 8          | work       | 23.31    | 25.00    | 75.00    | 41.00    | 700.00       | 1627.06      | 0.16     |\n",
      "| 36  | 19         | 0          | action     | 23.31    | 25.00    | 95.00    | 21.00    | 1050.00      | 1627.06      | 9.13     |\n",
      "| 36  | 20         | 0          | action     | 23.31    | 25.00    | 100.00   | 1.00     | 1400.00      | 1627.06      | 7.73     |\n",
      "| 36  | 21         | 6          | action     | 23.31    | 15.00    | 100.00   | 3.00     | 1400.00      | 1711.95      | 10.11    |\n",
      "| 36  | 22         | 6          | action     | 23.31    | 5.00     | 100.00   | 5.00     | 1400.00      | 1796.84      | 12.49    |\n",
      "| 36  | 23         | 8          | sleep      | 23.31    | 1.00     | 100.00   | 3.00     | 1400.00      | 1860.50      | 13.58    |\n",
      "| 37  | 0          | 8          | sleep      | 23.29    | 0.00     | 100.00   | 1.00     | 0.00         | 0.00         | 23.93    |\n",
      "| 37  | 1          | 8          | sleep      | 23.29    | 0.00     | 100.00   | 0.00     | 0.00         | 63.60        | 11.29    |\n",
      "| 37  | 2          | 8          | sleep      | 23.29    | 0.00     | 100.00   | 0.00     | 0.00         | 127.21       | 9.57     |\n",
      "| 37  | 3          | 8          | sleep      | 23.29    | 0.00     | 100.00   | 0.00     | 0.00         | 190.81       | 7.86     |\n",
      "| 37  | 4          | 8          | sleep      | 23.29    | 0.00     | 100.00   | 0.00     | 0.00         | 254.41       | 6.14     |\n",
      "| 37  | 5          | 8          | sleep      | 23.29    | 0.00     | 100.00   | 0.00     | 0.00         | 318.02       | 4.43     |\n",
      "| 37  | 6          | 8          | sleep      | 23.29    | 0.00     | 100.00   | 0.00     | 0.00         | 381.62       | 2.72     |\n",
      "| 37  | 7          | 0          | action     | 23.29    | 0.00     | 100.00   | 0.00     | 350.00       | 381.62       | 11.32    |\n",
      "| 37  | 8          | 0          | action     | 23.29    | 0.00     | 100.00   | 0.00     | 700.00       | 381.62       | 9.92     |\n",
      "| 37  | 9          | 6          | action     | 23.29    | 0.00     | 100.00   | 2.00     | 700.00       | 466.42       | 10.30    |\n",
      "| 37  | 10         | 6          | action     | 23.29    | 0.00     | 100.00   | 4.00     | 700.00       | 551.23       | 10.69    |\n",
      "| 37  | 11         | 8          | work       | 23.29    | 5.00     | 95.00    | 9.00     | 700.00       | 692.57       | 10.32    |\n",
      "| 37  | 12         | 8          | work       | 23.29    | 10.00    | 90.00    | 14.00    | 700.00       | 833.91       | 9.96     |\n",
      "| 37  | 13         | 6          | action     | 23.29    | 0.00     | 100.00   | 16.00    | 700.00       | 918.71       | 12.34    |\n",
      "| 37  | 14         | 8          | work       | 23.29    | 5.00     | 95.00    | 21.00    | 700.00       | 1060.05      | 9.97     |\n",
      "| 37  | 15         | 8          | work       | 23.29    | 10.00    | 90.00    | 26.00    | 700.00       | 1201.39      | 7.61     |\n",
      "| 37  | 16         | 8          | work       | 23.29    | 15.00    | 85.00    | 31.00    | 700.00       | 1342.73      | 5.24     |\n",
      "| 37  | 17         | 8          | work       | 23.29    | 20.00    | 80.00    | 36.00    | 700.00       | 1484.07      | 2.77     |\n",
      "| 37  | 18         | 8          | work       | 23.29    | 25.00    | 75.00    | 41.00    | 700.00       | 1625.41      | 0.15     |\n",
      "| 37  | 19         | 0          | action     | 23.29    | 25.00    | 95.00    | 21.00    | 1050.00      | 1625.41      | 9.12     |\n",
      "| 37  | 20         | 0          | action     | 23.29    | 25.00    | 100.00   | 1.00     | 1400.00      | 1625.41      | 7.72     |\n",
      "| 37  | 21         | 6          | action     | 23.29    | 15.00    | 100.00   | 3.00     | 1400.00      | 1710.22      | 10.10    |\n",
      "| 37  | 22         | 6          | action     | 23.29    | 5.00     | 100.00   | 5.00     | 1400.00      | 1795.02      | 12.49    |\n",
      "| 37  | 23         | 8          | sleep      | 23.29    | 1.00     | 100.00   | 3.00     | 1400.00      | 1858.62      | 13.57    |\n",
      "| 38  | 0          | 8          | sleep      | 23.27    | 0.00     | 100.00   | 1.00     | 0.00         | 0.00         | 23.92    |\n",
      "| 38  | 1          | 8          | sleep      | 23.27    | 0.00     | 100.00   | 0.00     | 0.00         | 63.54        | 11.29    |\n",
      "| 38  | 2          | 8          | sleep      | 23.27    | 0.00     | 100.00   | 0.00     | 0.00         | 127.08       | 9.57     |\n",
      "| 38  | 3          | 8          | sleep      | 23.27    | 0.00     | 100.00   | 0.00     | 0.00         | 190.62       | 7.86     |\n",
      "| 38  | 4          | 8          | sleep      | 23.27    | 0.00     | 100.00   | 0.00     | 0.00         | 254.16       | 6.14     |\n",
      "| 38  | 5          | 8          | sleep      | 23.27    | 0.00     | 100.00   | 0.00     | 0.00         | 317.70       | 4.43     |\n",
      "| 38  | 6          | 8          | sleep      | 23.27    | 0.00     | 100.00   | 0.00     | 0.00         | 381.23       | 2.72     |\n",
      "| 38  | 7          | 0          | action     | 23.27    | 0.00     | 100.00   | 0.00     | 350.00       | 381.23       | 11.32    |\n",
      "| 38  | 8          | 0          | action     | 23.27    | 0.00     | 100.00   | 0.00     | 700.00       | 381.23       | 9.92     |\n",
      "| 38  | 9          | 6          | action     | 23.27    | 0.00     | 100.00   | 2.00     | 700.00       | 465.95       | 10.30    |\n",
      "| 38  | 10         | 6          | action     | 23.27    | 0.00     | 100.00   | 4.00     | 700.00       | 550.67       | 10.68    |\n",
      "| 38  | 11         | 8          | work       | 23.27    | 5.00     | 95.00    | 9.00     | 700.00       | 691.87       | 10.32    |\n",
      "| 38  | 12         | 8          | work       | 23.27    | 10.00    | 90.00    | 14.00    | 700.00       | 833.07       | 9.95     |\n",
      "| 38  | 13         | 6          | action     | 23.27    | 0.00     | 100.00   | 16.00    | 700.00       | 917.79       | 12.33    |\n",
      "| 38  | 14         | 8          | work       | 23.27    | 5.00     | 95.00    | 21.00    | 700.00       | 1058.98      | 9.97     |\n",
      "| 38  | 15         | 8          | work       | 23.27    | 10.00    | 90.00    | 26.00    | 700.00       | 1200.18      | 7.61     |\n",
      "| 38  | 16         | 8          | work       | 23.27    | 15.00    | 85.00    | 31.00    | 700.00       | 1341.38      | 5.24     |\n",
      "| 38  | 17         | 8          | work       | 23.27    | 20.00    | 80.00    | 36.00    | 700.00       | 1482.58      | 2.77     |\n",
      "| 38  | 18         | 8          | work       | 23.27    | 25.00    | 75.00    | 41.00    | 700.00       | 1623.78      | 0.14     |\n",
      "| 38  | 19         | 0          | action     | 23.27    | 25.00    | 95.00    | 21.00    | 1050.00      | 1623.78      | 9.11     |\n",
      "| 38  | 20         | 0          | action     | 23.27    | 25.00    | 100.00   | 1.00     | 1400.00      | 1623.78      | 7.72     |\n",
      "| 38  | 21         | 6          | action     | 23.27    | 15.00    | 100.00   | 3.00     | 1400.00      | 1708.49      | 10.10    |\n",
      "| 38  | 22         | 6          | action     | 23.27    | 5.00     | 100.00   | 5.00     | 1400.00      | 1793.21      | 12.48    |\n",
      "| 38  | 23         | 8          | sleep      | 23.27    | 1.00     | 100.00   | 3.00     | 1400.00      | 1856.75      | 13.56    |\n",
      "| 39  | 0          | 8          | sleep      | 23.24    | 0.00     | 100.00   | 1.00     | 0.00         | 0.00         | 23.91    |\n",
      "| 39  | 1          | 8          | sleep      | 23.24    | 0.00     | 100.00   | 0.00     | 0.00         | 63.48        | 11.29    |\n",
      "| 39  | 2          | 8          | sleep      | 23.24    | 0.00     | 100.00   | 0.00     | 0.00         | 126.95       | 9.57     |\n",
      "| 39  | 3          | 8          | sleep      | 23.24    | 0.00     | 100.00   | 0.00     | 0.00         | 190.43       | 7.86     |\n",
      "| 39  | 4          | 8          | sleep      | 23.24    | 0.00     | 100.00   | 0.00     | 0.00         | 253.90       | 6.14     |\n",
      "| 39  | 5          | 8          | sleep      | 23.24    | 0.00     | 100.00   | 0.00     | 0.00         | 317.38       | 4.43     |\n",
      "| 39  | 6          | 8          | sleep      | 23.24    | 0.00     | 100.00   | 0.00     | 0.00         | 380.85       | 2.71     |\n",
      "| 39  | 7          | 0          | action     | 23.24    | 0.00     | 100.00   | 0.00     | 350.00       | 380.85       | 11.32    |\n",
      "| 39  | 8          | 0          | action     | 23.24    | 0.00     | 100.00   | 0.00     | 700.00       | 380.85       | 9.92     |\n",
      "| 39  | 9          | 6          | action     | 23.24    | 0.00     | 100.00   | 2.00     | 700.00       | 465.48       | 10.30    |\n",
      "| 39  | 10         | 6          | action     | 23.24    | 0.00     | 100.00   | 4.00     | 700.00       | 550.12       | 10.68    |\n",
      "| 39  | 11         | 8          | work       | 23.24    | 5.00     | 95.00    | 9.00     | 700.00       | 691.17       | 10.32    |\n",
      "| 39  | 12         | 8          | work       | 23.24    | 10.00    | 90.00    | 14.00    | 700.00       | 832.23       | 9.95     |\n",
      "| 39  | 13         | 0          | action     | 23.24    | 10.00    | 100.00   | 0.00     | 1050.00      | 832.23       | 8.55     |\n",
      "| 39  | 14         | 8          | work       | 23.24    | 15.00    | 95.00    | 5.00     | 1050.00      | 973.29       | 8.19     |\n",
      "| 39  | 15         | 8          | work       | 23.24    | 20.00    | 90.00    | 10.00    | 1050.00      | 1114.34      | 7.82     |\n",
      "| 39  | 16         | 8          | work       | 23.24    | 25.00    | 85.00    | 15.00    | 1050.00      | 1255.40      | 7.46     |\n",
      "| 39  | 17         | 8          | work       | 23.24    | 30.00    | 80.00    | 20.00    | 1050.00      | 1396.45      | 7.09     |\n",
      "| 39  | 18         | 8          | work       | 23.24    | 35.00    | 75.00    | 25.00    | 1050.00      | 1537.51      | 6.73     |\n",
      "| 39  | 19         | 6          | action     | 23.24    | 25.00    | 85.00    | 27.00    | 1050.00      | 1622.14      | 7.11     |\n",
      "| 39  | 20         | 0          | action     | 23.24    | 25.00    | 100.00   | 7.00     | 1400.00      | 1622.14      | 7.71     |\n",
      "| 39  | 21         | 6          | action     | 23.24    | 15.00    | 100.00   | 9.00     | 1400.00      | 1706.78      | 10.09    |\n",
      "| 39  | 22         | 6          | action     | 23.24    | 5.00     | 100.00   | 11.00    | 1400.00      | 1791.41      | 12.47    |\n",
      "| 39  | 23         | 8          | sleep      | 23.24    | 1.00     | 100.00   | 9.00     | 1400.00      | 1854.89      | 13.56    |\n",
      "| 40  | 0          | 8          | sleep      | 23.22    | 0.00     | 100.00   | 7.00     | 0.00         | 0.00         | 23.91    |\n",
      "| 40  | 1          | 8          | sleep      | 23.22    | 0.00     | 100.00   | 5.00     | 0.00         | 63.41        | 11.29    |\n",
      "| 40  | 2          | 8          | sleep      | 23.22    | 0.00     | 100.00   | 3.00     | 0.00         | 126.82       | 9.57     |\n",
      "| 40  | 3          | 8          | sleep      | 23.22    | 0.00     | 100.00   | 1.00     | 0.00         | 190.23       | 7.86     |\n",
      "| 40  | 4          | 8          | sleep      | 23.22    | 0.00     | 100.00   | 0.00     | 0.00         | 253.65       | 6.14     |\n",
      "| 40  | 5          | 8          | sleep      | 23.22    | 0.00     | 100.00   | 0.00     | 0.00         | 317.06       | 4.43     |\n",
      "| 40  | 6          | 8          | sleep      | 23.22    | 0.00     | 100.00   | 0.00     | 0.00         | 380.47       | 2.71     |\n",
      "| 40  | 7          | 0          | action     | 23.22    | 0.00     | 100.00   | 0.00     | 350.00       | 380.47       | 11.31    |\n",
      "| 40  | 8          | 0          | action     | 23.22    | 0.00     | 100.00   | 0.00     | 700.00       | 380.47       | 9.92     |\n",
      "| 40  | 9          | 6          | action     | 23.22    | 0.00     | 100.00   | 2.00     | 700.00       | 465.02       | 10.30    |\n",
      "| 40  | 10         | 6          | action     | 23.22    | 0.00     | 100.00   | 4.00     | 700.00       | 549.57       | 10.68    |\n",
      "| 40  | 11         | 8          | work       | 23.22    | 5.00     | 95.00    | 9.00     | 700.00       | 690.48       | 10.31    |\n",
      "| 40  | 12         | 8          | work       | 23.22    | 10.00    | 90.00    | 14.00    | 700.00       | 831.40       | 9.95     |\n",
      "| 40  | 13         | 0          | action     | 23.22    | 10.00    | 100.00   | 0.00     | 1050.00      | 831.40       | 8.55     |\n",
      "| 40  | 14         | 8          | work       | 23.22    | 15.00    | 95.00    | 5.00     | 1050.00      | 972.31       | 8.18     |\n",
      "| 40  | 15         | 8          | work       | 23.22    | 20.00    | 90.00    | 10.00    | 1050.00      | 1113.23      | 7.82     |\n",
      "| 40  | 16         | 8          | work       | 23.22    | 25.00    | 85.00    | 15.00    | 1050.00      | 1254.14      | 7.45     |\n",
      "| 40  | 17         | 8          | work       | 23.22    | 30.00    | 80.00    | 20.00    | 1050.00      | 1395.05      | 7.09     |\n",
      "| 40  | 18         | 8          | work       | 23.22    | 35.00    | 75.00    | 25.00    | 1050.00      | 1535.97      | 6.72     |\n",
      "| 40  | 19         | 6          | action     | 23.22    | 25.00    | 85.00    | 27.00    | 1050.00      | 1620.52      | 7.10     |\n",
      "| 40  | 20         | 0          | action     | 23.22    | 25.00    | 100.00   | 7.00     | 1400.00      | 1620.52      | 7.70     |\n",
      "| 40  | 21         | 6          | action     | 23.22    | 15.00    | 100.00   | 9.00     | 1400.00      | 1705.07      | 10.08    |\n",
      "| 40  | 22         | 6          | action     | 23.22    | 5.00     | 100.00   | 11.00    | 1400.00      | 1789.62      | 12.46    |\n",
      "| 40  | 23         | 8          | sleep      | 23.22    | 1.00     | 100.00   | 9.00     | 1400.00      | 1853.03      | 13.55    |\n",
      "| 41  | 0          | 8          | sleep      | 23.20    | 0.00     | 100.00   | 7.00     | 0.00         | 0.00         | 23.90    |\n",
      "| 41  | 1          | 8          | sleep      | 23.20    | 0.00     | 100.00   | 5.00     | 0.00         | 63.35        | 11.29    |\n",
      "| 41  | 2          | 8          | sleep      | 23.20    | 0.00     | 100.00   | 3.00     | 0.00         | 126.70       | 9.57     |\n",
      "| 41  | 3          | 8          | sleep      | 23.20    | 0.00     | 100.00   | 1.00     | 0.00         | 190.04       | 7.86     |\n",
      "| 41  | 4          | 8          | sleep      | 23.20    | 0.00     | 100.00   | 0.00     | 0.00         | 253.39       | 6.14     |\n",
      "| 41  | 5          | 8          | sleep      | 23.20    | 0.00     | 100.00   | 0.00     | 0.00         | 316.74       | 4.43     |\n",
      "| 41  | 6          | 8          | sleep      | 23.20    | 0.00     | 100.00   | 0.00     | 0.00         | 380.09       | 2.71     |\n",
      "| 41  | 7          | 0          | action     | 23.20    | 0.00     | 100.00   | 0.00     | 350.00       | 380.09       | 11.31    |\n",
      "| 41  | 8          | 0          | action     | 23.20    | 0.00     | 100.00   | 0.00     | 700.00       | 380.09       | 9.92     |\n",
      "| 41  | 9          | 6          | action     | 23.20    | 0.00     | 100.00   | 2.00     | 700.00       | 464.55       | 10.30    |\n",
      "| 41  | 10         | 6          | action     | 23.20    | 0.00     | 100.00   | 4.00     | 700.00       | 549.02       | 10.68    |\n",
      "| 41  | 11         | 8          | work       | 23.20    | 5.00     | 95.00    | 9.00     | 700.00       | 689.79       | 10.31    |\n",
      "| 41  | 12         | 8          | work       | 23.20    | 10.00    | 90.00    | 14.00    | 700.00       | 830.57       | 9.94     |\n",
      "| 41  | 13         | 0          | action     | 23.20    | 10.00    | 100.00   | 0.00     | 1050.00      | 830.57       | 8.55     |\n",
      "| 41  | 14         | 8          | work       | 23.20    | 15.00    | 95.00    | 5.00     | 1050.00      | 971.34       | 8.18     |\n",
      "| 41  | 15         | 8          | work       | 23.20    | 20.00    | 90.00    | 10.00    | 1050.00      | 1112.11      | 7.81     |\n",
      "| 41  | 16         | 8          | work       | 23.20    | 25.00    | 85.00    | 15.00    | 1050.00      | 1252.89      | 7.45     |\n",
      "| 41  | 17         | 8          | work       | 23.20    | 30.00    | 80.00    | 20.00    | 1050.00      | 1393.66      | 7.08     |\n",
      "| 41  | 18         | 8          | work       | 23.20    | 35.00    | 75.00    | 25.00    | 1050.00      | 1534.43      | 6.71     |\n",
      "| 41  | 19         | 6          | action     | 23.20    | 25.00    | 85.00    | 27.00    | 1050.00      | 1618.90      | 7.09     |\n",
      "| 41  | 20         | 0          | action     | 23.20    | 25.00    | 100.00   | 7.00     | 1400.00      | 1618.90      | 7.70     |\n",
      "| 41  | 21         | 6          | action     | 23.20    | 15.00    | 100.00   | 9.00     | 1400.00      | 1703.36      | 10.08    |\n",
      "| 41  | 22         | 6          | action     | 23.20    | 5.00     | 100.00   | 11.00    | 1400.00      | 1787.83      | 12.46    |\n",
      "| 41  | 23         | 8          | sleep      | 23.20    | 1.00     | 100.00   | 9.00     | 1400.00      | 1851.17      | 13.54    |\n",
      "| 42  | 0          | 8          | sleep      | 23.17    | 0.00     | 100.00   | 7.00     | 0.00         | 0.00         | 23.90    |\n",
      "| 42  | 1          | 8          | sleep      | 23.17    | 0.00     | 100.00   | 5.00     | 0.00         | 63.29        | 11.28    |\n",
      "| 42  | 2          | 8          | sleep      | 23.17    | 0.00     | 100.00   | 3.00     | 0.00         | 126.57       | 9.57     |\n",
      "| 42  | 3          | 8          | sleep      | 23.17    | 0.00     | 100.00   | 1.00     | 0.00         | 189.86       | 7.85     |\n",
      "| 42  | 4          | 8          | sleep      | 23.17    | 0.00     | 100.00   | 0.00     | 0.00         | 253.14       | 6.14     |\n",
      "| 42  | 5          | 8          | sleep      | 23.17    | 0.00     | 100.00   | 0.00     | 0.00         | 316.43       | 4.42     |\n",
      "| 42  | 6          | 8          | sleep      | 23.17    | 0.00     | 100.00   | 0.00     | 0.00         | 379.71       | 2.71     |\n",
      "| 42  | 7          | 0          | action     | 23.17    | 0.00     | 100.00   | 0.00     | 350.00       | 379.71       | 11.31    |\n",
      "| 42  | 8          | 0          | action     | 23.17    | 0.00     | 100.00   | 0.00     | 700.00       | 379.71       | 9.91     |\n",
      "| 42  | 9          | 6          | action     | 23.17    | 0.00     | 100.00   | 2.00     | 700.00       | 464.09       | 10.29    |\n",
      "| 42  | 10         | 6          | action     | 23.17    | 0.00     | 100.00   | 4.00     | 700.00       | 548.47       | 10.67    |\n",
      "| 42  | 11         | 8          | work       | 23.17    | 5.00     | 95.00    | 9.00     | 700.00       | 689.10       | 10.31    |\n",
      "| 42  | 12         | 8          | work       | 23.17    | 10.00    | 90.00    | 14.00    | 700.00       | 829.74       | 9.94     |\n",
      "| 42  | 13         | 0          | action     | 23.17    | 10.00    | 100.00   | 0.00     | 1050.00      | 829.74       | 8.54     |\n",
      "| 42  | 14         | 8          | work       | 23.17    | 15.00    | 95.00    | 5.00     | 1050.00      | 970.37       | 8.18     |\n",
      "| 42  | 15         | 8          | work       | 23.17    | 20.00    | 90.00    | 10.00    | 1050.00      | 1111.00      | 7.81     |\n",
      "| 42  | 16         | 8          | work       | 23.17    | 25.00    | 85.00    | 15.00    | 1050.00      | 1251.64      | 7.44     |\n",
      "| 42  | 17         | 8          | work       | 23.17    | 30.00    | 80.00    | 20.00    | 1050.00      | 1392.27      | 7.07     |\n",
      "| 42  | 18         | 8          | work       | 23.17    | 35.00    | 75.00    | 25.00    | 1050.00      | 1532.90      | 6.71     |\n",
      "| 42  | 19         | 6          | action     | 23.17    | 25.00    | 85.00    | 27.00    | 1050.00      | 1617.28      | 7.09     |\n",
      "| 42  | 20         | 0          | action     | 23.17    | 25.00    | 100.00   | 7.00     | 1400.00      | 1617.28      | 7.69     |\n",
      "| 42  | 21         | 6          | action     | 23.17    | 15.00    | 100.00   | 9.00     | 1400.00      | 1701.66      | 10.07    |\n",
      "| 42  | 22         | 6          | action     | 23.17    | 5.00     | 100.00   | 11.00    | 1400.00      | 1786.04      | 12.45    |\n",
      "| 42  | 23         | 8          | sleep      | 23.17    | 1.00     | 100.00   | 9.00     | 1400.00      | 1849.33      | 13.53    |\n",
      "| 43  | 0          | 8          | sleep      | 23.15    | 0.00     | 100.00   | 7.00     | 0.00         | 0.00         | 23.89    |\n",
      "| 43  | 1          | 8          | sleep      | 23.15    | 0.00     | 100.00   | 5.00     | 0.00         | 63.22        | 11.28    |\n",
      "| 43  | 2          | 8          | sleep      | 23.15    | 0.00     | 100.00   | 3.00     | 0.00         | 126.44       | 9.57     |\n",
      "| 43  | 3          | 8          | sleep      | 23.15    | 0.00     | 100.00   | 1.00     | 0.00         | 189.67       | 7.85     |\n",
      "| 43  | 4          | 8          | sleep      | 23.15    | 0.00     | 100.00   | 0.00     | 0.00         | 252.89       | 6.14     |\n",
      "| 43  | 5          | 8          | sleep      | 23.15    | 0.00     | 100.00   | 0.00     | 0.00         | 316.11       | 4.42     |\n",
      "| 43  | 6          | 8          | sleep      | 23.15    | 0.00     | 100.00   | 0.00     | 0.00         | 379.33       | 2.71     |\n",
      "| 43  | 7          | 0          | action     | 23.15    | 0.00     | 100.00   | 0.00     | 350.00       | 379.33       | 11.31    |\n",
      "| 43  | 8          | 0          | action     | 23.15    | 0.00     | 100.00   | 0.00     | 700.00       | 379.33       | 9.91     |\n",
      "| 43  | 9          | 6          | action     | 23.15    | 0.00     | 100.00   | 2.00     | 700.00       | 463.63       | 10.29    |\n",
      "| 43  | 10         | 6          | action     | 23.15    | 0.00     | 100.00   | 4.00     | 700.00       | 547.93       | 10.67    |\n",
      "| 43  | 11         | 8          | work       | 23.15    | 5.00     | 95.00    | 9.00     | 700.00       | 688.42       | 10.30    |\n",
      "| 43  | 12         | 8          | work       | 23.15    | 10.00    | 90.00    | 14.00    | 700.00       | 828.91       | 9.94     |\n",
      "| 43  | 13         | 0          | action     | 23.15    | 10.00    | 100.00   | 0.00     | 1050.00      | 828.91       | 8.54     |\n",
      "| 43  | 14         | 8          | work       | 23.15    | 15.00    | 95.00    | 5.00     | 1050.00      | 969.41       | 8.17     |\n",
      "| 43  | 15         | 8          | work       | 23.15    | 20.00    | 90.00    | 10.00    | 1050.00      | 1109.90      | 7.80     |\n",
      "| 43  | 16         | 8          | work       | 23.15    | 25.00    | 85.00    | 15.00    | 1050.00      | 1250.39      | 7.44     |\n",
      "| 43  | 17         | 8          | work       | 23.15    | 30.00    | 80.00    | 20.00    | 1050.00      | 1390.89      | 7.07     |\n",
      "| 43  | 18         | 8          | work       | 23.15    | 35.00    | 75.00    | 25.00    | 1050.00      | 1531.38      | 6.70     |\n",
      "| 43  | 19         | 6          | action     | 23.15    | 25.00    | 85.00    | 27.00    | 1050.00      | 1615.68      | 7.08     |\n",
      "| 43  | 20         | 6          | action     | 23.15    | 15.00    | 95.00    | 29.00    | 1050.00      | 1699.97      | 7.46     |\n",
      "| 43  | 21         | 0          | action     | 23.15    | 15.00    | 100.00   | 9.00     | 1400.00      | 1699.97      | 10.06    |\n",
      "| 43  | 22         | 6          | action     | 23.15    | 5.00     | 100.00   | 11.00    | 1400.00      | 1784.27      | 12.44    |\n",
      "| 43  | 23         | 8          | sleep      | 23.15    | 1.00     | 100.00   | 9.00     | 1400.00      | 1847.49      | 13.53    |\n",
      "| 44  | 0          | 8          | sleep      | 23.13    | 0.00     | 100.00   | 7.00     | 0.00         | 0.00         | 23.88    |\n",
      "| 44  | 1          | 8          | sleep      | 23.13    | 0.00     | 100.00   | 5.00     | 0.00         | 63.16        | 11.28    |\n",
      "| 44  | 2          | 8          | sleep      | 23.13    | 0.00     | 100.00   | 3.00     | 0.00         | 126.32       | 11.57    |\n",
      "| 44  | 3          | 8          | sleep      | 23.13    | 0.00     | 100.00   | 1.00     | 0.00         | 189.48       | 9.85     |\n",
      "| 44  | 4          | 8          | sleep      | 23.13    | 0.00     | 100.00   | 0.00     | 0.00         | 252.64       | 8.14     |\n",
      "| 44  | 5          | 8          | sleep      | 23.13    | 0.00     | 100.00   | 0.00     | 0.00         | 315.80       | 6.42     |\n",
      "| 44  | 6          | 8          | sleep      | 23.13    | 0.00     | 100.00   | 0.00     | 0.00         | 378.96       | 4.71     |\n",
      "| 44  | 7          | 0          | action     | 23.13    | 0.00     | 100.00   | 0.00     | 350.00       | 378.96       | 11.31    |\n",
      "| 44  | 8          | 0          | action     | 23.13    | 0.00     | 100.00   | 0.00     | 700.00       | 378.96       | 9.91     |\n",
      "| 44  | 9          | 6          | action     | 23.13    | 0.00     | 100.00   | 2.00     | 700.00       | 463.17       | 10.29    |\n",
      "| 44  | 10         | 6          | action     | 23.13    | 0.00     | 100.00   | 4.00     | 700.00       | 547.38       | 10.67    |\n",
      "| 44  | 11         | 8          | work       | 23.13    | 5.00     | 95.00    | 9.00     | 700.00       | 687.74       | 10.30    |\n",
      "| 44  | 12         | 8          | work       | 23.13    | 10.00    | 90.00    | 14.00    | 700.00       | 828.09       | 9.93     |\n",
      "| 44  | 13         | 0          | action     | 23.13    | 10.00    | 100.00   | 0.00     | 1050.00      | 828.09       | 8.54     |\n",
      "| 44  | 14         | 8          | work       | 23.13    | 15.00    | 95.00    | 5.00     | 1050.00      | 968.44       | 8.17     |\n",
      "| 44  | 15         | 8          | work       | 23.13    | 20.00    | 90.00    | 10.00    | 1050.00      | 1108.80      | 7.80     |\n",
      "| 44  | 16         | 8          | work       | 23.13    | 25.00    | 85.00    | 15.00    | 1050.00      | 1249.15      | 7.43     |\n",
      "| 44  | 17         | 8          | work       | 23.13    | 30.00    | 80.00    | 20.00    | 1050.00      | 1389.51      | 7.06     |\n",
      "| 44  | 18         | 8          | work       | 23.13    | 35.00    | 75.00    | 25.00    | 1050.00      | 1529.86      | 6.69     |\n",
      "| 44  | 19         | 6          | action     | 23.13    | 25.00    | 85.00    | 27.00    | 1050.00      | 1614.07      | 7.07     |\n",
      "| 44  | 20         | 6          | action     | 23.13    | 15.00    | 95.00    | 29.00    | 1050.00      | 1698.29      | 7.45     |\n",
      "| 44  | 21         | 0          | action     | 23.13    | 15.00    | 100.00   | 9.00     | 1400.00      | 1698.29      | 10.06    |\n",
      "| 44  | 22         | 6          | action     | 23.13    | 5.00     | 100.00   | 11.00    | 1400.00      | 1782.50      | 12.43    |\n",
      "| 44  | 23         | 8          | sleep      | 23.13    | 1.00     | 100.00   | 9.00     | 1400.00      | 1845.66      | 13.52    |\n",
      "| 45  | 0          | 8          | sleep      | 23.10    | 0.00     | 100.00   | 7.00     | 0.00         | 0.00         | 23.88    |\n",
      "| 45  | 1          | 8          | sleep      | 23.10    | 0.00     | 100.00   | 5.00     | 0.00         | 63.10        | 11.28    |\n",
      "| 45  | 2          | 8          | sleep      | 23.10    | 0.00     | 100.00   | 3.00     | 0.00         | 126.19       | 11.57    |\n",
      "| 45  | 3          | 8          | sleep      | 23.10    | 0.00     | 100.00   | 1.00     | 0.00         | 189.29       | 9.85     |\n",
      "| 45  | 4          | 8          | sleep      | 23.10    | 0.00     | 100.00   | 0.00     | 0.00         | 252.39       | 8.14     |\n",
      "| 45  | 5          | 8          | sleep      | 23.10    | 0.00     | 100.00   | 0.00     | 0.00         | 315.49       | 6.42     |\n",
      "| 45  | 6          | 8          | sleep      | 23.10    | 0.00     | 100.00   | 0.00     | 0.00         | 378.58       | 4.70     |\n",
      "| 45  | 7          | 0          | action     | 23.10    | 0.00     | 100.00   | 0.00     | 350.00       | 378.58       | 11.31    |\n",
      "| 45  | 8          | 0          | action     | 23.10    | 0.00     | 100.00   | 0.00     | 700.00       | 378.58       | 9.91     |\n",
      "| 45  | 9          | 6          | action     | 23.10    | 0.00     | 100.00   | 2.00     | 700.00       | 462.71       | 10.29    |\n",
      "| 45  | 10         | 6          | action     | 23.10    | 0.00     | 100.00   | 4.00     | 700.00       | 546.84       | 10.67    |\n",
      "| 45  | 11         | 8          | work       | 23.10    | 5.00     | 95.00    | 9.00     | 700.00       | 687.06       | 10.30    |\n",
      "| 45  | 12         | 8          | work       | 23.10    | 10.00    | 90.00    | 14.00    | 700.00       | 827.27       | 9.93     |\n",
      "| 45  | 13         | 0          | action     | 23.10    | 10.00    | 100.00   | 0.00     | 1050.00      | 827.27       | 8.53     |\n",
      "| 45  | 14         | 8          | work       | 23.10    | 15.00    | 95.00    | 5.00     | 1050.00      | 967.49       | 8.16     |\n",
      "| 45  | 15         | 8          | work       | 23.10    | 20.00    | 90.00    | 10.00    | 1050.00      | 1107.70      | 7.79     |\n",
      "| 45  | 16         | 8          | work       | 23.10    | 25.00    | 85.00    | 15.00    | 1050.00      | 1247.92      | 7.43     |\n",
      "| 45  | 17         | 8          | work       | 23.10    | 30.00    | 80.00    | 20.00    | 1050.00      | 1388.13      | 7.06     |\n",
      "| 45  | 18         | 8          | work       | 23.10    | 35.00    | 75.00    | 25.00    | 1050.00      | 1528.35      | 6.69     |\n",
      "| 45  | 19         | 6          | action     | 23.10    | 25.00    | 85.00    | 27.00    | 1050.00      | 1612.48      | 7.07     |\n",
      "| 45  | 20         | 6          | action     | 23.10    | 15.00    | 95.00    | 29.00    | 1050.00      | 1696.61      | 7.44     |\n",
      "| 45  | 21         | 0          | action     | 23.10    | 15.00    | 100.00   | 9.00     | 1400.00      | 1696.61      | 10.05    |\n",
      "| 45  | 22         | 6          | action     | 23.10    | 5.00     | 100.00   | 11.00    | 1400.00      | 1780.74      | 12.43    |\n",
      "| 45  | 23         | 8          | sleep      | 23.10    | 1.00     | 100.00   | 9.00     | 1400.00      | 1843.83      | 13.51    |\n",
      "| 46  | 0          | 8          | sleep      | 23.08    | 0.00     | 100.00   | 7.00     | 0.00         | 0.00         | 23.87    |\n",
      "| 46  | 1          | 8          | sleep      | 23.08    | 0.00     | 100.00   | 5.00     | 0.00         | 63.03        | 11.28    |\n",
      "| 46  | 2          | 8          | sleep      | 23.08    | 0.00     | 100.00   | 3.00     | 0.00         | 126.07       | 11.57    |\n",
      "| 46  | 3          | 8          | sleep      | 23.08    | 0.00     | 100.00   | 1.00     | 0.00         | 189.10       | 9.85     |\n",
      "| 46  | 4          | 8          | sleep      | 23.08    | 0.00     | 100.00   | 0.00     | 0.00         | 252.14       | 8.13     |\n",
      "| 46  | 5          | 8          | sleep      | 23.08    | 0.00     | 100.00   | 0.00     | 0.00         | 315.17       | 6.42     |\n",
      "| 46  | 6          | 8          | sleep      | 23.08    | 0.00     | 100.00   | 0.00     | 0.00         | 378.21       | 4.70     |\n",
      "| 46  | 7          | 0          | action     | 23.08    | 0.00     | 100.00   | 0.00     | 350.00       | 378.21       | 11.31    |\n",
      "| 46  | 8          | 0          | action     | 23.08    | 0.00     | 100.00   | 0.00     | 700.00       | 378.21       | 9.91     |\n",
      "| 46  | 9          | 6          | action     | 23.08    | 0.00     | 100.00   | 2.00     | 700.00       | 462.26       | 10.29    |\n",
      "| 46  | 10         | 6          | action     | 23.08    | 0.00     | 100.00   | 4.00     | 700.00       | 546.30       | 10.67    |\n",
      "| 46  | 11         | 8          | work       | 23.08    | 5.00     | 95.00    | 9.00     | 700.00       | 686.38       | 10.30    |\n",
      "| 46  | 12         | 8          | work       | 23.08    | 10.00    | 90.00    | 14.00    | 700.00       | 826.46       | 9.93     |\n",
      "| 46  | 13         | 0          | action     | 23.08    | 10.00    | 100.00   | 0.00     | 1050.00      | 826.46       | 8.53     |\n",
      "| 46  | 14         | 8          | work       | 23.08    | 15.00    | 95.00    | 5.00     | 1050.00      | 966.53       | 8.16     |\n",
      "| 46  | 15         | 8          | work       | 23.08    | 20.00    | 90.00    | 10.00    | 1050.00      | 1106.61      | 7.79     |\n",
      "| 46  | 16         | 8          | work       | 23.08    | 25.00    | 85.00    | 15.00    | 1050.00      | 1246.69      | 7.42     |\n",
      "| 46  | 17         | 8          | work       | 23.08    | 30.00    | 80.00    | 20.00    | 1050.00      | 1386.77      | 7.05     |\n",
      "| 46  | 18         | 8          | work       | 23.08    | 35.00    | 75.00    | 25.00    | 1050.00      | 1526.84      | 6.68     |\n",
      "| 46  | 19         | 6          | action     | 23.08    | 25.00    | 85.00    | 27.00    | 1050.00      | 1610.89      | 7.06     |\n",
      "| 46  | 20         | 6          | action     | 23.08    | 15.00    | 95.00    | 29.00    | 1050.00      | 1694.94      | 7.44     |\n",
      "| 46  | 21         | 0          | action     | 23.08    | 15.00    | 100.00   | 9.00     | 1400.00      | 1694.94      | 10.04    |\n",
      "| 46  | 22         | 6          | action     | 23.08    | 5.00     | 100.00   | 11.00    | 1400.00      | 1778.98      | 12.42    |\n",
      "| 46  | 23         | 8          | sleep      | 23.08    | 1.00     | 100.00   | 9.00     | 1400.00      | 1842.02      | 13.50    |\n",
      "| 47  | 0          | 8          | sleep      | 23.06    | 0.00     | 100.00   | 7.00     | 0.00         | 0.00         | 23.87    |\n",
      "| 47  | 1          | 8          | sleep      | 23.06    | 0.00     | 100.00   | 5.00     | 0.00         | 62.97        | 11.28    |\n",
      "| 47  | 2          | 8          | sleep      | 23.06    | 0.00     | 100.00   | 3.00     | 0.00         | 125.95       | 11.57    |\n",
      "| 47  | 3          | 8          | sleep      | 23.06    | 0.00     | 100.00   | 1.00     | 0.00         | 188.92       | 9.85     |\n",
      "| 47  | 4          | 8          | sleep      | 23.06    | 0.00     | 100.00   | 0.00     | 0.00         | 251.89       | 8.13     |\n",
      "| 47  | 5          | 8          | sleep      | 23.06    | 0.00     | 100.00   | 0.00     | 0.00         | 314.86       | 6.42     |\n",
      "| 47  | 6          | 8          | sleep      | 23.06    | 0.00     | 100.00   | 0.00     | 0.00         | 377.84       | 4.70     |\n",
      "| 47  | 7          | 0          | action     | 23.06    | 0.00     | 100.00   | 0.00     | 350.00       | 377.84       | 11.30    |\n",
      "| 47  | 8          | 0          | action     | 23.06    | 0.00     | 100.00   | 0.00     | 700.00       | 377.84       | 9.91     |\n",
      "| 47  | 9          | 6          | action     | 23.06    | 0.00     | 100.00   | 2.00     | 700.00       | 461.80       | 10.29    |\n",
      "| 47  | 10         | 6          | action     | 23.06    | 0.00     | 100.00   | 4.00     | 700.00       | 545.76       | 10.66    |\n",
      "| 47  | 11         | 8          | work       | 23.06    | 5.00     | 95.00    | 9.00     | 700.00       | 685.70       | 10.29    |\n",
      "| 47  | 12         | 8          | work       | 23.06    | 10.00    | 90.00    | 14.00    | 700.00       | 825.64       | 9.92     |\n",
      "| 47  | 13         | 0          | action     | 23.06    | 10.00    | 100.00   | 0.00     | 1050.00      | 825.64       | 8.53     |\n",
      "| 47  | 14         | 8          | work       | 23.06    | 15.00    | 95.00    | 5.00     | 1050.00      | 965.58       | 8.16     |\n",
      "| 47  | 15         | 8          | work       | 23.06    | 20.00    | 90.00    | 10.00    | 1050.00      | 1105.52      | 7.79     |\n",
      "| 47  | 16         | 8          | work       | 23.06    | 25.00    | 85.00    | 15.00    | 1050.00      | 1245.46      | 7.42     |\n",
      "| 47  | 17         | 8          | work       | 23.06    | 30.00    | 80.00    | 20.00    | 1050.00      | 1385.40      | 7.05     |\n",
      "| 47  | 18         | 8          | work       | 23.06    | 35.00    | 75.00    | 25.00    | 1050.00      | 1525.34      | 6.68     |\n",
      "| 47  | 19         | 6          | action     | 23.06    | 25.00    | 85.00    | 27.00    | 1050.00      | 1609.30      | 7.05     |\n",
      "| 47  | 20         | 0          | action     | 23.06    | 25.00    | 100.00   | 7.00     | 1400.00      | 1609.30      | 7.66     |\n",
      "| 47  | 21         | 6          | action     | 23.06    | 15.00    | 100.00   | 9.00     | 1400.00      | 1693.27      | 10.03    |\n",
      "| 47  | 22         | 6          | action     | 23.06    | 5.00     | 100.00   | 11.00    | 1400.00      | 1777.23      | 12.41    |\n",
      "| 47  | 23         | 8          | sleep      | 23.06    | 1.00     | 100.00   | 9.00     | 1400.00      | 1840.21      | 13.50    |\n",
      "| 48  | 0          | 8          | sleep      | 23.04    | 0.00     | 100.00   | 7.00     | 0.00         | 0.00         | 23.86    |\n",
      "| 48  | 1          | 8          | sleep      | 23.04    | 0.00     | 100.00   | 5.00     | 0.00         | 62.91        | 11.28    |\n",
      "| 48  | 2          | 8          | sleep      | 23.04    | 0.00     | 100.00   | 3.00     | 0.00         | 125.82       | 9.57     |\n",
      "| 48  | 3          | 8          | sleep      | 23.04    | 0.00     | 100.00   | 1.00     | 0.00         | 188.73       | 7.85     |\n",
      "| 48  | 4          | 8          | sleep      | 23.04    | 0.00     | 100.00   | 0.00     | 0.00         | 251.64       | 6.13     |\n",
      "| 48  | 5          | 8          | sleep      | 23.04    | 0.00     | 100.00   | 0.00     | 0.00         | 314.56       | 4.42     |\n",
      "| 48  | 6          | 8          | sleep      | 23.04    | 0.00     | 100.00   | 0.00     | 0.00         | 377.47       | 2.70     |\n",
      "| 48  | 7          | 0          | action     | 23.04    | 0.00     | 100.00   | 0.00     | 350.00       | 377.47       | 11.30    |\n",
      "| 48  | 8          | 0          | action     | 23.04    | 0.00     | 100.00   | 0.00     | 700.00       | 377.47       | 9.91     |\n",
      "| 48  | 9          | 6          | action     | 23.04    | 0.00     | 100.00   | 2.00     | 700.00       | 461.35       | 10.28    |\n",
      "| 48  | 10         | 6          | action     | 23.04    | 0.00     | 100.00   | 4.00     | 700.00       | 545.23       | 10.66    |\n",
      "| 48  | 11         | 8          | work       | 23.04    | 5.00     | 95.00    | 9.00     | 700.00       | 685.03       | 10.29    |\n",
      "| 48  | 12         | 8          | work       | 23.04    | 10.00    | 90.00    | 14.00    | 700.00       | 824.83       | 9.92     |\n",
      "| 48  | 13         | 0          | action     | 23.04    | 10.00    | 100.00   | 0.00     | 1050.00      | 824.83       | 8.52     |\n",
      "| 48  | 14         | 8          | work       | 23.04    | 15.00    | 95.00    | 5.00     | 1050.00      | 964.64       | 8.15     |\n",
      "| 48  | 15         | 8          | work       | 23.04    | 20.00    | 90.00    | 10.00    | 1050.00      | 1104.44      | 7.78     |\n",
      "| 48  | 16         | 8          | work       | 23.04    | 25.00    | 85.00    | 15.00    | 1050.00      | 1244.24      | 7.41     |\n",
      "| 48  | 17         | 8          | work       | 23.04    | 30.00    | 80.00    | 20.00    | 1050.00      | 1384.04      | 7.04     |\n",
      "| 48  | 18         | 8          | work       | 23.04    | 35.00    | 75.00    | 25.00    | 1050.00      | 1523.85      | 6.67     |\n",
      "| 48  | 19         | 6          | action     | 23.04    | 25.00    | 85.00    | 27.00    | 1050.00      | 1607.73      | 7.05     |\n",
      "| 48  | 20         | 0          | action     | 23.04    | 25.00    | 100.00   | 7.00     | 1400.00      | 1607.73      | 7.65     |\n",
      "| 48  | 21         | 6          | action     | 23.04    | 15.00    | 100.00   | 9.00     | 1400.00      | 1691.61      | 10.03    |\n",
      "| 48  | 22         | 6          | action     | 23.04    | 5.00     | 100.00   | 11.00    | 1400.00      | 1775.49      | 12.41    |\n",
      "| 48  | 23         | 8          | sleep      | 23.04    | 1.00     | 100.00   | 9.00     | 1400.00      | 1838.40      | 13.49    |\n",
      "| 49  | 0          | 8          | sleep      | 23.01    | 0.00     | 100.00   | 7.00     | 0.00         | 0.00         | 23.86    |\n",
      "| 49  | 1          | 8          | sleep      | 23.01    | 0.00     | 100.00   | 5.00     | 0.00         | 62.85        | 11.28    |\n",
      "| 49  | 2          | 8          | sleep      | 23.01    | 0.00     | 100.00   | 3.00     | 0.00         | 125.70       | 9.57     |\n",
      "| 49  | 3          | 8          | sleep      | 23.01    | 0.00     | 100.00   | 1.00     | 0.00         | 188.55       | 7.85     |\n",
      "| 49  | 4          | 8          | sleep      | 23.01    | 0.00     | 100.00   | 0.00     | 0.00         | 251.40       | 6.13     |\n",
      "| 49  | 5          | 8          | sleep      | 23.01    | 0.00     | 100.00   | 0.00     | 0.00         | 314.25       | 4.41     |\n",
      "| 49  | 6          | 8          | sleep      | 23.01    | 0.00     | 100.00   | 0.00     | 0.00         | 377.10       | 2.70     |\n",
      "| 49  | 7          | 0          | action     | 23.01    | 0.00     | 100.00   | 0.00     | 350.00       | 377.10       | 11.30    |\n",
      "| 49  | 8          | 0          | action     | 23.01    | 0.00     | 100.00   | 0.00     | 700.00       | 377.10       | 9.90     |\n",
      "| 49  | 9          | 6          | action     | 23.01    | 0.00     | 100.00   | 2.00     | 700.00       | 460.90       | 10.28    |\n",
      "| 49  | 10         | 6          | action     | 23.01    | 0.00     | 100.00   | 4.00     | 700.00       | 544.70       | 10.66    |\n",
      "| 49  | 11         | 8          | work       | 23.01    | 5.00     | 95.00    | 9.00     | 700.00       | 684.36       | 10.29    |\n",
      "| 49  | 12         | 8          | work       | 23.01    | 10.00    | 90.00    | 14.00    | 700.00       | 824.03       | 9.92     |\n",
      "| 49  | 13         | 0          | action     | 23.01    | 10.00    | 100.00   | 0.00     | 1050.00      | 824.03       | 8.52     |\n",
      "| 49  | 14         | 8          | work       | 23.01    | 15.00    | 95.00    | 5.00     | 1050.00      | 963.69       | 8.15     |\n",
      "| 49  | 15         | 8          | work       | 23.01    | 20.00    | 90.00    | 10.00    | 1050.00      | 1103.36      | 7.78     |\n",
      "| 49  | 16         | 8          | work       | 23.01    | 25.00    | 85.00    | 15.00    | 1050.00      | 1243.02      | 7.41     |\n",
      "| 49  | 17         | 8          | work       | 23.01    | 30.00    | 80.00    | 20.00    | 1050.00      | 1382.69      | 7.03     |\n",
      "| 49  | 18         | 8          | work       | 23.01    | 35.00    | 75.00    | 25.00    | 1050.00      | 1522.36      | 6.66     |\n",
      "| 49  | 19         | 6          | action     | 23.01    | 25.00    | 85.00    | 27.00    | 1050.00      | 1606.15      | 7.04     |\n",
      "| 49  | 20         | 0          | action     | 23.01    | 25.00    | 100.00   | 7.00     | 1400.00      | 1606.15      | 7.64     |\n",
      "| 49  | 21         | 6          | action     | 23.01    | 15.00    | 100.00   | 9.00     | 1400.00      | 1689.95      | 10.02    |\n",
      "| 49  | 22         | 6          | action     | 23.01    | 5.00     | 100.00   | 11.00    | 1400.00      | 1773.75      | 12.40    |\n",
      "| 49  | 23         | 8          | sleep      | 23.01    | 1.00     | 100.00   | 9.00     | 1400.00      | 1836.60      | 13.48    |\n",
      "| 50  | 0          | 8          | sleep      | 22.99    | 0.00     | 100.00   | 7.00     | 0.00         | 0.00         | 23.85    |\n",
      "| 50  | 1          | 8          | sleep      | 22.99    | 0.00     | 100.00   | 5.00     | 0.00         | 62.79        | 11.28    |\n",
      "| 50  | 2          | 8          | sleep      | 22.99    | 0.00     | 100.00   | 3.00     | 0.00         | 125.58       | 9.57     |\n",
      "| 50  | 3          | 8          | sleep      | 22.99    | 0.00     | 100.00   | 1.00     | 0.00         | 188.36       | 7.85     |\n",
      "| 50  | 4          | 8          | sleep      | 22.99    | 0.00     | 100.00   | 0.00     | 0.00         | 251.15       | 6.13     |\n",
      "| 50  | 5          | 8          | sleep      | 22.99    | 0.00     | 100.00   | 0.00     | 0.00         | 313.94       | 4.41     |\n",
      "| 50  | 6          | 8          | sleep      | 22.99    | 0.00     | 100.00   | 0.00     | 0.00         | 376.73       | 2.70     |\n",
      "| 50  | 7          | 0          | action     | 22.99    | 0.00     | 100.00   | 0.00     | 350.00       | 376.73       | 11.30    |\n",
      "| 50  | 8          | 0          | action     | 22.99    | 0.00     | 100.00   | 0.00     | 700.00       | 376.73       | 9.90     |\n",
      "| 50  | 9          | 6          | action     | 22.99    | 0.00     | 100.00   | 2.00     | 700.00       | 460.45       | 10.28    |\n",
      "| 50  | 10         | 6          | action     | 22.99    | 0.00     | 100.00   | 4.00     | 700.00       | 544.16       | 10.66    |\n",
      "| 50  | 11         | 8          | work       | 22.99    | 5.00     | 95.00    | 9.00     | 700.00       | 683.69       | 10.28    |\n",
      "| 50  | 12         | 8          | work       | 22.99    | 10.00    | 90.00    | 14.00    | 700.00       | 823.22       | 9.91     |\n",
      "| 50  | 13         | 0          | action     | 22.99    | 10.00    | 100.00   | 0.00     | 1050.00      | 823.22       | 8.52     |\n",
      "| 50  | 14         | 8          | work       | 22.99    | 15.00    | 95.00    | 5.00     | 1050.00      | 962.75       | 8.14     |\n",
      "| 50  | 15         | 8          | work       | 22.99    | 20.00    | 90.00    | 10.00    | 1050.00      | 1102.28      | 7.77     |\n",
      "| 50  | 16         | 8          | work       | 22.99    | 25.00    | 85.00    | 15.00    | 1050.00      | 1241.81      | 7.40     |\n",
      "| 50  | 17         | 8          | work       | 22.99    | 30.00    | 80.00    | 20.00    | 1050.00      | 1381.34      | 7.03     |\n",
      "| 50  | 18         | 8          | work       | 22.99    | 35.00    | 75.00    | 25.00    | 1050.00      | 1520.87      | 6.66     |\n",
      "| 50  | 19         | 6          | action     | 22.99    | 25.00    | 85.00    | 27.00    | 1050.00      | 1604.59      | 7.03     |\n",
      "| 50  | 20         | 0          | action     | 22.99    | 25.00    | 100.00   | 7.00     | 1400.00      | 1604.59      | 7.64     |\n",
      "| 50  | 21         | 6          | action     | 22.99    | 15.00    | 100.00   | 9.00     | 1400.00      | 1688.31      | 10.01    |\n",
      "| 50  | 22         | 6          | action     | 22.99    | 5.00     | 100.00   | 11.00    | 1400.00      | 1772.02      | 12.39    |\n",
      "| 50  | 23         | 8          | sleep      | 22.99    | 1.00     | 100.00   | 9.00     | 1400.00      | 1834.81      | 13.47    |\n",
      "| 51  | 0          | 8          | sleep      | 22.97    | 0.00     | 100.00   | 7.00     | 0.00         | 0.00         | 23.84    |\n",
      "| 51  | 1          | 8          | sleep      | 22.97    | 0.00     | 100.00   | 5.00     | 0.00         | 62.73        | 11.28    |\n",
      "| 51  | 2          | 8          | sleep      | 22.97    | 0.00     | 100.00   | 3.00     | 0.00         | 125.45       | 9.56     |\n",
      "| 51  | 3          | 8          | sleep      | 22.97    | 0.00     | 100.00   | 1.00     | 0.00         | 188.18       | 7.85     |\n",
      "| 51  | 4          | 8          | sleep      | 22.97    | 0.00     | 100.00   | 0.00     | 0.00         | 250.91       | 6.13     |\n",
      "| 51  | 5          | 8          | sleep      | 22.97    | 0.00     | 100.00   | 0.00     | 0.00         | 313.64       | 4.41     |\n",
      "| 51  | 6          | 8          | sleep      | 22.97    | 0.00     | 100.00   | 0.00     | 0.00         | 376.36       | 2.69     |\n",
      "| 51  | 7          | 0          | action     | 22.97    | 0.00     | 100.00   | 0.00     | 350.00       | 376.36       | 11.30    |\n",
      "| 51  | 8          | 0          | action     | 22.97    | 0.00     | 100.00   | 0.00     | 700.00       | 376.36       | 9.90     |\n",
      "| 51  | 9          | 6          | action     | 22.97    | 0.00     | 100.00   | 2.00     | 700.00       | 460.00       | 10.28    |\n",
      "| 51  | 10         | 6          | action     | 22.97    | 0.00     | 100.00   | 4.00     | 700.00       | 543.64       | 10.65    |\n",
      "| 51  | 11         | 8          | work       | 22.97    | 5.00     | 95.00    | 9.00     | 700.00       | 683.03       | 10.28    |\n",
      "| 51  | 12         | 8          | work       | 22.97    | 10.00    | 90.00    | 14.00    | 700.00       | 822.42       | 9.91     |\n",
      "| 51  | 13         | 0          | action     | 22.97    | 10.00    | 100.00   | 0.00     | 1050.00      | 822.42       | 8.51     |\n",
      "| 51  | 14         | 8          | work       | 22.97    | 15.00    | 95.00    | 5.00     | 1050.00      | 961.82       | 8.14     |\n",
      "| 51  | 15         | 8          | work       | 22.97    | 20.00    | 90.00    | 10.00    | 1050.00      | 1101.21      | 7.77     |\n",
      "| 51  | 16         | 8          | work       | 22.97    | 25.00    | 85.00    | 15.00    | 1050.00      | 1240.60      | 7.40     |\n",
      "| 51  | 17         | 8          | work       | 22.97    | 30.00    | 80.00    | 20.00    | 1050.00      | 1380.00      | 7.02     |\n",
      "| 51  | 18         | 8          | work       | 22.97    | 35.00    | 75.00    | 25.00    | 1050.00      | 1519.39      | 6.65     |\n",
      "| 51  | 19         | 0          | action     | 22.97    | 35.00    | 95.00    | 5.00     | 1400.00      | 1519.39      | 5.25     |\n",
      "| 51  | 20         | 6          | action     | 22.97    | 25.00    | 100.00   | 7.00     | 1400.00      | 1603.03      | 7.63     |\n",
      "| 51  | 21         | 6          | action     | 22.97    | 15.00    | 100.00   | 9.00     | 1400.00      | 1686.66      | 10.01    |\n",
      "| 51  | 22         | 6          | action     | 22.97    | 5.00     | 100.00   | 11.00    | 1400.00      | 1770.30      | 12.38    |\n",
      "| 51  | 23         | 8          | sleep      | 22.97    | 1.00     | 100.00   | 9.00     | 1400.00      | 1833.03      | 13.47    |\n",
      "| 52  | 0          | 8          | sleep      | 22.95    | 0.00     | 100.00   | 7.00     | 0.00         | 0.00         | 23.84    |\n",
      "| 52  | 1          | 8          | sleep      | 22.95    | 0.00     | 100.00   | 5.00     | 0.00         | 62.67        | 9.28     |\n",
      "| 52  | 2          | 8          | sleep      | 22.95    | 0.00     | 100.00   | 3.00     | 0.00         | 125.33       | 7.56     |\n",
      "| 52  | 3          | 8          | sleep      | 22.95    | 0.00     | 100.00   | 1.00     | 0.00         | 188.00       | 5.85     |\n",
      "| 52  | 4          | 8          | sleep      | 22.95    | 0.00     | 100.00   | 0.00     | 0.00         | 250.67       | 4.13     |\n",
      "| 52  | 5          | 8          | sleep      | 22.95    | 0.00     | 100.00   | 0.00     | 0.00         | 313.33       | 2.41     |\n",
      "| 52  | 6          | 8          | sleep      | 22.95    | 0.00     | 100.00   | 0.00     | 0.00         | 376.00       | 0.69     |\n",
      "| 52  | 7          | 0          | action     | 22.95    | 0.00     | 100.00   | 0.00     | 350.00       | 376.00       | 11.30    |\n",
      "| 52  | 8          | 0          | action     | 22.95    | 0.00     | 100.00   | 0.00     | 700.00       | 376.00       | 9.90     |\n",
      "| 52  | 9          | 6          | action     | 22.95    | 0.00     | 100.00   | 2.00     | 700.00       | 459.55       | 10.28    |\n",
      "| 52  | 10         | 6          | action     | 22.95    | 0.00     | 100.00   | 4.00     | 700.00       | 543.11       | 10.65    |\n",
      "| 52  | 11         | 8          | work       | 22.95    | 5.00     | 95.00    | 9.00     | 700.00       | 682.37       | 10.28    |\n",
      "| 52  | 12         | 8          | work       | 22.95    | 10.00    | 90.00    | 14.00    | 700.00       | 821.63       | 9.91     |\n",
      "| 52  | 13         | 0          | action     | 22.95    | 10.00    | 100.00   | 0.00     | 1050.00      | 821.63       | 8.51     |\n",
      "| 52  | 14         | 8          | work       | 22.95    | 15.00    | 95.00    | 5.00     | 1050.00      | 960.88       | 8.14     |\n",
      "| 52  | 15         | 8          | work       | 22.95    | 20.00    | 90.00    | 10.00    | 1050.00      | 1100.14      | 7.76     |\n",
      "| 52  | 16         | 8          | work       | 22.95    | 25.00    | 85.00    | 15.00    | 1050.00      | 1239.40      | 7.39     |\n",
      "| 52  | 17         | 8          | work       | 22.95    | 30.00    | 80.00    | 20.00    | 1050.00      | 1378.66      | 7.02     |\n",
      "| 52  | 18         | 8          | work       | 22.95    | 35.00    | 75.00    | 25.00    | 1050.00      | 1517.92      | 6.64     |\n",
      "| 52  | 19         | 0          | action     | 22.95    | 35.00    | 95.00    | 5.00     | 1400.00      | 1517.92      | 5.25     |\n",
      "| 52  | 20         | 6          | action     | 22.95    | 25.00    | 100.00   | 7.00     | 1400.00      | 1601.47      | 7.62     |\n",
      "| 52  | 21         | 6          | action     | 22.95    | 15.00    | 100.00   | 9.00     | 1400.00      | 1685.03      | 10.00    |\n",
      "| 52  | 22         | 6          | action     | 22.95    | 5.00     | 100.00   | 11.00    | 1400.00      | 1768.58      | 12.38    |\n",
      "| 52  | 23         | 8          | sleep      | 22.95    | 1.00     | 100.00   | 9.00     | 1400.00      | 1831.25      | 13.46    |\n",
      "| 53  | 0          | 8          | sleep      | 22.92    | 0.00     | 100.00   | 7.00     | 0.00         | 0.00         | 23.83    |\n",
      "| 53  | 1          | 8          | sleep      | 22.92    | 0.00     | 100.00   | 5.00     | 0.00         | 62.61        | 9.28     |\n",
      "| 53  | 2          | 8          | sleep      | 22.92    | 0.00     | 100.00   | 3.00     | 0.00         | 125.21       | 7.56     |\n",
      "| 53  | 3          | 8          | sleep      | 22.92    | 0.00     | 100.00   | 1.00     | 0.00         | 187.82       | 5.85     |\n",
      "| 53  | 4          | 8          | sleep      | 22.92    | 0.00     | 100.00   | 0.00     | 0.00         | 250.42       | 4.13     |\n",
      "| 53  | 5          | 8          | sleep      | 22.92    | 0.00     | 100.00   | 0.00     | 0.00         | 313.03       | 2.41     |\n",
      "| 53  | 6          | 8          | sleep      | 22.92    | 0.00     | 100.00   | 0.00     | 0.00         | 375.63       | 0.69     |\n",
      "| 53  | 7          | 0          | action     | 22.92    | 0.00     | 100.00   | 0.00     | 350.00       | 375.63       | 11.29    |\n",
      "| 53  | 8          | 0          | action     | 22.92    | 0.00     | 100.00   | 0.00     | 700.00       | 375.63       | 9.90     |\n",
      "| 53  | 9          | 6          | action     | 22.92    | 0.00     | 100.00   | 2.00     | 700.00       | 459.11       | 10.28    |\n",
      "| 53  | 10         | 6          | action     | 22.92    | 0.00     | 100.00   | 4.00     | 700.00       | 542.58       | 10.65    |\n",
      "| 53  | 11         | 8          | work       | 22.92    | 5.00     | 95.00    | 9.00     | 700.00       | 681.71       | 10.28    |\n",
      "| 53  | 12         | 8          | work       | 22.92    | 10.00    | 90.00    | 14.00    | 700.00       | 820.83       | 9.90     |\n",
      "| 53  | 13         | 0          | action     | 22.92    | 10.00    | 100.00   | 0.00     | 1050.00      | 820.83       | 8.51     |\n",
      "| 53  | 14         | 8          | work       | 22.92    | 15.00    | 95.00    | 5.00     | 1050.00      | 959.95       | 8.13     |\n",
      "| 53  | 15         | 8          | work       | 22.92    | 20.00    | 90.00    | 10.00    | 1050.00      | 1099.08      | 7.76     |\n",
      "| 53  | 16         | 8          | work       | 22.92    | 25.00    | 85.00    | 15.00    | 1050.00      | 1238.20      | 7.39     |\n",
      "| 53  | 17         | 8          | work       | 22.92    | 30.00    | 80.00    | 20.00    | 1050.00      | 1377.33      | 7.01     |\n",
      "| 53  | 18         | 8          | work       | 22.92    | 35.00    | 75.00    | 25.00    | 1050.00      | 1516.45      | 6.64     |\n",
      "| 53  | 19         | 0          | action     | 22.92    | 35.00    | 95.00    | 5.00     | 1400.00      | 1516.45      | 5.24     |\n",
      "| 53  | 20         | 6          | action     | 22.92    | 25.00    | 100.00   | 7.00     | 1400.00      | 1599.92      | 7.62     |\n",
      "| 53  | 21         | 6          | action     | 22.92    | 15.00    | 100.00   | 9.00     | 1400.00      | 1683.40      | 9.99     |\n",
      "| 53  | 22         | 6          | action     | 22.92    | 5.00     | 100.00   | 11.00    | 1400.00      | 1766.87      | 12.37    |\n",
      "| 53  | 23         | 8          | sleep      | 22.92    | 1.00     | 100.00   | 9.00     | 1400.00      | 1829.48      | 13.45    |\n",
      "| 54  | 0          | 8          | sleep      | 22.90    | 0.00     | 100.00   | 7.00     | 0.00         | 0.00         | 23.83    |\n",
      "| 54  | 1          | 8          | sleep      | 22.90    | 0.00     | 100.00   | 5.00     | 0.00         | 62.55        | 9.28     |\n",
      "| 54  | 2          | 8          | sleep      | 22.90    | 0.00     | 100.00   | 3.00     | 0.00         | 125.09       | 7.56     |\n",
      "| 54  | 3          | 8          | sleep      | 22.90    | 0.00     | 100.00   | 1.00     | 0.00         | 187.64       | 5.84     |\n",
      "| 54  | 4          | 8          | sleep      | 22.90    | 0.00     | 100.00   | 0.00     | 0.00         | 250.18       | 4.13     |\n",
      "| 54  | 5          | 8          | sleep      | 22.90    | 0.00     | 100.00   | 0.00     | 0.00         | 312.73       | 2.41     |\n",
      "| 54  | 6          | 8          | sleep      | 22.90    | 0.00     | 100.00   | 0.00     | 0.00         | 375.27       | 0.69     |\n",
      "| 54  | 7          | 0          | action     | 22.90    | 0.00     | 100.00   | 0.00     | 350.00       | 375.27       | 11.29    |\n",
      "| 54  | 8          | 0          | action     | 22.90    | 0.00     | 100.00   | 0.00     | 700.00       | 375.27       | 9.90     |\n",
      "| 54  | 9          | 6          | action     | 22.90    | 0.00     | 100.00   | 2.00     | 700.00       | 458.67       | 10.27    |\n",
      "| 54  | 10         | 6          | action     | 22.90    | 0.00     | 100.00   | 4.00     | 700.00       | 542.06       | 10.65    |\n",
      "| 54  | 11         | 8          | work       | 22.90    | 5.00     | 95.00    | 9.00     | 700.00       | 681.05       | 10.27    |\n",
      "| 54  | 12         | 8          | work       | 22.90    | 10.00    | 90.00    | 14.00    | 700.00       | 820.04       | 9.90     |\n",
      "| 54  | 13         | 0          | action     | 22.90    | 10.00    | 100.00   | 0.00     | 1050.00      | 820.04       | 8.50     |\n",
      "| 54  | 14         | 8          | work       | 22.90    | 15.00    | 95.00    | 5.00     | 1050.00      | 959.03       | 8.13     |\n",
      "| 54  | 15         | 8          | work       | 22.90    | 20.00    | 90.00    | 10.00    | 1050.00      | 1098.02      | 7.76     |\n",
      "| 54  | 16         | 8          | work       | 22.90    | 25.00    | 85.00    | 15.00    | 1050.00      | 1237.01      | 7.38     |\n",
      "| 54  | 17         | 8          | work       | 22.90    | 30.00    | 80.00    | 20.00    | 1050.00      | 1376.00      | 7.01     |\n",
      "| 54  | 18         | 8          | work       | 22.90    | 35.00    | 75.00    | 25.00    | 1050.00      | 1514.99      | 6.63     |\n",
      "| 54  | 19         | 0          | action     | 22.90    | 35.00    | 95.00    | 5.00     | 1400.00      | 1514.99      | 5.24     |\n",
      "| 54  | 20         | 6          | action     | 22.90    | 25.00    | 100.00   | 7.00     | 1400.00      | 1598.38      | 7.61     |\n",
      "| 54  | 21         | 6          | action     | 22.90    | 15.00    | 100.00   | 9.00     | 1400.00      | 1681.77      | 9.99     |\n",
      "| 54  | 22         | 6          | action     | 22.90    | 5.00     | 100.00   | 11.00    | 1400.00      | 1765.17      | 12.36    |\n",
      "| 54  | 23         | 8          | sleep      | 22.90    | 1.00     | 100.00   | 9.00     | 1400.00      | 1827.71      | 13.44    |\n",
      "| 55  | 0          | 8          | sleep      | 22.88    | 0.00     | 100.00   | 7.00     | 0.00         | 0.00         | 23.82    |\n",
      "| 55  | 1          | 8          | sleep      | 22.88    | 0.00     | 100.00   | 5.00     | 0.00         | 62.49        | 9.28     |\n",
      "| 55  | 2          | 8          | sleep      | 22.88    | 0.00     | 100.00   | 3.00     | 0.00         | 124.97       | 7.56     |\n",
      "| 55  | 3          | 8          | sleep      | 22.88    | 0.00     | 100.00   | 1.00     | 0.00         | 187.46       | 5.84     |\n",
      "| 55  | 4          | 8          | sleep      | 22.88    | 0.00     | 100.00   | 0.00     | 0.00         | 249.94       | 4.12     |\n",
      "| 55  | 5          | 8          | sleep      | 22.88    | 0.00     | 100.00   | 0.00     | 0.00         | 312.43       | 2.41     |\n",
      "| 55  | 6          | 8          | sleep      | 22.88    | 0.00     | 100.00   | 0.00     | 0.00         | 374.91       | 0.69     |\n",
      "| 55  | 7          | 0          | action     | 22.88    | 0.00     | 100.00   | 0.00     | 350.00       | 374.91       | 11.29    |\n",
      "| 55  | 8          | 0          | action     | 22.88    | 0.00     | 100.00   | 0.00     | 700.00       | 374.91       | 9.90     |\n",
      "| 55  | 9          | 6          | action     | 22.88    | 0.00     | 100.00   | 2.00     | 700.00       | 458.22       | 10.27    |\n",
      "| 55  | 10         | 6          | action     | 22.88    | 0.00     | 100.00   | 4.00     | 700.00       | 541.54       | 10.65    |\n",
      "| 55  | 11         | 8          | work       | 22.88    | 5.00     | 95.00    | 9.00     | 700.00       | 680.39       | 10.27    |\n",
      "| 55  | 12         | 8          | work       | 22.88    | 10.00    | 90.00    | 14.00    | 700.00       | 819.25       | 9.90     |\n",
      "| 55  | 13         | 0          | action     | 22.88    | 10.00    | 100.00   | 0.00     | 1050.00      | 819.25       | 8.50     |\n",
      "| 55  | 14         | 8          | work       | 22.88    | 15.00    | 95.00    | 5.00     | 1050.00      | 958.11       | 8.13     |\n",
      "| 55  | 15         | 8          | work       | 22.88    | 20.00    | 90.00    | 10.00    | 1050.00      | 1096.96      | 7.75     |\n",
      "| 55  | 16         | 8          | work       | 22.88    | 25.00    | 85.00    | 15.00    | 1050.00      | 1235.82      | 7.38     |\n",
      "| 55  | 17         | 8          | work       | 22.88    | 30.00    | 80.00    | 20.00    | 1050.00      | 1374.67      | 7.00     |\n",
      "| 55  | 18         | 8          | work       | 22.88    | 35.00    | 75.00    | 25.00    | 1050.00      | 1513.53      | 6.63     |\n",
      "| 55  | 19         | 0          | action     | 22.88    | 35.00    | 95.00    | 5.00     | 1400.00      | 1513.53      | 5.23     |\n",
      "| 55  | 20         | 6          | action     | 22.88    | 25.00    | 100.00   | 7.00     | 1400.00      | 1596.84      | 7.61     |\n",
      "| 55  | 21         | 6          | action     | 22.88    | 15.00    | 100.00   | 9.00     | 1400.00      | 1680.16      | 9.98     |\n",
      "| 55  | 22         | 6          | action     | 22.88    | 5.00     | 100.00   | 11.00    | 1400.00      | 1763.47      | 12.35    |\n",
      "| 55  | 23         | 8          | sleep      | 22.88    | 1.00     | 100.00   | 9.00     | 1400.00      | 1825.95      | 13.44    |\n",
      "| 56  | 0          | 8          | sleep      | 22.86    | 0.00     | 100.00   | 7.00     | 0.00         | 0.00         | 23.82    |\n",
      "| 56  | 1          | 8          | sleep      | 22.86    | 0.00     | 100.00   | 5.00     | 0.00         | 62.43        | 9.28     |\n",
      "| 56  | 2          | 8          | sleep      | 22.86    | 0.00     | 100.00   | 3.00     | 0.00         | 124.85       | 7.56     |\n",
      "| 56  | 3          | 8          | sleep      | 22.86    | 0.00     | 100.00   | 1.00     | 0.00         | 187.28       | 5.84     |\n",
      "| 56  | 4          | 8          | sleep      | 22.86    | 0.00     | 100.00   | 0.00     | 0.00         | 249.70       | 4.12     |\n",
      "| 56  | 5          | 8          | sleep      | 22.86    | 0.00     | 100.00   | 0.00     | 0.00         | 312.13       | 2.40     |\n",
      "| 56  | 6          | 8          | sleep      | 22.86    | 0.00     | 100.00   | 0.00     | 0.00         | 374.55       | 0.69     |\n",
      "| 56  | 7          | 0          | action     | 22.86    | 0.00     | 100.00   | 0.00     | 350.00       | 374.55       | 11.29    |\n",
      "| 56  | 8          | 0          | action     | 22.86    | 0.00     | 100.00   | 0.00     | 700.00       | 374.55       | 9.90     |\n",
      "| 56  | 9          | 6          | action     | 22.86    | 0.00     | 100.00   | 2.00     | 700.00       | 457.78       | 10.27    |\n",
      "| 56  | 10         | 6          | action     | 22.86    | 0.00     | 100.00   | 4.00     | 700.00       | 541.02       | 10.64    |\n",
      "| 56  | 11         | 8          | work       | 22.86    | 5.00     | 95.00    | 9.00     | 700.00       | 679.74       | 10.27    |\n",
      "| 56  | 12         | 8          | work       | 22.86    | 10.00    | 90.00    | 14.00    | 700.00       | 818.46       | 9.89     |\n",
      "| 56  | 13         | 0          | action     | 22.86    | 10.00    | 100.00   | 0.00     | 1050.00      | 818.46       | 8.50     |\n",
      "| 56  | 14         | 8          | work       | 22.86    | 15.00    | 95.00    | 5.00     | 1050.00      | 957.19       | 8.12     |\n",
      "| 56  | 15         | 8          | work       | 22.86    | 20.00    | 90.00    | 10.00    | 1050.00      | 1095.91      | 7.75     |\n",
      "| 56  | 16         | 8          | work       | 22.86    | 25.00    | 85.00    | 15.00    | 1050.00      | 1234.63      | 7.37     |\n",
      "| 56  | 17         | 8          | work       | 22.86    | 30.00    | 80.00    | 20.00    | 1050.00      | 1373.35      | 6.99     |\n",
      "| 56  | 18         | 8          | work       | 22.86    | 35.00    | 75.00    | 25.00    | 1050.00      | 1512.08      | 6.62     |\n",
      "| 56  | 19         | 0          | action     | 22.86    | 35.00    | 95.00    | 5.00     | 1400.00      | 1512.08      | 5.22     |\n",
      "| 56  | 20         | 6          | action     | 22.86    | 25.00    | 100.00   | 7.00     | 1400.00      | 1595.31      | 7.60     |\n",
      "| 56  | 21         | 6          | action     | 22.86    | 15.00    | 100.00   | 9.00     | 1400.00      | 1678.54      | 9.97     |\n",
      "| 56  | 22         | 6          | action     | 22.86    | 5.00     | 100.00   | 11.00    | 1400.00      | 1761.78      | 12.35    |\n",
      "| 56  | 23         | 8          | sleep      | 22.86    | 1.00     | 100.00   | 9.00     | 1400.00      | 1824.20      | 13.43    |\n",
      "| 57  | 0          | 8          | sleep      | 22.84    | 0.00     | 100.00   | 7.00     | 0.00         | 0.00         | 23.81    |\n",
      "| 57  | 1          | 8          | sleep      | 22.84    | 0.00     | 100.00   | 5.00     | 0.00         | 62.37        | 9.28     |\n",
      "| 57  | 2          | 8          | sleep      | 22.84    | 0.00     | 100.00   | 3.00     | 0.00         | 124.73       | 7.56     |\n",
      "| 57  | 3          | 8          | sleep      | 22.84    | 0.00     | 100.00   | 1.00     | 0.00         | 187.10       | 5.84     |\n",
      "| 57  | 4          | 8          | sleep      | 22.84    | 0.00     | 100.00   | 0.00     | 0.00         | 249.46       | 4.12     |\n",
      "| 57  | 5          | 8          | sleep      | 22.84    | 0.00     | 100.00   | 0.00     | 0.00         | 311.83       | 2.40     |\n",
      "| 57  | 6          | 8          | sleep      | 22.84    | 0.00     | 100.00   | 0.00     | 0.00         | 374.19       | 0.68     |\n",
      "| 57  | 7          | 0          | action     | 22.84    | 0.00     | 100.00   | 0.00     | 350.00       | 374.19       | 11.29    |\n",
      "| 57  | 8          | 0          | action     | 22.84    | 0.00     | 100.00   | 0.00     | 700.00       | 374.19       | 9.89     |\n",
      "| 57  | 9          | 6          | action     | 22.84    | 0.00     | 100.00   | 2.00     | 700.00       | 457.35       | 10.27    |\n",
      "| 57  | 10         | 6          | action     | 22.84    | 0.00     | 100.00   | 4.00     | 700.00       | 540.50       | 10.64    |\n",
      "| 57  | 11         | 8          | work       | 22.84    | 5.00     | 95.00    | 9.00     | 700.00       | 679.09       | 10.27    |\n",
      "| 57  | 12         | 8          | work       | 22.84    | 10.00    | 90.00    | 14.00    | 700.00       | 817.68       | 9.89     |\n",
      "| 57  | 13         | 0          | action     | 22.84    | 10.00    | 100.00   | 0.00     | 1050.00      | 817.68       | 8.49     |\n",
      "| 57  | 14         | 8          | work       | 22.84    | 15.00    | 95.00    | 5.00     | 1050.00      | 956.27       | 8.12     |\n",
      "| 57  | 15         | 8          | work       | 22.84    | 20.00    | 90.00    | 10.00    | 1050.00      | 1094.86      | 7.74     |\n",
      "| 57  | 16         | 8          | work       | 22.84    | 25.00    | 85.00    | 15.00    | 1050.00      | 1233.45      | 7.37     |\n",
      "| 57  | 17         | 8          | work       | 22.84    | 30.00    | 80.00    | 20.00    | 1050.00      | 1372.04      | 6.99     |\n",
      "| 57  | 18         | 8          | work       | 22.84    | 35.00    | 75.00    | 25.00    | 1050.00      | 1510.63      | 6.61     |\n",
      "| 57  | 19         | 0          | action     | 22.84    | 35.00    | 95.00    | 5.00     | 1400.00      | 1510.63      | 5.22     |\n",
      "| 57  | 20         | 6          | action     | 22.84    | 25.00    | 100.00   | 7.00     | 1400.00      | 1593.78      | 7.59     |\n",
      "| 57  | 21         | 6          | action     | 22.84    | 15.00    | 100.00   | 9.00     | 1400.00      | 1676.94      | 9.97     |\n",
      "| 57  | 22         | 6          | action     | 22.84    | 5.00     | 100.00   | 11.00    | 1400.00      | 1760.09      | 12.34    |\n",
      "| 57  | 23         | 8          | sleep      | 22.84    | 1.00     | 100.00   | 9.00     | 1400.00      | 1822.46      | 13.42    |\n",
      "| 58  | 0          | 8          | sleep      | 22.81    | 0.00     | 100.00   | 7.00     | 0.00         | 0.00         | 23.80    |\n",
      "| 58  | 1          | 8          | sleep      | 22.81    | 0.00     | 100.00   | 5.00     | 0.00         | 62.31        | 9.28     |\n",
      "| 58  | 2          | 8          | sleep      | 22.81    | 0.00     | 100.00   | 3.00     | 0.00         | 124.61       | 7.56     |\n",
      "| 58  | 3          | 8          | sleep      | 22.81    | 0.00     | 100.00   | 1.00     | 0.00         | 186.92       | 5.84     |\n",
      "| 58  | 4          | 8          | sleep      | 22.81    | 0.00     | 100.00   | 0.00     | 0.00         | 249.22       | 4.12     |\n",
      "| 58  | 5          | 8          | sleep      | 22.81    | 0.00     | 100.00   | 0.00     | 0.00         | 311.53       | 2.40     |\n",
      "| 58  | 6          | 8          | sleep      | 22.81    | 0.00     | 100.00   | 0.00     | 0.00         | 373.84       | 0.68     |\n",
      "| 58  | 7          | 0          | action     | 22.81    | 0.00     | 100.00   | 0.00     | 350.00       | 373.84       | 11.29    |\n",
      "| 58  | 8          | 0          | action     | 22.81    | 0.00     | 100.00   | 0.00     | 700.00       | 373.84       | 9.89     |\n",
      "| 58  | 9          | 6          | action     | 22.81    | 0.00     | 100.00   | 2.00     | 700.00       | 456.91       | 10.27    |\n",
      "| 58  | 10         | 6          | action     | 22.81    | 0.00     | 100.00   | 4.00     | 700.00       | 539.99       | 10.64    |\n",
      "| 58  | 11         | 8          | work       | 22.81    | 5.00     | 95.00    | 9.00     | 700.00       | 678.44       | 10.26    |\n",
      "| 58  | 12         | 8          | work       | 22.81    | 10.00    | 90.00    | 14.00    | 700.00       | 816.90       | 9.89     |\n",
      "| 58  | 13         | 0          | action     | 22.81    | 10.00    | 100.00   | 0.00     | 1050.00      | 816.90       | 8.49     |\n",
      "| 58  | 14         | 8          | work       | 22.81    | 15.00    | 95.00    | 5.00     | 1050.00      | 955.36       | 8.11     |\n",
      "| 58  | 15         | 8          | work       | 22.81    | 20.00    | 90.00    | 10.00    | 1050.00      | 1093.82      | 7.74     |\n",
      "| 58  | 16         | 8          | work       | 22.81    | 25.00    | 85.00    | 15.00    | 1050.00      | 1232.27      | 7.36     |\n",
      "| 58  | 17         | 8          | work       | 22.81    | 30.00    | 80.00    | 20.00    | 1050.00      | 1370.73      | 6.98     |\n",
      "| 58  | 18         | 8          | work       | 22.81    | 35.00    | 75.00    | 25.00    | 1050.00      | 1509.19      | 6.61     |\n",
      "| 58  | 19         | 0          | action     | 22.81    | 35.00    | 95.00    | 5.00     | 1400.00      | 1509.19      | 5.21     |\n",
      "| 58  | 20         | 6          | action     | 22.81    | 25.00    | 100.00   | 7.00     | 1400.00      | 1592.26      | 7.59     |\n",
      "| 58  | 21         | 6          | action     | 22.81    | 15.00    | 100.00   | 9.00     | 1400.00      | 1675.34      | 9.96     |\n",
      "| 58  | 22         | 6          | action     | 22.81    | 5.00     | 100.00   | 11.00    | 1400.00      | 1758.41      | 12.33    |\n",
      "| 58  | 23         | 8          | sleep      | 22.81    | 1.00     | 100.00   | 9.00     | 1400.00      | 1820.72      | 13.41    |\n",
      "| 59  | 0          | 8          | sleep      | 22.79    | 0.00     | 100.00   | 7.00     | 0.00         | 0.00         | 23.80    |\n",
      "| 59  | 1          | 8          | sleep      | 22.79    | 0.00     | 100.00   | 5.00     | 0.00         | 62.25        | 9.28     |\n",
      "| 59  | 2          | 8          | sleep      | 22.79    | 0.00     | 100.00   | 3.00     | 0.00         | 124.49       | 7.56     |\n",
      "| 59  | 3          | 8          | sleep      | 22.79    | 0.00     | 100.00   | 1.00     | 0.00         | 186.74       | 5.84     |\n",
      "| 59  | 4          | 8          | sleep      | 22.79    | 0.00     | 100.00   | 0.00     | 0.00         | 248.99       | 4.12     |\n",
      "| 59  | 5          | 8          | sleep      | 22.79    | 0.00     | 100.00   | 0.00     | 0.00         | 311.23       | 2.40     |\n",
      "| 59  | 6          | 8          | sleep      | 22.79    | 0.00     | 100.00   | 0.00     | 0.00         | 373.48       | 0.68     |\n",
      "| 59  | 7          | 0          | action     | 22.79    | 0.00     | 100.00   | 0.00     | 350.00       | 373.48       | 11.29    |\n",
      "| 59  | 8          | 0          | action     | 22.79    | 0.00     | 100.00   | 0.00     | 700.00       | 373.48       | 9.89     |\n",
      "| 59  | 9          | 6          | action     | 22.79    | 0.00     | 100.00   | 2.00     | 700.00       | 456.48       | 10.26    |\n",
      "| 59  | 10         | 6          | action     | 22.79    | 0.00     | 100.00   | 4.00     | 700.00       | 539.47       | 10.64    |\n",
      "| 59  | 11         | 8          | work       | 22.79    | 5.00     | 95.00    | 9.00     | 700.00       | 677.80       | 10.26    |\n",
      "| 59  | 12         | 8          | work       | 22.79    | 10.00    | 90.00    | 14.00    | 700.00       | 816.12       | 9.88     |\n",
      "| 59  | 13         | 0          | action     | 22.79    | 10.00    | 100.00   | 0.00     | 1050.00      | 816.12       | 8.49     |\n",
      "| 59  | 14         | 8          | work       | 22.79    | 15.00    | 95.00    | 5.00     | 1050.00      | 954.45       | 8.11     |\n",
      "| 59  | 15         | 8          | work       | 22.79    | 20.00    | 90.00    | 10.00    | 1050.00      | 1092.78      | 7.73     |\n",
      "| 59  | 16         | 8          | work       | 22.79    | 25.00    | 85.00    | 15.00    | 1050.00      | 1231.10      | 7.36     |\n",
      "| 59  | 17         | 8          | work       | 22.79    | 30.00    | 80.00    | 20.00    | 1050.00      | 1369.43      | 6.98     |\n",
      "| 59  | 18         | 8          | work       | 22.79    | 35.00    | 75.00    | 25.00    | 1050.00      | 1507.75      | 6.60     |\n",
      "| 59  | 19         | 0          | action     | 22.79    | 35.00    | 95.00    | 5.00     | 1400.00      | 1507.75      | 5.21     |\n",
      "| 59  | 20         | 6          | action     | 22.79    | 25.00    | 100.00   | 7.00     | 1400.00      | 1590.75      | 7.58     |\n",
      "| 59  | 21         | 6          | action     | 22.79    | 15.00    | 100.00   | 9.00     | 1400.00      | 1673.74      | 9.95     |\n",
      "| 59  | 22         | 6          | action     | 22.79    | 5.00     | 100.00   | 11.00    | 1400.00      | 1756.74      | 12.33    |\n",
      "| 59  | 23         | 8          | sleep      | 22.79    | 1.00     | 100.00   | 9.00     | 1400.00      | 1818.99      | 13.41    |\n",
      "| 60  | 0          | 8          | sleep      | 22.77    | 0.00     | 100.00   | 7.00     | 0.00         | 0.00         | 23.79    |\n",
      "| 60  | 1          | 8          | sleep      | 22.77    | 0.00     | 100.00   | 5.00     | 0.00         | 62.19        | 9.28     |\n",
      "| 60  | 2          | 8          | sleep      | 22.77    | 0.00     | 100.00   | 3.00     | 0.00         | 124.38       | 7.56     |\n",
      "| 60  | 3          | 8          | sleep      | 22.77    | 0.00     | 100.00   | 1.00     | 0.00         | 186.56       | 5.84     |\n",
      "| 60  | 4          | 8          | sleep      | 22.77    | 0.00     | 100.00   | 0.00     | 0.00         | 248.75       | 4.12     |\n",
      "| 60  | 5          | 8          | sleep      | 22.77    | 0.00     | 100.00   | 0.00     | 0.00         | 310.94       | 2.40     |\n",
      "| 60  | 6          | 8          | sleep      | 22.77    | 0.00     | 100.00   | 0.00     | 0.00         | 373.13       | 0.68     |\n",
      "| 60  | 7          | 0          | action     | 22.77    | 0.00     | 100.00   | 0.00     | 350.00       | 373.13       | 11.28    |\n",
      "| 60  | 8          | 0          | action     | 22.77    | 0.00     | 100.00   | 0.00     | 700.00       | 373.13       | 9.89     |\n",
      "| 60  | 9          | 6          | action     | 22.77    | 0.00     | 100.00   | 2.00     | 700.00       | 456.04       | 10.26    |\n",
      "| 60  | 10         | 6          | action     | 22.77    | 0.00     | 100.00   | 4.00     | 700.00       | 538.96       | 10.64    |\n",
      "| 60  | 11         | 8          | work       | 22.77    | 5.00     | 95.00    | 9.00     | 700.00       | 677.15       | 10.26    |\n",
      "| 60  | 12         | 8          | work       | 22.77    | 10.00    | 90.00    | 14.00    | 700.00       | 815.35       | 9.88     |\n",
      "| 60  | 13         | 0          | action     | 22.77    | 10.00    | 100.00   | 0.00     | 1050.00      | 815.35       | 8.49     |\n",
      "| 60  | 14         | 8          | work       | 22.77    | 15.00    | 95.00    | 5.00     | 1050.00      | 953.54       | 8.11     |\n",
      "| 60  | 15         | 8          | work       | 22.77    | 20.00    | 90.00    | 10.00    | 1050.00      | 1091.74      | 7.73     |\n",
      "| 60  | 16         | 8          | work       | 22.77    | 25.00    | 85.00    | 15.00    | 1050.00      | 1229.93      | 7.35     |\n",
      "| 60  | 17         | 8          | work       | 22.77    | 30.00    | 80.00    | 20.00    | 1050.00      | 1368.13      | 6.97     |\n",
      "| 60  | 18         | 8          | work       | 22.77    | 35.00    | 75.00    | 25.00    | 1050.00      | 1506.32      | 6.60     |\n",
      "| 60  | 19         | 0          | action     | 22.77    | 35.00    | 95.00    | 5.00     | 1400.00      | 1506.32      | 5.20     |\n",
      "| 60  | 20         | 6          | action     | 22.77    | 25.00    | 100.00   | 7.00     | 1400.00      | 1589.24      | 7.57     |\n",
      "| 60  | 21         | 6          | action     | 22.77    | 15.00    | 100.00   | 9.00     | 1400.00      | 1672.16      | 9.95     |\n",
      "| 60  | 22         | 6          | action     | 22.77    | 5.00     | 100.00   | 11.00    | 1400.00      | 1755.07      | 12.32    |\n",
      "| 60  | 23         | 8          | sleep      | 22.77    | 1.00     | 100.00   | 9.00     | 1400.00      | 1817.26      | 13.40    |\n",
      "| 61  | 0          | 8          | sleep      | 22.75    | 0.00     | 100.00   | 7.00     | 0.00         | 0.00         | 23.79    |\n",
      "| 61  | 1          | 8          | sleep      | 22.75    | 0.00     | 100.00   | 5.00     | 0.00         | 62.13        | 9.28     |\n",
      "| 61  | 2          | 8          | sleep      | 22.75    | 0.00     | 100.00   | 3.00     | 0.00         | 124.26       | 7.56     |\n",
      "| 61  | 3          | 8          | sleep      | 22.75    | 0.00     | 100.00   | 1.00     | 0.00         | 186.39       | 5.84     |\n",
      "| 61  | 4          | 8          | sleep      | 22.75    | 0.00     | 100.00   | 0.00     | 0.00         | 248.52       | 4.12     |\n",
      "| 61  | 5          | 8          | sleep      | 22.75    | 0.00     | 100.00   | 0.00     | 0.00         | 310.64       | 2.40     |\n",
      "| 61  | 6          | 8          | sleep      | 22.75    | 0.00     | 100.00   | 0.00     | 0.00         | 372.77       | 0.68     |\n",
      "| 61  | 7          | 0          | action     | 22.75    | 0.00     | 100.00   | 0.00     | 350.00       | 372.77       | 11.28    |\n",
      "| 61  | 8          | 0          | action     | 22.75    | 0.00     | 100.00   | 0.00     | 700.00       | 372.77       | 9.89     |\n",
      "| 61  | 9          | 6          | action     | 22.75    | 0.00     | 100.00   | 2.00     | 700.00       | 455.61       | 10.26    |\n",
      "| 61  | 10         | 6          | action     | 22.75    | 0.00     | 100.00   | 4.00     | 700.00       | 538.45       | 10.63    |\n",
      "| 61  | 11         | 8          | work       | 22.75    | 5.00     | 95.00    | 9.00     | 700.00       | 676.51       | 10.26    |\n",
      "| 61  | 12         | 8          | work       | 22.75    | 10.00    | 90.00    | 14.00    | 700.00       | 814.58       | 9.88     |\n",
      "| 61  | 13         | 0          | action     | 22.75    | 10.00    | 100.00   | 0.00     | 1050.00      | 814.58       | 8.48     |\n",
      "| 61  | 14         | 8          | work       | 22.75    | 15.00    | 95.00    | 5.00     | 1050.00      | 952.64       | 8.10     |\n",
      "| 61  | 15         | 8          | work       | 22.75    | 20.00    | 90.00    | 10.00    | 1050.00      | 1090.71      | 7.73     |\n",
      "| 61  | 16         | 8          | work       | 22.75    | 25.00    | 85.00    | 15.00    | 1050.00      | 1228.77      | 7.35     |\n",
      "| 61  | 17         | 8          | work       | 22.75    | 30.00    | 80.00    | 20.00    | 1050.00      | 1366.83      | 6.97     |\n",
      "| 61  | 18         | 8          | work       | 22.75    | 35.00    | 75.00    | 25.00    | 1050.00      | 1504.90      | 6.59     |\n",
      "| 61  | 19         | 0          | action     | 22.75    | 35.00    | 95.00    | 5.00     | 1400.00      | 1504.90      | 5.19     |\n",
      "| 61  | 20         | 6          | action     | 22.75    | 25.00    | 100.00   | 7.00     | 1400.00      | 1587.74      | 7.57     |\n",
      "| 61  | 21         | 6          | action     | 22.75    | 15.00    | 100.00   | 9.00     | 1400.00      | 1670.57      | 9.94     |\n",
      "| 61  | 22         | 6          | action     | 22.75    | 5.00     | 100.00   | 11.00    | 1400.00      | 1753.41      | 12.31    |\n",
      "| 61  | 23         | 8          | sleep      | 22.75    | 1.00     | 100.00   | 9.00     | 1400.00      | 1815.54      | 13.39    |\n",
      "| 62  | 0          | 8          | sleep      | 22.73    | 0.00     | 100.00   | 7.00     | 0.00         | 0.00         | 23.78    |\n",
      "| 62  | 1          | 8          | sleep      | 22.73    | 0.00     | 100.00   | 5.00     | 0.00         | 62.07        | 9.28     |\n",
      "| 62  | 2          | 8          | sleep      | 22.73    | 0.00     | 100.00   | 3.00     | 0.00         | 124.14       | 7.56     |\n",
      "| 62  | 3          | 8          | sleep      | 22.73    | 0.00     | 100.00   | 1.00     | 0.00         | 186.21       | 5.84     |\n",
      "| 62  | 4          | 8          | sleep      | 22.73    | 0.00     | 100.00   | 0.00     | 0.00         | 248.28       | 4.12     |\n",
      "| 62  | 5          | 8          | sleep      | 22.73    | 0.00     | 100.00   | 0.00     | 0.00         | 310.35       | 2.40     |\n",
      "| 62  | 6          | 8          | sleep      | 22.73    | 0.00     | 100.00   | 0.00     | 0.00         | 372.42       | 0.68     |\n",
      "| 62  | 7          | 0          | action     | 22.73    | 0.00     | 100.00   | 0.00     | 350.00       | 372.42       | 11.28    |\n",
      "| 62  | 8          | 0          | action     | 22.73    | 0.00     | 100.00   | 0.00     | 700.00       | 372.42       | 9.89     |\n",
      "| 62  | 9          | 6          | action     | 22.73    | 0.00     | 100.00   | 2.00     | 700.00       | 455.18       | 10.26    |\n",
      "| 62  | 10         | 6          | action     | 22.73    | 0.00     | 100.00   | 4.00     | 700.00       | 537.94       | 10.63    |\n",
      "| 62  | 11         | 8          | work       | 22.73    | 5.00     | 95.00    | 9.00     | 700.00       | 675.88       | 10.25    |\n",
      "| 62  | 12         | 8          | work       | 22.73    | 10.00    | 90.00    | 14.00    | 700.00       | 813.81       | 9.87     |\n",
      "| 62  | 13         | 0          | action     | 22.73    | 10.00    | 100.00   | 0.00     | 1050.00      | 813.81       | 8.48     |\n",
      "| 62  | 14         | 8          | work       | 22.73    | 15.00    | 95.00    | 5.00     | 1050.00      | 951.74       | 8.10     |\n",
      "| 62  | 15         | 8          | work       | 22.73    | 20.00    | 90.00    | 10.00    | 1050.00      | 1089.68      | 7.72     |\n",
      "| 62  | 16         | 8          | work       | 22.73    | 25.00    | 85.00    | 15.00    | 1050.00      | 1227.61      | 7.34     |\n",
      "| 62  | 17         | 8          | work       | 22.73    | 30.00    | 80.00    | 20.00    | 1050.00      | 1365.54      | 6.96     |\n",
      "| 62  | 18         | 8          | work       | 22.73    | 35.00    | 75.00    | 25.00    | 1050.00      | 1503.48      | 6.58     |\n",
      "| 62  | 19         | 0          | action     | 22.73    | 35.00    | 95.00    | 5.00     | 1400.00      | 1503.48      | 5.19     |\n",
      "| 62  | 20         | 6          | action     | 22.73    | 25.00    | 100.00   | 7.00     | 1400.00      | 1586.24      | 7.56     |\n",
      "| 62  | 21         | 6          | action     | 22.73    | 15.00    | 100.00   | 9.00     | 1400.00      | 1669.00      | 9.93     |\n",
      "| 62  | 22         | 6          | action     | 22.73    | 5.00     | 100.00   | 11.00    | 1400.00      | 1751.76      | 12.31    |\n",
      "| 62  | 23         | 8          | sleep      | 22.73    | 1.00     | 100.00   | 9.00     | 1400.00      | 1813.83      | 13.39    |\n",
      "| 63  | 0          | 8          | sleep      | 22.71    | 0.00     | 100.00   | 7.00     | 0.00         | 0.00         | 23.78    |\n",
      "| 63  | 1          | 8          | sleep      | 22.71    | 0.00     | 100.00   | 5.00     | 0.00         | 62.01        | 9.28     |\n",
      "| 63  | 2          | 8          | sleep      | 22.71    | 0.00     | 100.00   | 3.00     | 0.00         | 124.02       | 7.56     |\n",
      "| 63  | 3          | 8          | sleep      | 22.71    | 0.00     | 100.00   | 1.00     | 0.00         | 186.04       | 5.84     |\n",
      "| 63  | 4          | 8          | sleep      | 22.71    | 0.00     | 100.00   | 0.00     | 0.00         | 248.05       | 4.12     |\n",
      "| 63  | 5          | 8          | sleep      | 22.71    | 0.00     | 100.00   | 0.00     | 0.00         | 310.06       | 2.40     |\n",
      "| 63  | 6          | 8          | sleep      | 22.71    | 0.00     | 100.00   | 0.00     | 0.00         | 372.07       | 0.67     |\n",
      "| 63  | 7          | 0          | action     | 22.71    | 0.00     | 100.00   | 0.00     | 350.00       | 372.07       | 11.28    |\n",
      "| 63  | 8          | 0          | action     | 22.71    | 0.00     | 100.00   | 0.00     | 700.00       | 372.07       | 9.89     |\n",
      "| 63  | 9          | 6          | action     | 22.71    | 0.00     | 100.00   | 2.00     | 700.00       | 454.75       | 10.26    |\n",
      "| 63  | 10         | 6          | action     | 22.71    | 0.00     | 100.00   | 4.00     | 700.00       | 537.44       | 10.63    |\n",
      "| 63  | 11         | 8          | work       | 22.71    | 5.00     | 95.00    | 9.00     | 700.00       | 675.24       | 10.25    |\n",
      "| 63  | 12         | 8          | work       | 22.71    | 10.00    | 90.00    | 14.00    | 700.00       | 813.04       | 9.87     |\n",
      "| 63  | 13         | 0          | action     | 22.71    | 10.00    | 100.00   | 0.00     | 1050.00      | 813.04       | 8.48     |\n",
      "| 63  | 14         | 8          | work       | 22.71    | 15.00    | 95.00    | 5.00     | 1050.00      | 950.85       | 8.10     |\n",
      "| 63  | 15         | 8          | work       | 22.71    | 20.00    | 90.00    | 10.00    | 1050.00      | 1088.65      | 7.72     |\n",
      "| 63  | 16         | 8          | work       | 22.71    | 25.00    | 85.00    | 15.00    | 1050.00      | 1226.45      | 7.34     |\n",
      "| 63  | 17         | 8          | work       | 22.71    | 30.00    | 80.00    | 20.00    | 1050.00      | 1364.26      | 6.96     |\n",
      "| 63  | 18         | 8          | work       | 22.71    | 35.00    | 75.00    | 25.00    | 1050.00      | 1502.06      | 6.58     |\n",
      "| 63  | 19         | 0          | action     | 22.71    | 35.00    | 95.00    | 5.00     | 1400.00      | 1502.06      | 5.18     |\n",
      "| 63  | 20         | 6          | action     | 22.71    | 25.00    | 100.00   | 7.00     | 1400.00      | 1584.74      | 7.56     |\n",
      "| 63  | 21         | 6          | action     | 22.71    | 15.00    | 100.00   | 9.00     | 1400.00      | 1667.43      | 9.93     |\n",
      "| 63  | 22         | 6          | action     | 22.71    | 5.00     | 100.00   | 11.00    | 1400.00      | 1750.11      | 12.30    |\n",
      "| 63  | 23         | 8          | sleep      | 22.71    | 1.00     | 100.00   | 9.00     | 1400.00      | 1812.12      | 13.38    |\n",
      "| 64  | 0          | 8          | sleep      | 22.68    | 0.00     | 100.00   | 7.00     | 0.00         | 0.00         | 23.77    |\n",
      "| 64  | 1          | 8          | sleep      | 22.68    | 0.00     | 100.00   | 5.00     | 0.00         | 61.95        | 9.28     |\n",
      "| 64  | 2          | 8          | sleep      | 22.68    | 0.00     | 100.00   | 3.00     | 0.00         | 123.91       | 7.56     |\n",
      "| 64  | 3          | 8          | sleep      | 22.68    | 0.00     | 100.00   | 1.00     | 0.00         | 185.86       | 5.84     |\n",
      "| 64  | 4          | 8          | sleep      | 22.68    | 0.00     | 100.00   | 0.00     | 0.00         | 247.81       | 4.12     |\n",
      "| 64  | 5          | 8          | sleep      | 22.68    | 0.00     | 100.00   | 0.00     | 0.00         | 309.77       | 2.39     |\n",
      "| 64  | 6          | 8          | sleep      | 22.68    | 0.00     | 100.00   | 0.00     | 0.00         | 371.72       | 0.67     |\n",
      "| 64  | 7          | 0          | action     | 22.68    | 0.00     | 100.00   | 0.00     | 350.00       | 371.72       | 11.28    |\n",
      "| 64  | 8          | 0          | action     | 22.68    | 0.00     | 100.00   | 0.00     | 700.00       | 371.72       | 9.88     |\n",
      "| 64  | 9          | 6          | action     | 22.68    | 0.00     | 100.00   | 2.00     | 700.00       | 454.33       | 10.26    |\n",
      "| 64  | 10         | 6          | action     | 22.68    | 0.00     | 100.00   | 4.00     | 700.00       | 536.93       | 10.63    |\n",
      "| 64  | 11         | 8          | work       | 22.68    | 5.00     | 95.00    | 9.00     | 700.00       | 674.61       | 10.25    |\n",
      "| 64  | 12         | 8          | work       | 22.68    | 10.00    | 90.00    | 14.00    | 700.00       | 812.28       | 9.87     |\n",
      "| 64  | 13         | 0          | action     | 22.68    | 10.00    | 100.00   | 0.00     | 1050.00      | 812.28       | 8.47     |\n",
      "| 64  | 14         | 8          | work       | 22.68    | 15.00    | 95.00    | 5.00     | 1050.00      | 949.95       | 8.09     |\n",
      "| 64  | 15         | 8          | work       | 22.68    | 20.00    | 90.00    | 10.00    | 1050.00      | 1087.63      | 7.71     |\n",
      "| 64  | 16         | 8          | work       | 22.68    | 25.00    | 85.00    | 15.00    | 1050.00      | 1225.30      | 7.33     |\n",
      "| 64  | 17         | 8          | work       | 22.68    | 30.00    | 80.00    | 20.00    | 1050.00      | 1362.98      | 6.95     |\n",
      "| 64  | 18         | 8          | work       | 22.68    | 35.00    | 75.00    | 25.00    | 1050.00      | 1500.65      | 6.57     |\n",
      "| 64  | 19         | 0          | action     | 22.68    | 35.00    | 95.00    | 5.00     | 1400.00      | 1500.65      | 5.18     |\n",
      "| 64  | 20         | 6          | action     | 22.68    | 25.00    | 100.00   | 7.00     | 1400.00      | 1583.26      | 7.55     |\n",
      "| 64  | 21         | 6          | action     | 22.68    | 15.00    | 100.00   | 9.00     | 1400.00      | 1665.86      | 9.92     |\n",
      "| 64  | 22         | 6          | action     | 22.68    | 5.00     | 100.00   | 11.00    | 1400.00      | 1748.47      | 12.29    |\n",
      "| 64  | 23         | 8          | sleep      | 22.68    | 1.00     | 100.00   | 9.00     | 1400.00      | 1810.42      | 13.37    |\n",
      "| 65  | 0          | 8          | sleep      | 22.66    | 0.00     | 100.00   | 7.00     | 0.00         | 0.00         | 23.77    |\n",
      "| 65  | 1          | 8          | sleep      | 22.66    | 0.00     | 100.00   | 5.00     | 0.00         | 61.90        | 9.28     |\n",
      "| 65  | 2          | 8          | sleep      | 22.66    | 0.00     | 100.00   | 3.00     | 0.00         | 123.79       | 7.56     |\n",
      "| 65  | 3          | 8          | sleep      | 22.66    | 0.00     | 100.00   | 1.00     | 0.00         | 185.69       | 5.84     |\n",
      "| 65  | 4          | 8          | sleep      | 22.66    | 0.00     | 100.00   | 0.00     | 0.00         | 247.58       | 4.11     |\n",
      "| 65  | 5          | 8          | sleep      | 22.66    | 0.00     | 100.00   | 0.00     | 0.00         | 309.48       | 2.39     |\n",
      "| 65  | 6          | 8          | sleep      | 22.66    | 0.00     | 100.00   | 0.00     | 0.00         | 371.37       | 0.67     |\n",
      "| 65  | 7          | 0          | action     | 22.66    | 0.00     | 100.00   | 0.00     | 350.00       | 371.37       | 11.28    |\n",
      "| 65  | 8          | 0          | action     | 22.66    | 0.00     | 100.00   | 0.00     | 700.00       | 371.37       | 9.88     |\n",
      "| 65  | 9          | 6          | action     | 22.66    | 0.00     | 100.00   | 2.00     | 700.00       | 453.90       | 10.25    |\n",
      "| 65  | 10         | 6          | action     | 22.66    | 0.00     | 100.00   | 4.00     | 700.00       | 536.43       | 10.63    |\n",
      "| 65  | 11         | 8          | work       | 22.66    | 5.00     | 95.00    | 9.00     | 700.00       | 673.97       | 10.25    |\n",
      "| 65  | 12         | 8          | work       | 22.66    | 10.00    | 90.00    | 14.00    | 700.00       | 811.52       | 9.86     |\n",
      "| 65  | 13         | 0          | action     | 22.66    | 10.00    | 100.00   | 0.00     | 1050.00      | 811.52       | 8.47     |\n",
      "| 65  | 14         | 8          | work       | 22.66    | 15.00    | 95.00    | 5.00     | 1050.00      | 949.07       | 8.09     |\n",
      "| 65  | 15         | 8          | work       | 22.66    | 20.00    | 90.00    | 10.00    | 1050.00      | 1086.61      | 7.71     |\n",
      "| 65  | 16         | 8          | work       | 22.66    | 25.00    | 85.00    | 15.00    | 1050.00      | 1224.16      | 7.33     |\n",
      "| 65  | 17         | 8          | work       | 22.66    | 30.00    | 80.00    | 20.00    | 1050.00      | 1361.70      | 6.95     |\n",
      "| 65  | 18         | 8          | work       | 22.66    | 35.00    | 75.00    | 25.00    | 1050.00      | 1499.25      | 6.57     |\n",
      "| 65  | 19         | 0          | action     | 22.66    | 35.00    | 95.00    | 5.00     | 1400.00      | 1499.25      | 5.17     |\n",
      "| 65  | 20         | 6          | action     | 22.66    | 25.00    | 100.00   | 7.00     | 1400.00      | 1581.78      | 7.54     |\n",
      "| 65  | 21         | 6          | action     | 22.66    | 15.00    | 100.00   | 9.00     | 1400.00      | 1664.30      | 9.91     |\n",
      "| 65  | 22         | 6          | action     | 22.66    | 5.00     | 100.00   | 11.00    | 1400.00      | 1746.83      | 12.29    |\n",
      "| 65  | 23         | 8          | sleep      | 22.66    | 1.00     | 100.00   | 9.00     | 1400.00      | 1808.73      | 13.36    |\n",
      "| 66  | 0          | 8          | sleep      | 22.64    | 0.00     | 100.00   | 7.00     | 0.00         | 0.00         | 23.76    |\n",
      "| 66  | 1          | 8          | sleep      | 22.64    | 0.00     | 100.00   | 5.00     | 0.00         | 61.84        | 9.28     |\n",
      "| 66  | 2          | 8          | sleep      | 22.64    | 0.00     | 100.00   | 3.00     | 0.00         | 123.68       | 7.56     |\n",
      "| 66  | 3          | 8          | sleep      | 22.64    | 0.00     | 100.00   | 1.00     | 0.00         | 185.51       | 5.83     |\n",
      "| 66  | 4          | 8          | sleep      | 22.64    | 0.00     | 100.00   | 0.00     | 0.00         | 247.35       | 4.11     |\n",
      "| 66  | 5          | 8          | sleep      | 22.64    | 0.00     | 100.00   | 0.00     | 0.00         | 309.19       | 2.39     |\n",
      "| 66  | 6          | 8          | sleep      | 22.64    | 0.00     | 100.00   | 0.00     | 0.00         | 371.03       | 0.67     |\n",
      "| 66  | 7          | 0          | action     | 22.64    | 0.00     | 100.00   | 0.00     | 350.00       | 371.03       | 11.28    |\n",
      "| 66  | 8          | 0          | action     | 22.64    | 0.00     | 100.00   | 0.00     | 700.00       | 371.03       | 9.88     |\n",
      "| 66  | 9          | 6          | action     | 22.64    | 0.00     | 100.00   | 2.00     | 700.00       | 453.48       | 10.25    |\n",
      "| 66  | 10         | 6          | action     | 22.64    | 0.00     | 100.00   | 4.00     | 700.00       | 535.93       | 10.62    |\n",
      "| 66  | 11         | 8          | work       | 22.64    | 5.00     | 95.00    | 9.00     | 700.00       | 673.35       | 10.24    |\n",
      "| 66  | 12         | 8          | work       | 22.64    | 10.00    | 90.00    | 14.00    | 700.00       | 810.76       | 9.86     |\n",
      "| 66  | 13         | 0          | action     | 22.64    | 10.00    | 100.00   | 0.00     | 1050.00      | 810.76       | 8.47     |\n",
      "| 66  | 14         | 8          | work       | 22.64    | 15.00    | 95.00    | 5.00     | 1050.00      | 948.18       | 8.09     |\n",
      "| 66  | 15         | 8          | work       | 22.64    | 20.00    | 90.00    | 10.00    | 1050.00      | 1085.60      | 7.70     |\n",
      "| 66  | 16         | 8          | work       | 22.64    | 25.00    | 85.00    | 15.00    | 1050.00      | 1223.02      | 7.32     |\n",
      "| 66  | 17         | 8          | work       | 22.64    | 30.00    | 80.00    | 20.00    | 1050.00      | 1360.43      | 6.94     |\n",
      "| 66  | 18         | 8          | work       | 22.64    | 35.00    | 75.00    | 25.00    | 1050.00      | 1497.85      | 6.56     |\n",
      "| 66  | 19         | 0          | action     | 22.64    | 35.00    | 95.00    | 5.00     | 1400.00      | 1497.85      | 5.17     |\n",
      "| 66  | 20         | 6          | action     | 22.64    | 25.00    | 100.00   | 7.00     | 1400.00      | 1580.30      | 7.54     |\n",
      "| 66  | 21         | 6          | action     | 22.64    | 15.00    | 100.00   | 9.00     | 1400.00      | 1662.75      | 9.91     |\n",
      "| 66  | 22         | 6          | action     | 22.64    | 5.00     | 100.00   | 11.00    | 1400.00      | 1745.20      | 12.28    |\n",
      "| 66  | 23         | 8          | sleep      | 22.64    | 1.00     | 100.00   | 9.00     | 1400.00      | 1807.04      | 13.36    |\n",
      "| 67  | 0          | 8          | sleep      | 22.62    | 0.00     | 100.00   | 7.00     | 0.00         | 0.00         | 23.76    |\n",
      "| 67  | 1          | 8          | sleep      | 22.62    | 0.00     | 100.00   | 5.00     | 0.00         | 61.78        | 9.28     |\n",
      "| 67  | 2          | 8          | sleep      | 22.62    | 0.00     | 100.00   | 3.00     | 0.00         | 123.56       | 7.56     |\n",
      "| 67  | 3          | 8          | sleep      | 22.62    | 0.00     | 100.00   | 1.00     | 0.00         | 185.34       | 5.83     |\n",
      "| 67  | 4          | 8          | sleep      | 22.62    | 0.00     | 100.00   | 0.00     | 0.00         | 247.12       | 4.11     |\n",
      "| 67  | 5          | 8          | sleep      | 22.62    | 0.00     | 100.00   | 0.00     | 0.00         | 308.90       | 2.39     |\n",
      "| 67  | 6          | 8          | sleep      | 22.62    | 0.00     | 100.00   | 0.00     | 0.00         | 370.68       | 0.67     |\n",
      "| 67  | 7          | 0          | action     | 22.62    | 0.00     | 100.00   | 0.00     | 350.00       | 370.68       | 11.27    |\n",
      "| 67  | 8          | 0          | action     | 22.62    | 0.00     | 100.00   | 0.00     | 700.00       | 370.68       | 9.88     |\n",
      "| 67  | 9          | 6          | action     | 22.62    | 0.00     | 100.00   | 2.00     | 700.00       | 453.06       | 10.25    |\n",
      "| 67  | 10         | 6          | action     | 22.62    | 0.00     | 100.00   | 4.00     | 700.00       | 535.43       | 10.62    |\n",
      "| 67  | 11         | 8          | work       | 22.62    | 5.00     | 95.00    | 9.00     | 700.00       | 672.72       | 10.24    |\n",
      "| 67  | 12         | 8          | work       | 22.62    | 10.00    | 90.00    | 14.00    | 700.00       | 810.01       | 9.86     |\n",
      "| 67  | 13         | 0          | action     | 22.62    | 10.00    | 100.00   | 0.00     | 1050.00      | 810.01       | 8.46     |\n",
      "| 67  | 14         | 8          | work       | 22.62    | 15.00    | 95.00    | 5.00     | 1050.00      | 947.30       | 8.08     |\n",
      "| 67  | 15         | 8          | work       | 22.62    | 20.00    | 90.00    | 10.00    | 1050.00      | 1084.59      | 7.70     |\n",
      "| 67  | 16         | 8          | work       | 22.62    | 25.00    | 85.00    | 15.00    | 1050.00      | 1221.88      | 7.32     |\n",
      "| 67  | 17         | 8          | work       | 22.62    | 30.00    | 80.00    | 20.00    | 1050.00      | 1359.17      | 6.94     |\n",
      "| 67  | 18         | 8          | work       | 22.62    | 35.00    | 75.00    | 25.00    | 1050.00      | 1496.46      | 6.55     |\n",
      "| 67  | 19         | 0          | action     | 22.62    | 35.00    | 95.00    | 5.00     | 1400.00      | 1496.46      | 5.16     |\n",
      "| 67  | 20         | 6          | action     | 22.62    | 25.00    | 100.00   | 7.00     | 1400.00      | 1578.83      | 7.53     |\n",
      "| 67  | 21         | 6          | action     | 22.62    | 15.00    | 100.00   | 9.00     | 1400.00      | 1661.20      | 9.90     |\n",
      "| 67  | 22         | 6          | action     | 22.62    | 5.00     | 100.00   | 11.00    | 1400.00      | 1743.58      | 12.27    |\n",
      "| 67  | 23         | 8          | sleep      | 22.62    | 1.00     | 100.00   | 9.00     | 1400.00      | 1805.36      | 13.35    |\n",
      "| 68  | 0          | 8          | sleep      | 22.60    | 0.00     | 100.00   | 7.00     | 0.00         | 0.00         | 23.75    |\n",
      "| 68  | 1          | 8          | sleep      | 22.60    | 0.00     | 100.00   | 5.00     | 0.00         | 61.72        | 9.28     |\n",
      "| 68  | 2          | 8          | sleep      | 22.60    | 0.00     | 100.00   | 3.00     | 0.00         | 123.45       | 7.56     |\n",
      "| 68  | 3          | 8          | sleep      | 22.60    | 0.00     | 100.00   | 1.00     | 0.00         | 185.17       | 5.83     |\n",
      "| 68  | 4          | 8          | sleep      | 22.60    | 0.00     | 100.00   | 0.00     | 0.00         | 246.89       | 4.11     |\n",
      "| 68  | 5          | 8          | sleep      | 22.60    | 0.00     | 100.00   | 0.00     | 0.00         | 308.61       | 2.39     |\n",
      "| 68  | 6          | 8          | sleep      | 22.60    | 0.00     | 100.00   | 0.00     | 0.00         | 370.34       | 0.67     |\n",
      "| 68  | 7          | 0          | action     | 22.60    | 0.00     | 100.00   | 0.00     | 350.00       | 370.34       | 11.27    |\n",
      "| 68  | 8          | 0          | action     | 22.60    | 0.00     | 100.00   | 0.00     | 700.00       | 370.34       | 9.88     |\n",
      "| 68  | 9          | 6          | action     | 22.60    | 0.00     | 100.00   | 2.00     | 700.00       | 452.64       | 10.25    |\n",
      "| 68  | 10         | 6          | action     | 22.60    | 0.00     | 100.00   | 4.00     | 700.00       | 534.93       | 10.62    |\n",
      "| 68  | 11         | 8          | work       | 22.60    | 5.00     | 95.00    | 9.00     | 700.00       | 672.09       | 10.24    |\n",
      "| 68  | 12         | 8          | work       | 22.60    | 10.00    | 90.00    | 14.00    | 700.00       | 809.26       | 9.85     |\n",
      "| 68  | 13         | 0          | action     | 22.60    | 10.00    | 100.00   | 0.00     | 1050.00      | 809.26       | 8.46     |\n",
      "| 68  | 14         | 8          | work       | 22.60    | 15.00    | 95.00    | 5.00     | 1050.00      | 946.42       | 8.08     |\n",
      "| 68  | 15         | 8          | work       | 22.60    | 20.00    | 90.00    | 10.00    | 1050.00      | 1083.58      | 7.70     |\n",
      "| 68  | 16         | 8          | work       | 22.60    | 25.00    | 85.00    | 15.00    | 1050.00      | 1220.74      | 7.31     |\n",
      "| 68  | 17         | 8          | work       | 22.60    | 30.00    | 80.00    | 20.00    | 1050.00      | 1357.91      | 6.93     |\n",
      "| 68  | 18         | 8          | work       | 22.60    | 35.00    | 75.00    | 25.00    | 1050.00      | 1495.07      | 6.55     |\n",
      "| 68  | 19         | 0          | action     | 22.60    | 35.00    | 95.00    | 5.00     | 1400.00      | 1495.07      | 5.15     |\n",
      "| 68  | 20         | 6          | action     | 22.60    | 25.00    | 100.00   | 7.00     | 1400.00      | 1577.36      | 7.52     |\n",
      "| 68  | 21         | 6          | action     | 22.60    | 15.00    | 100.00   | 9.00     | 1400.00      | 1659.66      | 9.89     |\n",
      "| 68  | 22         | 6          | action     | 22.60    | 5.00     | 100.00   | 11.00    | 1400.00      | 1741.96      | 12.27    |\n",
      "| 68  | 23         | 8          | sleep      | 22.60    | 1.00     | 100.00   | 9.00     | 1400.00      | 1803.68      | 13.34    |\n",
      "| 69  | 0          | 8          | sleep      | 22.58    | 0.00     | 100.00   | 7.00     | 0.00         | 0.00         | 23.74    |\n",
      "| 69  | 1          | 8          | sleep      | 22.58    | 0.00     | 100.00   | 5.00     | 0.00         | 61.67        | 9.28     |\n",
      "| 69  | 2          | 8          | sleep      | 22.58    | 0.00     | 100.00   | 3.00     | 0.00         | 123.33       | 7.55     |\n",
      "| 69  | 3          | 8          | sleep      | 22.58    | 0.00     | 100.00   | 1.00     | 0.00         | 185.00       | 5.83     |\n",
      "| 69  | 4          | 8          | sleep      | 22.58    | 0.00     | 100.00   | 0.00     | 0.00         | 246.66       | 4.11     |\n",
      "| 69  | 5          | 8          | sleep      | 22.58    | 0.00     | 100.00   | 0.00     | 0.00         | 308.33       | 2.39     |\n",
      "| 69  | 6          | 8          | sleep      | 22.58    | 0.00     | 100.00   | 0.00     | 0.00         | 370.00       | 0.66     |\n",
      "| 69  | 7          | 0          | action     | 22.58    | 0.00     | 100.00   | 0.00     | 350.00       | 370.00       | 11.27    |\n",
      "| 69  | 8          | 0          | action     | 22.58    | 0.00     | 100.00   | 0.00     | 700.00       | 370.00       | 9.88     |\n",
      "| 69  | 9          | 6          | action     | 22.58    | 0.00     | 100.00   | 2.00     | 700.00       | 452.22       | 10.25    |\n",
      "| 69  | 10         | 6          | action     | 22.58    | 0.00     | 100.00   | 4.00     | 700.00       | 534.44       | 10.62    |\n",
      "| 69  | 11         | 8          | work       | 22.58    | 5.00     | 95.00    | 9.00     | 700.00       | 671.47       | 10.24    |\n",
      "| 69  | 12         | 8          | work       | 22.58    | 10.00    | 90.00    | 14.00    | 700.00       | 808.51       | 9.85     |\n",
      "| 69  | 13         | 0          | action     | 22.58    | 10.00    | 100.00   | 0.00     | 1050.00      | 808.51       | 8.46     |\n",
      "| 69  | 14         | 8          | work       | 22.58    | 15.00    | 95.00    | 5.00     | 1050.00      | 945.54       | 8.08     |\n",
      "| 69  | 15         | 8          | work       | 22.58    | 20.00    | 90.00    | 10.00    | 1050.00      | 1082.58      | 7.69     |\n",
      "| 69  | 16         | 8          | work       | 22.58    | 25.00    | 85.00    | 15.00    | 1050.00      | 1219.61      | 7.31     |\n",
      "| 69  | 17         | 8          | work       | 22.58    | 30.00    | 80.00    | 20.00    | 1050.00      | 1356.65      | 6.93     |\n",
      "| 69  | 18         | 8          | work       | 22.58    | 35.00    | 75.00    | 25.00    | 1050.00      | 1493.68      | 6.54     |\n",
      "| 69  | 19         | 0          | action     | 22.58    | 35.00    | 95.00    | 5.00     | 1400.00      | 1493.68      | 5.15     |\n",
      "| 69  | 20         | 6          | action     | 22.58    | 25.00    | 100.00   | 7.00     | 1400.00      | 1575.90      | 7.52     |\n",
      "| 69  | 21         | 6          | action     | 22.58    | 15.00    | 100.00   | 9.00     | 1400.00      | 1658.13      | 9.89     |\n",
      "| 69  | 22         | 6          | action     | 22.58    | 5.00     | 100.00   | 11.00    | 1400.00      | 1740.35      | 12.26    |\n",
      "| 69  | 23         | 8          | sleep      | 22.58    | 1.00     | 100.00   | 9.00     | 1400.00      | 1802.01      | 13.34    |\n",
      "| 70  | 0          | 8          | sleep      | 22.56    | 0.00     | 100.00   | 7.00     | 0.00         | 0.00         | 23.74    |\n",
      "| 70  | 1          | 8          | sleep      | 22.56    | 0.00     | 100.00   | 5.00     | 0.00         | 61.61        | 9.28     |\n",
      "| 70  | 2          | 8          | sleep      | 22.56    | 0.00     | 100.00   | 3.00     | 0.00         | 123.22       | 7.55     |\n",
      "| 70  | 3          | 8          | sleep      | 22.56    | 0.00     | 100.00   | 1.00     | 0.00         | 184.83       | 5.83     |\n",
      "| 70  | 4          | 8          | sleep      | 22.56    | 0.00     | 100.00   | 0.00     | 0.00         | 246.44       | 4.11     |\n",
      "| 70  | 5          | 8          | sleep      | 22.56    | 0.00     | 100.00   | 0.00     | 0.00         | 308.04       | 2.39     |\n",
      "| 70  | 6          | 8          | sleep      | 22.56    | 0.00     | 100.00   | 0.00     | 0.00         | 369.65       | 0.66     |\n",
      "| 70  | 7          | 0          | action     | 22.56    | 0.00     | 100.00   | 0.00     | 350.00       | 369.65       | 11.27    |\n",
      "| 70  | 8          | 0          | action     | 22.56    | 0.00     | 100.00   | 0.00     | 700.00       | 369.65       | 9.88     |\n",
      "| 70  | 9          | 6          | action     | 22.56    | 0.00     | 100.00   | 2.00     | 700.00       | 451.80       | 10.25    |\n",
      "| 70  | 10         | 6          | action     | 22.56    | 0.00     | 100.00   | 4.00     | 700.00       | 533.94       | 10.62    |\n",
      "| 70  | 11         | 8          | work       | 22.56    | 5.00     | 95.00    | 9.00     | 700.00       | 670.85       | 10.23    |\n",
      "| 70  | 12         | 8          | work       | 22.56    | 10.00    | 90.00    | 14.00    | 700.00       | 807.76       | 9.85     |\n",
      "| 70  | 13         | 0          | action     | 22.56    | 10.00    | 100.00   | 0.00     | 1050.00      | 807.76       | 8.46     |\n",
      "| 70  | 14         | 8          | work       | 22.56    | 15.00    | 95.00    | 5.00     | 1050.00      | 944.67       | 8.07     |\n",
      "| 70  | 15         | 8          | work       | 22.56    | 20.00    | 90.00    | 10.00    | 1050.00      | 1081.58      | 7.69     |\n",
      "| 70  | 16         | 8          | work       | 22.56    | 25.00    | 85.00    | 15.00    | 1050.00      | 1218.49      | 7.30     |\n",
      "| 70  | 17         | 8          | work       | 22.56    | 30.00    | 80.00    | 20.00    | 1050.00      | 1355.40      | 6.92     |\n",
      "| 70  | 18         | 8          | work       | 22.56    | 35.00    | 75.00    | 25.00    | 1050.00      | 1492.31      | 6.54     |\n",
      "| 70  | 19         | 0          | action     | 22.56    | 35.00    | 95.00    | 5.00     | 1400.00      | 1492.31      | 5.14     |\n",
      "| 70  | 20         | 6          | action     | 22.56    | 25.00    | 100.00   | 7.00     | 1400.00      | 1574.45      | 7.51     |\n",
      "| 70  | 21         | 6          | action     | 22.56    | 15.00    | 100.00   | 9.00     | 1400.00      | 1656.60      | 9.88     |\n",
      "| 70  | 22         | 6          | action     | 22.56    | 5.00     | 100.00   | 11.00    | 1400.00      | 1738.74      | 12.25    |\n",
      "| 70  | 23         | 8          | sleep      | 22.56    | 1.00     | 100.00   | 9.00     | 1400.00      | 1800.35      | 13.33    |\n",
      "| 71  | 0          | 8          | sleep      | 22.54    | 0.00     | 100.00   | 7.00     | 0.00         | 0.00         | 23.73    |\n",
      "| 71  | 1          | 8          | sleep      | 22.54    | 0.00     | 100.00   | 5.00     | 0.00         | 61.55        | 9.28     |\n",
      "| 71  | 2          | 8          | sleep      | 22.54    | 0.00     | 100.00   | 3.00     | 0.00         | 123.10       | 7.55     |\n",
      "| 71  | 3          | 8          | sleep      | 22.54    | 0.00     | 100.00   | 1.00     | 0.00         | 184.66       | 5.83     |\n",
      "| 71  | 4          | 8          | sleep      | 22.54    | 0.00     | 100.00   | 0.00     | 0.00         | 246.21       | 4.11     |\n",
      "| 71  | 5          | 8          | sleep      | 22.54    | 0.00     | 100.00   | 0.00     | 0.00         | 307.76       | 2.38     |\n",
      "| 71  | 6          | 8          | sleep      | 22.54    | 0.00     | 100.00   | 0.00     | 0.00         | 369.31       | 0.66     |\n",
      "| 71  | 7          | 0          | action     | 22.54    | 0.00     | 100.00   | 0.00     | 350.00       | 369.31       | 11.27    |\n",
      "| 71  | 8          | 0          | action     | 22.54    | 0.00     | 100.00   | 0.00     | 700.00       | 369.31       | 9.88     |\n",
      "| 71  | 9          | 6          | action     | 22.54    | 0.00     | 100.00   | 2.00     | 700.00       | 451.38       | 10.25    |\n",
      "| 71  | 10         | 6          | action     | 22.54    | 0.00     | 100.00   | 4.00     | 700.00       | 533.45       | 10.61    |\n",
      "| 71  | 11         | 8          | work       | 22.54    | 5.00     | 95.00    | 9.00     | 700.00       | 670.24       | 10.23    |\n",
      "| 71  | 12         | 8          | work       | 22.54    | 10.00    | 90.00    | 14.00    | 700.00       | 807.02       | 9.85     |\n",
      "| 71  | 13         | 0          | action     | 22.54    | 10.00    | 100.00   | 0.00     | 1050.00      | 807.02       | 8.45     |\n",
      "| 71  | 14         | 8          | work       | 22.54    | 15.00    | 95.00    | 5.00     | 1050.00      | 943.80       | 8.07     |\n",
      "| 71  | 15         | 8          | work       | 22.54    | 20.00    | 90.00    | 10.00    | 1050.00      | 1080.58      | 7.68     |\n",
      "| 71  | 16         | 8          | work       | 22.54    | 25.00    | 85.00    | 15.00    | 1050.00      | 1217.37      | 7.30     |\n",
      "| 71  | 17         | 8          | work       | 22.54    | 30.00    | 80.00    | 20.00    | 1050.00      | 1354.15      | 6.91     |\n",
      "| 71  | 18         | 8          | work       | 22.54    | 35.00    | 75.00    | 25.00    | 1050.00      | 1490.93      | 6.53     |\n",
      "| 71  | 19         | 0          | action     | 22.54    | 35.00    | 95.00    | 5.00     | 1400.00      | 1490.93      | 5.14     |\n",
      "| 71  | 20         | 6          | action     | 22.54    | 25.00    | 100.00   | 7.00     | 1400.00      | 1573.00      | 7.51     |\n",
      "| 71  | 21         | 6          | action     | 22.54    | 15.00    | 100.00   | 9.00     | 1400.00      | 1655.07      | 9.88     |\n",
      "| 71  | 22         | 6          | action     | 22.54    | 5.00     | 100.00   | 11.00    | 1400.00      | 1737.14      | 12.25    |\n",
      "| 71  | 23         | 8          | sleep      | 22.54    | 1.00     | 100.00   | 9.00     | 1400.00      | 1798.69      | 13.32    |\n",
      "| 72  | 0          | 8          | sleep      | 22.52    | 0.00     | 100.00   | 7.00     | 0.00         | 0.00         | 23.73    |\n",
      "| 72  | 1          | 8          | sleep      | 22.52    | 0.00     | 100.00   | 5.00     | 0.00         | 61.50        | 9.28     |\n",
      "| 72  | 2          | 8          | sleep      | 22.52    | 0.00     | 100.00   | 3.00     | 0.00         | 122.99       | 7.55     |\n",
      "| 72  | 3          | 8          | sleep      | 22.52    | 0.00     | 100.00   | 1.00     | 0.00         | 184.49       | 5.83     |\n",
      "| 72  | 4          | 8          | sleep      | 22.52    | 0.00     | 100.00   | 0.00     | 0.00         | 245.98       | 4.11     |\n",
      "| 72  | 5          | 8          | sleep      | 22.52    | 0.00     | 100.00   | 0.00     | 0.00         | 307.48       | 2.38     |\n",
      "| 72  | 6          | 8          | sleep      | 22.52    | 0.00     | 100.00   | 0.00     | 0.00         | 368.97       | 0.66     |\n",
      "| 72  | 7          | 0          | action     | 22.52    | 0.00     | 100.00   | 0.00     | 350.00       | 368.97       | 11.27    |\n",
      "| 72  | 8          | 0          | action     | 22.52    | 0.00     | 100.00   | 0.00     | 700.00       | 368.97       | 9.87     |\n",
      "| 72  | 9          | 6          | action     | 22.52    | 0.00     | 100.00   | 2.00     | 700.00       | 450.97       | 10.24    |\n",
      "| 72  | 10         | 6          | action     | 22.52    | 0.00     | 100.00   | 4.00     | 700.00       | 532.96       | 10.61    |\n",
      "| 72  | 11         | 8          | work       | 22.52    | 5.00     | 95.00    | 9.00     | 700.00       | 669.62       | 10.23    |\n",
      "| 72  | 12         | 8          | work       | 22.52    | 10.00    | 90.00    | 14.00    | 700.00       | 806.28       | 9.84     |\n",
      "| 72  | 13         | 0          | action     | 22.52    | 10.00    | 100.00   | 0.00     | 1050.00      | 806.28       | 8.45     |\n",
      "| 72  | 14         | 8          | work       | 22.52    | 15.00    | 95.00    | 5.00     | 1050.00      | 942.94       | 8.06     |\n",
      "| 72  | 15         | 8          | work       | 22.52    | 20.00    | 90.00    | 10.00    | 1050.00      | 1079.59      | 7.68     |\n",
      "| 72  | 16         | 8          | work       | 22.52    | 25.00    | 85.00    | 15.00    | 1050.00      | 1216.25      | 7.29     |\n",
      "| 72  | 17         | 8          | work       | 22.52    | 30.00    | 80.00    | 20.00    | 1050.00      | 1352.91      | 6.91     |\n",
      "| 72  | 18         | 8          | work       | 22.52    | 35.00    | 75.00    | 25.00    | 1050.00      | 1489.56      | 6.52     |\n",
      "| 72  | 19         | 0          | action     | 22.52    | 35.00    | 95.00    | 5.00     | 1400.00      | 1489.56      | 5.13     |\n",
      "| 72  | 20         | 6          | action     | 22.52    | 25.00    | 100.00   | 7.00     | 1400.00      | 1571.56      | 7.50     |\n",
      "| 72  | 21         | 6          | action     | 22.52    | 15.00    | 100.00   | 9.00     | 1400.00      | 1653.55      | 9.87     |\n",
      "| 72  | 22         | 6          | action     | 22.52    | 5.00     | 100.00   | 11.00    | 1400.00      | 1735.55      | 12.24    |\n",
      "| 72  | 23         | 8          | sleep      | 22.52    | 1.00     | 100.00   | 9.00     | 1400.00      | 1797.04      | 13.32    |\n",
      "| 73  | 0          | 8          | sleep      | 22.50    | 0.00     | 100.00   | 7.00     | 0.00         | 0.00         | 23.72    |\n",
      "| 73  | 1          | 8          | sleep      | 22.50    | 0.00     | 100.00   | 5.00     | 0.00         | 61.44        | 9.28     |\n",
      "| 73  | 2          | 8          | sleep      | 22.50    | 0.00     | 100.00   | 3.00     | 0.00         | 122.88       | 7.55     |\n",
      "| 73  | 3          | 8          | sleep      | 22.50    | 0.00     | 100.00   | 1.00     | 0.00         | 184.32       | 5.83     |\n",
      "| 73  | 4          | 8          | sleep      | 22.50    | 0.00     | 100.00   | 0.00     | 0.00         | 245.76       | 4.11     |\n",
      "| 73  | 5          | 8          | sleep      | 22.50    | 0.00     | 100.00   | 0.00     | 0.00         | 307.20       | 2.38     |\n",
      "| 73  | 6          | 8          | sleep      | 22.50    | 0.00     | 100.00   | 0.00     | 0.00         | 368.64       | 0.66     |\n",
      "| 73  | 7          | 0          | action     | 22.50    | 0.00     | 100.00   | 0.00     | 350.00       | 368.64       | 11.27    |\n",
      "| 73  | 8          | 0          | action     | 22.50    | 0.00     | 100.00   | 0.00     | 700.00       | 368.64       | 9.87     |\n",
      "| 73  | 9          | 6          | action     | 22.50    | 0.00     | 100.00   | 2.00     | 700.00       | 450.56       | 10.24    |\n",
      "| 73  | 10         | 6          | action     | 22.50    | 0.00     | 100.00   | 4.00     | 700.00       | 532.48       | 10.61    |\n",
      "| 73  | 11         | 8          | work       | 22.50    | 5.00     | 95.00    | 9.00     | 700.00       | 669.01       | 10.23    |\n",
      "| 73  | 12         | 8          | work       | 22.50    | 10.00    | 90.00    | 14.00    | 700.00       | 805.54       | 9.84     |\n",
      "| 73  | 13         | 0          | action     | 22.50    | 10.00    | 100.00   | 0.00     | 1050.00      | 805.54       | 8.45     |\n",
      "| 73  | 14         | 8          | work       | 22.50    | 15.00    | 95.00    | 5.00     | 1050.00      | 942.07       | 8.06     |\n",
      "| 73  | 15         | 8          | work       | 22.50    | 20.00    | 90.00    | 10.00    | 1050.00      | 1078.60      | 7.68     |\n",
      "| 73  | 16         | 8          | work       | 22.50    | 25.00    | 85.00    | 15.00    | 1050.00      | 1215.14      | 7.29     |\n",
      "| 73  | 17         | 8          | work       | 22.50    | 30.00    | 80.00    | 20.00    | 1050.00      | 1351.67      | 6.90     |\n",
      "| 73  | 18         | 8          | work       | 22.50    | 35.00    | 75.00    | 25.00    | 1050.00      | 1488.20      | 6.52     |\n",
      "| 73  | 19         | 0          | action     | 22.50    | 35.00    | 95.00    | 5.00     | 1400.00      | 1488.20      | 5.13     |\n",
      "| 73  | 20         | 6          | action     | 22.50    | 25.00    | 100.00   | 7.00     | 1400.00      | 1570.12      | 7.49     |\n",
      "| 73  | 21         | 6          | action     | 22.50    | 15.00    | 100.00   | 9.00     | 1400.00      | 1652.04      | 9.86     |\n",
      "| 73  | 22         | 6          | action     | 22.50    | 5.00     | 100.00   | 11.00    | 1400.00      | 1733.96      | 12.23    |\n",
      "| 73  | 23         | 8          | sleep      | 22.50    | 1.00     | 100.00   | 9.00     | 1400.00      | 1795.40      | 13.31    |\n",
      "| 74  | 0          | 8          | sleep      | 22.48    | 0.00     | 100.00   | 7.00     | 0.00         | 0.00         | 23.72    |\n",
      "| 74  | 1          | 8          | sleep      | 22.48    | 0.00     | 100.00   | 5.00     | 0.00         | 61.38        | 9.28     |\n",
      "| 74  | 2          | 8          | sleep      | 22.48    | 0.00     | 100.00   | 3.00     | 0.00         | 122.77       | 7.55     |\n",
      "| 74  | 3          | 8          | sleep      | 22.48    | 0.00     | 100.00   | 1.00     | 0.00         | 184.15       | 5.83     |\n",
      "| 74  | 4          | 8          | sleep      | 22.48    | 0.00     | 100.00   | 0.00     | 0.00         | 245.53       | 4.10     |\n",
      "| 74  | 5          | 8          | sleep      | 22.48    | 0.00     | 100.00   | 0.00     | 0.00         | 306.92       | 2.38     |\n",
      "| 74  | 6          | 8          | sleep      | 22.48    | 0.00     | 100.00   | 0.00     | 0.00         | 368.30       | 0.66     |\n",
      "| 74  | 7          | 0          | action     | 22.48    | 0.00     | 100.00   | 0.00     | 350.00       | 368.30       | 11.26    |\n",
      "| 74  | 8          | 0          | action     | 22.48    | 0.00     | 100.00   | 0.00     | 700.00       | 368.30       | 9.87     |\n",
      "| 74  | 9          | 6          | action     | 22.48    | 0.00     | 100.00   | 2.00     | 700.00       | 450.15       | 10.24    |\n",
      "| 74  | 10         | 6          | action     | 22.48    | 0.00     | 100.00   | 4.00     | 700.00       | 531.99       | 10.61    |\n",
      "| 74  | 11         | 8          | work       | 22.48    | 5.00     | 95.00    | 9.00     | 700.00       | 668.40       | 10.22    |\n",
      "| 74  | 12         | 8          | work       | 22.48    | 10.00    | 90.00    | 14.00    | 700.00       | 804.80       | 9.84     |\n",
      "| 74  | 13         | 0          | action     | 22.48    | 10.00    | 100.00   | 0.00     | 1050.00      | 804.80       | 8.44     |\n",
      "| 74  | 14         | 8          | work       | 22.48    | 15.00    | 95.00    | 5.00     | 1050.00      | 941.21       | 8.06     |\n",
      "| 74  | 15         | 8          | work       | 22.48    | 20.00    | 90.00    | 10.00    | 1050.00      | 1077.62      | 7.67     |\n",
      "| 74  | 16         | 8          | work       | 22.48    | 25.00    | 85.00    | 15.00    | 1050.00      | 1214.03      | 7.29     |\n",
      "| 74  | 17         | 8          | work       | 22.48    | 30.00    | 80.00    | 20.00    | 1050.00      | 1350.44      | 6.90     |\n",
      "| 74  | 18         | 8          | work       | 22.48    | 35.00    | 75.00    | 25.00    | 1050.00      | 1486.84      | 6.51     |\n",
      "| 74  | 19         | 0          | action     | 22.48    | 35.00    | 95.00    | 5.00     | 1400.00      | 1486.84      | 5.12     |\n",
      "| 74  | 20         | 6          | action     | 22.48    | 25.00    | 100.00   | 7.00     | 1400.00      | 1568.69      | 7.49     |\n",
      "| 74  | 21         | 6          | action     | 22.48    | 15.00    | 100.00   | 9.00     | 1400.00      | 1650.53      | 9.86     |\n",
      "| 74  | 22         | 6          | action     | 22.48    | 5.00     | 100.00   | 11.00    | 1400.00      | 1732.38      | 12.23    |\n",
      "| 74  | 23         | 8          | sleep      | 22.48    | 1.00     | 100.00   | 9.00     | 1400.00      | 1793.76      | 13.30    |\n",
      "| 75  | 0          | 8          | sleep      | 22.46    | 0.00     | 100.00   | 7.00     | 0.00         | 0.00         | 23.71    |\n",
      "| 75  | 1          | 8          | sleep      | 22.46    | 0.00     | 100.00   | 5.00     | 0.00         | 61.33        | 9.28     |\n",
      "| 75  | 2          | 8          | sleep      | 22.46    | 0.00     | 100.00   | 3.00     | 0.00         | 122.66       | 7.55     |\n",
      "| 75  | 3          | 8          | sleep      | 22.46    | 0.00     | 100.00   | 1.00     | 0.00         | 183.98       | 5.83     |\n",
      "| 75  | 4          | 8          | sleep      | 22.46    | 0.00     | 100.00   | 0.00     | 0.00         | 245.31       | 4.10     |\n",
      "| 75  | 5          | 8          | sleep      | 22.46    | 0.00     | 100.00   | 0.00     | 0.00         | 306.64       | 2.38     |\n",
      "| 75  | 6          | 8          | sleep      | 22.46    | 0.00     | 100.00   | 0.00     | 0.00         | 367.97       | 0.66     |\n",
      "| 75  | 7          | 0          | action     | 22.46    | 0.00     | 100.00   | 0.00     | 350.00       | 367.97       | 11.26    |\n",
      "| 75  | 8          | 0          | action     | 22.46    | 0.00     | 100.00   | 0.00     | 700.00       | 367.97       | 9.87     |\n",
      "| 75  | 9          | 6          | action     | 22.46    | 0.00     | 100.00   | 2.00     | 700.00       | 449.74       | 10.24    |\n",
      "| 75  | 10         | 6          | action     | 22.46    | 0.00     | 100.00   | 4.00     | 700.00       | 531.51       | 10.61    |\n",
      "| 75  | 11         | 8          | work       | 22.46    | 5.00     | 95.00    | 9.00     | 700.00       | 667.79       | 10.22    |\n",
      "| 75  | 12         | 8          | work       | 22.46    | 10.00    | 90.00    | 14.00    | 700.00       | 804.07       | 9.83     |\n",
      "| 75  | 13         | 0          | action     | 22.46    | 10.00    | 100.00   | 0.00     | 1050.00      | 804.07       | 8.44     |\n",
      "| 75  | 14         | 8          | work       | 22.46    | 15.00    | 95.00    | 5.00     | 1050.00      | 940.36       | 8.05     |\n",
      "| 75  | 15         | 8          | work       | 22.46    | 20.00    | 90.00    | 10.00    | 1050.00      | 1076.64      | 7.67     |\n",
      "| 75  | 16         | 8          | work       | 22.46    | 25.00    | 85.00    | 15.00    | 1050.00      | 1212.92      | 7.28     |\n",
      "| 75  | 17         | 8          | work       | 22.46    | 30.00    | 80.00    | 20.00    | 1050.00      | 1349.21      | 6.89     |\n",
      "| 75  | 18         | 8          | work       | 22.46    | 35.00    | 75.00    | 25.00    | 1050.00      | 1485.49      | 6.51     |\n",
      "| 75  | 19         | 0          | action     | 22.46    | 35.00    | 95.00    | 5.00     | 1400.00      | 1485.49      | 5.12     |\n",
      "| 75  | 20         | 6          | action     | 22.46    | 25.00    | 100.00   | 7.00     | 1400.00      | 1567.26      | 7.48     |\n",
      "| 75  | 21         | 6          | action     | 22.46    | 15.00    | 100.00   | 9.00     | 1400.00      | 1649.03      | 9.85     |\n",
      "| 75  | 22         | 6          | action     | 22.46    | 5.00     | 100.00   | 11.00    | 1400.00      | 1730.80      | 12.22    |\n",
      "| 75  | 23         | 8          | sleep      | 22.46    | 1.00     | 100.00   | 9.00     | 1400.00      | 1792.13      | 13.29    |\n",
      "| 76  | 0          | 8          | sleep      | 22.44    | 0.00     | 100.00   | 7.00     | 0.00         | 0.00         | 23.71    |\n",
      "| 76  | 1          | 8          | sleep      | 22.44    | 0.00     | 100.00   | 5.00     | 0.00         | 61.27        | 9.28     |\n",
      "| 76  | 2          | 8          | sleep      | 22.44    | 0.00     | 100.00   | 3.00     | 0.00         | 122.54       | 7.55     |\n",
      "| 76  | 3          | 8          | sleep      | 22.44    | 0.00     | 100.00   | 1.00     | 0.00         | 183.82       | 5.83     |\n",
      "| 76  | 4          | 8          | sleep      | 22.44    | 0.00     | 100.00   | 0.00     | 0.00         | 245.09       | 4.10     |\n",
      "| 76  | 5          | 8          | sleep      | 22.44    | 0.00     | 100.00   | 0.00     | 0.00         | 306.36       | 2.38     |\n",
      "| 76  | 6          | 8          | sleep      | 22.44    | 0.00     | 100.00   | 0.00     | 0.00         | 367.63       | 0.65     |\n",
      "| 76  | 7          | 0          | action     | 22.44    | 0.00     | 100.00   | 0.00     | 350.00       | 367.63       | 11.26    |\n",
      "| 76  | 8          | 0          | action     | 22.44    | 0.00     | 100.00   | 0.00     | 700.00       | 367.63       | 9.87     |\n",
      "| 76  | 9          | 6          | action     | 22.44    | 0.00     | 100.00   | 2.00     | 700.00       | 449.33       | 10.24    |\n",
      "| 76  | 10         | 6          | action     | 22.44    | 0.00     | 100.00   | 4.00     | 700.00       | 531.02       | 10.61    |\n",
      "| 76  | 11         | 8          | work       | 22.44    | 5.00     | 95.00    | 9.00     | 700.00       | 667.18       | 10.22    |\n",
      "| 76  | 12         | 8          | work       | 22.44    | 10.00    | 90.00    | 14.00    | 700.00       | 803.34       | 9.83     |\n",
      "| 76  | 13         | 0          | action     | 22.44    | 10.00    | 100.00   | 0.00     | 1050.00      | 803.34       | 8.44     |\n",
      "| 76  | 14         | 8          | work       | 22.44    | 15.00    | 95.00    | 5.00     | 1050.00      | 939.50       | 8.05     |\n",
      "| 76  | 15         | 8          | work       | 22.44    | 20.00    | 90.00    | 10.00    | 1050.00      | 1075.66      | 7.66     |\n",
      "| 76  | 16         | 8          | work       | 22.44    | 25.00    | 85.00    | 15.00    | 1050.00      | 1211.82      | 7.28     |\n",
      "| 76  | 17         | 8          | work       | 22.44    | 30.00    | 80.00    | 20.00    | 1050.00      | 1347.98      | 6.89     |\n",
      "| 76  | 18         | 8          | work       | 22.44    | 35.00    | 75.00    | 25.00    | 1050.00      | 1484.14      | 6.50     |\n",
      "| 76  | 19         | 0          | action     | 22.44    | 35.00    | 95.00    | 5.00     | 1400.00      | 1484.14      | 5.11     |\n",
      "| 76  | 20         | 6          | action     | 22.44    | 25.00    | 100.00   | 7.00     | 1400.00      | 1565.84      | 7.48     |\n",
      "| 76  | 21         | 6          | action     | 22.44    | 15.00    | 100.00   | 9.00     | 1400.00      | 1647.53      | 9.84     |\n",
      "| 76  | 22         | 6          | action     | 22.44    | 5.00     | 100.00   | 11.00    | 1400.00      | 1729.23      | 12.21    |\n",
      "| 76  | 23         | 8          | sleep      | 22.44    | 1.00     | 100.00   | 9.00     | 1400.00      | 1790.50      | 13.29    |\n",
      "| 77  | 0          | 8          | sleep      | 22.41    | 0.00     | 100.00   | 7.00     | 0.00         | 0.00         | 23.70    |\n",
      "| 77  | 1          | 8          | sleep      | 22.41    | 0.00     | 100.00   | 5.00     | 0.00         | 61.22        | 9.28     |\n",
      "| 77  | 2          | 8          | sleep      | 22.41    | 0.00     | 100.00   | 3.00     | 0.00         | 122.43       | 7.55     |\n",
      "| 77  | 3          | 8          | sleep      | 22.41    | 0.00     | 100.00   | 1.00     | 0.00         | 183.65       | 5.83     |\n",
      "| 77  | 4          | 8          | sleep      | 22.41    | 0.00     | 100.00   | 0.00     | 0.00         | 244.87       | 4.10     |\n",
      "| 77  | 5          | 8          | sleep      | 22.41    | 0.00     | 100.00   | 0.00     | 0.00         | 306.08       | 2.38     |\n",
      "| 77  | 6          | 8          | sleep      | 22.41    | 0.00     | 100.00   | 0.00     | 0.00         | 367.30       | 0.65     |\n",
      "| 77  | 7          | 0          | action     | 22.41    | 0.00     | 100.00   | 0.00     | 350.00       | 367.30       | 11.26    |\n",
      "| 77  | 8          | 0          | action     | 22.41    | 0.00     | 100.00   | 0.00     | 700.00       | 367.30       | 9.87     |\n",
      "| 77  | 9          | 6          | action     | 22.41    | 0.00     | 100.00   | 2.00     | 700.00       | 448.92       | 10.24    |\n",
      "| 77  | 10         | 6          | action     | 22.41    | 0.00     | 100.00   | 4.00     | 700.00       | 530.54       | 10.60    |\n",
      "| 77  | 11         | 8          | work       | 22.41    | 5.00     | 95.00    | 9.00     | 700.00       | 666.58       | 10.22    |\n",
      "| 77  | 12         | 8          | work       | 22.41    | 10.00    | 90.00    | 14.00    | 700.00       | 802.62       | 9.83     |\n",
      "| 77  | 13         | 0          | action     | 22.41    | 10.00    | 100.00   | 0.00     | 1050.00      | 802.62       | 8.44     |\n",
      "| 77  | 14         | 8          | work       | 22.41    | 15.00    | 95.00    | 5.00     | 1050.00      | 938.65       | 8.05     |\n",
      "| 77  | 15         | 8          | work       | 22.41    | 20.00    | 90.00    | 10.00    | 1050.00      | 1074.69      | 7.66     |\n",
      "| 77  | 16         | 8          | work       | 22.41    | 25.00    | 85.00    | 15.00    | 1050.00      | 1210.73      | 7.27     |\n",
      "| 77  | 17         | 8          | work       | 22.41    | 30.00    | 80.00    | 20.00    | 1050.00      | 1346.76      | 6.88     |\n",
      "| 77  | 18         | 8          | work       | 22.41    | 35.00    | 75.00    | 25.00    | 1050.00      | 1482.80      | 6.50     |\n",
      "| 77  | 19         | 0          | action     | 22.41    | 35.00    | 95.00    | 5.00     | 1400.00      | 1482.80      | 5.10     |\n",
      "| 77  | 20         | 6          | action     | 22.41    | 25.00    | 100.00   | 7.00     | 1400.00      | 1564.42      | 7.47     |\n",
      "| 77  | 21         | 6          | action     | 22.41    | 15.00    | 100.00   | 9.00     | 1400.00      | 1646.04      | 9.84     |\n",
      "| 77  | 22         | 6          | action     | 22.41    | 5.00     | 100.00   | 11.00    | 1400.00      | 1727.66      | 12.21    |\n",
      "| 77  | 23         | 8          | sleep      | 22.41    | 1.00     | 100.00   | 9.00     | 1400.00      | 1788.88      | 13.28    |\n",
      "| 78  | 0          | 8          | sleep      | 22.39    | 0.00     | 100.00   | 7.00     | 0.00         | 0.00         | 23.70    |\n",
      "| 78  | 1          | 8          | sleep      | 22.39    | 0.00     | 100.00   | 5.00     | 0.00         | 61.16        | 9.28     |\n",
      "| 78  | 2          | 8          | sleep      | 22.39    | 0.00     | 100.00   | 3.00     | 0.00         | 122.32       | 7.55     |\n",
      "| 78  | 3          | 8          | sleep      | 22.39    | 0.00     | 100.00   | 1.00     | 0.00         | 183.48       | 5.83     |\n",
      "| 78  | 4          | 8          | sleep      | 22.39    | 0.00     | 100.00   | 0.00     | 0.00         | 244.64       | 4.10     |\n",
      "| 78  | 5          | 8          | sleep      | 22.39    | 0.00     | 100.00   | 0.00     | 0.00         | 305.81       | 2.38     |\n",
      "| 78  | 6          | 8          | sleep      | 22.39    | 0.00     | 100.00   | 0.00     | 0.00         | 366.97       | 0.65     |\n",
      "| 78  | 7          | 0          | action     | 22.39    | 0.00     | 100.00   | 0.00     | 350.00       | 366.97       | 11.26    |\n",
      "| 78  | 8          | 0          | action     | 22.39    | 0.00     | 100.00   | 0.00     | 700.00       | 366.97       | 9.87     |\n",
      "| 78  | 9          | 6          | action     | 22.39    | 0.00     | 100.00   | 2.00     | 700.00       | 448.52       | 10.23    |\n",
      "| 78  | 10         | 6          | action     | 22.39    | 0.00     | 100.00   | 4.00     | 700.00       | 530.06       | 10.60    |\n",
      "| 78  | 11         | 8          | work       | 22.39    | 5.00     | 95.00    | 9.00     | 700.00       | 665.98       | 10.21    |\n",
      "| 78  | 12         | 8          | work       | 22.39    | 10.00    | 90.00    | 14.00    | 700.00       | 801.89       | 9.82     |\n",
      "| 78  | 13         | 0          | action     | 22.39    | 10.00    | 100.00   | 0.00     | 1050.00      | 801.89       | 8.43     |\n",
      "| 78  | 14         | 8          | work       | 22.39    | 15.00    | 95.00    | 5.00     | 1050.00      | 937.81       | 8.04     |\n",
      "| 78  | 15         | 8          | work       | 22.39    | 20.00    | 90.00    | 10.00    | 1050.00      | 1073.72      | 7.66     |\n",
      "| 78  | 16         | 8          | work       | 22.39    | 25.00    | 85.00    | 15.00    | 1050.00      | 1209.63      | 7.27     |\n",
      "| 78  | 17         | 8          | work       | 22.39    | 30.00    | 80.00    | 20.00    | 1050.00      | 1345.55      | 6.88     |\n",
      "| 78  | 18         | 8          | work       | 22.39    | 35.00    | 75.00    | 25.00    | 1050.00      | 1481.46      | 6.49     |\n",
      "| 78  | 19         | 0          | action     | 22.39    | 35.00    | 95.00    | 5.00     | 1400.00      | 1481.46      | 5.10     |\n",
      "| 78  | 20         | 6          | action     | 22.39    | 25.00    | 100.00   | 7.00     | 1400.00      | 1563.01      | 7.47     |\n",
      "| 78  | 21         | 6          | action     | 22.39    | 15.00    | 100.00   | 9.00     | 1400.00      | 1644.56      | 9.83     |\n",
      "| 78  | 22         | 6          | action     | 22.39    | 5.00     | 100.00   | 11.00    | 1400.00      | 1726.11      | 12.20    |\n",
      "| 78  | 23         | 8          | sleep      | 22.39    | 1.00     | 100.00   | 9.00     | 1400.00      | 1787.27      | 13.27    |\n",
      "| 79  | 0          | 8          | sleep      | 22.37    | 0.00     | 100.00   | 7.00     | 0.00         | 0.00         | 23.69    |\n",
      "| 79  | 1          | 8          | sleep      | 22.37    | 0.00     | 100.00   | 5.00     | 0.00         | 61.11        | 9.27     |\n",
      "| 79  | 2          | 8          | sleep      | 22.37    | 0.00     | 100.00   | 3.00     | 0.00         | 122.21       | 7.55     |\n",
      "| 79  | 3          | 8          | sleep      | 22.37    | 0.00     | 100.00   | 1.00     | 0.00         | 183.32       | 5.82     |\n",
      "| 79  | 4          | 8          | sleep      | 22.37    | 0.00     | 100.00   | 0.00     | 0.00         | 244.42       | 4.10     |\n",
      "| 79  | 5          | 8          | sleep      | 22.37    | 0.00     | 100.00   | 0.00     | 0.00         | 305.53       | 2.37     |\n",
      "| 79  | 6          | 8          | sleep      | 22.37    | 0.00     | 100.00   | 0.00     | 0.00         | 366.64       | 0.65     |\n",
      "| 79  | 7          | 0          | action     | 22.37    | 0.00     | 100.00   | 0.00     | 350.00       | 366.64       | 11.26    |\n",
      "| 79  | 8          | 0          | action     | 22.37    | 0.00     | 100.00   | 0.00     | 700.00       | 366.64       | 9.87     |\n",
      "| 79  | 9          | 6          | action     | 22.37    | 0.00     | 100.00   | 2.00     | 700.00       | 448.11       | 10.23    |\n",
      "| 79  | 10         | 6          | action     | 22.37    | 0.00     | 100.00   | 4.00     | 700.00       | 529.59       | 10.60    |\n",
      "| 79  | 11         | 8          | work       | 22.37    | 5.00     | 95.00    | 9.00     | 700.00       | 665.38       | 10.21    |\n",
      "| 79  | 12         | 8          | work       | 22.37    | 10.00    | 90.00    | 14.00    | 700.00       | 801.17       | 9.82     |\n",
      "| 79  | 13         | 0          | action     | 22.37    | 10.00    | 100.00   | 0.00     | 1050.00      | 801.17       | 8.43     |\n",
      "| 79  | 14         | 8          | work       | 22.37    | 15.00    | 95.00    | 5.00     | 1050.00      | 936.96       | 8.04     |\n",
      "| 79  | 15         | 8          | work       | 22.37    | 20.00    | 90.00    | 10.00    | 1050.00      | 1072.75      | 7.65     |\n",
      "| 79  | 16         | 8          | work       | 22.37    | 25.00    | 85.00    | 15.00    | 1050.00      | 1208.54      | 7.26     |\n",
      "| 79  | 17         | 8          | work       | 22.37    | 30.00    | 80.00    | 20.00    | 1050.00      | 1344.34      | 6.87     |\n",
      "| 79  | 18         | 8          | work       | 22.37    | 35.00    | 75.00    | 25.00    | 1050.00      | 1480.13      | 6.48     |\n",
      "| 79  | 19         | 0          | action     | 22.37    | 35.00    | 95.00    | 5.00     | 1400.00      | 1480.13      | 5.09     |\n",
      "| 79  | 20         | 6          | action     | 22.37    | 25.00    | 100.00   | 7.00     | 1400.00      | 1561.60      | 7.46     |\n",
      "| 79  | 21         | 6          | action     | 22.37    | 15.00    | 100.00   | 9.00     | 1400.00      | 1643.08      | 9.83     |\n",
      "| 79  | 22         | 6          | action     | 22.37    | 5.00     | 100.00   | 11.00    | 1400.00      | 1724.55      | 12.19    |\n",
      "| 79  | 23         | 8          | sleep      | 22.37    | 1.00     | 100.00   | 9.00     | 1400.00      | 1785.66      | 13.27    |\n",
      "| 80  | 0          | 8          | sleep      | 22.35    | 0.00     | 100.00   | 7.00     | 0.00         | 0.00         | 23.69    |\n",
      "| 80  | 1          | 8          | sleep      | 22.35    | 0.00     | 100.00   | 5.00     | 0.00         | 61.05        | 9.27     |\n",
      "| 80  | 2          | 8          | sleep      | 22.35    | 0.00     | 100.00   | 3.00     | 0.00         | 122.10       | 7.55     |\n",
      "| 80  | 3          | 8          | sleep      | 22.35    | 0.00     | 100.00   | 1.00     | 0.00         | 183.15       | 5.82     |\n",
      "| 80  | 4          | 8          | sleep      | 22.35    | 0.00     | 100.00   | 0.00     | 0.00         | 244.21       | 4.10     |\n",
      "| 80  | 5          | 8          | sleep      | 22.35    | 0.00     | 100.00   | 0.00     | 0.00         | 305.26       | 2.37     |\n",
      "| 80  | 6          | 8          | sleep      | 22.35    | 0.00     | 100.00   | 0.00     | 0.00         | 366.31       | 0.65     |\n",
      "| 80  | 7          | 0          | action     | 22.35    | 0.00     | 100.00   | 0.00     | 350.00       | 366.31       | 11.26    |\n",
      "| 80  | 8          | 0          | action     | 22.35    | 0.00     | 100.00   | 0.00     | 700.00       | 366.31       | 9.86     |\n",
      "| 80  | 9          | 6          | action     | 22.35    | 0.00     | 100.00   | 2.00     | 700.00       | 447.71       | 10.23    |\n",
      "| 80  | 10         | 6          | action     | 22.35    | 0.00     | 100.00   | 4.00     | 700.00       | 529.11       | 10.60    |\n",
      "| 80  | 11         | 8          | work       | 22.35    | 5.00     | 95.00    | 9.00     | 700.00       | 664.78       | 10.21    |\n",
      "| 80  | 12         | 8          | work       | 22.35    | 10.00    | 90.00    | 14.00    | 700.00       | 800.45       | 9.82     |\n",
      "| 80  | 13         | 0          | action     | 22.35    | 10.00    | 100.00   | 0.00     | 1050.00      | 800.45       | 8.43     |\n",
      "| 80  | 14         | 8          | work       | 22.35    | 15.00    | 95.00    | 5.00     | 1050.00      | 936.12       | 8.04     |\n",
      "| 80  | 15         | 8          | work       | 22.35    | 20.00    | 90.00    | 10.00    | 1050.00      | 1071.79      | 7.65     |\n",
      "| 80  | 16         | 8          | work       | 22.35    | 25.00    | 85.00    | 15.00    | 1050.00      | 1207.46      | 7.26     |\n",
      "| 80  | 17         | 8          | work       | 22.35    | 30.00    | 80.00    | 20.00    | 1050.00      | 1343.13      | 6.87     |\n",
      "| 80  | 18         | 8          | work       | 22.35    | 35.00    | 75.00    | 25.00    | 1050.00      | 1478.80      | 6.48     |\n",
      "| 80  | 19         | 0          | action     | 22.35    | 35.00    | 95.00    | 5.00     | 1400.00      | 1478.80      | 5.09     |\n",
      "| 80  | 20         | 6          | action     | 22.35    | 25.00    | 100.00   | 7.00     | 1400.00      | 1560.20      | 7.45     |\n",
      "| 80  | 21         | 6          | action     | 22.35    | 15.00    | 100.00   | 9.00     | 1400.00      | 1641.60      | 9.82     |\n",
      "| 80  | 22         | 6          | action     | 22.35    | 5.00     | 100.00   | 11.00    | 1400.00      | 1723.01      | 12.19    |\n",
      "| 80  | 23         | 8          | sleep      | 22.35    | 1.00     | 100.00   | 9.00     | 1400.00      | 1784.06      | 13.26    |\n",
      "| 81  | 0          | 8          | sleep      | 22.33    | 0.00     | 100.00   | 7.00     | 0.00         | 0.00         | 23.68    |\n",
      "| 81  | 1          | 8          | sleep      | 22.33    | 0.00     | 100.00   | 5.00     | 0.00         | 61.00        | 9.27     |\n",
      "| 81  | 2          | 8          | sleep      | 22.33    | 0.00     | 100.00   | 3.00     | 0.00         | 121.99       | 7.55     |\n",
      "| 81  | 3          | 8          | sleep      | 22.33    | 0.00     | 100.00   | 1.00     | 0.00         | 182.99       | 5.82     |\n",
      "| 81  | 4          | 8          | sleep      | 22.33    | 0.00     | 100.00   | 0.00     | 0.00         | 243.99       | 4.10     |\n",
      "| 81  | 5          | 8          | sleep      | 22.33    | 0.00     | 100.00   | 0.00     | 0.00         | 304.98       | 2.37     |\n",
      "| 81  | 6          | 8          | sleep      | 22.33    | 0.00     | 100.00   | 0.00     | 0.00         | 365.98       | 0.65     |\n",
      "| 81  | 7          | 0          | action     | 22.33    | 0.00     | 100.00   | 0.00     | 350.00       | 365.98       | 11.26    |\n",
      "| 81  | 8          | 0          | action     | 22.33    | 0.00     | 100.00   | 0.00     | 700.00       | 365.98       | 9.86     |\n",
      "| 81  | 9          | 6          | action     | 22.33    | 0.00     | 100.00   | 2.00     | 700.00       | 447.31       | 10.23    |\n",
      "| 81  | 10         | 6          | action     | 22.33    | 0.00     | 100.00   | 4.00     | 700.00       | 528.64       | 10.60    |\n",
      "| 81  | 11         | 8          | work       | 22.33    | 5.00     | 95.00    | 9.00     | 700.00       | 664.19       | 10.21    |\n",
      "| 81  | 12         | 8          | work       | 22.33    | 10.00    | 90.00    | 14.00    | 700.00       | 799.73       | 9.82     |\n",
      "| 81  | 13         | 0          | action     | 22.33    | 10.00    | 100.00   | 0.00     | 1050.00      | 799.73       | 8.42     |\n",
      "| 81  | 14         | 8          | work       | 22.33    | 15.00    | 95.00    | 5.00     | 1050.00      | 935.28       | 8.03     |\n",
      "| 81  | 15         | 8          | work       | 22.33    | 20.00    | 90.00    | 10.00    | 1050.00      | 1070.83      | 7.64     |\n",
      "| 81  | 16         | 8          | work       | 22.33    | 25.00    | 85.00    | 15.00    | 1050.00      | 1206.38      | 7.25     |\n",
      "| 81  | 17         | 8          | work       | 22.33    | 30.00    | 80.00    | 20.00    | 1050.00      | 1341.93      | 6.86     |\n",
      "| 81  | 18         | 8          | work       | 22.33    | 35.00    | 75.00    | 25.00    | 1050.00      | 1477.48      | 6.47     |\n",
      "| 81  | 19         | 0          | action     | 22.33    | 35.00    | 95.00    | 5.00     | 1400.00      | 1477.48      | 5.08     |\n",
      "| 81  | 20         | 6          | action     | 22.33    | 25.00    | 100.00   | 7.00     | 1400.00      | 1558.81      | 7.45     |\n",
      "| 81  | 21         | 6          | action     | 22.33    | 15.00    | 100.00   | 9.00     | 1400.00      | 1640.13      | 9.81     |\n",
      "| 81  | 22         | 6          | action     | 22.33    | 5.00     | 100.00   | 11.00    | 1400.00      | 1721.46      | 12.18    |\n",
      "| 81  | 23         | 8          | sleep      | 22.33    | 1.00     | 100.00   | 9.00     | 1400.00      | 1782.46      | 13.25    |\n",
      "| 82  | 0          | 8          | sleep      | 22.31    | 0.00     | 100.00   | 7.00     | 0.00         | 0.00         | 23.68    |\n",
      "| 82  | 1          | 8          | sleep      | 22.31    | 0.00     | 100.00   | 5.00     | 0.00         | 60.94        | 9.27     |\n",
      "| 82  | 2          | 8          | sleep      | 22.31    | 0.00     | 100.00   | 3.00     | 0.00         | 121.88       | 7.55     |\n",
      "| 82  | 3          | 8          | sleep      | 22.31    | 0.00     | 100.00   | 1.00     | 0.00         | 182.83       | 5.82     |\n",
      "| 82  | 4          | 8          | sleep      | 22.31    | 0.00     | 100.00   | 0.00     | 0.00         | 243.77       | 4.10     |\n",
      "| 82  | 5          | 8          | sleep      | 22.31    | 0.00     | 100.00   | 0.00     | 0.00         | 304.71       | 2.37     |\n",
      "| 82  | 6          | 8          | sleep      | 22.31    | 0.00     | 100.00   | 0.00     | 0.00         | 365.65       | 0.65     |\n",
      "| 82  | 7          | 0          | action     | 22.31    | 0.00     | 100.00   | 0.00     | 350.00       | 365.65       | 11.25    |\n",
      "| 82  | 8          | 0          | action     | 22.31    | 0.00     | 100.00   | 0.00     | 700.00       | 365.65       | 9.86     |\n",
      "| 82  | 9          | 6          | action     | 22.31    | 0.00     | 100.00   | 2.00     | 700.00       | 446.91       | 10.23    |\n",
      "| 82  | 10         | 6          | action     | 22.31    | 0.00     | 100.00   | 4.00     | 700.00       | 528.17       | 10.59    |\n",
      "| 82  | 11         | 8          | work       | 22.31    | 5.00     | 95.00    | 9.00     | 700.00       | 663.59       | 10.20    |\n",
      "| 82  | 12         | 8          | work       | 22.31    | 10.00    | 90.00    | 14.00    | 700.00       | 799.02       | 9.81     |\n",
      "| 82  | 13         | 0          | action     | 22.31    | 10.00    | 100.00   | 0.00     | 1050.00      | 799.02       | 8.42     |\n",
      "| 82  | 14         | 8          | work       | 22.31    | 15.00    | 95.00    | 5.00     | 1050.00      | 934.45       | 8.03     |\n",
      "| 82  | 15         | 8          | work       | 22.31    | 20.00    | 90.00    | 10.00    | 1050.00      | 1069.88      | 7.64     |\n",
      "| 82  | 16         | 8          | work       | 22.31    | 25.00    | 85.00    | 15.00    | 1050.00      | 1205.30      | 7.25     |\n",
      "| 82  | 17         | 8          | work       | 22.31    | 30.00    | 80.00    | 20.00    | 1050.00      | 1340.73      | 6.86     |\n",
      "| 82  | 18         | 8          | work       | 22.31    | 35.00    | 75.00    | 25.00    | 1050.00      | 1476.16      | 6.47     |\n",
      "| 82  | 19         | 0          | action     | 22.31    | 35.00    | 95.00    | 5.00     | 1400.00      | 1476.16      | 5.08     |\n",
      "| 82  | 20         | 6          | action     | 22.31    | 25.00    | 100.00   | 7.00     | 1400.00      | 1557.41      | 7.44     |\n",
      "| 82  | 21         | 6          | action     | 22.31    | 15.00    | 100.00   | 9.00     | 1400.00      | 1638.67      | 9.81     |\n",
      "| 82  | 22         | 6          | action     | 22.31    | 5.00     | 100.00   | 11.00    | 1400.00      | 1719.93      | 12.17    |\n",
      "| 82  | 23         | 8          | sleep      | 22.31    | 1.00     | 100.00   | 9.00     | 1400.00      | 1780.87      | 13.25    |\n",
      "| 83  | 0          | 8          | sleep      | 22.29    | 0.00     | 100.00   | 7.00     | 0.00         | 0.00         | 23.67    |\n",
      "| 83  | 1          | 8          | sleep      | 22.29    | 0.00     | 100.00   | 5.00     | 0.00         | 60.89        | 9.27     |\n",
      "| 83  | 2          | 8          | sleep      | 22.29    | 0.00     | 100.00   | 3.00     | 0.00         | 121.78       | 7.55     |\n",
      "| 83  | 3          | 8          | sleep      | 22.29    | 0.00     | 100.00   | 1.00     | 0.00         | 182.66       | 5.82     |\n",
      "| 83  | 4          | 8          | sleep      | 22.29    | 0.00     | 100.00   | 0.00     | 0.00         | 243.55       | 4.10     |\n",
      "| 83  | 5          | 8          | sleep      | 22.29    | 0.00     | 100.00   | 0.00     | 0.00         | 304.44       | 2.37     |\n",
      "| 83  | 6          | 8          | sleep      | 22.29    | 0.00     | 100.00   | 0.00     | 0.00         | 365.33       | 0.64     |\n",
      "| 83  | 7          | 0          | action     | 22.29    | 0.00     | 100.00   | 0.00     | 350.00       | 365.33       | 11.25    |\n",
      "| 83  | 8          | 0          | action     | 22.29    | 0.00     | 100.00   | 0.00     | 700.00       | 365.33       | 9.86     |\n",
      "| 83  | 9          | 6          | action     | 22.29    | 0.00     | 100.00   | 2.00     | 700.00       | 446.51       | 10.23    |\n",
      "| 83  | 10         | 6          | action     | 22.29    | 0.00     | 100.00   | 4.00     | 700.00       | 527.70       | 10.59    |\n",
      "| 83  | 11         | 8          | work       | 22.29    | 5.00     | 95.00    | 9.00     | 700.00       | 663.00       | 10.20    |\n",
      "| 83  | 12         | 8          | work       | 22.29    | 10.00    | 90.00    | 14.00    | 700.00       | 798.31       | 9.81     |\n",
      "| 83  | 13         | 0          | action     | 22.29    | 10.00    | 100.00   | 0.00     | 1050.00      | 798.31       | 8.42     |\n",
      "| 83  | 14         | 8          | work       | 22.29    | 15.00    | 95.00    | 5.00     | 1050.00      | 933.62       | 8.03     |\n",
      "| 83  | 15         | 8          | work       | 22.29    | 20.00    | 90.00    | 10.00    | 1050.00      | 1068.92      | 7.64     |\n",
      "| 83  | 16         | 8          | work       | 22.29    | 25.00    | 85.00    | 15.00    | 1050.00      | 1204.23      | 7.25     |\n",
      "| 83  | 17         | 8          | work       | 22.29    | 30.00    | 80.00    | 20.00    | 1050.00      | 1339.54      | 6.85     |\n",
      "| 83  | 18         | 8          | work       | 22.29    | 35.00    | 75.00    | 25.00    | 1050.00      | 1474.84      | 6.46     |\n",
      "| 83  | 19         | 0          | action     | 22.29    | 35.00    | 95.00    | 5.00     | 1400.00      | 1474.84      | 5.07     |\n",
      "| 83  | 20         | 6          | action     | 22.29    | 25.00    | 100.00   | 7.00     | 1400.00      | 1556.03      | 7.44     |\n",
      "| 83  | 21         | 6          | action     | 22.29    | 15.00    | 100.00   | 9.00     | 1400.00      | 1637.21      | 9.80     |\n",
      "| 83  | 22         | 6          | action     | 22.29    | 5.00     | 100.00   | 11.00    | 1400.00      | 1718.40      | 12.17    |\n",
      "| 83  | 23         | 8          | sleep      | 22.29    | 1.00     | 100.00   | 9.00     | 1400.00      | 1779.29      | 13.24    |\n",
      "| 84  | 0          | 8          | sleep      | 22.27    | 0.00     | 100.00   | 7.00     | 0.00         | 0.00         | 23.67    |\n",
      "| 84  | 1          | 8          | sleep      | 22.27    | 0.00     | 100.00   | 5.00     | 0.00         | 60.83        | 9.27     |\n",
      "| 84  | 2          | 8          | sleep      | 22.27    | 0.00     | 100.00   | 3.00     | 0.00         | 121.67       | 7.55     |\n",
      "| 84  | 3          | 8          | sleep      | 22.27    | 0.00     | 100.00   | 1.00     | 0.00         | 182.50       | 5.82     |\n",
      "| 84  | 4          | 8          | sleep      | 22.27    | 0.00     | 100.00   | 0.00     | 0.00         | 243.34       | 4.10     |\n",
      "| 84  | 5          | 8          | sleep      | 22.27    | 0.00     | 100.00   | 0.00     | 0.00         | 304.17       | 2.37     |\n",
      "| 84  | 6          | 8          | sleep      | 22.27    | 0.00     | 100.00   | 0.00     | 0.00         | 365.00       | 0.64     |\n",
      "| 84  | 7          | 0          | action     | 22.27    | 0.00     | 100.00   | 0.00     | 350.00       | 365.00       | 11.25    |\n",
      "| 84  | 8          | 0          | action     | 22.27    | 0.00     | 100.00   | 0.00     | 700.00       | 365.00       | 9.86     |\n",
      "| 84  | 9          | 6          | action     | 22.27    | 0.00     | 100.00   | 2.00     | 700.00       | 446.12       | 10.23    |\n",
      "| 84  | 10         | 6          | action     | 22.27    | 0.00     | 100.00   | 4.00     | 700.00       | 527.23       | 10.59    |\n",
      "| 84  | 11         | 8          | work       | 22.27    | 5.00     | 95.00    | 9.00     | 700.00       | 662.42       | 10.20    |\n",
      "| 84  | 12         | 8          | work       | 22.27    | 10.00    | 90.00    | 14.00    | 700.00       | 797.60       | 9.81     |\n",
      "| 84  | 13         | 0          | action     | 22.27    | 10.00    | 100.00   | 0.00     | 1050.00      | 797.60       | 8.42     |\n",
      "| 84  | 14         | 8          | work       | 22.27    | 15.00    | 95.00    | 5.00     | 1050.00      | 932.79       | 8.02     |\n",
      "| 84  | 15         | 8          | work       | 22.27    | 20.00    | 90.00    | 10.00    | 1050.00      | 1067.98      | 7.63     |\n",
      "| 84  | 16         | 8          | work       | 22.27    | 25.00    | 85.00    | 15.00    | 1050.00      | 1203.16      | 7.24     |\n",
      "| 84  | 17         | 8          | work       | 22.27    | 30.00    | 80.00    | 20.00    | 1050.00      | 1338.35      | 6.85     |\n",
      "| 84  | 18         | 8          | work       | 22.27    | 35.00    | 75.00    | 25.00    | 1050.00      | 1473.54      | 6.46     |\n",
      "| 84  | 19         | 0          | action     | 22.27    | 35.00    | 95.00    | 5.00     | 1400.00      | 1473.54      | 5.07     |\n",
      "| 84  | 20         | 6          | action     | 22.27    | 25.00    | 100.00   | 7.00     | 1400.00      | 1554.65      | 7.43     |\n",
      "| 84  | 21         | 6          | action     | 22.27    | 15.00    | 100.00   | 9.00     | 1400.00      | 1635.76      | 9.80     |\n",
      "| 84  | 22         | 6          | action     | 22.27    | 5.00     | 100.00   | 11.00    | 1400.00      | 1716.87      | 12.16    |\n",
      "| 84  | 23         | 8          | sleep      | 22.27    | 1.00     | 100.00   | 9.00     | 1400.00      | 1777.71      | 13.23    |\n",
      "| 85  | 0          | 8          | sleep      | 22.26    | 0.00     | 100.00   | 7.00     | 0.00         | 0.00         | 23.66    |\n",
      "| 85  | 1          | 8          | sleep      | 22.26    | 0.00     | 100.00   | 5.00     | 0.00         | 60.78        | 9.27     |\n",
      "| 85  | 2          | 8          | sleep      | 22.26    | 0.00     | 100.00   | 3.00     | 0.00         | 121.56       | 7.55     |\n",
      "| 85  | 3          | 8          | sleep      | 22.26    | 0.00     | 100.00   | 1.00     | 0.00         | 182.34       | 5.82     |\n",
      "| 85  | 4          | 8          | sleep      | 22.26    | 0.00     | 100.00   | 0.00     | 0.00         | 243.12       | 4.09     |\n",
      "| 85  | 5          | 8          | sleep      | 22.26    | 0.00     | 100.00   | 0.00     | 0.00         | 303.90       | 2.37     |\n",
      "| 85  | 6          | 8          | sleep      | 22.26    | 0.00     | 100.00   | 0.00     | 0.00         | 364.68       | 0.64     |\n",
      "| 85  | 7          | 0          | action     | 22.26    | 0.00     | 100.00   | 0.00     | 350.00       | 364.68       | 11.25    |\n",
      "| 85  | 8          | 0          | action     | 22.26    | 0.00     | 100.00   | 0.00     | 700.00       | 364.68       | 9.86     |\n",
      "| 85  | 9          | 6          | action     | 22.26    | 0.00     | 100.00   | 2.00     | 700.00       | 445.72       | 10.22    |\n",
      "| 85  | 10         | 6          | action     | 22.26    | 0.00     | 100.00   | 4.00     | 700.00       | 526.76       | 10.59    |\n",
      "| 85  | 11         | 8          | work       | 22.26    | 5.00     | 95.00    | 9.00     | 700.00       | 661.83       | 10.20    |\n",
      "| 85  | 12         | 8          | work       | 22.26    | 10.00    | 90.00    | 14.00    | 700.00       | 796.90       | 9.80     |\n",
      "| 85  | 13         | 0          | action     | 22.26    | 10.00    | 100.00   | 0.00     | 1050.00      | 796.90       | 8.41     |\n",
      "| 85  | 14         | 8          | work       | 22.26    | 15.00    | 95.00    | 5.00     | 1050.00      | 931.96       | 8.02     |\n",
      "| 85  | 15         | 8          | work       | 22.26    | 20.00    | 90.00    | 10.00    | 1050.00      | 1067.03      | 7.63     |\n",
      "| 85  | 16         | 8          | work       | 22.26    | 25.00    | 85.00    | 15.00    | 1050.00      | 1202.10      | 7.24     |\n",
      "| 85  | 17         | 8          | work       | 22.26    | 30.00    | 80.00    | 20.00    | 1050.00      | 1337.17      | 6.84     |\n",
      "| 85  | 18         | 8          | work       | 22.26    | 35.00    | 75.00    | 25.00    | 1050.00      | 1472.23      | 6.45     |\n",
      "| 85  | 19         | 0          | action     | 22.26    | 35.00    | 95.00    | 5.00     | 1400.00      | 1472.23      | 5.06     |\n",
      "| 85  | 20         | 6          | action     | 22.26    | 25.00    | 100.00   | 7.00     | 1400.00      | 1553.27      | 7.43     |\n",
      "| 85  | 21         | 6          | action     | 22.26    | 15.00    | 100.00   | 9.00     | 1400.00      | 1634.31      | 9.79     |\n",
      "| 85  | 22         | 6          | action     | 22.26    | 5.00     | 100.00   | 11.00    | 1400.00      | 1715.35      | 12.15    |\n",
      "| 85  | 23         | 8          | sleep      | 22.26    | 1.00     | 100.00   | 9.00     | 1400.00      | 1776.13      | 13.23    |\n",
      "| 86  | 0          | 8          | sleep      | 22.24    | 0.00     | 100.00   | 7.00     | 0.00         | 0.00         | 23.66    |\n",
      "| 86  | 1          | 8          | sleep      | 22.24    | 0.00     | 100.00   | 5.00     | 0.00         | 60.73        | 9.27     |\n",
      "| 86  | 2          | 8          | sleep      | 22.24    | 0.00     | 100.00   | 3.00     | 0.00         | 121.45       | 7.55     |\n",
      "| 86  | 3          | 8          | sleep      | 22.24    | 0.00     | 100.00   | 1.00     | 0.00         | 182.18       | 5.82     |\n",
      "| 86  | 4          | 8          | sleep      | 22.24    | 0.00     | 100.00   | 0.00     | 0.00         | 242.91       | 4.09     |\n",
      "| 86  | 5          | 8          | sleep      | 22.24    | 0.00     | 100.00   | 0.00     | 0.00         | 303.63       | 2.37     |\n",
      "| 86  | 6          | 8          | sleep      | 22.24    | 0.00     | 100.00   | 0.00     | 0.00         | 364.36       | 0.64     |\n",
      "| 86  | 7          | 0          | action     | 22.24    | 0.00     | 100.00   | 0.00     | 350.00       | 364.36       | 11.25    |\n",
      "| 86  | 8          | 0          | action     | 22.24    | 0.00     | 100.00   | 0.00     | 700.00       | 364.36       | 9.86     |\n",
      "| 86  | 9          | 6          | action     | 22.24    | 0.00     | 100.00   | 2.00     | 700.00       | 445.33       | 10.22    |\n",
      "| 86  | 10         | 6          | action     | 22.24    | 0.00     | 100.00   | 4.00     | 700.00       | 526.30       | 10.59    |\n",
      "| 86  | 11         | 8          | work       | 22.24    | 5.00     | 95.00    | 9.00     | 700.00       | 661.25       | 10.19    |\n",
      "| 86  | 12         | 8          | work       | 22.24    | 10.00    | 90.00    | 14.00    | 700.00       | 796.19       | 9.80     |\n",
      "| 86  | 13         | 0          | action     | 22.24    | 10.00    | 100.00   | 0.00     | 1050.00      | 796.19       | 8.41     |\n",
      "| 86  | 14         | 8          | work       | 22.24    | 15.00    | 95.00    | 5.00     | 1050.00      | 931.14       | 8.02     |\n",
      "| 86  | 15         | 8          | work       | 22.24    | 20.00    | 90.00    | 10.00    | 1050.00      | 1066.09      | 7.62     |\n",
      "| 86  | 16         | 8          | work       | 22.24    | 25.00    | 85.00    | 15.00    | 1050.00      | 1201.04      | 7.23     |\n",
      "| 86  | 17         | 8          | work       | 22.24    | 30.00    | 80.00    | 20.00    | 1050.00      | 1335.99      | 6.84     |\n",
      "| 86  | 18         | 8          | work       | 22.24    | 35.00    | 75.00    | 25.00    | 1050.00      | 1470.93      | 6.45     |\n",
      "| 86  | 19         | 0          | action     | 22.24    | 35.00    | 95.00    | 5.00     | 1400.00      | 1470.93      | 5.06     |\n",
      "| 86  | 20         | 6          | action     | 22.24    | 25.00    | 100.00   | 7.00     | 1400.00      | 1551.90      | 7.42     |\n",
      "| 86  | 21         | 6          | action     | 22.24    | 15.00    | 100.00   | 9.00     | 1400.00      | 1632.87      | 9.78     |\n",
      "| 86  | 22         | 6          | action     | 22.24    | 5.00     | 100.00   | 11.00    | 1400.00      | 1713.84      | 12.15    |\n",
      "| 86  | 23         | 8          | sleep      | 22.24    | 1.00     | 100.00   | 9.00     | 1400.00      | 1774.57      | 13.22    |\n",
      "| 87  | 0          | 8          | sleep      | 22.22    | 0.00     | 100.00   | 7.00     | 0.00         | 0.00         | 23.65    |\n",
      "| 87  | 1          | 8          | sleep      | 22.22    | 0.00     | 100.00   | 5.00     | 0.00         | 60.67        | 9.27     |\n",
      "| 87  | 2          | 8          | sleep      | 22.22    | 0.00     | 100.00   | 3.00     | 0.00         | 121.35       | 7.55     |\n",
      "| 87  | 3          | 8          | sleep      | 22.22    | 0.00     | 100.00   | 1.00     | 0.00         | 182.02       | 5.82     |\n",
      "| 87  | 4          | 8          | sleep      | 22.22    | 0.00     | 100.00   | 0.00     | 0.00         | 242.69       | 4.09     |\n",
      "| 87  | 5          | 8          | sleep      | 22.22    | 0.00     | 100.00   | 0.00     | 0.00         | 303.37       | 2.37     |\n",
      "| 87  | 6          | 8          | sleep      | 22.22    | 0.00     | 100.00   | 0.00     | 0.00         | 364.04       | 0.64     |\n",
      "| 87  | 7          | 0          | action     | 22.22    | 0.00     | 100.00   | 0.00     | 350.00       | 364.04       | 11.25    |\n",
      "| 87  | 8          | 0          | action     | 22.22    | 0.00     | 100.00   | 0.00     | 700.00       | 364.04       | 9.86     |\n",
      "| 87  | 9          | 6          | action     | 22.22    | 0.00     | 100.00   | 2.00     | 700.00       | 444.94       | 10.22    |\n",
      "| 87  | 10         | 6          | action     | 22.22    | 0.00     | 100.00   | 4.00     | 700.00       | 525.83       | 10.58    |\n",
      "| 87  | 11         | 8          | work       | 22.22    | 5.00     | 95.00    | 9.00     | 700.00       | 660.66       | 10.19    |\n",
      "| 87  | 12         | 8          | work       | 22.22    | 10.00    | 90.00    | 14.00    | 700.00       | 795.49       | 9.80     |\n",
      "| 87  | 13         | 0          | action     | 22.22    | 10.00    | 100.00   | 0.00     | 1050.00      | 795.49       | 8.41     |\n",
      "| 87  | 14         | 8          | work       | 22.22    | 15.00    | 95.00    | 5.00     | 1050.00      | 930.32       | 8.01     |\n",
      "| 87  | 15         | 8          | work       | 22.22    | 20.00    | 90.00    | 10.00    | 1050.00      | 1065.15      | 7.62     |\n",
      "| 87  | 16         | 8          | work       | 22.22    | 25.00    | 85.00    | 15.00    | 1050.00      | 1199.98      | 7.23     |\n",
      "| 87  | 17         | 8          | work       | 22.22    | 30.00    | 80.00    | 20.00    | 1050.00      | 1334.81      | 6.83     |\n",
      "| 87  | 18         | 8          | work       | 22.22    | 35.00    | 75.00    | 25.00    | 1050.00      | 1469.64      | 6.44     |\n",
      "| 87  | 19         | 0          | action     | 22.22    | 35.00    | 95.00    | 5.00     | 1400.00      | 1469.64      | 5.05     |\n",
      "| 87  | 20         | 6          | action     | 22.22    | 25.00    | 100.00   | 7.00     | 1400.00      | 1550.54      | 7.41     |\n",
      "| 87  | 21         | 6          | action     | 22.22    | 15.00    | 100.00   | 9.00     | 1400.00      | 1631.43      | 9.78     |\n",
      "| 87  | 22         | 6          | action     | 22.22    | 5.00     | 100.00   | 11.00    | 1400.00      | 1712.33      | 12.14    |\n",
      "| 87  | 23         | 8          | sleep      | 22.22    | 1.00     | 100.00   | 9.00     | 1400.00      | 1773.01      | 13.22    |\n",
      "| 88  | 0          | 8          | sleep      | 22.20    | 0.00     | 100.00   | 7.00     | 0.00         | 0.00         | 23.65    |\n",
      "| 88  | 1          | 8          | sleep      | 22.20    | 0.00     | 100.00   | 5.00     | 0.00         | 60.62        | 9.27     |\n",
      "| 88  | 2          | 8          | sleep      | 22.20    | 0.00     | 100.00   | 3.00     | 0.00         | 121.24       | 7.55     |\n",
      "| 88  | 3          | 8          | sleep      | 22.20    | 0.00     | 100.00   | 1.00     | 0.00         | 181.86       | 5.82     |\n",
      "| 88  | 4          | 8          | sleep      | 22.20    | 0.00     | 100.00   | 0.00     | 0.00         | 242.48       | 4.09     |\n",
      "| 88  | 5          | 8          | sleep      | 22.20    | 0.00     | 100.00   | 0.00     | 0.00         | 303.10       | 2.36     |\n",
      "| 88  | 6          | 8          | sleep      | 22.20    | 0.00     | 100.00   | 0.00     | 0.00         | 363.72       | 0.64     |\n",
      "| 88  | 7          | 0          | action     | 22.20    | 0.00     | 100.00   | 0.00     | 350.00       | 363.72       | 11.25    |\n",
      "| 88  | 8          | 0          | action     | 22.20    | 0.00     | 100.00   | 0.00     | 700.00       | 363.72       | 9.86     |\n",
      "| 88  | 9          | 6          | action     | 22.20    | 0.00     | 100.00   | 2.00     | 700.00       | 444.55       | 10.22    |\n",
      "| 88  | 10         | 6          | action     | 22.20    | 0.00     | 100.00   | 4.00     | 700.00       | 525.37       | 10.58    |\n",
      "| 88  | 11         | 8          | work       | 22.20    | 5.00     | 95.00    | 9.00     | 700.00       | 660.08       | 10.19    |\n",
      "| 88  | 12         | 8          | work       | 22.20    | 10.00    | 90.00    | 14.00    | 700.00       | 794.80       | 9.80     |\n",
      "| 88  | 13         | 0          | action     | 22.20    | 10.00    | 100.00   | 0.00     | 1050.00      | 794.80       | 8.40     |\n",
      "| 88  | 14         | 8          | work       | 22.20    | 15.00    | 95.00    | 5.00     | 1050.00      | 929.51       | 8.01     |\n",
      "| 88  | 15         | 8          | work       | 22.20    | 20.00    | 90.00    | 10.00    | 1050.00      | 1064.22      | 7.62     |\n",
      "| 88  | 16         | 8          | work       | 22.20    | 25.00    | 85.00    | 15.00    | 1050.00      | 1198.93      | 7.22     |\n",
      "| 88  | 17         | 8          | work       | 22.20    | 30.00    | 80.00    | 20.00    | 1050.00      | 1333.64      | 6.83     |\n",
      "| 88  | 18         | 8          | work       | 22.20    | 35.00    | 75.00    | 25.00    | 1050.00      | 1468.35      | 6.44     |\n",
      "| 88  | 19         | 0          | action     | 22.20    | 35.00    | 95.00    | 5.00     | 1400.00      | 1468.35      | 5.04     |\n",
      "| 88  | 20         | 6          | action     | 22.20    | 25.00    | 100.00   | 7.00     | 1400.00      | 1549.18      | 7.41     |\n",
      "| 88  | 21         | 6          | action     | 22.20    | 15.00    | 100.00   | 9.00     | 1400.00      | 1630.00      | 9.77     |\n",
      "| 88  | 22         | 6          | action     | 22.20    | 5.00     | 100.00   | 11.00    | 1400.00      | 1710.83      | 12.14    |\n",
      "| 88  | 23         | 8          | sleep      | 22.20    | 1.00     | 100.00   | 9.00     | 1400.00      | 1771.45      | 13.21    |\n",
      "| 89  | 0          | 8          | sleep      | 22.18    | 0.00     | 100.00   | 7.00     | 0.00         | 0.00         | 23.64    |\n",
      "| 89  | 1          | 8          | sleep      | 22.18    | 0.00     | 100.00   | 5.00     | 0.00         | 60.57        | 9.27     |\n",
      "| 89  | 2          | 8          | sleep      | 22.18    | 0.00     | 100.00   | 3.00     | 0.00         | 121.13       | 7.55     |\n",
      "| 89  | 3          | 8          | sleep      | 22.18    | 0.00     | 100.00   | 1.00     | 0.00         | 181.70       | 5.82     |\n",
      "| 89  | 4          | 8          | sleep      | 22.18    | 0.00     | 100.00   | 0.00     | 0.00         | 242.27       | 4.09     |\n",
      "| 89  | 5          | 8          | sleep      | 22.18    | 0.00     | 100.00   | 0.00     | 0.00         | 302.83       | 2.36     |\n",
      "| 89  | 6          | 8          | sleep      | 22.18    | 0.00     | 100.00   | 0.00     | 0.00         | 363.40       | 0.64     |\n",
      "| 89  | 7          | 0          | action     | 22.18    | 0.00     | 100.00   | 0.00     | 350.00       | 363.40       | 11.24    |\n",
      "| 89  | 8          | 0          | action     | 22.18    | 0.00     | 100.00   | 0.00     | 700.00       | 363.40       | 9.85     |\n",
      "| 89  | 9          | 6          | action     | 22.18    | 0.00     | 100.00   | 2.00     | 700.00       | 444.16       | 10.22    |\n",
      "| 89  | 10         | 6          | action     | 22.18    | 0.00     | 100.00   | 4.00     | 700.00       | 524.91       | 10.58    |\n",
      "| 89  | 11         | 8          | work       | 22.18    | 5.00     | 95.00    | 9.00     | 700.00       | 659.51       | 10.19    |\n",
      "| 89  | 12         | 8          | work       | 22.18    | 10.00    | 90.00    | 14.00    | 700.00       | 794.10       | 9.79     |\n",
      "| 89  | 13         | 0          | action     | 22.18    | 10.00    | 100.00   | 0.00     | 1050.00      | 794.10       | 8.40     |\n",
      "| 89  | 14         | 8          | work       | 22.18    | 15.00    | 95.00    | 5.00     | 1050.00      | 928.69       | 8.01     |\n",
      "| 89  | 15         | 8          | work       | 22.18    | 20.00    | 90.00    | 10.00    | 1050.00      | 1063.29      | 7.61     |\n",
      "| 89  | 16         | 8          | work       | 22.18    | 25.00    | 85.00    | 15.00    | 1050.00      | 1197.88      | 7.22     |\n",
      "| 89  | 17         | 8          | work       | 22.18    | 30.00    | 80.00    | 20.00    | 1050.00      | 1332.47      | 6.82     |\n",
      "| 89  | 18         | 8          | work       | 22.18    | 35.00    | 75.00    | 25.00    | 1050.00      | 1467.07      | 6.43     |\n",
      "| 89  | 19         | 0          | action     | 22.18    | 35.00    | 95.00    | 5.00     | 1400.00      | 1467.07      | 5.04     |\n",
      "| 89  | 20         | 6          | action     | 22.18    | 25.00    | 100.00   | 7.00     | 1400.00      | 1547.82      | 7.40     |\n",
      "| 89  | 21         | 6          | action     | 22.18    | 15.00    | 100.00   | 9.00     | 1400.00      | 1628.58      | 9.77     |\n",
      "| 89  | 22         | 6          | action     | 22.18    | 5.00     | 100.00   | 11.00    | 1400.00      | 1709.33      | 12.13    |\n",
      "| 89  | 23         | 8          | sleep      | 22.18    | 1.00     | 100.00   | 9.00     | 1400.00      | 1769.90      | 13.20    |\n",
      "| 90  | 0          | 8          | sleep      | 22.16    | 0.00     | 100.00   | 7.00     | 0.00         | 0.00         | 23.64    |\n",
      "| 90  | 1          | 8          | sleep      | 22.16    | 0.00     | 100.00   | 5.00     | 0.00         | 60.51        | 9.27     |\n",
      "| 90  | 2          | 8          | sleep      | 22.16    | 0.00     | 100.00   | 3.00     | 0.00         | 121.03       | 7.54     |\n",
      "| 90  | 3          | 8          | sleep      | 22.16    | 0.00     | 100.00   | 1.00     | 0.00         | 181.54       | 5.82     |\n",
      "| 90  | 4          | 8          | sleep      | 22.16    | 0.00     | 100.00   | 0.00     | 0.00         | 242.06       | 4.09     |\n",
      "| 90  | 5          | 8          | sleep      | 22.16    | 0.00     | 100.00   | 0.00     | 0.00         | 302.57       | 2.36     |\n",
      "| 90  | 6          | 8          | sleep      | 22.16    | 0.00     | 100.00   | 0.00     | 0.00         | 363.08       | 0.63     |\n",
      "| 90  | 7          | 0          | action     | 22.16    | 0.00     | 100.00   | 0.00     | 350.00       | 363.08       | 11.24    |\n",
      "| 90  | 8          | 0          | action     | 22.16    | 0.00     | 100.00   | 0.00     | 700.00       | 363.08       | 9.85     |\n",
      "| 90  | 9          | 6          | action     | 22.16    | 0.00     | 100.00   | 2.00     | 700.00       | 443.77       | 10.22    |\n",
      "| 90  | 10         | 6          | action     | 22.16    | 0.00     | 100.00   | 4.00     | 700.00       | 524.46       | 10.58    |\n",
      "| 90  | 11         | 8          | work       | 22.16    | 5.00     | 95.00    | 9.00     | 700.00       | 658.93       | 10.18    |\n",
      "| 90  | 12         | 8          | work       | 22.16    | 10.00    | 90.00    | 14.00    | 700.00       | 793.41       | 9.79     |\n",
      "| 90  | 13         | 0          | action     | 22.16    | 10.00    | 100.00   | 0.00     | 1050.00      | 793.41       | 8.40     |\n",
      "| 90  | 14         | 8          | work       | 22.16    | 15.00    | 95.00    | 5.00     | 1050.00      | 927.88       | 8.00     |\n",
      "| 90  | 15         | 8          | work       | 22.16    | 20.00    | 90.00    | 10.00    | 1050.00      | 1062.36      | 7.61     |\n",
      "| 90  | 16         | 8          | work       | 22.16    | 25.00    | 85.00    | 15.00    | 1050.00      | 1196.83      | 7.21     |\n",
      "| 90  | 17         | 8          | work       | 22.16    | 30.00    | 80.00    | 20.00    | 1050.00      | 1331.31      | 6.82     |\n",
      "| 90  | 18         | 8          | work       | 22.16    | 35.00    | 75.00    | 25.00    | 1050.00      | 1465.79      | 6.42     |\n",
      "| 90  | 19         | 0          | action     | 22.16    | 35.00    | 95.00    | 5.00     | 1400.00      | 1465.79      | 5.03     |\n",
      "| 90  | 20         | 6          | action     | 22.16    | 25.00    | 100.00   | 7.00     | 1400.00      | 1546.47      | 7.40     |\n",
      "| 90  | 21         | 6          | action     | 22.16    | 15.00    | 100.00   | 9.00     | 1400.00      | 1627.16      | 9.76     |\n",
      "| 90  | 22         | 6          | action     | 22.16    | 5.00     | 100.00   | 11.00    | 1400.00      | 1707.84      | 12.12    |\n",
      "| 90  | 23         | 8          | sleep      | 22.16    | 1.00     | 100.00   | 9.00     | 1400.00      | 1768.36      | 13.20    |\n",
      "| 91  | 0          | 8          | sleep      | 22.14    | 0.00     | 100.00   | 7.00     | 0.00         | 0.00         | 23.63    |\n",
      "| 91  | 1          | 8          | sleep      | 22.14    | 0.00     | 100.00   | 5.00     | 0.00         | 60.46        | 9.27     |\n",
      "| 91  | 2          | 8          | sleep      | 22.14    | 0.00     | 100.00   | 3.00     | 0.00         | 120.92       | 7.54     |\n",
      "| 91  | 3          | 8          | sleep      | 22.14    | 0.00     | 100.00   | 1.00     | 0.00         | 181.38       | 5.82     |\n",
      "| 91  | 4          | 8          | sleep      | 22.14    | 0.00     | 100.00   | 0.00     | 0.00         | 241.85       | 4.09     |\n",
      "| 91  | 5          | 8          | sleep      | 22.14    | 0.00     | 100.00   | 0.00     | 0.00         | 302.31       | 2.36     |\n",
      "| 91  | 6          | 8          | sleep      | 22.14    | 0.00     | 100.00   | 0.00     | 0.00         | 362.77       | 0.63     |\n",
      "| 91  | 7          | 0          | action     | 22.14    | 0.00     | 100.00   | 0.00     | 350.00       | 362.77       | 11.24    |\n",
      "| 91  | 8          | 0          | action     | 22.14    | 0.00     | 100.00   | 0.00     | 700.00       | 362.77       | 9.85     |\n",
      "| 91  | 9          | 6          | action     | 22.14    | 0.00     | 100.00   | 2.00     | 700.00       | 443.38       | 10.21    |\n",
      "| 91  | 10         | 6          | action     | 22.14    | 0.00     | 100.00   | 4.00     | 700.00       | 524.00       | 10.58    |\n",
      "| 91  | 11         | 8          | work       | 22.14    | 5.00     | 95.00    | 9.00     | 700.00       | 658.36       | 10.18    |\n",
      "| 91  | 12         | 8          | work       | 22.14    | 10.00    | 90.00    | 14.00    | 700.00       | 792.72       | 9.79     |\n",
      "| 91  | 13         | 0          | action     | 22.14    | 10.00    | 100.00   | 0.00     | 1050.00      | 792.72       | 8.40     |\n",
      "| 91  | 14         | 8          | work       | 22.14    | 15.00    | 95.00    | 5.00     | 1050.00      | 927.08       | 8.00     |\n",
      "| 91  | 15         | 8          | work       | 22.14    | 20.00    | 90.00    | 10.00    | 1050.00      | 1061.43      | 7.61     |\n",
      "| 91  | 16         | 8          | work       | 22.14    | 25.00    | 85.00    | 15.00    | 1050.00      | 1195.79      | 7.21     |\n",
      "| 91  | 17         | 8          | work       | 22.14    | 30.00    | 80.00    | 20.00    | 1050.00      | 1330.15      | 6.81     |\n",
      "| 91  | 18         | 8          | work       | 22.14    | 35.00    | 75.00    | 25.00    | 1050.00      | 1464.51      | 6.42     |\n",
      "| 91  | 19         | 0          | action     | 22.14    | 35.00    | 95.00    | 5.00     | 1400.00      | 1464.51      | 5.03     |\n",
      "| 91  | 20         | 6          | action     | 22.14    | 25.00    | 100.00   | 7.00     | 1400.00      | 1545.13      | 7.39     |\n",
      "| 91  | 21         | 6          | action     | 22.14    | 15.00    | 100.00   | 9.00     | 1400.00      | 1625.74      | 9.75     |\n",
      "| 91  | 22         | 6          | action     | 22.14    | 5.00     | 100.00   | 11.00    | 1400.00      | 1706.36      | 12.12    |\n",
      "| 91  | 23         | 8          | sleep      | 22.14    | 1.00     | 100.00   | 9.00     | 1400.00      | 1766.82      | 13.19    |\n",
      "| 92  | 0          | 8          | sleep      | 22.12    | 0.00     | 100.00   | 7.00     | 0.00         | 0.00         | 23.63    |\n",
      "| 92  | 1          | 8          | sleep      | 22.12    | 0.00     | 100.00   | 5.00     | 0.00         | 60.41        | 9.27     |\n",
      "| 92  | 2          | 8          | sleep      | 22.12    | 0.00     | 100.00   | 3.00     | 0.00         | 120.82       | 7.54     |\n",
      "| 92  | 3          | 8          | sleep      | 22.12    | 0.00     | 100.00   | 1.00     | 0.00         | 181.23       | 5.82     |\n",
      "| 92  | 4          | 8          | sleep      | 22.12    | 0.00     | 100.00   | 0.00     | 0.00         | 241.64       | 4.09     |\n",
      "| 92  | 5          | 8          | sleep      | 22.12    | 0.00     | 100.00   | 0.00     | 0.00         | 302.05       | 2.36     |\n",
      "| 92  | 6          | 8          | sleep      | 22.12    | 0.00     | 100.00   | 0.00     | 0.00         | 362.45       | 0.63     |\n",
      "| 92  | 7          | 0          | action     | 22.12    | 0.00     | 100.00   | 0.00     | 350.00       | 362.45       | 11.24    |\n",
      "| 92  | 8          | 0          | action     | 22.12    | 0.00     | 100.00   | 0.00     | 700.00       | 362.45       | 9.85     |\n",
      "| 92  | 9          | 6          | action     | 22.12    | 0.00     | 100.00   | 2.00     | 700.00       | 443.00       | 10.21    |\n",
      "| 92  | 10         | 6          | action     | 22.12    | 0.00     | 100.00   | 4.00     | 700.00       | 523.55       | 10.58    |\n",
      "| 92  | 11         | 8          | work       | 22.12    | 5.00     | 95.00    | 9.00     | 700.00       | 657.79       | 10.18    |\n",
      "| 92  | 12         | 8          | work       | 22.12    | 10.00    | 90.00    | 14.00    | 700.00       | 792.03       | 9.78     |\n",
      "| 92  | 13         | 0          | action     | 22.12    | 10.00    | 100.00   | 0.00     | 1050.00      | 792.03       | 8.39     |\n",
      "| 92  | 14         | 8          | work       | 22.12    | 15.00    | 95.00    | 5.00     | 1050.00      | 926.27       | 8.00     |\n",
      "| 92  | 15         | 8          | work       | 22.12    | 20.00    | 90.00    | 10.00    | 1050.00      | 1060.51      | 7.60     |\n",
      "| 92  | 16         | 8          | work       | 22.12    | 25.00    | 85.00    | 15.00    | 1050.00      | 1194.76      | 7.21     |\n",
      "| 92  | 17         | 8          | work       | 22.12    | 30.00    | 80.00    | 20.00    | 1050.00      | 1329.00      | 6.81     |\n",
      "| 92  | 18         | 8          | work       | 22.12    | 35.00    | 75.00    | 25.00    | 1050.00      | 1463.24      | 6.41     |\n",
      "| 92  | 19         | 0          | action     | 22.12    | 35.00    | 95.00    | 5.00     | 1400.00      | 1463.24      | 5.02     |\n",
      "| 92  | 20         | 6          | action     | 22.12    | 25.00    | 100.00   | 7.00     | 1400.00      | 1543.79      | 7.39     |\n",
      "| 92  | 21         | 6          | action     | 22.12    | 15.00    | 100.00   | 9.00     | 1400.00      | 1624.33      | 9.75     |\n",
      "| 92  | 22         | 6          | action     | 22.12    | 5.00     | 100.00   | 11.00    | 1400.00      | 1704.88      | 12.11    |\n",
      "| 92  | 23         | 8          | sleep      | 22.12    | 1.00     | 100.00   | 9.00     | 1400.00      | 1765.29      | 13.18    |\n",
      "| 93  | 0          | 8          | sleep      | 22.10    | 0.00     | 100.00   | 7.00     | 0.00         | 0.00         | 23.62    |\n",
      "| 93  | 1          | 8          | sleep      | 22.10    | 0.00     | 100.00   | 5.00     | 0.00         | 60.36        | 9.27     |\n",
      "| 93  | 2          | 8          | sleep      | 22.10    | 0.00     | 100.00   | 3.00     | 0.00         | 120.71       | 7.54     |\n",
      "| 93  | 3          | 8          | sleep      | 22.10    | 0.00     | 100.00   | 1.00     | 0.00         | 181.07       | 5.81     |\n",
      "| 93  | 4          | 8          | sleep      | 22.10    | 0.00     | 100.00   | 0.00     | 0.00         | 241.43       | 4.09     |\n",
      "| 93  | 5          | 8          | sleep      | 22.10    | 0.00     | 100.00   | 0.00     | 0.00         | 301.78       | 2.36     |\n",
      "| 93  | 6          | 8          | sleep      | 22.10    | 0.00     | 100.00   | 0.00     | 0.00         | 362.14       | 0.63     |\n",
      "| 93  | 7          | 0          | action     | 22.10    | 0.00     | 100.00   | 0.00     | 350.00       | 362.14       | 11.24    |\n",
      "| 93  | 8          | 0          | action     | 22.10    | 0.00     | 100.00   | 0.00     | 700.00       | 362.14       | 9.85     |\n",
      "| 93  | 9          | 6          | action     | 22.10    | 0.00     | 100.00   | 2.00     | 700.00       | 442.62       | 10.21    |\n",
      "| 93  | 10         | 6          | action     | 22.10    | 0.00     | 100.00   | 4.00     | 700.00       | 523.09       | 10.57    |\n",
      "| 93  | 11         | 8          | work       | 22.10    | 5.00     | 95.00    | 9.00     | 700.00       | 657.22       | 10.18    |\n",
      "| 93  | 12         | 8          | work       | 22.10    | 10.00    | 90.00    | 14.00    | 700.00       | 791.34       | 9.78     |\n",
      "| 93  | 13         | 0          | action     | 22.10    | 10.00    | 100.00   | 0.00     | 1050.00      | 791.34       | 8.39     |\n",
      "| 93  | 14         | 8          | work       | 22.10    | 15.00    | 95.00    | 5.00     | 1050.00      | 925.47       | 7.99     |\n",
      "| 93  | 15         | 8          | work       | 22.10    | 20.00    | 90.00    | 10.00    | 1050.00      | 1059.60      | 7.60     |\n",
      "| 93  | 16         | 8          | work       | 22.10    | 25.00    | 85.00    | 15.00    | 1050.00      | 1193.72      | 7.20     |\n",
      "| 93  | 17         | 8          | work       | 22.10    | 30.00    | 80.00    | 20.00    | 1050.00      | 1327.85      | 6.81     |\n",
      "| 93  | 18         | 8          | work       | 22.10    | 35.00    | 75.00    | 25.00    | 1050.00      | 1461.98      | 6.41     |\n",
      "| 93  | 19         | 0          | action     | 22.10    | 35.00    | 95.00    | 5.00     | 1400.00      | 1461.98      | 5.02     |\n",
      "| 93  | 20         | 6          | action     | 22.10    | 25.00    | 100.00   | 7.00     | 1400.00      | 1542.45      | 7.38     |\n",
      "| 93  | 21         | 6          | action     | 22.10    | 15.00    | 100.00   | 9.00     | 1400.00      | 1622.93      | 9.74     |\n",
      "| 93  | 22         | 6          | action     | 22.10    | 5.00     | 100.00   | 11.00    | 1400.00      | 1703.40      | 12.11    |\n",
      "| 93  | 23         | 8          | sleep      | 22.10    | 1.00     | 100.00   | 9.00     | 1400.00      | 1763.76      | 13.18    |\n",
      "| 94  | 0          | 8          | sleep      | 22.08    | 0.00     | 100.00   | 7.00     | 0.00         | 0.00         | 23.62    |\n",
      "| 94  | 1          | 8          | sleep      | 22.08    | 0.00     | 100.00   | 5.00     | 0.00         | 60.30        | 9.27     |\n",
      "| 94  | 2          | 8          | sleep      | 22.08    | 0.00     | 100.00   | 3.00     | 0.00         | 120.61       | 7.54     |\n",
      "| 94  | 3          | 8          | sleep      | 22.08    | 0.00     | 100.00   | 1.00     | 0.00         | 180.91       | 5.81     |\n",
      "| 94  | 4          | 8          | sleep      | 22.08    | 0.00     | 100.00   | 0.00     | 0.00         | 241.22       | 4.09     |\n",
      "| 94  | 5          | 8          | sleep      | 22.08    | 0.00     | 100.00   | 0.00     | 0.00         | 301.52       | 2.36     |\n",
      "| 94  | 6          | 8          | sleep      | 22.08    | 0.00     | 100.00   | 0.00     | 0.00         | 361.83       | 0.63     |\n",
      "| 94  | 7          | 0          | action     | 22.08    | 0.00     | 100.00   | 0.00     | 350.00       | 361.83       | 11.24    |\n",
      "| 94  | 8          | 0          | action     | 22.08    | 0.00     | 100.00   | 0.00     | 700.00       | 361.83       | 9.85     |\n",
      "| 94  | 9          | 6          | action     | 22.08    | 0.00     | 100.00   | 2.00     | 700.00       | 442.23       | 10.21    |\n",
      "| 94  | 10         | 6          | action     | 22.08    | 0.00     | 100.00   | 4.00     | 700.00       | 522.64       | 10.57    |\n",
      "| 94  | 11         | 8          | work       | 22.08    | 5.00     | 95.00    | 9.00     | 700.00       | 656.65       | 10.18    |\n",
      "| 94  | 12         | 8          | work       | 22.08    | 10.00    | 90.00    | 14.00    | 700.00       | 790.66       | 9.78     |\n",
      "| 94  | 13         | 6          | action     | 22.08    | 0.00     | 100.00   | 16.00    | 700.00       | 871.07       | 12.14    |\n",
      "| 94  | 14         | 8          | work       | 22.08    | 5.00     | 95.00    | 21.00    | 700.00       | 1005.08      | 9.74     |\n",
      "| 94  | 15         | 8          | work       | 22.08    | 10.00    | 90.00    | 26.00    | 700.00       | 1139.09      | 7.35     |\n",
      "| 94  | 16         | 8          | work       | 22.08    | 15.00    | 85.00    | 31.00    | 700.00       | 1273.10      | 4.95     |\n",
      "| 94  | 17         | 8          | work       | 22.08    | 20.00    | 80.00    | 36.00    | 700.00       | 1407.11      | 2.44     |\n",
      "| 94  | 18         | 8          | work       | 22.08    | 25.00    | 75.00    | 41.00    | 700.00       | 1541.12      | -0.22    |\n",
      "| 94  | 19         | 0          | action     | 22.08    | 25.00    | 95.00    | 21.00    | 1050.00      | 1541.12      | 8.77     |\n",
      "| 94  | 20         | 0          | action     | 22.08    | 25.00    | 100.00   | 1.00     | 1400.00      | 1541.12      | 7.38     |\n",
      "| 94  | 21         | 6          | action     | 22.08    | 15.00    | 100.00   | 3.00     | 1400.00      | 1621.53      | 9.74     |\n",
      "| 94  | 22         | 6          | action     | 22.08    | 5.00     | 100.00   | 5.00     | 1400.00      | 1701.93      | 12.10    |\n",
      "| 94  | 23         | 8          | sleep      | 22.08    | 1.00     | 100.00   | 3.00     | 1400.00      | 1762.24      | 13.17    |\n",
      "| 95  | 0          | 8          | sleep      | 22.06    | 0.00     | 100.00   | 1.00     | 0.00         | 0.00         | 23.61    |\n",
      "| 95  | 1          | 8          | sleep      | 22.06    | 0.00     | 100.00   | 0.00     | 0.00         | 60.25        | 11.27    |\n",
      "| 95  | 2          | 8          | sleep      | 22.06    | 0.00     | 100.00   | 0.00     | 0.00         | 120.51       | 9.54     |\n",
      "| 95  | 3          | 8          | sleep      | 22.06    | 0.00     | 100.00   | 0.00     | 0.00         | 180.76       | 7.81     |\n",
      "| 95  | 4          | 8          | sleep      | 22.06    | 0.00     | 100.00   | 0.00     | 0.00         | 241.01       | 6.08     |\n",
      "| 95  | 5          | 8          | sleep      | 22.06    | 0.00     | 100.00   | 0.00     | 0.00         | 301.26       | 4.36     |\n",
      "| 95  | 6          | 8          | sleep      | 22.06    | 0.00     | 100.00   | 0.00     | 0.00         | 361.52       | 2.63     |\n",
      "| 95  | 7          | 0          | action     | 22.06    | 0.00     | 100.00   | 0.00     | 350.00       | 361.52       | 11.24    |\n",
      "| 95  | 8          | 0          | action     | 22.06    | 0.00     | 100.00   | 0.00     | 700.00       | 361.52       | 9.85     |\n",
      "| 95  | 9          | 6          | action     | 22.06    | 0.00     | 100.00   | 2.00     | 700.00       | 441.85       | 10.21    |\n",
      "| 95  | 10         | 6          | action     | 22.06    | 0.00     | 100.00   | 4.00     | 700.00       | 522.19       | 10.57    |\n",
      "| 95  | 11         | 8          | work       | 22.06    | 5.00     | 95.00    | 9.00     | 700.00       | 656.09       | 10.17    |\n",
      "| 95  | 12         | 8          | work       | 22.06    | 10.00    | 90.00    | 14.00    | 700.00       | 789.98       | 9.78     |\n",
      "| 95  | 13         | 6          | action     | 22.06    | 0.00     | 100.00   | 16.00    | 700.00       | 870.32       | 12.14    |\n",
      "| 95  | 14         | 8          | work       | 22.06    | 5.00     | 95.00    | 21.00    | 700.00       | 1004.21      | 9.74     |\n",
      "| 95  | 15         | 8          | work       | 22.06    | 10.00    | 90.00    | 26.00    | 700.00       | 1138.11      | 7.34     |\n",
      "| 95  | 16         | 8          | work       | 22.06    | 15.00    | 85.00    | 31.00    | 700.00       | 1272.01      | 4.94     |\n",
      "| 95  | 17         | 8          | work       | 22.06    | 20.00    | 80.00    | 36.00    | 700.00       | 1405.90      | 2.44     |\n",
      "| 95  | 18         | 8          | work       | 22.06    | 25.00    | 75.00    | 41.00    | 700.00       | 1539.80      | -0.22    |\n",
      "| 95  | 19         | 0          | action     | 22.06    | 25.00    | 95.00    | 21.00    | 1050.00      | 1539.80      | 8.76     |\n",
      "| 95  | 20         | 0          | action     | 22.06    | 25.00    | 100.00   | 1.00     | 1400.00      | 1539.80      | 7.37     |\n",
      "| 95  | 21         | 6          | action     | 22.06    | 15.00    | 100.00   | 3.00     | 1400.00      | 1620.13      | 9.73     |\n",
      "| 95  | 22         | 6          | action     | 22.06    | 5.00     | 100.00   | 5.00     | 1400.00      | 1700.47      | 12.09    |\n",
      "| 95  | 23         | 8          | sleep      | 22.06    | 1.00     | 100.00   | 3.00     | 1400.00      | 1760.72      | 13.16    |\n",
      "| 96  | 0          | 8          | sleep      | 22.04    | 0.00     | 100.00   | 1.00     | 0.00         | 0.00         | 23.61    |\n",
      "| 96  | 1          | 8          | sleep      | 22.04    | 0.00     | 100.00   | 0.00     | 0.00         | 60.20        | 11.27    |\n",
      "| 96  | 2          | 8          | sleep      | 22.04    | 0.00     | 100.00   | 0.00     | 0.00         | 120.40       | 9.54     |\n",
      "| 96  | 3          | 8          | sleep      | 22.04    | 0.00     | 100.00   | 0.00     | 0.00         | 180.60       | 7.81     |\n",
      "| 96  | 4          | 8          | sleep      | 22.04    | 0.00     | 100.00   | 0.00     | 0.00         | 240.80       | 6.08     |\n",
      "| 96  | 5          | 8          | sleep      | 22.04    | 0.00     | 100.00   | 0.00     | 0.00         | 301.01       | 4.35     |\n",
      "| 96  | 6          | 8          | sleep      | 22.04    | 0.00     | 100.00   | 0.00     | 0.00         | 361.21       | 2.63     |\n",
      "| 96  | 7          | 0          | action     | 22.04    | 0.00     | 100.00   | 0.00     | 350.00       | 361.21       | 11.24    |\n",
      "| 96  | 8          | 0          | action     | 22.04    | 0.00     | 100.00   | 0.00     | 700.00       | 361.21       | 9.85     |\n",
      "| 96  | 9          | 6          | action     | 22.04    | 0.00     | 100.00   | 2.00     | 700.00       | 441.48       | 10.21    |\n",
      "| 96  | 10         | 6          | action     | 22.04    | 0.00     | 100.00   | 4.00     | 700.00       | 521.74       | 10.57    |\n",
      "| 96  | 11         | 8          | work       | 22.04    | 5.00     | 95.00    | 9.00     | 700.00       | 655.52       | 10.17    |\n",
      "| 96  | 12         | 8          | work       | 22.04    | 10.00    | 90.00    | 14.00    | 700.00       | 789.31       | 9.77     |\n",
      "| 96  | 13         | 6          | action     | 22.04    | 0.00     | 100.00   | 16.00    | 700.00       | 869.57       | 12.13    |\n",
      "| 96  | 14         | 8          | work       | 22.04    | 5.00     | 95.00    | 21.00    | 700.00       | 1003.35      | 9.74     |\n",
      "| 96  | 15         | 8          | work       | 22.04    | 10.00    | 90.00    | 26.00    | 700.00       | 1137.13      | 7.34     |\n",
      "| 96  | 16         | 8          | work       | 22.04    | 15.00    | 85.00    | 31.00    | 700.00       | 1270.91      | 4.94     |\n",
      "| 96  | 17         | 8          | work       | 22.04    | 20.00    | 80.00    | 36.00    | 700.00       | 1404.70      | 2.43     |\n",
      "| 96  | 18         | 8          | work       | 22.04    | 25.00    | 75.00    | 41.00    | 700.00       | 1538.48      | -0.23    |\n",
      "| 96  | 19         | 0          | action     | 22.04    | 25.00    | 95.00    | 21.00    | 1050.00      | 1538.48      | 8.75     |\n",
      "| 96  | 20         | 0          | action     | 22.04    | 25.00    | 100.00   | 1.00     | 1400.00      | 1538.48      | 7.36     |\n",
      "| 96  | 21         | 6          | action     | 22.04    | 15.00    | 100.00   | 3.00     | 1400.00      | 1618.74      | 9.73     |\n",
      "| 96  | 22         | 6          | action     | 22.04    | 5.00     | 100.00   | 5.00     | 1400.00      | 1699.01      | 12.09    |\n",
      "| 96  | 23         | 8          | sleep      | 22.04    | 1.00     | 100.00   | 3.00     | 1400.00      | 1759.21      | 13.16    |\n",
      "| 97  | 0          | 8          | sleep      | 22.02    | 0.00     | 100.00   | 1.00     | 0.00         | 0.00         | 23.60    |\n",
      "| 97  | 1          | 8          | sleep      | 22.02    | 0.00     | 100.00   | 0.00     | 0.00         | 60.15        | 11.27    |\n",
      "| 97  | 2          | 8          | sleep      | 22.02    | 0.00     | 100.00   | 0.00     | 0.00         | 120.30       | 9.54     |\n",
      "| 97  | 3          | 8          | sleep      | 22.02    | 0.00     | 100.00   | 0.00     | 0.00         | 180.45       | 7.81     |\n",
      "| 97  | 4          | 8          | sleep      | 22.02    | 0.00     | 100.00   | 0.00     | 0.00         | 240.60       | 6.08     |\n",
      "| 97  | 5          | 8          | sleep      | 22.02    | 0.00     | 100.00   | 0.00     | 0.00         | 300.75       | 4.35     |\n",
      "| 97  | 6          | 8          | sleep      | 22.02    | 0.00     | 100.00   | 0.00     | 0.00         | 360.90       | 2.62     |\n",
      "| 97  | 7          | 0          | action     | 22.02    | 0.00     | 100.00   | 0.00     | 350.00       | 360.90       | 11.23    |\n",
      "| 97  | 8          | 0          | action     | 22.02    | 0.00     | 100.00   | 0.00     | 700.00       | 360.90       | 9.85     |\n",
      "| 97  | 9          | 6          | action     | 22.02    | 0.00     | 100.00   | 2.00     | 700.00       | 441.10       | 10.21    |\n",
      "| 97  | 10         | 6          | action     | 22.02    | 0.00     | 100.00   | 4.00     | 700.00       | 521.30       | 10.57    |\n",
      "| 97  | 11         | 8          | work       | 22.02    | 5.00     | 95.00    | 9.00     | 700.00       | 654.96       | 10.17    |\n",
      "| 97  | 12         | 8          | work       | 22.02    | 10.00    | 90.00    | 14.00    | 700.00       | 788.63       | 9.77     |\n",
      "| 97  | 13         | 6          | action     | 22.02    | 0.00     | 100.00   | 16.00    | 700.00       | 868.83       | 12.13    |\n",
      "| 97  | 14         | 8          | work       | 22.02    | 5.00     | 95.00    | 21.00    | 700.00       | 1002.50      | 9.73     |\n",
      "| 97  | 15         | 8          | work       | 22.02    | 10.00    | 90.00    | 26.00    | 700.00       | 1136.16      | 7.33     |\n",
      "| 97  | 16         | 8          | work       | 22.02    | 15.00    | 85.00    | 31.00    | 700.00       | 1269.83      | 4.93     |\n",
      "| 97  | 17         | 8          | work       | 22.02    | 20.00    | 80.00    | 36.00    | 700.00       | 1403.49      | 2.43     |\n",
      "| 97  | 18         | 8          | work       | 22.02    | 25.00    | 75.00    | 41.00    | 700.00       | 1537.16      | -0.23    |\n",
      "| 97  | 19         | 0          | action     | 22.02    | 25.00    | 95.00    | 21.00    | 1050.00      | 1537.16      | 8.75     |\n",
      "| 97  | 20         | 0          | action     | 22.02    | 25.00    | 100.00   | 1.00     | 1400.00      | 1537.16      | 7.36     |\n",
      "| 97  | 21         | 6          | action     | 22.02    | 15.00    | 100.00   | 3.00     | 1400.00      | 1617.36      | 9.72     |\n",
      "| 97  | 22         | 6          | action     | 22.02    | 5.00     | 100.00   | 5.00     | 1400.00      | 1697.56      | 12.08    |\n",
      "| 97  | 23         | 8          | sleep      | 22.02    | 1.00     | 100.00   | 3.00     | 1400.00      | 1757.71      | 13.15    |\n",
      "| 98  | 0          | 8          | sleep      | 22.01    | 0.00     | 100.00   | 1.00     | 0.00         | 0.00         | 23.60    |\n",
      "| 98  | 1          | 8          | sleep      | 22.01    | 0.00     | 100.00   | 0.00     | 0.00         | 60.10        | 11.27    |\n",
      "| 98  | 2          | 8          | sleep      | 22.01    | 0.00     | 100.00   | 0.00     | 0.00         | 120.20       | 9.54     |\n",
      "| 98  | 3          | 8          | sleep      | 22.01    | 0.00     | 100.00   | 0.00     | 0.00         | 180.30       | 7.81     |\n",
      "| 98  | 4          | 8          | sleep      | 22.01    | 0.00     | 100.00   | 0.00     | 0.00         | 240.39       | 6.08     |\n",
      "| 98  | 5          | 8          | sleep      | 22.01    | 0.00     | 100.00   | 0.00     | 0.00         | 300.49       | 4.35     |\n",
      "| 98  | 6          | 8          | sleep      | 22.01    | 0.00     | 100.00   | 0.00     | 0.00         | 360.59       | 2.62     |\n",
      "| 98  | 7          | 0          | action     | 22.01    | 0.00     | 100.00   | 0.00     | 350.00       | 360.59       | 11.23    |\n",
      "| 98  | 8          | 0          | action     | 22.01    | 0.00     | 100.00   | 0.00     | 700.00       | 360.59       | 9.84     |\n",
      "| 98  | 9          | 6          | action     | 22.01    | 0.00     | 100.00   | 2.00     | 700.00       | 440.72       | 10.20    |\n",
      "| 98  | 10         | 6          | action     | 22.01    | 0.00     | 100.00   | 4.00     | 700.00       | 520.85       | 10.57    |\n",
      "| 98  | 11         | 8          | work       | 22.01    | 5.00     | 95.00    | 9.00     | 700.00       | 654.41       | 10.17    |\n",
      "| 98  | 12         | 8          | work       | 22.01    | 10.00    | 90.00    | 14.00    | 700.00       | 787.96       | 9.77     |\n",
      "| 98  | 13         | 6          | action     | 22.01    | 0.00     | 100.00   | 16.00    | 700.00       | 868.09       | 12.13    |\n",
      "| 98  | 14         | 8          | work       | 22.01    | 5.00     | 95.00    | 21.00    | 700.00       | 1001.64      | 9.73     |\n",
      "| 98  | 15         | 8          | work       | 22.01    | 10.00    | 90.00    | 26.00    | 700.00       | 1135.19      | 7.33     |\n",
      "| 98  | 16         | 8          | work       | 22.01    | 15.00    | 85.00    | 31.00    | 700.00       | 1268.75      | 4.93     |\n",
      "| 98  | 17         | 8          | work       | 22.01    | 20.00    | 80.00    | 36.00    | 700.00       | 1402.30      | 2.42     |\n",
      "| 98  | 18         | 8          | work       | 22.01    | 25.00    | 75.00    | 41.00    | 700.00       | 1535.85      | -0.24    |\n",
      "| 98  | 19         | 0          | action     | 22.01    | 25.00    | 95.00    | 21.00    | 1050.00      | 1535.85      | 8.74     |\n",
      "| 98  | 20         | 0          | action     | 22.01    | 25.00    | 100.00   | 1.00     | 1400.00      | 1535.85      | 7.35     |\n",
      "| 98  | 21         | 6          | action     | 22.01    | 15.00    | 100.00   | 3.00     | 1400.00      | 1615.98      | 9.71     |\n",
      "| 98  | 22         | 6          | action     | 22.01    | 5.00     | 100.00   | 5.00     | 1400.00      | 1696.11      | 12.08    |\n",
      "| 98  | 23         | 8          | sleep      | 22.01    | 1.00     | 100.00   | 3.00     | 1400.00      | 1756.21      | 13.15    |\n",
      "| 99  | 0          | 8          | sleep      | 21.99    | 0.00     | 100.00   | 1.00     | 0.00         | 0.00         | 23.59    |\n",
      "| 99  | 1          | 8          | sleep      | 21.99    | 0.00     | 100.00   | 0.00     | 0.00         | 60.05        | 11.27    |\n",
      "| 99  | 2          | 8          | sleep      | 21.99    | 0.00     | 100.00   | 0.00     | 0.00         | 120.09       | 9.54     |\n",
      "| 99  | 3          | 8          | sleep      | 21.99    | 0.00     | 100.00   | 0.00     | 0.00         | 180.14       | 7.81     |\n",
      "| 99  | 4          | 8          | sleep      | 21.99    | 0.00     | 100.00   | 0.00     | 0.00         | 240.19       | 6.08     |\n",
      "| 99  | 5          | 8          | sleep      | 21.99    | 0.00     | 100.00   | 0.00     | 0.00         | 300.24       | 4.35     |\n",
      "| 99  | 6          | 8          | sleep      | 21.99    | 0.00     | 100.00   | 0.00     | 0.00         | 360.28       | 2.62     |\n",
      "| 99  | 7          | 0          | action     | 21.99    | 0.00     | 100.00   | 0.00     | 350.00       | 360.28       | 11.23    |\n",
      "| 99  | 8          | 0          | action     | 21.99    | 0.00     | 100.00   | 0.00     | 700.00       | 360.28       | 9.84     |\n",
      "| 99  | 9          | 6          | action     | 21.99    | 0.00     | 100.00   | 2.00     | 700.00       | 440.35       | 10.20    |\n",
      "| 99  | 10         | 6          | action     | 21.99    | 0.00     | 100.00   | 4.00     | 700.00       | 520.41       | 10.56    |\n",
      "| 99  | 11         | 8          | work       | 21.99    | 5.00     | 95.00    | 9.00     | 700.00       | 653.85       | 10.16    |\n",
      "| 99  | 12         | 8          | work       | 21.99    | 10.00    | 90.00    | 14.00    | 700.00       | 787.29       | 9.76     |\n",
      "| 99  | 13         | 6          | action     | 21.99    | 0.00     | 100.00   | 16.00    | 700.00       | 867.35       | 12.12    |\n",
      "| 99  | 14         | 8          | work       | 21.99    | 5.00     | 95.00    | 21.00    | 700.00       | 1000.79      | 9.73     |\n",
      "| 99  | 15         | 8          | work       | 21.99    | 10.00    | 90.00    | 26.00    | 700.00       | 1134.23      | 7.33     |\n",
      "| 99  | 16         | 8          | work       | 21.99    | 15.00    | 85.00    | 31.00    | 700.00       | 1267.67      | 4.92     |\n",
      "| 99  | 17         | 8          | work       | 21.99    | 20.00    | 80.00    | 36.00    | 700.00       | 1401.11      | 2.42     |\n",
      "| 99  | 18         | 8          | work       | 21.99    | 25.00    | 75.00    | 41.00    | 700.00       | 1534.54      | -0.24    |\n",
      "| 99  | 19         | 0          | action     | 21.99    | 25.00    | 95.00    | 21.00    | 1050.00      | 1534.54      | 8.74     |\n",
      "| 99  | 20         | 0          | action     | 21.99    | 25.00    | 100.00   | 1.00     | 1400.00      | 1534.54      | 7.35     |\n",
      "| 99  | 21         | 6          | action     | 21.99    | 15.00    | 100.00   | 3.00     | 1400.00      | 1614.61      | 9.71     |\n",
      "| 99  | 22         | 6          | action     | 21.99    | 5.00     | 100.00   | 5.00     | 1400.00      | 1694.67      | 12.07    |\n",
      "| 99  | 23         | 8          | sleep      | 21.99    | 1.00     | 100.00   | 3.00     | 1400.00      | 1754.72      | 13.14    |\n",
      "| 100 | 0          | 8          | sleep      | 21.97    | 0.00     | 100.00   | 1.00     | 0.00         | 0.00         | 23.59    |\n",
      "| 100 | 1          | 8          | sleep      | 21.97    | 0.00     | 100.00   | 0.00     | 0.00         | 60.00        | 11.27    |\n",
      "| 100 | 2          | 8          | sleep      | 21.97    | 0.00     | 100.00   | 0.00     | 0.00         | 119.99       | 9.54     |\n",
      "| 100 | 3          | 8          | sleep      | 21.97    | 0.00     | 100.00   | 0.00     | 0.00         | 179.99       | 7.81     |\n",
      "| 100 | 4          | 8          | sleep      | 21.97    | 0.00     | 100.00   | 0.00     | 0.00         | 239.99       | 6.08     |\n",
      "| 100 | 5          | 8          | sleep      | 21.97    | 0.00     | 100.00   | 0.00     | 0.00         | 299.98       | 4.35     |\n",
      "| 100 | 6          | 8          | sleep      | 21.97    | 0.00     | 100.00   | 0.00     | 0.00         | 359.98       | 2.62     |\n",
      "| 100 | 7          | 0          | action     | 21.97    | 0.00     | 100.00   | 0.00     | 350.00       | 359.98       | 11.23    |\n",
      "| 100 | 8          | 0          | action     | 21.97    | 0.00     | 100.00   | 0.00     | 700.00       | 359.98       | 9.84     |\n",
      "| 100 | 9          | 6          | action     | 21.97    | 0.00     | 100.00   | 2.00     | 700.00       | 439.97       | 10.20    |\n",
      "| 100 | 10         | 6          | action     | 21.97    | 0.00     | 100.00   | 4.00     | 700.00       | 519.97       | 10.56    |\n",
      "| 100 | 11         | 8          | work       | 21.97    | 5.00     | 95.00    | 9.00     | 700.00       | 653.29       | 10.16    |\n",
      "| 100 | 12         | 8          | work       | 21.97    | 10.00    | 90.00    | 14.00    | 700.00       | 786.62       | 9.76     |\n",
      "| 100 | 13         | 6          | action     | 21.97    | 0.00     | 100.00   | 16.00    | 700.00       | 866.62       | 12.12    |\n",
      "| 100 | 14         | 8          | work       | 21.97    | 5.00     | 95.00    | 21.00    | 700.00       | 999.94       | 9.72     |\n",
      "| 100 | 15         | 8          | work       | 21.97    | 10.00    | 90.00    | 26.00    | 700.00       | 1133.27      | 7.32     |\n",
      "| 100 | 16         | 8          | work       | 21.97    | 15.00    | 85.00    | 31.00    | 700.00       | 1266.59      | 4.92     |\n",
      "| 100 | 17         | 8          | work       | 21.97    | 20.00    | 80.00    | 36.00    | 700.00       | 1399.92      | 2.41     |\n",
      "| 100 | 18         | 8          | work       | 21.97    | 25.00    | 75.00    | 41.00    | 700.00       | 1533.24      | -0.25    |\n",
      "| 100 | 19         | 0          | action     | 21.97    | 25.00    | 95.00    | 21.00    | 1050.00      | 1533.24      | 8.73     |\n",
      "| 100 | 20         | 0          | action     | 21.97    | 25.00    | 100.00   | 1.00     | 1400.00      | 1533.24      | 7.34     |\n",
      "| 100 | 21         | 6          | action     | 21.97    | 15.00    | 100.00   | 3.00     | 1400.00      | 1613.24      | 9.70     |\n",
      "| 100 | 22         | 6          | action     | 21.97    | 5.00     | 100.00   | 5.00     | 1400.00      | 1693.23      | 12.06    |\n",
      "| 100 | 23         | 8          | sleep      | 21.97    | 1.00     | 100.00   | 3.00     | 1400.00      | 1753.23      | 13.13    |\n",
      "| 101 | 0          | 8          | sleep      | 21.95    | 0.00     | 100.00   | 1.00     | 0.00         | 0.00         | 123.58   |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------\n",
      "Mean evaluation reward: 9.185252857350893\n",
      "Std deviation: 4.874386055035989\n"
     ]
    }
   ],
   "source": [
    "from environment3 import LifeStyleEnv\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from sb3_contrib.common.maskable.utils import get_action_masks\n",
    "import numpy as np\n",
    "from MaskableA2C import MaskableA2C\n",
    "\n",
    "def make_env(is_eval: bool = False):\n",
    "    env = LifeStyleEnv(days_per_episode = 365)\n",
    "    env = Monitor(env)\n",
    "    if not is_eval:\n",
    "        check_env(env, warn=True)\n",
    "    return env\n",
    "\n",
    "model = MaskableA2C.load(\"logs/a2c/a2c_best_model/best_model.zip\")\n",
    "\n",
    "eval_env = make_env(is_eval=True)\n",
    "\n",
    "print(\"Starting Final Evaluation...\")\n",
    "print(\"-------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "print(f\"| {'Day':<3} | {'Timeslot':<10} | {'Action':<10} | {'Event':<10} | {'BMI':<8} | {'Stress':<8} | {'Energy':<8} | {'Hunger':<8} | {'Cal. Intake':<12} | {'Cal. Burned':<12} | {'Reward':<8} |\")\n",
    "print(\"-------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "episode_rewards = []\n",
    "for episode in range(1):  \n",
    "    obs, info = eval_env.reset()\n",
    "    unwrapped_env = eval_env.unwrapped\n",
    "    \n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        action_masks = get_action_masks(unwrapped_env)\n",
    "        action, _ = model.predict(obs, deterministic=True, action_masks=action_masks)\n",
    "        obs, reward, terminated, truncated, info = eval_env.step(action)\n",
    "        done = terminated or truncated\n",
    "        total_reward += reward\n",
    "        \n",
    "        timeslot_applied = unwrapped_env.state['current_timeslot'] - 1\n",
    "        timeslot_applied = max(timeslot_applied, 0)  \n",
    "        event_applied = unwrapped_env.daily_schedule[timeslot_applied]\n",
    "\n",
    "        print(\n",
    "            f\"| {unwrapped_env.state['day_of_episode']:<3} | \"\n",
    "            f\"{unwrapped_env.state['current_timeslot']:<10} | \"\n",
    "            f\"{action:<10} | \"\n",
    "            f\"{event_applied:<10} | \"\n",
    "            f\"{unwrapped_env.state['current_bmi']:<8.2f} | \"\n",
    "            f\"{unwrapped_env.state['current_stress_level']:<8.2f} | \"\n",
    "            f\"{unwrapped_env.state['current_energy_level']:<8.2f} | \"\n",
    "            f\"{unwrapped_env.state['current_hunger_level']:<8.2f} | \"\n",
    "            f\"{unwrapped_env.state['daily_calories_intake']:<12.2f} | \"\n",
    "            f\"{unwrapped_env.state['daily_calories_burned']:<12.2f} | \"\n",
    "            f\"{reward:<8.2f} |\"\n",
    "        )\n",
    "        \n",
    "        episode_rewards.append(reward)\n",
    "\n",
    "print(\"-------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "print(\"Mean evaluation reward:\", np.mean(episode_rewards))\n",
    "print(\"Std deviation:\", np.std(episode_rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ebc2339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of the NPZ file: ['timesteps', 'results', 'ep_lengths']\n",
      "Mean reward for LR = 0.001: -9025.50\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "file_path = 'logs/a2c/a2c_results/evaluations.npz'\n",
    "\n",
    "try:\n",
    "    data = np.load(file_path)\n",
    "    print(f\"Contents of the NPZ file: {data.files}\")\n",
    "    timesteps = data['timesteps']\n",
    "    results = data['results']\n",
    "\n",
    "    mean_reward = np.mean(results)\n",
    "    print(f\"Mean reward for {label}: {mean_reward:.2f}\")\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(timesteps, results)\n",
    "\n",
    "    plt.title('A2C Performance (Learning Rate = 0.0005, vf coef = 0.5)')\n",
    "    plt.xlabel('Total Timesteps')\n",
    "    plt.ylabel('Rewards')\n",
    "    plt.grid(True)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{file_path}' was not found.\")\n",
    "except KeyError as e:\n",
    "    print(f\"Error: The key {e} was not found in the NPZ file. Check the contents using data.files.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528620d0",
   "metadata": {},
   "source": [
    "tensorboard --logdir logs/a2c/a2c_tensorboard"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.18)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
